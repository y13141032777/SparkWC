2019-06-11 09:21:31,649  INFO [org.apache.spark.SparkContext] - Running Spark version 2.2.0
2019-06-11 09:21:32,161  INFO [org.apache.spark.SparkContext] - Submitted application: trans
2019-06-11 09:21:32,185  INFO [org.apache.spark.SecurityManager] - Changing view acls to: 于羊,ÓÚÑò
2019-06-11 09:21:32,186  INFO [org.apache.spark.SecurityManager] - Changing modify acls to: 于羊,ÓÚÑò
2019-06-11 09:21:32,187  INFO [org.apache.spark.SecurityManager] - Changing view acls groups to: 
2019-06-11 09:21:32,187  INFO [org.apache.spark.SecurityManager] - Changing modify acls groups to: 
2019-06-11 09:21:32,188  INFO [org.apache.spark.SecurityManager] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(于羊, ÓÚÑò); groups with view permissions: Set(); users  with modify permissions: Set(于羊, ÓÚÑò); groups with modify permissions: Set()
2019-06-11 09:21:32,914  INFO [org.apache.spark.util.Utils] - Successfully started service 'sparkDriver' on port 63501.
2019-06-11 09:21:32,930  INFO [org.apache.spark.SparkEnv] - Registering MapOutputTracker
2019-06-11 09:21:32,943  INFO [org.apache.spark.SparkEnv] - Registering BlockManagerMaster
2019-06-11 09:21:32,947  INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-06-11 09:21:32,947  INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - BlockManagerMasterEndpoint up
2019-06-11 09:21:32,981  INFO [org.apache.spark.storage.DiskBlockManager] - Created local directory at C:\Users\于羊\AppData\Local\Temp\blockmgr-df510867-e106-4dad-b6b1-96aaf41c0281
2019-06-11 09:21:32,996  INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore started with capacity 1989.6 MB
2019-06-11 09:21:33,035  INFO [org.apache.spark.SparkEnv] - Registering OutputCommitCoordinator
2019-06-11 09:21:33,103  INFO [org.spark_project.jetty.util.log] - Logging initialized @2319ms
2019-06-11 09:21:33,159  INFO [org.spark_project.jetty.server.Server] - jetty-9.3.z-SNAPSHOT
2019-06-11 09:21:33,172  INFO [org.spark_project.jetty.server.Server] - Started @2390ms
2019-06-11 09:21:33,188  INFO [org.spark_project.jetty.server.AbstractConnector] - Started ServerConnector@58e6d4b8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-06-11 09:21:33,191  INFO [org.apache.spark.util.Utils] - Successfully started service 'SparkUI' on port 4040.
2019-06-11 09:21:33,210  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3383649e{/jobs,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,211  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1cd201a8{/jobs/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,211  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1992eaf4{/jobs/job,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,212  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3f28bd56{/jobs/job/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,213  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@19fe4644{/stages,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,213  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5be067de{/stages/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,213  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@18245eb0{/stages/stage,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,214  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@72a85671{/stages/stage/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,215  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@18f20260{/stages/pool,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,215  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,216  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3a94964{/storage,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,216  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6d0b5baf{/storage/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,216  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2a3591c5{/storage/rdd,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,217  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@346a361{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,217  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@1643d68f{/environment,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,218  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@2e029d61{/environment/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,218  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@4052274f{/executors,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,219  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@297ea53a{/executors/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,219  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5bf22f18{/executors/threadDump,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,219  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@7a7471ce{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,225  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@62e70ea3{/static,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,226  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@29ef6856{/,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,227  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/api,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,227  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@eb6449b{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,228  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@180e6ac4{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,229  INFO [org.apache.spark.ui.SparkUI] - Bound SparkUI to 0.0.0.0, and started at http://192.168.91.1:4040
2019-06-11 09:21:33,304  INFO [org.apache.spark.executor.Executor] - Starting executor ID driver on host localhost
2019-06-11 09:21:33,329  INFO [org.apache.spark.util.Utils] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63518.
2019-06-11 09:21:33,329  INFO [org.apache.spark.network.netty.NettyBlockTransferService] - Server created on 192.168.91.1:63518
2019-06-11 09:21:33,331  INFO [org.apache.spark.storage.BlockManager] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-06-11 09:21:33,333  INFO [org.apache.spark.storage.BlockManagerMaster] - Registering BlockManager BlockManagerId(driver, 192.168.91.1, 63518, None)
2019-06-11 09:21:33,336  INFO [org.apache.spark.storage.BlockManagerMasterEndpoint] - Registering block manager 192.168.91.1:63518 with 1989.6 MB RAM, BlockManagerId(driver, 192.168.91.1, 63518, None)
2019-06-11 09:21:33,338  INFO [org.apache.spark.storage.BlockManagerMaster] - Registered BlockManager BlockManagerId(driver, 192.168.91.1, 63518, None)
2019-06-11 09:21:33,338  INFO [org.apache.spark.storage.BlockManager] - Initialized BlockManager: BlockManagerId(driver, 192.168.91.1, 63518, None)
2019-06-11 09:21:33,500  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@9257031{/metrics/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,819  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - Starting 1 receivers
2019-06-11 09:21:33,821  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - ReceiverTracker started
2019-06-11 09:21:33,828  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Slide time = 5000 ms
2019-06-11 09:21:33,829  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Storage level = Serialized 1x Replicated
2019-06-11 09:21:33,829  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Checkpoint interval = null
2019-06-11 09:21:33,830  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Remember interval = 5000 ms
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Initialized and validated org.apache.spark.streaming.dstream.SocketInputDStream@1cf575d
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.MappedDStream] - Slide time = 5000 ms
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.MappedDStream] - Storage level = Serialized 1x Replicated
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.MappedDStream] - Checkpoint interval = null
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.MappedDStream] - Remember interval = 5000 ms
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.MappedDStream] - Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@2ba4013c
2019-06-11 09:21:33,831  INFO [org.apache.spark.streaming.dstream.TransformedDStream] - Slide time = 5000 ms
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.TransformedDStream] - Storage level = Serialized 1x Replicated
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.TransformedDStream] - Checkpoint interval = null
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.TransformedDStream] - Remember interval = 5000 ms
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.TransformedDStream] - Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@4a90d051
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.ForEachDStream] - Slide time = 5000 ms
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.ForEachDStream] - Storage level = Serialized 1x Replicated
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.ForEachDStream] - Checkpoint interval = null
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.ForEachDStream] - Remember interval = 5000 ms
2019-06-11 09:21:33,832  INFO [org.apache.spark.streaming.dstream.ForEachDStream] - Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@61529349
2019-06-11 09:21:33,883  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - Receiver 0 started
2019-06-11 09:21:33,888  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 0 (start at Transform.scala:37) with 1 output partitions
2019-06-11 09:21:33,889  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 0 (start at Transform.scala:37)
2019-06-11 09:21:33,889  INFO [org.apache.spark.streaming.util.RecurringTimer] - Started timer for JobGenerator at time 1560216095000
2019-06-11 09:21:33,889  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List()
2019-06-11 09:21:33,890  INFO [org.apache.spark.streaming.scheduler.JobGenerator] - Started JobGenerator at 1560216095000 ms
2019-06-11 09:21:33,890  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:33,890  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Started JobScheduler
2019-06-11 09:21:33,894  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@5cd61783{/streaming,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,895  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@57aa341b{/streaming/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,895  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@769d513{/streaming/batch,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,896  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@588cd519{/streaming/batch/json,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,897  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Started o.s.j.s.ServletContextHandler@6be25526{/static/streaming,null,AVAILABLE,@Spark}
2019-06-11 09:21:33,897  INFO [org.apache.spark.streaming.StreamingContext] - StreamingContext started
2019-06-11 09:21:33,898  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 0 (Receiver 0 ParallelCollectionRDD[1] at makeRDD at ReceiverTracker.scala:620), which has no missing parents
2019-06-11 09:21:33,996  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0 stored as values in memory (estimated size 50.7 KB, free 1989.6 MB)
2019-06-11 09:21:34,062  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.9 KB, free 1989.5 MB)
2019-06-11 09:21:34,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_0_piece0 in memory on 192.168.91.1:63518 (size: 16.9 KB, free: 1989.6 MB)
2019-06-11 09:21:34,068  INFO [org.apache.spark.SparkContext] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:34,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 0 (Receiver 0 ParallelCollectionRDD[1] at makeRDD at ReceiverTracker.scala:620) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:34,087  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 0.0 with 1 tasks
2019-06-11 09:21:34,122  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5413 bytes)
2019-06-11 09:21:34,133  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 0.0 (TID 0)
2019-06-11 09:21:34,188  INFO [org.apache.spark.streaming.util.RecurringTimer] - Started timer for BlockGenerator at time 1560216094200
2019-06-11 09:21:34,189  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Started BlockGenerator
2019-06-11 09:21:34,189  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Started block pushing thread
2019-06-11 09:21:34,195  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - Registered receiver for stream 0 from 192.168.91.1:63501
2019-06-11 09:21:34,195  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Starting receiver 0
2019-06-11 09:21:34,196  INFO [org.apache.spark.streaming.dstream.SocketReceiver] - Connecting to hadoop01:8989
2019-06-11 09:21:34,200  INFO [org.apache.spark.streaming.dstream.SocketReceiver] - Connected to hadoop01:8989
2019-06-11 09:21:34,201  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Called receiver 0 onStart
2019-06-11 09:21:34,201  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Waiting for receiver to be stopped
2019-06-11 09:21:35,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216095000 ms
2019-06-11 09:21:35,059  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216095000 ms.0 from job set of time 1560216095000 ms
2019-06-11 09:21:35,090  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:21:35,093  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 3 (map at Transform.scala:20)
2019-06-11 09:21:35,093  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 1 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:35,093  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 3 (print at Transform.scala:36)
2019-06-11 09:21:35,093  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 2)
2019-06-11 09:21:35,094  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1)
2019-06-11 09:21:35,095  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:21:35,099  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:35,103  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1308.0 B, free 1989.5 MB)
2019-06-11 09:21:35,104  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_1_piece0 in memory on 192.168.91.1:63518 (size: 1308.0 B, free: 1989.6 MB)
2019-06-11 09:21:35,104  INFO [org.apache.spark.SparkContext] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:35,107  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:21:35,107  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1.0 with 2 tasks
2019-06-11 09:21:35,110  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:35,111  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1.0 (TID 1)
2019-06-11 09:21:35,156  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1.0 (TID 1). 896 bytes result sent to driver
2019-06-11 09:21:35,157  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:35,158  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1.0 (TID 2)
2019-06-11 09:21:35,164  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on localhost (executor driver) (1/2)
2019-06-11 09:21:35,176  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1.0 (TID 2). 853 bytes result sent to driver
2019-06-11 09:21:35,177  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1.0 (TID 2) in 20 ms on localhost (executor driver) (2/2)
2019-06-11 09:21:35,178  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-06-11 09:21:35,179  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1 (parallelize at Transform.scala:16) finished in 0.071 s
2019-06-11 09:21:35,179  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:21:35,179  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:21:35,180  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 3)
2019-06-11 09:21:35,180  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:21:35,183  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 3 (MapPartitionsRDD[8] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:35,186  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:35,189  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:35,190  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_2_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:35,191  INFO [org.apache.spark.SparkContext] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:35,191  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:35,191  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 3.0 with 1 tasks
2019-06-11 09:21:35,194  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:35,194  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 3.0 (TID 3)
2019-06-11 09:21:35,206  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:35,207  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 4 ms
2019-06-11 09:21:35,210  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:35,210  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:21:35,232  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 3.0 (TID 3). 1095 bytes result sent to driver
2019-06-11 09:21:35,234  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 3.0 (TID 3) in 42 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:35,234  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-06-11 09:21:35,234  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 3 (print at Transform.scala:36) finished in 0.042 s
2019-06-11 09:21:35,239  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 1 finished: print at Transform.scala:36, took 0.149756 s
2019-06-11 09:21:35,246  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:35,248  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 1 is 160 bytes
2019-06-11 09:21:35,249  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 0 is 83 bytes
2019-06-11 09:21:35,250  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 2 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:35,250  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 6 (print at Transform.scala:36)
2019-06-11 09:21:35,250  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 4)
2019-06-11 09:21:35,250  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:35,250  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 6 (MapPartitionsRDD[8] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:35,253  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:35,255  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:35,255  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_3_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:35,256  INFO [org.apache.spark.SparkContext] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:35,257  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[8] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:21:35,257  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 6.0 with 1 tasks
2019-06-11 09:21:35,258  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 6.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:35,258  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 6.0 (TID 4)
2019-06-11 09:21:35,261  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:35,261  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:35,261  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:35,261  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:35,264  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 6.0 (TID 4). 1009 bytes result sent to driver
2019-06-11 09:21:35,266  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 6.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:35,266  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2019-06-11 09:21:35,267  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 6 (print at Transform.scala:36) finished in 0.010 s
2019-06-11 09:21:35,269  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 2 finished: print at Transform.scala:36, took 0.021998 s
2019-06-11 09:21:35,274  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216095000 ms.0 from job set of time 1560216095000 ms
2019-06-11 09:21:35,276  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.273 s for time 1560216095000 ms (execution: 0.215 s)
2019-06-11 09:21:35,281  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 
2019-06-11 09:21:35,285  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 
2019-06-11 09:21:40,015  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216100000 ms
2019-06-11 09:21:40,016  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216100000 ms.0 from job set of time 1560216100000 ms
2019-06-11 09:21:40,020  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:40,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 10 (map at Transform.scala:20)
2019-06-11 09:21:40,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:21:40,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 3 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:40,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 9 (print at Transform.scala:36)
2019-06-11 09:21:40,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 7, ShuffleMapStage 8)
2019-06-11 09:21:40,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 8)
2019-06-11 09:21:40,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 8 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:21:40,023  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:40,025  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:21:40,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_4_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:21:40,027  INFO [org.apache.spark.SparkContext] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 8 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:21:40,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 8.0 with 2 tasks
2019-06-11 09:21:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 8.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:40,028  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 8.0 (TID 5)
2019-06-11 09:21:40,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 8.0 (TID 5). 853 bytes result sent to driver
2019-06-11 09:21:40,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 8.0 (TID 6, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:40,042  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 8.0 (TID 6)
2019-06-11 09:21:40,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 8.0 (TID 5) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:21:40,056  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 8.0 (TID 6). 853 bytes result sent to driver
2019-06-11 09:21:40,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 8.0 (TID 6) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:21:40,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2019-06-11 09:21:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 8 (parallelize at Transform.scala:16) finished in 0.031 s
2019-06-11 09:21:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:21:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:21:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 9)
2019-06-11 09:21:40,059  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:21:40,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 9 (MapPartitionsRDD[15] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:40,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:40,064  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:40,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_5_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:40,066  INFO [org.apache.spark.SparkContext] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[15] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:40,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 9.0 with 1 tasks
2019-06-11 09:21:40,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 9.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:40,067  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 9.0 (TID 7)
2019-06-11 09:21:40,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:40,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:40,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:40,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:40,073  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 9.0 (TID 7). 1009 bytes result sent to driver
2019-06-11 09:21:40,074  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 9.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:40,074  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2019-06-11 09:21:40,075  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 9 (print at Transform.scala:36) finished in 0.007 s
2019-06-11 09:21:40,075  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 3 finished: print at Transform.scala:36, took 0.054677 s
2019-06-11 09:21:40,080  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:40,081  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 2 is 83 bytes
2019-06-11 09:21:40,082  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 3 is 160 bytes
2019-06-11 09:21:40,082  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 4 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:40,082  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 12 (print at Transform.scala:36)
2019-06-11 09:21:40,082  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 10, ShuffleMapStage 11)
2019-06-11 09:21:40,083  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:40,083  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 12 (MapPartitionsRDD[15] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:40,084  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:40,086  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:40,087  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_6_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:40,088  INFO [org.apache.spark.SparkContext] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:40,088  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[15] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:21:40,088  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 12.0 with 1 tasks
2019-06-11 09:21:40,089  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 12.0 (TID 8, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:40,089  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 12.0 (TID 8)
2019-06-11 09:21:40,092  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:40,092  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:40,092  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:40,092  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:40,095  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 12.0 (TID 8). 1052 bytes result sent to driver
2019-06-11 09:21:40,096  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 12.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:40,096  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2019-06-11 09:21:40,096  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 12 (print at Transform.scala:36) finished in 0.008 s
2019-06-11 09:21:40,097  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 4 finished: print at Transform.scala:36, took 0.016436 s
2019-06-11 09:21:40,097  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216100000 ms.0 from job set of time 1560216100000 ms
2019-06-11 09:21:40,097  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.097 s for time 1560216100000 ms (execution: 0.081 s)
2019-06-11 09:21:40,097  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 8 from persistence list
2019-06-11 09:21:40,104  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 3 from persistence list
2019-06-11 09:21:40,105  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 2 from persistence list
2019-06-11 09:21:40,105  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 8
2019-06-11 09:21:40,106  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[2] at socketTextStream at Transform.scala:18 of time 1560216100000 ms
2019-06-11 09:21:40,106  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 3
2019-06-11 09:21:40,107  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 2
2019-06-11 09:21:40,107  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 
2019-06-11 09:21:40,107  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 
2019-06-11 09:21:45,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216105000 ms
2019-06-11 09:21:45,013  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216105000 ms.0 from job set of time 1560216105000 ms
2019-06-11 09:21:45,017  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:45,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:21:45,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 17 (map at Transform.scala:20)
2019-06-11 09:21:45,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 5 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:45,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 15 (print at Transform.scala:36)
2019-06-11 09:21:45,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 13, ShuffleMapStage 14)
2019-06-11 09:21:45,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 13)
2019-06-11 09:21:45,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 13 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:21:45,021  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:45,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:21:45,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_7_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:21:45,035  INFO [org.apache.spark.SparkContext] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 13 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:21:45,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 13.0 with 2 tasks
2019-06-11 09:21:45,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 13.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:45,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 13.0 (TID 9)
2019-06-11 09:21:45,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_1_piece0 on 192.168.91.1:63518 in memory (size: 1308.0 B, free: 1989.6 MB)
2019-06-11 09:21:45,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 0
2019-06-11 09:21:45,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_5_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_4_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:21:45,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 1
2019-06-11 09:21:45,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 13.0 (TID 9). 896 bytes result sent to driver
2019-06-11 09:21:45,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 13.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:45,053  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 13.0 (TID 10)
2019-06-11 09:21:45,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 13.0 (TID 9) in 17 ms on localhost (executor driver) (1/2)
2019-06-11 09:21:45,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_6_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_2_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_3_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,066  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 13.0 (TID 10). 810 bytes result sent to driver
2019-06-11 09:21:45,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 13.0 (TID 10) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:21:45,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 13 (parallelize at Transform.scala:16) finished in 0.032 s
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 15)
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:21:45,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 15 (MapPartitionsRDD[22] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:45,070  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:45,071  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:45,072  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_8_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,072  INFO [org.apache.spark.SparkContext] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:45,073  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[22] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:45,073  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 15.0 with 1 tasks
2019-06-11 09:21:45,073  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 15.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:45,073  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 15.0 (TID 11)
2019-06-11 09:21:45,075  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:45,075  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:45,075  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:45,075  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:45,077  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 15.0 (TID 11). 1009 bytes result sent to driver
2019-06-11 09:21:45,078  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 15.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:45,078  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2019-06-11 09:21:45,079  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 15 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:21:45,079  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 5 finished: print at Transform.scala:36, took 0.061433 s
2019-06-11 09:21:45,084  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:45,085  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 5 is 160 bytes
2019-06-11 09:21:45,085  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 4 is 83 bytes
2019-06-11 09:21:45,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 6 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:45,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 18 (print at Transform.scala:36)
2019-06-11 09:21:45,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 16, ShuffleMapStage 17)
2019-06-11 09:21:45,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:45,086  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 18 (MapPartitionsRDD[22] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:45,088  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:45,090  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:45,092  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_9_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:45,092  INFO [org.apache.spark.SparkContext] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:45,093  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[22] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:21:45,093  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 18.0 with 1 tasks
2019-06-11 09:21:45,094  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 18.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:45,094  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 18.0 (TID 12)
2019-06-11 09:21:45,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:45,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:45,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:45,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:45,098  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 18.0 (TID 12). 966 bytes result sent to driver
2019-06-11 09:21:45,099  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 18.0 (TID 12) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:45,099  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2019-06-11 09:21:45,099  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 18 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:21:45,100  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 6 finished: print at Transform.scala:36, took 0.015199 s
2019-06-11 09:21:45,100  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216105000 ms.0 from job set of time 1560216105000 ms
2019-06-11 09:21:45,101  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 15 from persistence list
2019-06-11 09:21:45,101  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.100 s for time 1560216105000 ms (execution: 0.087 s)
2019-06-11 09:21:45,101  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 15
2019-06-11 09:21:45,101  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 10 from persistence list
2019-06-11 09:21:45,101  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 10
2019-06-11 09:21:45,102  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 9 from persistence list
2019-06-11 09:21:45,102  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 9
2019-06-11 09:21:45,102  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[9] at socketTextStream at Transform.scala:18 of time 1560216105000 ms
2019-06-11 09:21:45,102  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216095000 ms
2019-06-11 09:21:45,102  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216095000 ms
2019-06-11 09:21:50,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216110000 ms
2019-06-11 09:21:50,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216110000 ms.0 from job set of time 1560216110000 ms
2019-06-11 09:21:50,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 24 (map at Transform.scala:20)
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 7 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 21 (print at Transform.scala:36)
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 19, ShuffleMapStage 20)
2019-06-11 09:21:50,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 20)
2019-06-11 09:21:50,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 20 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:21:50,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:50,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:21:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_10_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:21:50,021  INFO [org.apache.spark.SparkContext] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:50,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 20 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:21:50,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 20.0 with 2 tasks
2019-06-11 09:21:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 20.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:50,022  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 20.0 (TID 13)
2019-06-11 09:21:50,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 20.0 (TID 13). 810 bytes result sent to driver
2019-06-11 09:21:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 20.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:50,034  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 20.0 (TID 14)
2019-06-11 09:21:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 20.0 (TID 13) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:21:50,050  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 20.0 (TID 14). 853 bytes result sent to driver
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 20.0 (TID 14) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 20 (parallelize at Transform.scala:16) finished in 0.029 s
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 21)
2019-06-11 09:21:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:21:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 21 (MapPartitionsRDD[29] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:50,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:50,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:50,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_11_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:50,058  INFO [org.apache.spark.SparkContext] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:50,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[29] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:50,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 21.0 with 1 tasks
2019-06-11 09:21:50,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 21.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:50,060  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 21.0 (TID 15)
2019-06-11 09:21:50,062  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:50,062  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:50,062  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:50,062  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:50,063  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 21.0 (TID 15). 1009 bytes result sent to driver
2019-06-11 09:21:50,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 21.0 (TID 15) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:50,064  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2019-06-11 09:21:50,065  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 21 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:21:50,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 7 finished: print at Transform.scala:36, took 0.050792 s
2019-06-11 09:21:50,070  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:50,070  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 6 is 83 bytes
2019-06-11 09:21:50,071  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 7 is 160 bytes
2019-06-11 09:21:50,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 8 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:50,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 24 (print at Transform.scala:36)
2019-06-11 09:21:50,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 22, ShuffleMapStage 23)
2019-06-11 09:21:50,072  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:50,072  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 24 (MapPartitionsRDD[29] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:50,073  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:50,076  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:50,077  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_12_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:50,077  INFO [org.apache.spark.SparkContext] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:50,078  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[29] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:21:50,078  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 24.0 with 1 tasks
2019-06-11 09:21:50,079  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 24.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:50,079  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 24.0 (TID 16)
2019-06-11 09:21:50,082  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:50,082  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:50,082  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:50,082  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:50,084  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 24.0 (TID 16). 1009 bytes result sent to driver
2019-06-11 09:21:50,084  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 24.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:50,084  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2019-06-11 09:21:50,085  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 24 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:21:50,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 8 finished: print at Transform.scala:36, took 0.015394 s
2019-06-11 09:21:50,086  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216110000 ms.0 from job set of time 1560216110000 ms
2019-06-11 09:21:50,086  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.086 s for time 1560216110000 ms (execution: 0.075 s)
2019-06-11 09:21:50,086  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 22 from persistence list
2019-06-11 09:21:50,086  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 22
2019-06-11 09:21:50,086  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 17 from persistence list
2019-06-11 09:21:50,087  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 17
2019-06-11 09:21:50,087  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 16 from persistence list
2019-06-11 09:21:50,087  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 16
2019-06-11 09:21:50,087  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[16] at socketTextStream at Transform.scala:18 of time 1560216110000 ms
2019-06-11 09:21:50,087  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216100000 ms
2019-06-11 09:21:50,087  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216100000 ms
2019-06-11 09:21:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216115000 ms
2019-06-11 09:21:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216115000 ms.0 from job set of time 1560216115000 ms
2019-06-11 09:21:55,015  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:55,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 31 (map at Transform.scala:20)
2019-06-11 09:21:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:21:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 9 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 27 (print at Transform.scala:36)
2019-06-11 09:21:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 25, ShuffleMapStage 26)
2019-06-11 09:21:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 26)
2019-06-11 09:21:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 26 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:21:55,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:55,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:21:55,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_13_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:21:55,021  INFO [org.apache.spark.SparkContext] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:55,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 26 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:21:55,022  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 26.0 with 2 tasks
2019-06-11 09:21:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 26.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:55,023  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 26.0 (TID 17)
2019-06-11 09:21:55,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 26.0 (TID 17). 810 bytes result sent to driver
2019-06-11 09:21:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 26.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:21:55,034  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 26.0 (TID 18)
2019-06-11 09:21:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 26.0 (TID 17) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:21:55,046  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 26.0 (TID 18). 853 bytes result sent to driver
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 26.0 (TID 18) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 26 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 27)
2019-06-11 09:21:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:21:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 27 (MapPartitionsRDD[36] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:55,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:55,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:55,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_14_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:55,053  INFO [org.apache.spark.SparkContext] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:55,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[36] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:21:55,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 27.0 with 1 tasks
2019-06-11 09:21:55,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 27.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:55,054  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 27.0 (TID 19)
2019-06-11 09:21:55,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:55,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:55,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:55,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:55,058  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 27.0 (TID 19). 1009 bytes result sent to driver
2019-06-11 09:21:55,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 27.0 (TID 19) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:55,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2019-06-11 09:21:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 27 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:21:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 9 finished: print at Transform.scala:36, took 0.043639 s
2019-06-11 09:21:55,062  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:21:55,063  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 8 is 83 bytes
2019-06-11 09:21:55,063  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 9 is 160 bytes
2019-06-11 09:21:55,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 10 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:21:55,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 30 (print at Transform.scala:36)
2019-06-11 09:21:55,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 28, ShuffleMapStage 29)
2019-06-11 09:21:55,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:21:55,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 30 (MapPartitionsRDD[36] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:21:55,065  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:21:55,067  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:21:55,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_15_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:21:55,068  INFO [org.apache.spark.SparkContext] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:21:55,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[36] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:21:55,069  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 30.0 with 1 tasks
2019-06-11 09:21:55,069  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 30.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:21:55,070  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 30.0 (TID 20)
2019-06-11 09:21:55,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:21:55,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:55,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:21:55,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:21:55,073  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 30.0 (TID 20). 1009 bytes result sent to driver
2019-06-11 09:21:55,073  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 30.0 (TID 20) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:21:55,073  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2019-06-11 09:21:55,074  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 30 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:21:55,074  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 10 finished: print at Transform.scala:36, took 0.012096 s
2019-06-11 09:21:55,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216115000 ms.0 from job set of time 1560216115000 ms
2019-06-11 09:21:55,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.075 s for time 1560216115000 ms (execution: 0.064 s)
2019-06-11 09:21:55,075  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 29 from persistence list
2019-06-11 09:21:55,075  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 29
2019-06-11 09:21:55,076  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 24 from persistence list
2019-06-11 09:21:55,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 24
2019-06-11 09:21:55,076  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 23 from persistence list
2019-06-11 09:21:55,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 23
2019-06-11 09:21:55,077  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[23] at socketTextStream at Transform.scala:18 of time 1560216115000 ms
2019-06-11 09:21:55,077  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216105000 ms
2019-06-11 09:21:55,077  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216105000 ms
2019-06-11 09:22:00,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216120000 ms
2019-06-11 09:22:00,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216120000 ms.0 from job set of time 1560216120000 ms
2019-06-11 09:22:00,015  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 38 (map at Transform.scala:20)
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 11 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 33 (print at Transform.scala:36)
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 31, ShuffleMapStage 32)
2019-06-11 09:22:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 31)
2019-06-11 09:22:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 31 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:00,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:00,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:00,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_16_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:00,021  INFO [org.apache.spark.SparkContext] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:00,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 31 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:00,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 31.0 with 2 tasks
2019-06-11 09:22:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 31.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:00,022  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 31.0 (TID 21)
2019-06-11 09:22:00,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 31.0 (TID 21). 853 bytes result sent to driver
2019-06-11 09:22:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 31.0 (TID 22, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:00,042  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 31.0 (TID 22)
2019-06-11 09:22:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 31.0 (TID 21) in 20 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:00,053  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 31.0 (TID 22). 853 bytes result sent to driver
2019-06-11 09:22:00,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 31.0 (TID 22) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:00,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2019-06-11 09:22:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 31 (parallelize at Transform.scala:16) finished in 0.032 s
2019-06-11 09:22:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 33)
2019-06-11 09:22:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 33 (MapPartitionsRDD[43] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:00,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:00,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:00,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_17_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:00,060  INFO [org.apache.spark.SparkContext] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[43] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:00,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 33.0 with 1 tasks
2019-06-11 09:22:00,061  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 33.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:00,061  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 33.0 (TID 23)
2019-06-11 09:22:00,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:00,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:00,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:00,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:00,064  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 33.0 (TID 23). 1052 bytes result sent to driver
2019-06-11 09:22:00,065  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 33.0 (TID 23) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:00,065  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2019-06-11 09:22:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 33 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 11 finished: print at Transform.scala:36, took 0.050326 s
2019-06-11 09:22:00,069  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:00,070  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 11 is 160 bytes
2019-06-11 09:22:00,071  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 10 is 83 bytes
2019-06-11 09:22:00,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 12 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:00,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 36 (print at Transform.scala:36)
2019-06-11 09:22:00,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 35)
2019-06-11 09:22:00,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:00,072  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 36 (MapPartitionsRDD[43] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:00,073  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:00,074  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:00,075  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_18_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:00,075  INFO [org.apache.spark.SparkContext] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:00,075  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[43] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:00,075  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 36.0 with 1 tasks
2019-06-11 09:22:00,076  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 36.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:00,076  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 36.0 (TID 24)
2019-06-11 09:22:00,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:00,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:00,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:00,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:00,079  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 36.0 (TID 24). 1052 bytes result sent to driver
2019-06-11 09:22:00,080  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 36.0 (TID 24) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:00,080  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2019-06-11 09:22:00,081  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 36 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:22:00,081  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 12 finished: print at Transform.scala:36, took 0.011628 s
2019-06-11 09:22:00,082  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216120000 ms.0 from job set of time 1560216120000 ms
2019-06-11 09:22:00,082  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.082 s for time 1560216120000 ms (execution: 0.071 s)
2019-06-11 09:22:00,082  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 36 from persistence list
2019-06-11 09:22:00,082  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 36
2019-06-11 09:22:00,082  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 31 from persistence list
2019-06-11 09:22:00,082  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 31
2019-06-11 09:22:00,083  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 30 from persistence list
2019-06-11 09:22:00,083  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 30
2019-06-11 09:22:00,083  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[30] at socketTextStream at Transform.scala:18 of time 1560216120000 ms
2019-06-11 09:22:00,083  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216110000 ms
2019-06-11 09:22:00,083  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216110000 ms
2019-06-11 09:22:05,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216125000 ms
2019-06-11 09:22:05,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216125000 ms.0 from job set of time 1560216125000 ms
2019-06-11 09:22:05,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:05,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:05,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 45 (map at Transform.scala:20)
2019-06-11 09:22:05,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 13 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:05,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 39 (print at Transform.scala:36)
2019-06-11 09:22:05,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 37, ShuffleMapStage 38)
2019-06-11 09:22:05,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 37)
2019-06-11 09:22:05,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 37 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:05,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:05,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:05,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_19_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:05,022  INFO [org.apache.spark.SparkContext] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:05,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 37 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:05,022  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 37.0 with 2 tasks
2019-06-11 09:22:05,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 37.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:05,023  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 37.0 (TID 25)
2019-06-11 09:22:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 37.0 (TID 25). 853 bytes result sent to driver
2019-06-11 09:22:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 37.0 (TID 26, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:05,036  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 37.0 (TID 26)
2019-06-11 09:22:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 37.0 (TID 25) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:05,047  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 37.0 (TID 26). 896 bytes result sent to driver
2019-06-11 09:22:05,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 37.0 (TID 26) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:05,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2019-06-11 09:22:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 37 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:22:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 39)
2019-06-11 09:22:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:05,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 39 (MapPartitionsRDD[50] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:05,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:05,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:05,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_20_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:05,056  INFO [org.apache.spark.SparkContext] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:05,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[50] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:05,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 39.0 with 1 tasks
2019-06-11 09:22:05,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 39.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:05,058  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 39.0 (TID 27)
2019-06-11 09:22:05,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:05,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:05,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:05,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:05,061  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 39.0 (TID 27). 1009 bytes result sent to driver
2019-06-11 09:22:05,061  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 39.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:05,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2019-06-11 09:22:05,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 39 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:22:05,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 13 finished: print at Transform.scala:36, took 0.048328 s
2019-06-11 09:22:05,068  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:05,069  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 13 is 160 bytes
2019-06-11 09:22:05,070  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 12 is 83 bytes
2019-06-11 09:22:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 14 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 42 (print at Transform.scala:36)
2019-06-11 09:22:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 40, ShuffleMapStage 41)
2019-06-11 09:22:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:05,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 42 (MapPartitionsRDD[50] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:05,072  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:05,075  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:05,076  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_21_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:05,076  INFO [org.apache.spark.SparkContext] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:05,077  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[50] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:05,078  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 42.0 with 1 tasks
2019-06-11 09:22:05,078  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 42.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:05,078  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 42.0 (TID 28)
2019-06-11 09:22:05,081  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:05,081  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:05,081  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:05,082  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:05,083  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 42.0 (TID 28). 1009 bytes result sent to driver
2019-06-11 09:22:05,084  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 42.0 (TID 28) in 6 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:05,084  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2019-06-11 09:22:05,084  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 42 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:22:05,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 14 finished: print at Transform.scala:36, took 0.016085 s
2019-06-11 09:22:05,085  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216125000 ms.0 from job set of time 1560216125000 ms
2019-06-11 09:22:05,086  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.085 s for time 1560216125000 ms (execution: 0.074 s)
2019-06-11 09:22:05,086  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 43 from persistence list
2019-06-11 09:22:05,086  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 43
2019-06-11 09:22:05,086  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 38 from persistence list
2019-06-11 09:22:05,086  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 38
2019-06-11 09:22:05,087  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 37 from persistence list
2019-06-11 09:22:05,087  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 37
2019-06-11 09:22:05,087  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[37] at socketTextStream at Transform.scala:18 of time 1560216125000 ms
2019-06-11 09:22:05,087  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216115000 ms
2019-06-11 09:22:05,087  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216115000 ms
2019-06-11 09:22:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216130000 ms
2019-06-11 09:22:10,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216130000 ms.0 from job set of time 1560216130000 ms
2019-06-11 09:22:10,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 52 (map at Transform.scala:20)
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 15 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 45 (print at Transform.scala:36)
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 43, ShuffleMapStage 44)
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 44)
2019-06-11 09:22:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 44 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:10,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:10,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:10,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_22_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:10,016  INFO [org.apache.spark.SparkContext] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:10,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 44 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:10,017  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 44.0 with 2 tasks
2019-06-11 09:22:10,017  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 44.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:10,018  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 44.0 (TID 29)
2019-06-11 09:22:10,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 44.0 (TID 29). 810 bytes result sent to driver
2019-06-11 09:22:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 44.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:10,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 44.0 (TID 30)
2019-06-11 09:22:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 44.0 (TID 29) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:10,041  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 44.0 (TID 30). 853 bytes result sent to driver
2019-06-11 09:22:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 44.0 (TID 30) in 13 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 44 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 45)
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 45 (MapPartitionsRDD[57] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:10,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:10,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_23_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:10,045  INFO [org.apache.spark.SparkContext] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[57] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:10,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 45.0 with 1 tasks
2019-06-11 09:22:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 45.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:10,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 45.0 (TID 31)
2019-06-11 09:22:10,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:10,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:10,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:10,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:10,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 45.0 (TID 31). 966 bytes result sent to driver
2019-06-11 09:22:10,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 45.0 (TID 31) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:10,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2019-06-11 09:22:10,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 45 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:22:10,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 15 finished: print at Transform.scala:36, took 0.040061 s
2019-06-11 09:22:10,055  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:10,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 14 is 83 bytes
2019-06-11 09:22:10,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 15 is 160 bytes
2019-06-11 09:22:10,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 16 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:10,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 48 (print at Transform.scala:36)
2019-06-11 09:22:10,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 46, ShuffleMapStage 47)
2019-06-11 09:22:10,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:10,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 48 (MapPartitionsRDD[57] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:10,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:10,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:10,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_24_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:10,061  INFO [org.apache.spark.SparkContext] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:10,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[57] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:10,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 48.0 with 1 tasks
2019-06-11 09:22:10,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 48.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:10,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 48.0 (TID 32)
2019-06-11 09:22:10,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:10,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:10,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:10,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:10,066  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 48.0 (TID 32). 1009 bytes result sent to driver
2019-06-11 09:22:10,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 48.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:10,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2019-06-11 09:22:10,067  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 48 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:22:10,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 16 finished: print at Transform.scala:36, took 0.011901 s
2019-06-11 09:22:10,068  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216130000 ms.0 from job set of time 1560216130000 ms
2019-06-11 09:22:10,068  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.068 s for time 1560216130000 ms (execution: 0.060 s)
2019-06-11 09:22:10,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 50 from persistence list
2019-06-11 09:22:10,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 50
2019-06-11 09:22:10,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 45 from persistence list
2019-06-11 09:22:10,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 45
2019-06-11 09:22:10,069  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 44 from persistence list
2019-06-11 09:22:10,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 44
2019-06-11 09:22:10,069  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[44] at socketTextStream at Transform.scala:18 of time 1560216130000 ms
2019-06-11 09:22:10,069  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216120000 ms
2019-06-11 09:22:10,069  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216120000 ms
2019-06-11 09:22:15,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216135000 ms
2019-06-11 09:22:15,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216135000 ms.0 from job set of time 1560216135000 ms
2019-06-11 09:22:15,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 59 (map at Transform.scala:20)
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 17 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 51 (print at Transform.scala:36)
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 49, ShuffleMapStage 50)
2019-06-11 09:22:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 50)
2019-06-11 09:22:15,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 50 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:15,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:15,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:22:15,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_25_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,019  INFO [org.apache.spark.SparkContext] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 50 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:15,020  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 50.0 with 2 tasks
2019-06-11 09:22:15,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 50.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:15,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 50.0 (TID 33)
2019-06-11 09:22:15,029  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 50.0 (TID 33). 810 bytes result sent to driver
2019-06-11 09:22:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 50.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:15,030  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 50.0 (TID 34)
2019-06-11 09:22:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 50.0 (TID 33) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:15,041  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 50.0 (TID 34). 853 bytes result sent to driver
2019-06-11 09:22:15,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 50.0 (TID 34) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:15,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 50 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 51)
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 51 (MapPartitionsRDD[64] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:15,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:15,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:15,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_26_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:15,046  INFO [org.apache.spark.SparkContext] - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[64] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:15,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 51.0 with 1 tasks
2019-06-11 09:22:15,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 51.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:15,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 51.0 (TID 35)
2019-06-11 09:22:15,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:15,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 51.0 (TID 35). 966 bytes result sent to driver
2019-06-11 09:22:15,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 51.0 (TID 35) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:15,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2019-06-11 09:22:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 51 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 17 finished: print at Transform.scala:36, took 0.038965 s
2019-06-11 09:22:15,055  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:15,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 16 is 83 bytes
2019-06-11 09:22:15,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 17 is 160 bytes
2019-06-11 09:22:15,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 18 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:15,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 54 (print at Transform.scala:36)
2019-06-11 09:22:15,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 52, ShuffleMapStage 53)
2019-06-11 09:22:15,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:15,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 54 (MapPartitionsRDD[64] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:15,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:15,070  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:15,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_24_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_27_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:15,071  INFO [org.apache.spark.SparkContext] - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:15,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[64] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:15,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 54.0 with 1 tasks
2019-06-11 09:22:15,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_19_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,072  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 54.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:15,072  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 54.0 (TID 36)
2019-06-11 09:22:15,072  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 6
2019-06-11 09:22:15,073  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_20_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,074  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:15,074  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:15,074  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:15,074  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:15,074  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_7_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,075  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 8
2019-06-11 09:22:15,076  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 7
2019-06-11 09:22:15,076  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 54.0 (TID 36). 1009 bytes result sent to driver
2019-06-11 09:22:15,077  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 54.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:15,077  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2019-06-11 09:22:15,077  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_23_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,077  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 54 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:22:15,078  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 18 finished: print at Transform.scala:36, took 0.022912 s
2019-06-11 09:22:15,078  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216135000 ms.0 from job set of time 1560216135000 ms
2019-06-11 09:22:15,078  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.078 s for time 1560216135000 ms (execution: 0.068 s)
2019-06-11 09:22:15,078  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 57 from persistence list
2019-06-11 09:22:15,078  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_26_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,079  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 57
2019-06-11 09:22:15,079  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 52 from persistence list
2019-06-11 09:22:15,079  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 52
2019-06-11 09:22:15,079  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 51 from persistence list
2019-06-11 09:22:15,079  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 51
2019-06-11 09:22:15,080  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[51] at socketTextStream at Transform.scala:18 of time 1560216135000 ms
2019-06-11 09:22:15,080  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216125000 ms
2019-06-11 09:22:15,080  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_18_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,080  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216125000 ms
2019-06-11 09:22:15,081  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_10_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,082  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_25_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,083  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 12
2019-06-11 09:22:15,084  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_17_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,084  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 4
2019-06-11 09:22:15,084  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 11
2019-06-11 09:22:15,085  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_16_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,086  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 5
2019-06-11 09:22:15,087  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_9_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,088  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 10
2019-06-11 09:22:15,089  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_21_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,090  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_8_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,091  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_15_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,093  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_12_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,093  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 2
2019-06-11 09:22:15,094  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_14_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,095  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_22_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,096  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 3
2019-06-11 09:22:15,097  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_11_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:15,098  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 13
2019-06-11 09:22:15,099  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_13_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:15,100  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 9
2019-06-11 09:22:20,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216140000 ms
2019-06-11 09:22:20,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216140000 ms.0 from job set of time 1560216140000 ms
2019-06-11 09:22:20,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 66 (map at Transform.scala:20)
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 19 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 57 (print at Transform.scala:36)
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 56, ShuffleMapStage 55)
2019-06-11 09:22:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 56)
2019-06-11 09:22:20,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 56 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:20,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:20,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:20,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_28_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:20,019  INFO [org.apache.spark.SparkContext] - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:20,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 56 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:20,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 56.0 with 2 tasks
2019-06-11 09:22:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 56.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:20,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 56.0 (TID 37)
2019-06-11 09:22:20,029  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 56.0 (TID 37). 810 bytes result sent to driver
2019-06-11 09:22:20,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 56.0 (TID 38, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:20,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 56.0 (TID 37) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:20,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 56.0 (TID 38)
2019-06-11 09:22:20,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 56.0 (TID 38). 853 bytes result sent to driver
2019-06-11 09:22:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 56.0 (TID 38) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2019-06-11 09:22:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 56 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:22:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 57)
2019-06-11 09:22:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 57 (MapPartitionsRDD[71] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:20,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:20,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:20,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_29_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:20,044  INFO [org.apache.spark.SparkContext] - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[71] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:20,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 57.0 with 1 tasks
2019-06-11 09:22:20,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 57.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:20,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 57.0 (TID 39)
2019-06-11 09:22:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:20,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 57.0 (TID 39). 1052 bytes result sent to driver
2019-06-11 09:22:20,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 57.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:20,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2019-06-11 09:22:20,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 57 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:20,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 19 finished: print at Transform.scala:36, took 0.034513 s
2019-06-11 09:22:20,053  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:20,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 18 is 83 bytes
2019-06-11 09:22:20,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 19 is 160 bytes
2019-06-11 09:22:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 20 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 60 (print at Transform.scala:36)
2019-06-11 09:22:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 58, ShuffleMapStage 59)
2019-06-11 09:22:20,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:20,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 60 (MapPartitionsRDD[71] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:20,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:20,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:20,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_30_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:20,058  INFO [org.apache.spark.SparkContext] - Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:20,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[71] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:20,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 60.0 with 1 tasks
2019-06-11 09:22:20,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 60.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:20,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 60.0 (TID 40)
2019-06-11 09:22:20,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:20,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:20,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:20,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:20,061  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 60.0 (TID 40). 1009 bytes result sent to driver
2019-06-11 09:22:20,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 60.0 (TID 40) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:20,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2019-06-11 09:22:20,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 60 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:20,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 20 finished: print at Transform.scala:36, took 0.009139 s
2019-06-11 09:22:20,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216140000 ms.0 from job set of time 1560216140000 ms
2019-06-11 09:22:20,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.063 s for time 1560216140000 ms (execution: 0.051 s)
2019-06-11 09:22:20,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 64 from persistence list
2019-06-11 09:22:20,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 64
2019-06-11 09:22:20,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 59 from persistence list
2019-06-11 09:22:20,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 59
2019-06-11 09:22:20,064  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 58 from persistence list
2019-06-11 09:22:20,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 58
2019-06-11 09:22:20,064  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[58] at socketTextStream at Transform.scala:18 of time 1560216140000 ms
2019-06-11 09:22:20,064  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216130000 ms
2019-06-11 09:22:20,064  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216130000 ms
2019-06-11 09:22:25,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216145000 ms
2019-06-11 09:22:25,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216145000 ms.0 from job set of time 1560216145000 ms
2019-06-11 09:22:25,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 73 (map at Transform.scala:20)
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 21 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 63 (print at Transform.scala:36)
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 61, ShuffleMapStage 62)
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 62)
2019-06-11 09:22:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 62 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:25,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:25,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:25,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_31_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:25,018  INFO [org.apache.spark.SparkContext] - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:25,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 62 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:25,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 62.0 with 2 tasks
2019-06-11 09:22:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 62.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:25,019  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 62.0 (TID 41)
2019-06-11 09:22:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 62.0 (TID 41). 810 bytes result sent to driver
2019-06-11 09:22:25,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 62.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:25,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 62.0 (TID 42)
2019-06-11 09:22:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 62.0 (TID 41) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:25,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 62.0 (TID 42). 853 bytes result sent to driver
2019-06-11 09:22:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 62.0 (TID 42) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 62 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 63)
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 63 (MapPartitionsRDD[78] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:25,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:25,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:25,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_32_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:25,044  INFO [org.apache.spark.SparkContext] - Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[78] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:25,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 63.0 with 1 tasks
2019-06-11 09:22:25,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 63.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:25,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 63.0 (TID 43)
2019-06-11 09:22:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:25,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 63.0 (TID 43). 1052 bytes result sent to driver
2019-06-11 09:22:25,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 63.0 (TID 43) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:25,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2019-06-11 09:22:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 63 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 21 finished: print at Transform.scala:36, took 0.036676 s
2019-06-11 09:22:25,052  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:25,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 20 is 83 bytes
2019-06-11 09:22:25,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 21 is 160 bytes
2019-06-11 09:22:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 22 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 66 (print at Transform.scala:36)
2019-06-11 09:22:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 64, ShuffleMapStage 65)
2019-06-11 09:22:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 66 (MapPartitionsRDD[78] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:25,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:25,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_33_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:25,056  INFO [org.apache.spark.SparkContext] - Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:25,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[78] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:25,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 66.0 with 1 tasks
2019-06-11 09:22:25,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 66.0 (TID 44, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:25,057  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 66.0 (TID 44)
2019-06-11 09:22:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:25,060  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 66.0 (TID 44). 966 bytes result sent to driver
2019-06-11 09:22:25,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 66.0 (TID 44) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:25,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2019-06-11 09:22:25,060  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 66 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:25,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 22 finished: print at Transform.scala:36, took 0.008554 s
2019-06-11 09:22:25,061  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216145000 ms.0 from job set of time 1560216145000 ms
2019-06-11 09:22:25,061  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.061 s for time 1560216145000 ms (execution: 0.052 s)
2019-06-11 09:22:25,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 71 from persistence list
2019-06-11 09:22:25,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 71
2019-06-11 09:22:25,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 66 from persistence list
2019-06-11 09:22:25,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 66
2019-06-11 09:22:25,062  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 65 from persistence list
2019-06-11 09:22:25,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 65
2019-06-11 09:22:25,062  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[65] at socketTextStream at Transform.scala:18 of time 1560216145000 ms
2019-06-11 09:22:25,062  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216135000 ms
2019-06-11 09:22:25,062  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216135000 ms
2019-06-11 09:22:30,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216150000 ms
2019-06-11 09:22:30,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216150000 ms.0 from job set of time 1560216150000 ms
2019-06-11 09:22:30,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 80 (map at Transform.scala:20)
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 23 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 69 (print at Transform.scala:36)
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 67, ShuffleMapStage 68)
2019-06-11 09:22:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 67)
2019-06-11 09:22:30,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 67 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:30,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:30,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:30,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_34_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:30,017  INFO [org.apache.spark.SparkContext] - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 67 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:30,018  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 67.0 with 2 tasks
2019-06-11 09:22:30,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 67.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:30,018  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 67.0 (TID 45)
2019-06-11 09:22:30,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 67.0 (TID 45). 810 bytes result sent to driver
2019-06-11 09:22:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 67.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:30,031  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 67.0 (TID 46)
2019-06-11 09:22:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 67.0 (TID 45) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:30,042  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 67.0 (TID 46). 810 bytes result sent to driver
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 67.0 (TID 46) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 67 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 69)
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 69 (MapPartitionsRDD[85] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:30,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:30,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:30,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_35_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:30,047  INFO [org.apache.spark.SparkContext] - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:30,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[85] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:30,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 69.0 with 1 tasks
2019-06-11 09:22:30,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 69.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:30,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 69.0 (TID 47)
2019-06-11 09:22:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:30,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 69.0 (TID 47). 966 bytes result sent to driver
2019-06-11 09:22:30,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 69.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:30,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2019-06-11 09:22:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 69 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:22:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 23 finished: print at Transform.scala:36, took 0.039737 s
2019-06-11 09:22:30,056  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:30,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 23 is 160 bytes
2019-06-11 09:22:30,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 22 is 83 bytes
2019-06-11 09:22:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 24 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 72 (print at Transform.scala:36)
2019-06-11 09:22:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 70, ShuffleMapStage 71)
2019-06-11 09:22:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 72 (MapPartitionsRDD[85] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:30,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:30,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:30,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_36_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:30,061  INFO [org.apache.spark.SparkContext] - Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:30,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[85] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:30,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 72.0 with 1 tasks
2019-06-11 09:22:30,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 72.0 (TID 48, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:30,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 72.0 (TID 48)
2019-06-11 09:22:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:30,065  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 72.0 (TID 48). 1009 bytes result sent to driver
2019-06-11 09:22:30,065  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 72.0 (TID 48) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:30,065  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2019-06-11 09:22:30,065  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 72 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:30,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 24 finished: print at Transform.scala:36, took 0.009030 s
2019-06-11 09:22:30,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216150000 ms.0 from job set of time 1560216150000 ms
2019-06-11 09:22:30,066  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 78 from persistence list
2019-06-11 09:22:30,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.066 s for time 1560216150000 ms (execution: 0.057 s)
2019-06-11 09:22:30,066  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 78
2019-06-11 09:22:30,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 73 from persistence list
2019-06-11 09:22:30,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 73
2019-06-11 09:22:30,067  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 72 from persistence list
2019-06-11 09:22:30,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 72
2019-06-11 09:22:30,067  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[72] at socketTextStream at Transform.scala:18 of time 1560216150000 ms
2019-06-11 09:22:30,068  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216140000 ms
2019-06-11 09:22:30,068  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216140000 ms
2019-06-11 09:22:35,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216155000 ms
2019-06-11 09:22:35,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216155000 ms.0 from job set of time 1560216155000 ms
2019-06-11 09:22:35,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 87 (map at Transform.scala:20)
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 25 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 75 (print at Transform.scala:36)
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 74, ShuffleMapStage 73)
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 74)
2019-06-11 09:22:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 74 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:35,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:35,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:35,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_37_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:35,019  INFO [org.apache.spark.SparkContext] - Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 74 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:35,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 74.0 with 2 tasks
2019-06-11 09:22:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 74.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:35,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 74.0 (TID 49)
2019-06-11 09:22:35,029  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 74.0 (TID 49). 767 bytes result sent to driver
2019-06-11 09:22:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 74.0 (TID 50, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:35,030  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 74.0 (TID 50)
2019-06-11 09:22:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 74.0 (TID 49) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:35,045  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 74.0 (TID 50). 810 bytes result sent to driver
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 74.0 (TID 50) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 74 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 75)
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 75 (MapPartitionsRDD[92] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:35,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:35,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:35,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_38_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:35,049  INFO [org.apache.spark.SparkContext] - Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:35,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[92] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:35,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 75.0 with 1 tasks
2019-06-11 09:22:35,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 75.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:35,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 75.0 (TID 51)
2019-06-11 09:22:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:35,056  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 75.0 (TID 51). 966 bytes result sent to driver
2019-06-11 09:22:35,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 75.0 (TID 51) in 6 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:35,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2019-06-11 09:22:35,057  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 75 (print at Transform.scala:36) finished in 0.007 s
2019-06-11 09:22:35,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 25 finished: print at Transform.scala:36, took 0.044092 s
2019-06-11 09:22:35,061  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:35,062  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 24 is 83 bytes
2019-06-11 09:22:35,062  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 25 is 160 bytes
2019-06-11 09:22:35,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 26 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:35,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 78 (print at Transform.scala:36)
2019-06-11 09:22:35,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 76, ShuffleMapStage 77)
2019-06-11 09:22:35,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:35,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 78 (MapPartitionsRDD[92] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:35,064  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:35,066  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:35,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_39_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:35,067  INFO [org.apache.spark.SparkContext] - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:35,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[92] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:35,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 78.0 with 1 tasks
2019-06-11 09:22:35,068  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 78.0 (TID 52, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:35,068  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 78.0 (TID 52)
2019-06-11 09:22:35,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:35,070  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:35,070  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:35,070  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:35,071  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 78.0 (TID 52). 966 bytes result sent to driver
2019-06-11 09:22:35,071  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 78.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:35,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2019-06-11 09:22:35,071  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 78 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:35,072  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 26 finished: print at Transform.scala:36, took 0.010490 s
2019-06-11 09:22:35,072  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216155000 ms.0 from job set of time 1560216155000 ms
2019-06-11 09:22:35,072  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.072 s for time 1560216155000 ms (execution: 0.061 s)
2019-06-11 09:22:35,072  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 85 from persistence list
2019-06-11 09:22:35,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 85
2019-06-11 09:22:35,073  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 80 from persistence list
2019-06-11 09:22:35,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 80
2019-06-11 09:22:35,073  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 79 from persistence list
2019-06-11 09:22:35,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 79
2019-06-11 09:22:35,074  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[79] at socketTextStream at Transform.scala:18 of time 1560216155000 ms
2019-06-11 09:22:35,074  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216145000 ms
2019-06-11 09:22:35,074  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216145000 ms
2019-06-11 09:22:40,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216160000 ms
2019-06-11 09:22:40,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216160000 ms.0 from job set of time 1560216160000 ms
2019-06-11 09:22:40,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 94 (map at Transform.scala:20)
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 27 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 81 (print at Transform.scala:36)
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 79, ShuffleMapStage 80)
2019-06-11 09:22:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 80)
2019-06-11 09:22:40,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 80 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:40,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:40,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:40,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_40_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:40,014  INFO [org.apache.spark.SparkContext] - Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 80 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:40,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 80.0 with 2 tasks
2019-06-11 09:22:40,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 80.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:40,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 80.0 (TID 53)
2019-06-11 09:22:40,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 80.0 (TID 53). 810 bytes result sent to driver
2019-06-11 09:22:40,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 80.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:40,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 80.0 (TID 54)
2019-06-11 09:22:40,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 80.0 (TID 53) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:40,038  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 80.0 (TID 54). 853 bytes result sent to driver
2019-06-11 09:22:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 80.0 (TID 54) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2019-06-11 09:22:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 80 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:22:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 81)
2019-06-11 09:22:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 81 (MapPartitionsRDD[99] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:40,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:40,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:40,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_41_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:40,041  INFO [org.apache.spark.SparkContext] - Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[99] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:40,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 81.0 with 1 tasks
2019-06-11 09:22:40,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 81.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:40,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 81.0 (TID 55)
2019-06-11 09:22:40,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:40,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:22:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 81.0 (TID 55). 966 bytes result sent to driver
2019-06-11 09:22:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 81.0 (TID 55) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:40,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2019-06-11 09:22:40,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 81 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 27 finished: print at Transform.scala:36, took 0.034915 s
2019-06-11 09:22:40,051  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:40,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 26 is 83 bytes
2019-06-11 09:22:40,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 27 is 160 bytes
2019-06-11 09:22:40,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 28 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:40,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 84 (print at Transform.scala:36)
2019-06-11 09:22:40,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 82, ShuffleMapStage 83)
2019-06-11 09:22:40,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:40,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 84 (MapPartitionsRDD[99] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:40,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:40,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:40,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_42_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:40,055  INFO [org.apache.spark.SparkContext] - Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:40,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[99] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:40,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 84.0 with 1 tasks
2019-06-11 09:22:40,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 84.0 (TID 56, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:40,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 84.0 (TID 56)
2019-06-11 09:22:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:40,058  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 84.0 (TID 56). 1009 bytes result sent to driver
2019-06-11 09:22:40,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 84.0 (TID 56) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:40,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2019-06-11 09:22:40,059  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 84 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:40,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 28 finished: print at Transform.scala:36, took 0.008253 s
2019-06-11 09:22:40,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216160000 ms.0 from job set of time 1560216160000 ms
2019-06-11 09:22:40,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.060 s for time 1560216160000 ms (execution: 0.051 s)
2019-06-11 09:22:40,060  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 92 from persistence list
2019-06-11 09:22:40,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 92
2019-06-11 09:22:40,060  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 87 from persistence list
2019-06-11 09:22:40,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 87
2019-06-11 09:22:40,060  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 86 from persistence list
2019-06-11 09:22:40,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 86
2019-06-11 09:22:40,061  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[86] at socketTextStream at Transform.scala:18 of time 1560216160000 ms
2019-06-11 09:22:40,061  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216150000 ms
2019-06-11 09:22:40,061  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216150000 ms
2019-06-11 09:22:45,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216165000 ms
2019-06-11 09:22:45,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216165000 ms.0 from job set of time 1560216165000 ms
2019-06-11 09:22:45,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 101 (map at Transform.scala:20)
2019-06-11 09:22:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 29 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 87 (print at Transform.scala:36)
2019-06-11 09:22:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 85, ShuffleMapStage 86)
2019-06-11 09:22:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 85)
2019-06-11 09:22:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 85 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:45,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:45,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:22:45,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_43_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:45,017  INFO [org.apache.spark.SparkContext] - Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:45,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 85 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:45,018  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 85.0 with 2 tasks
2019-06-11 09:22:45,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 85.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:45,018  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 85.0 (TID 57)
2019-06-11 09:22:45,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 85.0 (TID 57). 810 bytes result sent to driver
2019-06-11 09:22:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 85.0 (TID 58, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:45,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 85.0 (TID 58)
2019-06-11 09:22:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 85.0 (TID 57) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:45,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 85.0 (TID 58). 853 bytes result sent to driver
2019-06-11 09:22:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 85.0 (TID 58) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2019-06-11 09:22:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 85 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:22:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 87)
2019-06-11 09:22:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 87 (MapPartitionsRDD[106] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:45,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:45,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:45,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_44_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:45,042  INFO [org.apache.spark.SparkContext] - Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:45,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[106] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:45,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 87.0 with 1 tasks
2019-06-11 09:22:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 87.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:45,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 87.0 (TID 59)
2019-06-11 09:22:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:45,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 87.0 (TID 59). 1009 bytes result sent to driver
2019-06-11 09:22:45,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 87.0 (TID 59) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2019-06-11 09:22:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 87 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 29 finished: print at Transform.scala:36, took 0.032996 s
2019-06-11 09:22:45,051  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:45,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 29 is 160 bytes
2019-06-11 09:22:45,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 28 is 83 bytes
2019-06-11 09:22:45,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 30 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 90 (print at Transform.scala:36)
2019-06-11 09:22:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 88, ShuffleMapStage 89)
2019-06-11 09:22:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 90 (MapPartitionsRDD[106] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:45,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:45,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:45,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_45_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:45,054  INFO [org.apache.spark.SparkContext] - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:45,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[106] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:45,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 90.0 with 1 tasks
2019-06-11 09:22:45,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 90.0 (TID 60, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:45,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 90.0 (TID 60)
2019-06-11 09:22:45,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:45,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:45,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:45,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:45,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 90.0 (TID 60). 1009 bytes result sent to driver
2019-06-11 09:22:45,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 90.0 (TID 60) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:45,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2019-06-11 09:22:45,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 90 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:22:45,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 30 finished: print at Transform.scala:36, took 0.007788 s
2019-06-11 09:22:45,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216165000 ms.0 from job set of time 1560216165000 ms
2019-06-11 09:22:45,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560216165000 ms (execution: 0.050 s)
2019-06-11 09:22:45,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 99 from persistence list
2019-06-11 09:22:45,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 99
2019-06-11 09:22:45,059  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 94 from persistence list
2019-06-11 09:22:45,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 94
2019-06-11 09:22:45,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 93 from persistence list
2019-06-11 09:22:45,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 93
2019-06-11 09:22:45,060  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[93] at socketTextStream at Transform.scala:18 of time 1560216165000 ms
2019-06-11 09:22:45,060  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216155000 ms
2019-06-11 09:22:45,060  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216155000 ms
2019-06-11 09:22:50,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216170000 ms
2019-06-11 09:22:50,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216170000 ms.0 from job set of time 1560216170000 ms
2019-06-11 09:22:50,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 108 (map at Transform.scala:20)
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 31 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 93 (print at Transform.scala:36)
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 91, ShuffleMapStage 92)
2019-06-11 09:22:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 91)
2019-06-11 09:22:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 91 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:50,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:50,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:22:50,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_46_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:22:50,016  INFO [org.apache.spark.SparkContext] - Created broadcast 46 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:50,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 91 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:50,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 91.0 with 2 tasks
2019-06-11 09:22:50,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 91.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:50,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 91.0 (TID 61)
2019-06-11 09:22:50,029  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 91.0 (TID 61). 810 bytes result sent to driver
2019-06-11 09:22:50,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 91.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:50,030  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 91.0 (TID 62)
2019-06-11 09:22:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 91.0 (TID 61) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:50,048  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 91.0 (TID 62). 896 bytes result sent to driver
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 91.0 (TID 62) in 20 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 91 (parallelize at Transform.scala:16) finished in 0.033 s
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 93)
2019-06-11 09:22:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 93 (MapPartitionsRDD[113] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:50,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:50,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:50,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_47_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:50,054  INFO [org.apache.spark.SparkContext] - Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:50,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[113] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:50,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 93.0 with 1 tasks
2019-06-11 09:22:50,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 93.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:50,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 93.0 (TID 63)
2019-06-11 09:22:50,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:50,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:50,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:50,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:50,059  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 93.0 (TID 63). 1009 bytes result sent to driver
2019-06-11 09:22:50,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 93.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:50,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2019-06-11 09:22:50,059  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 93 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:50,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 31 finished: print at Transform.scala:36, took 0.049516 s
2019-06-11 09:22:50,063  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:50,063  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 31 is 160 bytes
2019-06-11 09:22:50,064  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 30 is 83 bytes
2019-06-11 09:22:50,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 32 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:50,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 96 (print at Transform.scala:36)
2019-06-11 09:22:50,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 94, ShuffleMapStage 95)
2019-06-11 09:22:50,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:50,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 96 (MapPartitionsRDD[113] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:50,066  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:50,068  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:50,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_48_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:50,069  INFO [org.apache.spark.SparkContext] - Created broadcast 48 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:50,069  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[113] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:50,069  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 96.0 with 1 tasks
2019-06-11 09:22:50,070  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 96.0 (TID 64, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:50,070  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 96.0 (TID 64)
2019-06-11 09:22:50,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:50,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:50,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:50,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:50,073  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 96.0 (TID 64). 1009 bytes result sent to driver
2019-06-11 09:22:50,074  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 96.0 (TID 64) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:50,074  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2019-06-11 09:22:50,074  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 96 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:22:50,075  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 32 finished: print at Transform.scala:36, took 0.011669 s
2019-06-11 09:22:50,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216170000 ms.0 from job set of time 1560216170000 ms
2019-06-11 09:22:50,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.075 s for time 1560216170000 ms (execution: 0.067 s)
2019-06-11 09:22:50,075  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 106 from persistence list
2019-06-11 09:22:50,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 106
2019-06-11 09:22:50,076  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 101 from persistence list
2019-06-11 09:22:50,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 101
2019-06-11 09:22:50,076  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 100 from persistence list
2019-06-11 09:22:50,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 100
2019-06-11 09:22:50,076  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[100] at socketTextStream at Transform.scala:18 of time 1560216170000 ms
2019-06-11 09:22:50,076  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216160000 ms
2019-06-11 09:22:50,076  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216160000 ms
2019-06-11 09:22:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216175000 ms
2019-06-11 09:22:55,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216175000 ms.0 from job set of time 1560216175000 ms
2019-06-11 09:22:55,016  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 115 (map at Transform.scala:20)
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 33 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 99 (print at Transform.scala:36)
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 97, ShuffleMapStage 98)
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 98)
2019-06-11 09:22:55,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 98 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:22:55,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:55,022  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_49_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:22:55,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_49_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:22:55,023  INFO [org.apache.spark.SparkContext] - Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:55,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 98 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:22:55,023  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 98.0 with 2 tasks
2019-06-11 09:22:55,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 98.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:55,024  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 98.0 (TID 65)
2019-06-11 09:22:55,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 98.0 (TID 65). 810 bytes result sent to driver
2019-06-11 09:22:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 98.0 (TID 66, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:22:55,040  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 98.0 (TID 66)
2019-06-11 09:22:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 98.0 (TID 65) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:22:55,055  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 98.0 (TID 66). 853 bytes result sent to driver
2019-06-11 09:22:55,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 98.0 (TID 66) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:22:55,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2019-06-11 09:22:55,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 98 (parallelize at Transform.scala:16) finished in 0.031 s
2019-06-11 09:22:55,055  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:22:55,056  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:22:55,056  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 99)
2019-06-11 09:22:55,056  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:22:55,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 99 (MapPartitionsRDD[120] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:55,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:22:55,071  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:22:55,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_42_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:55,073  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 21
2019-06-11 09:22:55,073  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_50_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:55,073  INFO [org.apache.spark.SparkContext] - Created broadcast 50 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:55,074  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[120] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:22:55,074  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 99.0 with 1 tasks
2019-06-11 09:22:55,074  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_44_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:55,075  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 99.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:55,075  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 99.0 (TID 67)
2019-06-11 09:22:55,075  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 28
2019-06-11 09:22:55,076  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_32_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:22:55,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:55,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:55,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:55,078  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:55,079  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_40_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:22:55,080  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 99.0 (TID 67). 966 bytes result sent to driver
2019-06-11 09:22:55,080  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 19
2019-06-11 09:22:55,082  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 99.0 (TID 67) in 7 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:55,082  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2019-06-11 09:22:55,082  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 99 (print at Transform.scala:36) finished in 0.008 s
2019-06-11 09:22:55,083  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_39_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,083  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 33 finished: print at Transform.scala:36, took 0.066445 s
2019-06-11 09:22:55,085  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 17
2019-06-11 09:22:55,089  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_27_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,092  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_43_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:55,093  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:22:55,094  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 32 is 83 bytes
2019-06-11 09:22:55,094  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_41_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,094  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 33 is 160 bytes
2019-06-11 09:22:55,094  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 26
2019-06-11 09:22:55,095  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 18
2019-06-11 09:22:55,095  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 20
2019-06-11 09:22:55,095  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 34 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:22:55,095  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 102 (print at Transform.scala:36)
2019-06-11 09:22:55,095  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 100, ShuffleMapStage 101)
2019-06-11 09:22:55,095  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 15
2019-06-11 09:22:55,096  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:22:55,096  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 102 (MapPartitionsRDD[120] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:22:55,097  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_48_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,098  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:22:55,099  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_34_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:55,099  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 24
2019-06-11 09:22:55,099  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:22:55,100  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_51_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,100  INFO [org.apache.spark.SparkContext] - Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:22:55,100  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_30_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,101  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[120] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:22:55,101  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 102.0 with 1 tasks
2019-06-11 09:22:55,101  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 22
2019-06-11 09:22:55,101  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 14
2019-06-11 09:22:55,101  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 102.0 (TID 68, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:22:55,102  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 102.0 (TID 68)
2019-06-11 09:22:55,102  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_38_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,105  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_28_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:55,105  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:22:55,105  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:55,106  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:22:55,106  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:22:55,106  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_33_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,107  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 102.0 (TID 68). 1009 bytes result sent to driver
2019-06-11 09:22:55,107  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_45_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,107  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 102.0 (TID 68) in 6 ms on localhost (executor driver) (1/1)
2019-06-11 09:22:55,108  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2019-06-11 09:22:55,108  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 27
2019-06-11 09:22:55,108  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 102 (print at Transform.scala:36) finished in 0.007 s
2019-06-11 09:22:55,108  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 25
2019-06-11 09:22:55,108  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 16
2019-06-11 09:22:55,108  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 34 finished: print at Transform.scala:36, took 0.015019 s
2019-06-11 09:22:55,109  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216175000 ms.0 from job set of time 1560216175000 ms
2019-06-11 09:22:55,109  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.109 s for time 1560216175000 ms (execution: 0.097 s)
2019-06-11 09:22:55,110  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 113 from persistence list
2019-06-11 09:22:55,110  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_29_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,110  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 113
2019-06-11 09:22:55,110  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 108 from persistence list
2019-06-11 09:22:55,111  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 108
2019-06-11 09:22:55,111  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 107 from persistence list
2019-06-11 09:22:55,111  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 107
2019-06-11 09:22:55,111  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[107] at socketTextStream at Transform.scala:18 of time 1560216175000 ms
2019-06-11 09:22:55,111  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216165000 ms
2019-06-11 09:22:55,111  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216165000 ms
2019-06-11 09:22:55,113  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_35_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,114  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_36_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,115  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 23
2019-06-11 09:22:55,116  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_31_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:55,117  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 29
2019-06-11 09:22:55,119  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_37_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:22:55,121  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_47_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:22:55,122  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_46_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:00,015  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216180000 ms
2019-06-11 09:23:00,016  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216180000 ms.0 from job set of time 1560216180000 ms
2019-06-11 09:23:00,022  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 122 (map at Transform.scala:20)
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 35 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 105 (print at Transform.scala:36)
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 103, ShuffleMapStage 104)
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 103)
2019-06-11 09:23:00,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 103 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:00,024  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:00,025  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_52_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_52_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:00,026  INFO [org.apache.spark.SparkContext] - Created broadcast 52 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:00,026  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 103 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:00,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 103.0 with 2 tasks
2019-06-11 09:23:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 103.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:00,027  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 103.0 (TID 69)
2019-06-11 09:23:00,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 103.0 (TID 69). 853 bytes result sent to driver
2019-06-11 09:23:00,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 103.0 (TID 70, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:00,042  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 103.0 (TID 70)
2019-06-11 09:23:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 103.0 (TID 69) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:00,059  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 103.0 (TID 70). 853 bytes result sent to driver
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 103.0 (TID 70) in 19 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 103 (parallelize at Transform.scala:16) finished in 0.034 s
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 105)
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 105 (MapPartitionsRDD[127] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:00,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:00,063  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_53_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:00,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_53_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:00,064  INFO [org.apache.spark.SparkContext] - Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:00,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[127] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:00,064  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 105.0 with 1 tasks
2019-06-11 09:23:00,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 105.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:00,065  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 105.0 (TID 71)
2019-06-11 09:23:00,068  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:00,068  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:00,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:00,070  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:23:00,071  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 105.0 (TID 71). 1009 bytes result sent to driver
2019-06-11 09:23:00,072  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 105.0 (TID 71) in 8 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:00,072  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2019-06-11 09:23:00,072  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 105 (print at Transform.scala:36) finished in 0.008 s
2019-06-11 09:23:00,072  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 35 finished: print at Transform.scala:36, took 0.050082 s
2019-06-11 09:23:00,075  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:00,076  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 35 is 160 bytes
2019-06-11 09:23:00,076  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 34 is 83 bytes
2019-06-11 09:23:00,076  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 36 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:00,076  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 108 (print at Transform.scala:36)
2019-06-11 09:23:00,076  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 107, ShuffleMapStage 106)
2019-06-11 09:23:00,076  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:00,077  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 108 (MapPartitionsRDD[127] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:00,078  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:00,079  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_54_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:00,080  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_54_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:00,080  INFO [org.apache.spark.SparkContext] - Created broadcast 54 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:00,081  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[127] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:00,081  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 108.0 with 1 tasks
2019-06-11 09:23:00,081  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 108.0 (TID 72, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:00,082  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 108.0 (TID 72)
2019-06-11 09:23:00,085  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:00,085  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:00,086  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:00,086  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:00,098  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 108.0 (TID 72). 1052 bytes result sent to driver
2019-06-11 09:23:00,099  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 108.0 (TID 72) in 18 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:00,099  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2019-06-11 09:23:00,100  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 108 (print at Transform.scala:36) finished in 0.018 s
2019-06-11 09:23:00,101  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 36 finished: print at Transform.scala:36, took 0.025221 s
2019-06-11 09:23:00,102  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216180000 ms.0 from job set of time 1560216180000 ms
2019-06-11 09:23:00,103  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 120 from persistence list
2019-06-11 09:23:00,103  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.102 s for time 1560216180000 ms (execution: 0.086 s)
2019-06-11 09:23:00,103  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 120
2019-06-11 09:23:00,103  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 115 from persistence list
2019-06-11 09:23:00,104  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 115
2019-06-11 09:23:00,104  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 114 from persistence list
2019-06-11 09:23:00,104  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 114
2019-06-11 09:23:00,104  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[114] at socketTextStream at Transform.scala:18 of time 1560216180000 ms
2019-06-11 09:23:00,104  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216170000 ms
2019-06-11 09:23:00,104  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216170000 ms
2019-06-11 09:23:05,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216185000 ms
2019-06-11 09:23:05,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216185000 ms.0 from job set of time 1560216185000 ms
2019-06-11 09:23:05,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 129 (map at Transform.scala:20)
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 37 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 111 (print at Transform.scala:36)
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 109, ShuffleMapStage 110)
2019-06-11 09:23:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 109)
2019-06-11 09:23:05,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 109 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:05,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_55 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:05,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_55_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:05,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_55_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:05,020  INFO [org.apache.spark.SparkContext] - Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:05,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 109 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:05,020  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 109.0 with 2 tasks
2019-06-11 09:23:05,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 109.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:05,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 109.0 (TID 73)
2019-06-11 09:23:05,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 109.0 (TID 73). 853 bytes result sent to driver
2019-06-11 09:23:05,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 109.0 (TID 74, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:05,034  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 109.0 (TID 74)
2019-06-11 09:23:05,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 109.0 (TID 73) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:05,044  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 109.0 (TID 74). 810 bytes result sent to driver
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 109.0 (TID 74) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 109 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 111)
2019-06-11 09:23:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 111 (MapPartitionsRDD[134] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:05,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_56 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:05,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_56_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:05,050  INFO [org.apache.spark.SparkContext] - Created broadcast 56 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:05,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[134] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:05,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 111.0 with 1 tasks
2019-06-11 09:23:05,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 111.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:05,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 111.0 (TID 75)
2019-06-11 09:23:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:05,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 111.0 (TID 75). 1009 bytes result sent to driver
2019-06-11 09:23:05,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 111.0 (TID 75) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:05,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2019-06-11 09:23:05,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 111 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:05,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 37 finished: print at Transform.scala:36, took 0.042498 s
2019-06-11 09:23:05,057  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:05,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 37 is 160 bytes
2019-06-11 09:23:05,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 36 is 83 bytes
2019-06-11 09:23:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 38 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 114 (print at Transform.scala:36)
2019-06-11 09:23:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 112, ShuffleMapStage 113)
2019-06-11 09:23:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:05,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 114 (MapPartitionsRDD[134] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:05,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_57 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:05,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:05,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_57_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:05,061  INFO [org.apache.spark.SparkContext] - Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:05,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[134] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:05,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 114.0 with 1 tasks
2019-06-11 09:23:05,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 114.0 (TID 76, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:05,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 114.0 (TID 76)
2019-06-11 09:23:05,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:05,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:23:05,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:05,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:05,070  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 114.0 (TID 76). 966 bytes result sent to driver
2019-06-11 09:23:05,071  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 114.0 (TID 76) in 9 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:05,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2019-06-11 09:23:05,071  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 114 (print at Transform.scala:36) finished in 0.009 s
2019-06-11 09:23:05,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 38 finished: print at Transform.scala:36, took 0.013541 s
2019-06-11 09:23:05,071  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216185000 ms.0 from job set of time 1560216185000 ms
2019-06-11 09:23:05,072  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.071 s for time 1560216185000 ms (execution: 0.062 s)
2019-06-11 09:23:05,072  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 127 from persistence list
2019-06-11 09:23:05,072  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 127
2019-06-11 09:23:05,072  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 122 from persistence list
2019-06-11 09:23:05,072  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 122
2019-06-11 09:23:05,073  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 121 from persistence list
2019-06-11 09:23:05,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 121
2019-06-11 09:23:05,073  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[121] at socketTextStream at Transform.scala:18 of time 1560216185000 ms
2019-06-11 09:23:05,073  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216175000 ms
2019-06-11 09:23:05,073  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216175000 ms
2019-06-11 09:23:10,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216190000 ms
2019-06-11 09:23:10,013  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216190000 ms.0 from job set of time 1560216190000 ms
2019-06-11 09:23:10,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 136 (map at Transform.scala:20)
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 39 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 117 (print at Transform.scala:36)
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 115, ShuffleMapStage 116)
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 115)
2019-06-11 09:23:10,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 115 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:10,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_58 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:10,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_58_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:10,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_58_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:10,018  INFO [org.apache.spark.SparkContext] - Created broadcast 58 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:10,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 115 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:10,018  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 115.0 with 2 tasks
2019-06-11 09:23:10,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 115.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:10,019  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 115.0 (TID 77)
2019-06-11 09:23:10,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 115.0 (TID 77). 810 bytes result sent to driver
2019-06-11 09:23:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 115.0 (TID 78, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:10,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 115.0 (TID 78)
2019-06-11 09:23:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 115.0 (TID 77) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:10,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 115.0 (TID 78). 810 bytes result sent to driver
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 115.0 (TID 78) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 115 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 117)
2019-06-11 09:23:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 117 (MapPartitionsRDD[141] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_59 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:10,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:10,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_59_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:10,040  INFO [org.apache.spark.SparkContext] - Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[141] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 117.0 with 1 tasks
2019-06-11 09:23:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 117.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:10,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 117.0 (TID 79)
2019-06-11 09:23:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:10,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 117.0 (TID 79). 1009 bytes result sent to driver
2019-06-11 09:23:10,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 117.0 (TID 79) in 13 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:10,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2019-06-11 09:23:10,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 117 (print at Transform.scala:36) finished in 0.013 s
2019-06-11 09:23:10,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 39 finished: print at Transform.scala:36, took 0.040452 s
2019-06-11 09:23:10,058  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:10,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 39 is 160 bytes
2019-06-11 09:23:10,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 38 is 83 bytes
2019-06-11 09:23:10,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 40 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:10,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 120 (print at Transform.scala:36)
2019-06-11 09:23:10,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 118, ShuffleMapStage 119)
2019-06-11 09:23:10,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:10,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 120 (MapPartitionsRDD[141] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:10,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_60 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:10,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:10,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_60_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:10,062  INFO [org.apache.spark.SparkContext] - Created broadcast 60 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:10,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[141] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:10,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 120.0 with 1 tasks
2019-06-11 09:23:10,063  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 120.0 (TID 80, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:10,063  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 120.0 (TID 80)
2019-06-11 09:23:10,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:10,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:10,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:10,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:10,066  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 120.0 (TID 80). 1009 bytes result sent to driver
2019-06-11 09:23:10,066  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 120.0 (TID 80) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:10,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2019-06-11 09:23:10,066  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 120 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:10,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 40 finished: print at Transform.scala:36, took 0.008568 s
2019-06-11 09:23:10,067  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216190000 ms.0 from job set of time 1560216190000 ms
2019-06-11 09:23:10,067  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.067 s for time 1560216190000 ms (execution: 0.055 s)
2019-06-11 09:23:10,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 134 from persistence list
2019-06-11 09:23:10,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 134
2019-06-11 09:23:10,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 129 from persistence list
2019-06-11 09:23:10,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 129
2019-06-11 09:23:10,068  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 128 from persistence list
2019-06-11 09:23:10,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 128
2019-06-11 09:23:10,068  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[128] at socketTextStream at Transform.scala:18 of time 1560216190000 ms
2019-06-11 09:23:10,068  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216180000 ms
2019-06-11 09:23:10,068  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216180000 ms
2019-06-11 09:23:15,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216195000 ms
2019-06-11 09:23:15,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216195000 ms.0 from job set of time 1560216195000 ms
2019-06-11 09:23:15,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 143 (map at Transform.scala:20)
2019-06-11 09:23:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 41 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:15,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 123 (print at Transform.scala:36)
2019-06-11 09:23:15,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 121, ShuffleMapStage 122)
2019-06-11 09:23:15,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 122)
2019-06-11 09:23:15,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 122 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:15,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_61 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:15,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_61_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:15,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_61_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:15,014  INFO [org.apache.spark.SparkContext] - Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:15,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 122 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:15,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 122.0 with 2 tasks
2019-06-11 09:23:15,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 122.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:15,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 122.0 (TID 81)
2019-06-11 09:23:15,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 122.0 (TID 81). 767 bytes result sent to driver
2019-06-11 09:23:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 122.0 (TID 82, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:15,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 122.0 (TID 82)
2019-06-11 09:23:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 122.0 (TID 81) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:15,041  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 122.0 (TID 82). 853 bytes result sent to driver
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 122.0 (TID 82) in 17 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 122 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 123)
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 123 (MapPartitionsRDD[148] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:15,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_62 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:15,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:15,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_62_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:15,046  INFO [org.apache.spark.SparkContext] - Created broadcast 62 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[148] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:15,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 123.0 with 1 tasks
2019-06-11 09:23:15,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 123.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:15,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 123.0 (TID 83)
2019-06-11 09:23:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:15,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 123.0 (TID 83). 1009 bytes result sent to driver
2019-06-11 09:23:15,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 123.0 (TID 83) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:15,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 123.0, whose tasks have all completed, from pool 
2019-06-11 09:23:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 123 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 41 finished: print at Transform.scala:36, took 0.040242 s
2019-06-11 09:23:15,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:15,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 40 is 83 bytes
2019-06-11 09:23:15,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 41 is 160 bytes
2019-06-11 09:23:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 42 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 126 (print at Transform.scala:36)
2019-06-11 09:23:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 125, ShuffleMapStage 124)
2019-06-11 09:23:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 126 (MapPartitionsRDD[148] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:15,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_63 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:15,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:15,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_63_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:15,058  INFO [org.apache.spark.SparkContext] - Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:15,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[148] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:15,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 126.0 with 1 tasks
2019-06-11 09:23:15,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 126.0 (TID 84, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:15,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 126.0 (TID 84)
2019-06-11 09:23:15,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:15,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:15,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:15,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:15,062  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 126.0 (TID 84). 1009 bytes result sent to driver
2019-06-11 09:23:15,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 126.0 (TID 84) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:15,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2019-06-11 09:23:15,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 126 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:15,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 42 finished: print at Transform.scala:36, took 0.008396 s
2019-06-11 09:23:15,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216195000 ms.0 from job set of time 1560216195000 ms
2019-06-11 09:23:15,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.063 s for time 1560216195000 ms (execution: 0.055 s)
2019-06-11 09:23:15,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 141 from persistence list
2019-06-11 09:23:15,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 141
2019-06-11 09:23:15,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 136 from persistence list
2019-06-11 09:23:15,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 136
2019-06-11 09:23:15,064  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 135 from persistence list
2019-06-11 09:23:15,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 135
2019-06-11 09:23:15,064  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[135] at socketTextStream at Transform.scala:18 of time 1560216195000 ms
2019-06-11 09:23:15,064  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216185000 ms
2019-06-11 09:23:15,064  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216185000 ms
2019-06-11 09:23:20,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216200000 ms
2019-06-11 09:23:20,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216200000 ms.0 from job set of time 1560216200000 ms
2019-06-11 09:23:20,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 150 (map at Transform.scala:20)
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 43 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 129 (print at Transform.scala:36)
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 127, ShuffleMapStage 128)
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 127)
2019-06-11 09:23:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 127 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:20,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_64 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:20,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_64_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:20,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_64_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:20,015  INFO [org.apache.spark.SparkContext] - Created broadcast 64 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:20,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 127 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:20,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 127.0 with 2 tasks
2019-06-11 09:23:20,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 127.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:20,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 127.0 (TID 85)
2019-06-11 09:23:20,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 127.0 (TID 85). 767 bytes result sent to driver
2019-06-11 09:23:20,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 127.0 (TID 86, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:20,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 127.0 (TID 86)
2019-06-11 09:23:20,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 127.0 (TID 85) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:20,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 127.0 (TID 86). 853 bytes result sent to driver
2019-06-11 09:23:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 127.0 (TID 86) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 127.0, whose tasks have all completed, from pool 
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 127 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 129)
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 129 (MapPartitionsRDD[155] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_65 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:20,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:20,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_65_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:20,037  INFO [org.apache.spark.SparkContext] - Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[155] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:20,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 129.0 with 1 tasks
2019-06-11 09:23:20,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 129.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:20,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 129.0 (TID 87)
2019-06-11 09:23:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:20,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 129.0 (TID 87). 1009 bytes result sent to driver
2019-06-11 09:23:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 129.0 (TID 87) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 129.0, whose tasks have all completed, from pool 
2019-06-11 09:23:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 129 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 43 finished: print at Transform.scala:36, took 0.031671 s
2019-06-11 09:23:20,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:20,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 43 is 160 bytes
2019-06-11 09:23:20,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 42 is 83 bytes
2019-06-11 09:23:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 44 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 132 (print at Transform.scala:36)
2019-06-11 09:23:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 130, ShuffleMapStage 131)
2019-06-11 09:23:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 132 (MapPartitionsRDD[155] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:20,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_66 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:20,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_66_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:20,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_66_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:20,051  INFO [org.apache.spark.SparkContext] - Created broadcast 66 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:20,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[155] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:20,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 132.0 with 1 tasks
2019-06-11 09:23:20,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 132.0 (TID 88, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:20,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 132.0 (TID 88)
2019-06-11 09:23:20,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:20,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:20,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:20,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:20,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 132.0 (TID 88). 966 bytes result sent to driver
2019-06-11 09:23:20,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 132.0 (TID 88) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:20,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2019-06-11 09:23:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 132 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 44 finished: print at Transform.scala:36, took 0.007081 s
2019-06-11 09:23:20,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216200000 ms.0 from job set of time 1560216200000 ms
2019-06-11 09:23:20,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560216200000 ms (execution: 0.046 s)
2019-06-11 09:23:20,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 148 from persistence list
2019-06-11 09:23:20,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 148
2019-06-11 09:23:20,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 143 from persistence list
2019-06-11 09:23:20,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 143
2019-06-11 09:23:20,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 142 from persistence list
2019-06-11 09:23:20,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 142
2019-06-11 09:23:20,056  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[142] at socketTextStream at Transform.scala:18 of time 1560216200000 ms
2019-06-11 09:23:20,056  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216190000 ms
2019-06-11 09:23:20,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216190000 ms
2019-06-11 09:23:25,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216205000 ms
2019-06-11 09:23:25,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216205000 ms.0 from job set of time 1560216205000 ms
2019-06-11 09:23:25,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 157 (map at Transform.scala:20)
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 45 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 135 (print at Transform.scala:36)
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 133, ShuffleMapStage 134)
2019-06-11 09:23:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 133)
2019-06-11 09:23:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 133 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:25,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_67 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:25,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_67_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:23:25,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_67_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:25,013  INFO [org.apache.spark.SparkContext] - Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:25,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 133 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:25,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 133.0 with 2 tasks
2019-06-11 09:23:25,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 133.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:25,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 133.0 (TID 89)
2019-06-11 09:23:25,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 133.0 (TID 89). 810 bytes result sent to driver
2019-06-11 09:23:25,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 133.0 (TID 90, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:25,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 133.0 (TID 90)
2019-06-11 09:23:25,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 133.0 (TID 89) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:25,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 133.0 (TID 90). 810 bytes result sent to driver
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 133.0 (TID 90) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 133.0, whose tasks have all completed, from pool 
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 133 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 135)
2019-06-11 09:23:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 135 (MapPartitionsRDD[162] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:25,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_68 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:23:25,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_68_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:25,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_68_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:25,043  INFO [org.apache.spark.SparkContext] - Created broadcast 68 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[162] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:25,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 135.0 with 1 tasks
2019-06-11 09:23:25,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 135.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:25,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 135.0 (TID 91)
2019-06-11 09:23:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:25,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:25,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:25,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 135.0 (TID 91). 1009 bytes result sent to driver
2019-06-11 09:23:25,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 135.0 (TID 91) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:25,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 135.0, whose tasks have all completed, from pool 
2019-06-11 09:23:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 135 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 45 finished: print at Transform.scala:36, took 0.036049 s
2019-06-11 09:23:25,050  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:25,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 45 is 160 bytes
2019-06-11 09:23:25,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 44 is 83 bytes
2019-06-11 09:23:25,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 46 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:25,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 138 (print at Transform.scala:36)
2019-06-11 09:23:25,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 136, ShuffleMapStage 137)
2019-06-11 09:23:25,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 138 (MapPartitionsRDD[162] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:25,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_69 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:23:25,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:25,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_69_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:25,054  INFO [org.apache.spark.SparkContext] - Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:25,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[162] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:25,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 138.0 with 1 tasks
2019-06-11 09:23:25,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 138.0 (TID 92, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:25,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 138.0 (TID 92)
2019-06-11 09:23:25,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:25,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:25,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:25,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:25,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 138.0 (TID 92). 966 bytes result sent to driver
2019-06-11 09:23:25,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 138.0 (TID 92) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:25,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2019-06-11 09:23:25,057  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 138 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:25,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 46 finished: print at Transform.scala:36, took 0.007015 s
2019-06-11 09:23:25,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216205000 ms.0 from job set of time 1560216205000 ms
2019-06-11 09:23:25,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 155 from persistence list
2019-06-11 09:23:25,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560216205000 ms (execution: 0.051 s)
2019-06-11 09:23:25,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 155
2019-06-11 09:23:25,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 150 from persistence list
2019-06-11 09:23:25,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 150
2019-06-11 09:23:25,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 149 from persistence list
2019-06-11 09:23:25,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 149
2019-06-11 09:23:25,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[149] at socketTextStream at Transform.scala:18 of time 1560216205000 ms
2019-06-11 09:23:25,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216195000 ms
2019-06-11 09:23:25,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216195000 ms
2019-06-11 09:23:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216210000 ms
2019-06-11 09:23:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216210000 ms.0 from job set of time 1560216210000 ms
2019-06-11 09:23:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 164 (map at Transform.scala:20)
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 47 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 141 (print at Transform.scala:36)
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 139, ShuffleMapStage 140)
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 139)
2019-06-11 09:23:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 139 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:30,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_70 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:30,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_70_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:23:30,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_70_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:23:30,013  INFO [org.apache.spark.SparkContext] - Created broadcast 70 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:30,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 139 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:30,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 139.0 with 2 tasks
2019-06-11 09:23:30,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 139.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:30,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 139.0 (TID 93)
2019-06-11 09:23:30,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 139.0 (TID 93). 810 bytes result sent to driver
2019-06-11 09:23:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 139.0 (TID 94, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:30,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 139.0 (TID 94)
2019-06-11 09:23:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 139.0 (TID 93) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 139.0 (TID 94). 810 bytes result sent to driver
2019-06-11 09:23:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 139.0 (TID 94) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 139.0, whose tasks have all completed, from pool 
2019-06-11 09:23:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 139 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:23:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 141)
2019-06-11 09:23:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 141 (MapPartitionsRDD[169] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:30,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_71 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:23:30,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:30,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_71_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:30,036  INFO [org.apache.spark.SparkContext] - Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[169] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:30,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 141.0 with 1 tasks
2019-06-11 09:23:30,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 141.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:30,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 141.0 (TID 95)
2019-06-11 09:23:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:30,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 141.0 (TID 95). 1009 bytes result sent to driver
2019-06-11 09:23:30,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 141.0 (TID 95) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:30,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 141.0, whose tasks have all completed, from pool 
2019-06-11 09:23:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 141 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 47 finished: print at Transform.scala:36, took 0.030654 s
2019-06-11 09:23:30,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:30,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 47 is 160 bytes
2019-06-11 09:23:30,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 46 is 83 bytes
2019-06-11 09:23:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 48 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 144 (print at Transform.scala:36)
2019-06-11 09:23:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 143, ShuffleMapStage 142)
2019-06-11 09:23:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 144 (MapPartitionsRDD[169] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:30,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_72 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:23:30,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:30,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_72_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:30,047  INFO [org.apache.spark.SparkContext] - Created broadcast 72 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[169] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:30,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 144.0 with 1 tasks
2019-06-11 09:23:30,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 144.0 (TID 96, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:30,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 144.0 (TID 96)
2019-06-11 09:23:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:30,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 144.0 (TID 96). 1009 bytes result sent to driver
2019-06-11 09:23:30,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 144.0 (TID 96) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:30,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2019-06-11 09:23:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 144 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 48 finished: print at Transform.scala:36, took 0.009085 s
2019-06-11 09:23:30,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216210000 ms.0 from job set of time 1560216210000 ms
2019-06-11 09:23:30,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216210000 ms (execution: 0.045 s)
2019-06-11 09:23:30,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 162 from persistence list
2019-06-11 09:23:30,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 162
2019-06-11 09:23:30,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 157 from persistence list
2019-06-11 09:23:30,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 157
2019-06-11 09:23:30,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 156 from persistence list
2019-06-11 09:23:30,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 156
2019-06-11 09:23:30,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[156] at socketTextStream at Transform.scala:18 of time 1560216210000 ms
2019-06-11 09:23:30,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216200000 ms
2019-06-11 09:23:30,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216200000 ms
2019-06-11 09:23:35,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216215000 ms
2019-06-11 09:23:35,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216215000 ms.0 from job set of time 1560216215000 ms
2019-06-11 09:23:35,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 171 (map at Transform.scala:20)
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 49 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 147 (print at Transform.scala:36)
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 145, ShuffleMapStage 146)
2019-06-11 09:23:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 145)
2019-06-11 09:23:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 145 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_73 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:23:35,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 34
2019-06-11 09:23:35,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_73_piece0 stored as bytes in memory (estimated size 1308.0 B, free 1989.4 MB)
2019-06-11 09:23:35,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_73_piece0 in memory on 192.168.91.1:63518 (size: 1308.0 B, free: 1989.5 MB)
2019-06-11 09:23:35,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_60_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:35,024  INFO [org.apache.spark.SparkContext] - Created broadcast 73 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:35,025  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 145 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:35,025  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 145.0 with 2 tasks
2019-06-11 09:23:35,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_69_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:35,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 145.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:35,025  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 145.0 (TID 97)
2019-06-11 09:23:35,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_54_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:35,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_71_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:23:35,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 39
2019-06-11 09:23:35,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_53_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 35
2019-06-11 09:23:35,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 38
2019-06-11 09:23:35,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_62_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_58_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_65_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 40
2019-06-11 09:23:35,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 41
2019-06-11 09:23:35,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_66_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,037  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 45
2019-06-11 09:23:35,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_67_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_70_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 145.0 (TID 97). 810 bytes result sent to driver
2019-06-11 09:23:35,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 145.0 (TID 98, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:35,039  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 145.0 (TID 98)
2019-06-11 09:23:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 145.0 (TID 97) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:35,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_51_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_52_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_56_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 37
2019-06-11 09:23:35,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_57_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_50_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 36
2019-06-11 09:23:35,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_55_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 43
2019-06-11 09:23:35,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 30
2019-06-11 09:23:35,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_61_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_63_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 44
2019-06-11 09:23:35,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_49_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 31
2019-06-11 09:23:35,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 32
2019-06-11 09:23:35,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_72_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,054  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 145.0 (TID 98). 853 bytes result sent to driver
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 145.0 (TID 98) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 145.0, whose tasks have all completed, from pool 
2019-06-11 09:23:35,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_59_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 145 (parallelize at Transform.scala:16) finished in 0.029 s
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 147)
2019-06-11 09:23:35,054  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:35,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 42
2019-06-11 09:23:35,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 147 (MapPartitionsRDD[176] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:35,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_68_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 33
2019-06-11 09:23:35,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_74 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:35,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_64_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:35,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_74_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:35,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_74_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,058  INFO [org.apache.spark.SparkContext] - Created broadcast 74 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:35,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[176] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:35,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 147.0 with 1 tasks
2019-06-11 09:23:35,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 147.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:35,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 147.0 (TID 99)
2019-06-11 09:23:35,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:35,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:35,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:35,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:35,062  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 147.0 (TID 99). 1009 bytes result sent to driver
2019-06-11 09:23:35,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 147.0 (TID 99) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:35,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2019-06-11 09:23:35,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 147 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:35,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 49 finished: print at Transform.scala:36, took 0.052808 s
2019-06-11 09:23:35,067  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:35,068  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 49 is 160 bytes
2019-06-11 09:23:35,068  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 48 is 83 bytes
2019-06-11 09:23:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 50 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 150 (print at Transform.scala:36)
2019-06-11 09:23:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 148, ShuffleMapStage 149)
2019-06-11 09:23:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 150 (MapPartitionsRDD[176] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:35,069  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_75 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:35,070  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_75_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:35,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_75_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:35,071  INFO [org.apache.spark.SparkContext] - Created broadcast 75 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:35,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[176] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:35,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 150.0 with 1 tasks
2019-06-11 09:23:35,072  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 150.0 (TID 100, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:35,072  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 150.0 (TID 100)
2019-06-11 09:23:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:35,074  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 150.0 (TID 100). 1009 bytes result sent to driver
2019-06-11 09:23:35,075  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 150.0 (TID 100) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:35,075  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2019-06-11 09:23:35,075  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 150 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:35,075  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 50 finished: print at Transform.scala:36, took 0.007766 s
2019-06-11 09:23:35,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216215000 ms.0 from job set of time 1560216215000 ms
2019-06-11 09:23:35,076  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.075 s for time 1560216215000 ms (execution: 0.067 s)
2019-06-11 09:23:35,076  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 169 from persistence list
2019-06-11 09:23:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 169
2019-06-11 09:23:35,076  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 164 from persistence list
2019-06-11 09:23:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 164
2019-06-11 09:23:35,076  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 163 from persistence list
2019-06-11 09:23:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 163
2019-06-11 09:23:35,077  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[163] at socketTextStream at Transform.scala:18 of time 1560216215000 ms
2019-06-11 09:23:35,077  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216205000 ms
2019-06-11 09:23:35,077  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216205000 ms
2019-06-11 09:23:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216220000 ms
2019-06-11 09:23:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216220000 ms.0 from job set of time 1560216220000 ms
2019-06-11 09:23:40,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 178 (map at Transform.scala:20)
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 51 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 153 (print at Transform.scala:36)
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 151, ShuffleMapStage 152)
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 151)
2019-06-11 09:23:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 151 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_76 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:40,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_76_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:40,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_76_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:40,013  INFO [org.apache.spark.SparkContext] - Created broadcast 76 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:40,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 151 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:40,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 151.0 with 2 tasks
2019-06-11 09:23:40,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 151.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:40,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 151.0 (TID 101)
2019-06-11 09:23:40,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 151.0 (TID 101). 853 bytes result sent to driver
2019-06-11 09:23:40,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 151.0 (TID 102, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:40,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 151.0 (TID 102)
2019-06-11 09:23:40,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 151.0 (TID 101) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:40,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 151.0 (TID 102). 810 bytes result sent to driver
2019-06-11 09:23:40,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 151.0 (TID 102) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:40,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 151.0, whose tasks have all completed, from pool 
2019-06-11 09:23:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 151 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:23:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 153)
2019-06-11 09:23:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 153 (MapPartitionsRDD[183] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_77 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_77_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 77 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[183] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 153.0 with 1 tasks
2019-06-11 09:23:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 153.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 153.0 (TID 103)
2019-06-11 09:23:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:40,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 153.0 (TID 103). 966 bytes result sent to driver
2019-06-11 09:23:40,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 153.0 (TID 103) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 153.0, whose tasks have all completed, from pool 
2019-06-11 09:23:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 153 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 51 finished: print at Transform.scala:36, took 0.031061 s
2019-06-11 09:23:40,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:40,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 51 is 160 bytes
2019-06-11 09:23:40,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 50 is 83 bytes
2019-06-11 09:23:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 52 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 156 (print at Transform.scala:36)
2019-06-11 09:23:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 154, ShuffleMapStage 155)
2019-06-11 09:23:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 156 (MapPartitionsRDD[183] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:40,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_78 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:40,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:40,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_78_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:40,047  INFO [org.apache.spark.SparkContext] - Created broadcast 78 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:40,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[183] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:40,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 156.0 with 1 tasks
2019-06-11 09:23:40,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 156.0 (TID 104, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:40,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 156.0 (TID 104)
2019-06-11 09:23:40,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:40,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:40,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:40,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:40,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 156.0 (TID 104). 1009 bytes result sent to driver
2019-06-11 09:23:40,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 156.0 (TID 104) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:40,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2019-06-11 09:23:40,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 156 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:40,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 52 finished: print at Transform.scala:36, took 0.007802 s
2019-06-11 09:23:40,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216220000 ms.0 from job set of time 1560216220000 ms
2019-06-11 09:23:40,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.051 s for time 1560216220000 ms (execution: 0.044 s)
2019-06-11 09:23:40,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 176 from persistence list
2019-06-11 09:23:40,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 176
2019-06-11 09:23:40,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 171 from persistence list
2019-06-11 09:23:40,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 171
2019-06-11 09:23:40,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 170 from persistence list
2019-06-11 09:23:40,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 170
2019-06-11 09:23:40,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[170] at socketTextStream at Transform.scala:18 of time 1560216220000 ms
2019-06-11 09:23:40,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216210000 ms
2019-06-11 09:23:40,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216210000 ms
2019-06-11 09:23:45,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216225000 ms
2019-06-11 09:23:45,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216225000 ms.0 from job set of time 1560216225000 ms
2019-06-11 09:23:45,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 185 (map at Transform.scala:20)
2019-06-11 09:23:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 53 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 159 (print at Transform.scala:36)
2019-06-11 09:23:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 157, ShuffleMapStage 158)
2019-06-11 09:23:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 157)
2019-06-11 09:23:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 157 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:45,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_79 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:45,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_79_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:45,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_79_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:45,014  INFO [org.apache.spark.SparkContext] - Created broadcast 79 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:45,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 157 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:45,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 157.0 with 2 tasks
2019-06-11 09:23:45,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 157.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:45,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 157.0 (TID 105)
2019-06-11 09:23:45,029  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 157.0 (TID 105). 767 bytes result sent to driver
2019-06-11 09:23:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 157.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:45,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 157.0 (TID 106)
2019-06-11 09:23:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 157.0 (TID 105) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:45,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 157.0 (TID 106). 810 bytes result sent to driver
2019-06-11 09:23:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 157.0 (TID 106) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 157.0, whose tasks have all completed, from pool 
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 157 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 159)
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 159 (MapPartitionsRDD[190] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:45,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_80 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:45,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_80_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:45,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_80_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:45,042  INFO [org.apache.spark.SparkContext] - Created broadcast 80 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:45,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[190] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:45,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 159.0 with 1 tasks
2019-06-11 09:23:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 159.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:45,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 159.0 (TID 107)
2019-06-11 09:23:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:45,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 159.0 (TID 107). 966 bytes result sent to driver
2019-06-11 09:23:45,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 159.0 (TID 107) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:45,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 159.0, whose tasks have all completed, from pool 
2019-06-11 09:23:45,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 159 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:23:45,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 53 finished: print at Transform.scala:36, took 0.034187 s
2019-06-11 09:23:45,049  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:45,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 53 is 160 bytes
2019-06-11 09:23:45,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 52 is 83 bytes
2019-06-11 09:23:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 54 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 162 (print at Transform.scala:36)
2019-06-11 09:23:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 161, ShuffleMapStage 160)
2019-06-11 09:23:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:45,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 162 (MapPartitionsRDD[190] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:45,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_81 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:45,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_81_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:45,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_81_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:45,053  INFO [org.apache.spark.SparkContext] - Created broadcast 81 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:45,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[190] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:45,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 162.0 with 1 tasks
2019-06-11 09:23:45,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 162.0 (TID 108, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:45,053  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 162.0 (TID 108)
2019-06-11 09:23:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:45,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 162.0 (TID 108). 966 bytes result sent to driver
2019-06-11 09:23:45,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 162.0 (TID 108) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:45,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2019-06-11 09:23:45,056  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 162 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:45,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 54 finished: print at Transform.scala:36, took 0.006649 s
2019-06-11 09:23:45,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216225000 ms.0 from job set of time 1560216225000 ms
2019-06-11 09:23:45,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.056 s for time 1560216225000 ms (execution: 0.047 s)
2019-06-11 09:23:45,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 183 from persistence list
2019-06-11 09:23:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 183
2019-06-11 09:23:45,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 178 from persistence list
2019-06-11 09:23:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 178
2019-06-11 09:23:45,057  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 177 from persistence list
2019-06-11 09:23:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 177
2019-06-11 09:23:45,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[177] at socketTextStream at Transform.scala:18 of time 1560216225000 ms
2019-06-11 09:23:45,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216215000 ms
2019-06-11 09:23:45,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216215000 ms
2019-06-11 09:23:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216230000 ms
2019-06-11 09:23:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216230000 ms.0 from job set of time 1560216230000 ms
2019-06-11 09:23:50,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 192 (map at Transform.scala:20)
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 55 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 165 (print at Transform.scala:36)
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 163, ShuffleMapStage 164)
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 164)
2019-06-11 09:23:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 164 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_82 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_82_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_82_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:50,012  INFO [org.apache.spark.SparkContext] - Created broadcast 82 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 164 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:50,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 164.0 with 2 tasks
2019-06-11 09:23:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 164.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 164.0 (TID 109)
2019-06-11 09:23:50,027  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 164.0 (TID 109). 853 bytes result sent to driver
2019-06-11 09:23:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 164.0 (TID 110, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:50,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 164.0 (TID 110)
2019-06-11 09:23:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 164.0 (TID 109) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:50,036  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 164.0 (TID 110). 810 bytes result sent to driver
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 164.0 (TID 110) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 164 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 165)
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 165 (MapPartitionsRDD[197] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:50,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_83 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:50,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_83_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:50,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_83_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:50,039  INFO [org.apache.spark.SparkContext] - Created broadcast 83 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[197] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:50,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 165.0 with 1 tasks
2019-06-11 09:23:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 165.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:50,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 165.0 (TID 111)
2019-06-11 09:23:50,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:50,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:50,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:50,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:50,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 165.0 (TID 111). 1009 bytes result sent to driver
2019-06-11 09:23:50,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 165.0 (TID 111) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:50,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 165.0, whose tasks have all completed, from pool 
2019-06-11 09:23:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 165 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 55 finished: print at Transform.scala:36, took 0.033726 s
2019-06-11 09:23:50,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:50,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 54 is 83 bytes
2019-06-11 09:23:50,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 55 is 160 bytes
2019-06-11 09:23:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 56 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 168 (print at Transform.scala:36)
2019-06-11 09:23:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 166, ShuffleMapStage 167)
2019-06-11 09:23:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 168 (MapPartitionsRDD[197] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:50,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_84 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:50,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_84_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:50,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_84_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:50,048  INFO [org.apache.spark.SparkContext] - Created broadcast 84 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[197] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:50,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 168.0 with 1 tasks
2019-06-11 09:23:50,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 168.0 (TID 112, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:50,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 168.0 (TID 112)
2019-06-11 09:23:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:50,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 168.0 (TID 112). 966 bytes result sent to driver
2019-06-11 09:23:50,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 168.0 (TID 112) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:50,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2019-06-11 09:23:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 168 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 56 finished: print at Transform.scala:36, took 0.006742 s
2019-06-11 09:23:50,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216230000 ms.0 from job set of time 1560216230000 ms
2019-06-11 09:23:50,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216230000 ms (execution: 0.045 s)
2019-06-11 09:23:50,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 190 from persistence list
2019-06-11 09:23:50,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 190
2019-06-11 09:23:50,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 185 from persistence list
2019-06-11 09:23:50,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 185
2019-06-11 09:23:50,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 184 from persistence list
2019-06-11 09:23:50,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 184
2019-06-11 09:23:50,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[184] at socketTextStream at Transform.scala:18 of time 1560216230000 ms
2019-06-11 09:23:50,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216220000 ms
2019-06-11 09:23:50,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216220000 ms
2019-06-11 09:23:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216235000 ms
2019-06-11 09:23:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216235000 ms.0 from job set of time 1560216235000 ms
2019-06-11 09:23:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 199 (map at Transform.scala:20)
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 57 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 171 (print at Transform.scala:36)
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 169, ShuffleMapStage 170)
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 170)
2019-06-11 09:23:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 170 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:23:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_85 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:55,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_85_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:23:55,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_85_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:23:55,013  INFO [org.apache.spark.SparkContext] - Created broadcast 85 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 170 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:23:55,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 170.0 with 2 tasks
2019-06-11 09:23:55,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 170.0 (TID 113, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:55,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 170.0 (TID 113)
2019-06-11 09:23:55,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 170.0 (TID 113). 853 bytes result sent to driver
2019-06-11 09:23:55,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 170.0 (TID 114, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:23:55,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 170.0 (TID 114)
2019-06-11 09:23:55,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 170.0 (TID 113) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:23:55,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 170.0 (TID 114). 853 bytes result sent to driver
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 170.0 (TID 114) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 170 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 171)
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:23:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 171 (MapPartitionsRDD[204] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_86 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:55,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_86_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:55,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_86_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:55,037  INFO [org.apache.spark.SparkContext] - Created broadcast 86 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 171 (MapPartitionsRDD[204] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:23:55,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 171.0 with 1 tasks
2019-06-11 09:23:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 171.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:55,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 171.0 (TID 115)
2019-06-11 09:23:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:55,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 171.0 (TID 115). 1009 bytes result sent to driver
2019-06-11 09:23:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 171.0 (TID 115) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 171.0, whose tasks have all completed, from pool 
2019-06-11 09:23:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 171 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:23:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 57 finished: print at Transform.scala:36, took 0.030771 s
2019-06-11 09:23:55,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:23:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 56 is 83 bytes
2019-06-11 09:23:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 57 is 160 bytes
2019-06-11 09:23:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 58 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:23:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 174 (print at Transform.scala:36)
2019-06-11 09:23:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 172, ShuffleMapStage 173)
2019-06-11 09:23:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:23:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 174 (MapPartitionsRDD[204] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:23:55,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_87 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:23:55,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_87_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:23:55,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_87_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:23:55,046  INFO [org.apache.spark.SparkContext] - Created broadcast 87 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:23:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[204] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:23:55,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 174.0 with 1 tasks
2019-06-11 09:23:55,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 174.0 (TID 116, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:23:55,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 174.0 (TID 116)
2019-06-11 09:23:55,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:23:55,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:55,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:23:55,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:23:55,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 174.0 (TID 116). 966 bytes result sent to driver
2019-06-11 09:23:55,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 174.0 (TID 116) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:23:55,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2019-06-11 09:23:55,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 174 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:23:55,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 58 finished: print at Transform.scala:36, took 0.007024 s
2019-06-11 09:23:55,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216235000 ms.0 from job set of time 1560216235000 ms
2019-06-11 09:23:55,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.051 s for time 1560216235000 ms (execution: 0.044 s)
2019-06-11 09:23:55,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 197 from persistence list
2019-06-11 09:23:55,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 197
2019-06-11 09:23:55,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 192 from persistence list
2019-06-11 09:23:55,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 192
2019-06-11 09:23:55,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 191 from persistence list
2019-06-11 09:23:55,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 191
2019-06-11 09:23:55,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[191] at socketTextStream at Transform.scala:18 of time 1560216235000 ms
2019-06-11 09:23:55,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216225000 ms
2019-06-11 09:23:55,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216225000 ms
2019-06-11 09:24:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216240000 ms
2019-06-11 09:24:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216240000 ms.0 from job set of time 1560216240000 ms
2019-06-11 09:24:00,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 206 (map at Transform.scala:20)
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 59 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 177 (print at Transform.scala:36)
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 176, ShuffleMapStage 175)
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 175)
2019-06-11 09:24:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 175 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_88 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:00,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_88_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:00,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_88_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:00,016  INFO [org.apache.spark.SparkContext] - Created broadcast 88 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 175 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:00,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 175.0 with 2 tasks
2019-06-11 09:24:00,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 175.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:00,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 175.0 (TID 117)
2019-06-11 09:24:00,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 175.0 (TID 117). 810 bytes result sent to driver
2019-06-11 09:24:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 175.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:00,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 175.0 (TID 118)
2019-06-11 09:24:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 175.0 (TID 117) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 175.0 (TID 118). 810 bytes result sent to driver
2019-06-11 09:24:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 175.0 (TID 118) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 175.0, whose tasks have all completed, from pool 
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 175 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 177)
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 177 (MapPartitionsRDD[211] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:00,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_89 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:00,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_89_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:00,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_89_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:00,036  INFO [org.apache.spark.SparkContext] - Created broadcast 89 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 177 (MapPartitionsRDD[211] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:00,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 177.0 with 1 tasks
2019-06-11 09:24:00,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 177.0 (TID 119, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:00,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 177.0 (TID 119)
2019-06-11 09:24:00,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:00,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:00,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 177.0 (TID 119). 966 bytes result sent to driver
2019-06-11 09:24:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 177.0 (TID 119) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 177.0, whose tasks have all completed, from pool 
2019-06-11 09:24:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 177 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 59 finished: print at Transform.scala:36, took 0.028352 s
2019-06-11 09:24:00,044  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:00,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 59 is 160 bytes
2019-06-11 09:24:00,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 58 is 83 bytes
2019-06-11 09:24:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 60 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 180 (print at Transform.scala:36)
2019-06-11 09:24:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 179, ShuffleMapStage 178)
2019-06-11 09:24:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 180 (MapPartitionsRDD[211] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:00,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_90 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:00,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_90_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:00,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_90_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:00,047  INFO [org.apache.spark.SparkContext] - Created broadcast 90 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[211] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:00,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 180.0 with 1 tasks
2019-06-11 09:24:00,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 180.0 (TID 120, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:00,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 180.0 (TID 120)
2019-06-11 09:24:00,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:00,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:00,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:00,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:00,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 180.0 (TID 120). 1009 bytes result sent to driver
2019-06-11 09:24:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 180.0 (TID 120) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:00,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2019-06-11 09:24:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 180 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 60 finished: print at Transform.scala:36, took 0.007428 s
2019-06-11 09:24:00,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216240000 ms.0 from job set of time 1560216240000 ms
2019-06-11 09:24:00,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.051 s for time 1560216240000 ms (execution: 0.041 s)
2019-06-11 09:24:00,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 204 from persistence list
2019-06-11 09:24:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 204
2019-06-11 09:24:00,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 199 from persistence list
2019-06-11 09:24:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 199
2019-06-11 09:24:00,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 198 from persistence list
2019-06-11 09:24:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 198
2019-06-11 09:24:00,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[198] at socketTextStream at Transform.scala:18 of time 1560216240000 ms
2019-06-11 09:24:00,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216230000 ms
2019-06-11 09:24:00,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216230000 ms
2019-06-11 09:24:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216245000 ms
2019-06-11 09:24:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216245000 ms.0 from job set of time 1560216245000 ms
2019-06-11 09:24:05,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 213 (map at Transform.scala:20)
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 61 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 183 (print at Transform.scala:36)
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 181, ShuffleMapStage 182)
2019-06-11 09:24:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 182)
2019-06-11 09:24:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 182 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_91 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_91_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:24:05,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_91_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:05,010  INFO [org.apache.spark.SparkContext] - Created broadcast 91 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 182 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:05,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 182.0 with 2 tasks
2019-06-11 09:24:05,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 182.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:05,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 182.0 (TID 121)
2019-06-11 09:24:05,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 182.0 (TID 121). 810 bytes result sent to driver
2019-06-11 09:24:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 182.0 (TID 122, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:05,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 182.0 (TID 122)
2019-06-11 09:24:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 182.0 (TID 121) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:05,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 182.0 (TID 122). 810 bytes result sent to driver
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 182.0 (TID 122) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 182 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 183)
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 183 (MapPartitionsRDD[218] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_92 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:05,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_92_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_92_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:05,038  INFO [org.apache.spark.SparkContext] - Created broadcast 92 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 183 (MapPartitionsRDD[218] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 183.0 with 1 tasks
2019-06-11 09:24:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 183.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:05,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 183.0 (TID 123)
2019-06-11 09:24:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:05,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 183.0 (TID 123). 1009 bytes result sent to driver
2019-06-11 09:24:05,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 183.0 (TID 123) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:05,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 183.0, whose tasks have all completed, from pool 
2019-06-11 09:24:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 183 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 61 finished: print at Transform.scala:36, took 0.035251 s
2019-06-11 09:24:05,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:05,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 60 is 83 bytes
2019-06-11 09:24:05,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 61 is 160 bytes
2019-06-11 09:24:05,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 62 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:05,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 186 (print at Transform.scala:36)
2019-06-11 09:24:05,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 184, ShuffleMapStage 185)
2019-06-11 09:24:05,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:05,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 186 (MapPartitionsRDD[218] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:05,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_93 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:05,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_93_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:05,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_93_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:05,052  INFO [org.apache.spark.SparkContext] - Created broadcast 93 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:05,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 186 (MapPartitionsRDD[218] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:05,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 186.0 with 1 tasks
2019-06-11 09:24:05,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 186.0 (TID 124, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:05,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 186.0 (TID 124)
2019-06-11 09:24:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:05,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:05,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 186.0 (TID 124). 966 bytes result sent to driver
2019-06-11 09:24:05,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 186.0 (TID 124) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:05,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2019-06-11 09:24:05,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 186 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:05,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 62 finished: print at Transform.scala:36, took 0.007669 s
2019-06-11 09:24:05,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216245000 ms.0 from job set of time 1560216245000 ms
2019-06-11 09:24:05,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560216245000 ms (execution: 0.050 s)
2019-06-11 09:24:05,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 211 from persistence list
2019-06-11 09:24:05,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 211
2019-06-11 09:24:05,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 206 from persistence list
2019-06-11 09:24:05,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 206
2019-06-11 09:24:05,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 205 from persistence list
2019-06-11 09:24:05,056  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[205] at socketTextStream at Transform.scala:18 of time 1560216245000 ms
2019-06-11 09:24:05,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 205
2019-06-11 09:24:05,056  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216235000 ms
2019-06-11 09:24:05,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216235000 ms
2019-06-11 09:24:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216250000 ms
2019-06-11 09:24:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216250000 ms.0 from job set of time 1560216250000 ms
2019-06-11 09:24:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 220 (map at Transform.scala:20)
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 63 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 189 (print at Transform.scala:36)
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 187, ShuffleMapStage 188)
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 187)
2019-06-11 09:24:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 187 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_94 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:10,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_94_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:24:10,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_94_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:10,012  INFO [org.apache.spark.SparkContext] - Created broadcast 94 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:10,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 187 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:10,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 187.0 with 2 tasks
2019-06-11 09:24:10,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 187.0 (TID 125, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:10,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 187.0 (TID 125)
2019-06-11 09:24:10,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 187.0 (TID 125). 853 bytes result sent to driver
2019-06-11 09:24:10,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 187.0 (TID 126, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:10,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 187.0 (TID 126)
2019-06-11 09:24:10,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 187.0 (TID 125) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:10,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 187.0 (TID 126). 853 bytes result sent to driver
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 187.0 (TID 126) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 187.0, whose tasks have all completed, from pool 
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 187 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 189)
2019-06-11 09:24:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 189 (MapPartitionsRDD[225] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:10,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_95 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:10,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_95_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:10,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_95_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:10,038  INFO [org.apache.spark.SparkContext] - Created broadcast 95 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[225] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:10,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 189.0 with 1 tasks
2019-06-11 09:24:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 189.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:10,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 189.0 (TID 127)
2019-06-11 09:24:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:10,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 189.0 (TID 127). 1009 bytes result sent to driver
2019-06-11 09:24:10,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 189.0 (TID 127) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 189.0, whose tasks have all completed, from pool 
2019-06-11 09:24:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 189 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 63 finished: print at Transform.scala:36, took 0.033137 s
2019-06-11 09:24:10,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:10,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 63 is 160 bytes
2019-06-11 09:24:10,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 62 is 83 bytes
2019-06-11 09:24:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 64 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 192 (print at Transform.scala:36)
2019-06-11 09:24:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 190, ShuffleMapStage 191)
2019-06-11 09:24:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 192 (MapPartitionsRDD[225] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:10,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_96 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:10,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_96_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:10,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_96_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:10,061  INFO [org.apache.spark.SparkContext] - Created broadcast 96 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:10,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_88_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:10,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 192 (MapPartitionsRDD[225] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:10,063  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 192.0 with 1 tasks
2019-06-11 09:24:10,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 192.0 (TID 128, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:10,064  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 192.0 (TID 128)
2019-06-11 09:24:10,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_78_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:10,064  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 48
2019-06-11 09:24:10,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_89_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:10,066  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 54
2019-06-11 09:24:10,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:10,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:10,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:10,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:10,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_75_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:10,067  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 56
2019-06-11 09:24:10,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_86_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,068  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 192.0 (TID 128). 1009 bytes result sent to driver
2019-06-11 09:24:10,068  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 192.0 (TID 128) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:10,068  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2019-06-11 09:24:10,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_84_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,069  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 192 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:24:10,069  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 64 finished: print at Transform.scala:36, took 0.023085 s
2019-06-11 09:24:10,069  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216250000 ms.0 from job set of time 1560216250000 ms
2019-06-11 09:24:10,070  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 218 from persistence list
2019-06-11 09:24:10,070  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.069 s for time 1560216250000 ms (execution: 0.062 s)
2019-06-11 09:24:10,070  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 218
2019-06-11 09:24:10,070  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 213 from persistence list
2019-06-11 09:24:10,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_82_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,070  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 213
2019-06-11 09:24:10,070  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 212 from persistence list
2019-06-11 09:24:10,070  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 212
2019-06-11 09:24:10,070  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[212] at socketTextStream at Transform.scala:18 of time 1560216250000 ms
2019-06-11 09:24:10,071  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216240000 ms
2019-06-11 09:24:10,071  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216240000 ms
2019-06-11 09:24:10,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_94_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,072  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 59
2019-06-11 09:24:10,072  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_85_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,073  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 51
2019-06-11 09:24:10,074  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 49
2019-06-11 09:24:10,074  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 50
2019-06-11 09:24:10,075  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_81_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,075  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 58
2019-06-11 09:24:10,076  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_73_piece0 on 192.168.91.1:63518 in memory (size: 1308.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,077  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_93_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,078  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 55
2019-06-11 09:24:10,079  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 53
2019-06-11 09:24:10,080  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_92_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,082  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_79_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,083  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_91_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,083  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 46
2019-06-11 09:24:10,085  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_83_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,086  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_90_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,087  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_80_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,088  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_74_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,088  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 57
2019-06-11 09:24:10,089  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_76_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:10,089  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 47
2019-06-11 09:24:10,090  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_77_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,091  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_87_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:10,091  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 52
2019-06-11 09:24:10,092  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_95_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216255000 ms
2019-06-11 09:24:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216255000 ms.0 from job set of time 1560216255000 ms
2019-06-11 09:24:15,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 227 (map at Transform.scala:20)
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 65 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 195 (print at Transform.scala:36)
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 194, ShuffleMapStage 193)
2019-06-11 09:24:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 194)
2019-06-11 09:24:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 194 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_97 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:15,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_97_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:15,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_97_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:15,012  INFO [org.apache.spark.SparkContext] - Created broadcast 97 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:15,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 194 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:15,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 194.0 with 2 tasks
2019-06-11 09:24:15,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 194.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:15,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 194.0 (TID 129)
2019-06-11 09:24:15,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 194.0 (TID 129). 853 bytes result sent to driver
2019-06-11 09:24:15,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 194.0 (TID 130, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:15,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 194.0 (TID 130)
2019-06-11 09:24:15,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 194.0 (TID 129) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:15,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 194.0 (TID 130). 810 bytes result sent to driver
2019-06-11 09:24:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 194.0 (TID 130) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2019-06-11 09:24:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 194 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:24:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 195)
2019-06-11 09:24:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 195 (MapPartitionsRDD[232] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:15,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_98 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:15,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_98_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:15,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_98_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:15,033  INFO [org.apache.spark.SparkContext] - Created broadcast 98 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[232] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:15,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 195.0 with 1 tasks
2019-06-11 09:24:15,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 195.0 (TID 131, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:15,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 195.0 (TID 131)
2019-06-11 09:24:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:24:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:15,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 195.0 (TID 131). 966 bytes result sent to driver
2019-06-11 09:24:15,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 195.0 (TID 131) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:15,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 195.0, whose tasks have all completed, from pool 
2019-06-11 09:24:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 195 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 65 finished: print at Transform.scala:36, took 0.027885 s
2019-06-11 09:24:15,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:15,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 64 is 83 bytes
2019-06-11 09:24:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 65 is 160 bytes
2019-06-11 09:24:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 66 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 198 (print at Transform.scala:36)
2019-06-11 09:24:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 197, ShuffleMapStage 196)
2019-06-11 09:24:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 198 (MapPartitionsRDD[232] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_99 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:15,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_99_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_99_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 99 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[232] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:15,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 198.0 with 1 tasks
2019-06-11 09:24:15,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 198.0 (TID 132, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:15,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 198.0 (TID 132)
2019-06-11 09:24:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:15,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 198.0 (TID 132). 966 bytes result sent to driver
2019-06-11 09:24:15,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 198.0 (TID 132) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:15,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2019-06-11 09:24:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 198 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:24:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 66 finished: print at Transform.scala:36, took 0.006234 s
2019-06-11 09:24:15,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216255000 ms.0 from job set of time 1560216255000 ms
2019-06-11 09:24:15,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216255000 ms (execution: 0.039 s)
2019-06-11 09:24:15,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 225 from persistence list
2019-06-11 09:24:15,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 225
2019-06-11 09:24:15,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 220 from persistence list
2019-06-11 09:24:15,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 220
2019-06-11 09:24:15,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 219 from persistence list
2019-06-11 09:24:15,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 219
2019-06-11 09:24:15,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[219] at socketTextStream at Transform.scala:18 of time 1560216255000 ms
2019-06-11 09:24:15,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216245000 ms
2019-06-11 09:24:15,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216245000 ms
2019-06-11 09:24:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216260000 ms
2019-06-11 09:24:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216260000 ms.0 from job set of time 1560216260000 ms
2019-06-11 09:24:20,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 234 (map at Transform.scala:20)
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 67 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 201 (print at Transform.scala:36)
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 199, ShuffleMapStage 200)
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 200)
2019-06-11 09:24:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 200 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_100 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:20,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_100_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:20,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_100_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:20,012  INFO [org.apache.spark.SparkContext] - Created broadcast 100 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 200 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:20,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 200.0 with 2 tasks
2019-06-11 09:24:20,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 200.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:20,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 200.0 (TID 133)
2019-06-11 09:24:20,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 200.0 (TID 133). 853 bytes result sent to driver
2019-06-11 09:24:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 200.0 (TID 134, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:20,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 200.0 (TID 134)
2019-06-11 09:24:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 200.0 (TID 133) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 200.0 (TID 134). 853 bytes result sent to driver
2019-06-11 09:24:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 200.0 (TID 134) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 200 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 201)
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 201 (MapPartitionsRDD[239] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:20,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_101 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:20,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_101_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:20,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_101_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:20,034  INFO [org.apache.spark.SparkContext] - Created broadcast 101 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 201 (MapPartitionsRDD[239] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 201.0 with 1 tasks
2019-06-11 09:24:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 201.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:20,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 201.0 (TID 135)
2019-06-11 09:24:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:20,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 201.0 (TID 135). 966 bytes result sent to driver
2019-06-11 09:24:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 201.0 (TID 135) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 201.0, whose tasks have all completed, from pool 
2019-06-11 09:24:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 201 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 67 finished: print at Transform.scala:36, took 0.027660 s
2019-06-11 09:24:20,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:20,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 66 is 83 bytes
2019-06-11 09:24:20,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 67 is 160 bytes
2019-06-11 09:24:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 68 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 204 (print at Transform.scala:36)
2019-06-11 09:24:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 202, ShuffleMapStage 203)
2019-06-11 09:24:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 204 (MapPartitionsRDD[239] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:20,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_102 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:20,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_102_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:20,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_102_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:20,044  INFO [org.apache.spark.SparkContext] - Created broadcast 102 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[239] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:20,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 204.0 with 1 tasks
2019-06-11 09:24:20,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 204.0 (TID 136, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:20,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 204.0 (TID 136)
2019-06-11 09:24:20,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:20,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:20,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 204.0 (TID 136). 1009 bytes result sent to driver
2019-06-11 09:24:20,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 204.0 (TID 136) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:20,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2019-06-11 09:24:20,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 204 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:20,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 68 finished: print at Transform.scala:36, took 0.006523 s
2019-06-11 09:24:20,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216260000 ms.0 from job set of time 1560216260000 ms
2019-06-11 09:24:20,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560216260000 ms (execution: 0.041 s)
2019-06-11 09:24:20,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 232 from persistence list
2019-06-11 09:24:20,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 232
2019-06-11 09:24:20,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 227 from persistence list
2019-06-11 09:24:20,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 227
2019-06-11 09:24:20,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 226 from persistence list
2019-06-11 09:24:20,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 226
2019-06-11 09:24:20,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[226] at socketTextStream at Transform.scala:18 of time 1560216260000 ms
2019-06-11 09:24:20,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216250000 ms
2019-06-11 09:24:20,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216250000 ms
2019-06-11 09:24:25,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216265000 ms
2019-06-11 09:24:25,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216265000 ms.0 from job set of time 1560216265000 ms
2019-06-11 09:24:25,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 241 (map at Transform.scala:20)
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 69 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 207 (print at Transform.scala:36)
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 205, ShuffleMapStage 206)
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 206)
2019-06-11 09:24:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 206 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:25,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_103 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:25,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_103_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:25,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_103_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:25,013  INFO [org.apache.spark.SparkContext] - Created broadcast 103 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:25,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 206 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:25,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 206.0 with 2 tasks
2019-06-11 09:24:25,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 206.0 (TID 137, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:25,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 206.0 (TID 137)
2019-06-11 09:24:25,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 206.0 (TID 137). 853 bytes result sent to driver
2019-06-11 09:24:25,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 206.0 (TID 138, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:25,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 206.0 (TID 138)
2019-06-11 09:24:25,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 206.0 (TID 137) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 206.0 (TID 138). 810 bytes result sent to driver
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 206.0 (TID 138) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 206 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 207)
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 207 (MapPartitionsRDD[246] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:25,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_104 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:25,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_104_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:25,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_104_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:25,034  INFO [org.apache.spark.SparkContext] - Created broadcast 104 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[246] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:25,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 207.0 with 1 tasks
2019-06-11 09:24:25,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 207.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:25,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 207.0 (TID 139)
2019-06-11 09:24:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:25,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 207.0 (TID 139). 1009 bytes result sent to driver
2019-06-11 09:24:25,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 207.0 (TID 139) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:25,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 207.0, whose tasks have all completed, from pool 
2019-06-11 09:24:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 207 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 69 finished: print at Transform.scala:36, took 0.028121 s
2019-06-11 09:24:25,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:25,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 68 is 83 bytes
2019-06-11 09:24:25,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 69 is 160 bytes
2019-06-11 09:24:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 70 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 210 (print at Transform.scala:36)
2019-06-11 09:24:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 208, ShuffleMapStage 209)
2019-06-11 09:24:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 210 (MapPartitionsRDD[246] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:25,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_105 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:25,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_105_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:25,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_105_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:25,044  INFO [org.apache.spark.SparkContext] - Created broadcast 105 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:25,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[246] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:25,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 210.0 with 1 tasks
2019-06-11 09:24:25,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 210.0 (TID 140, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:25,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 210.0 (TID 140)
2019-06-11 09:24:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:25,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 210.0 (TID 140). 1052 bytes result sent to driver
2019-06-11 09:24:25,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 210.0 (TID 140) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:25,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2019-06-11 09:24:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 210 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 70 finished: print at Transform.scala:36, took 0.006843 s
2019-06-11 09:24:25,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216265000 ms.0 from job set of time 1560216265000 ms
2019-06-11 09:24:25,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560216265000 ms (execution: 0.041 s)
2019-06-11 09:24:25,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 239 from persistence list
2019-06-11 09:24:25,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 239
2019-06-11 09:24:25,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 234 from persistence list
2019-06-11 09:24:25,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 234
2019-06-11 09:24:25,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 233 from persistence list
2019-06-11 09:24:25,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 233
2019-06-11 09:24:25,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[233] at socketTextStream at Transform.scala:18 of time 1560216265000 ms
2019-06-11 09:24:25,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216255000 ms
2019-06-11 09:24:25,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216255000 ms
2019-06-11 09:24:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216270000 ms
2019-06-11 09:24:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216270000 ms.0 from job set of time 1560216270000 ms
2019-06-11 09:24:30,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 248 (map at Transform.scala:20)
2019-06-11 09:24:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 71 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 213 (print at Transform.scala:36)
2019-06-11 09:24:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 212, ShuffleMapStage 211)
2019-06-11 09:24:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 211)
2019-06-11 09:24:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 211 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:30,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_106 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:30,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_106_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:30,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_106_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:30,014  INFO [org.apache.spark.SparkContext] - Created broadcast 106 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:30,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 211 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:30,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 211.0 with 2 tasks
2019-06-11 09:24:30,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 211.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:30,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 211.0 (TID 141)
2019-06-11 09:24:30,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 211.0 (TID 141). 767 bytes result sent to driver
2019-06-11 09:24:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 211.0 (TID 142, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:30,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 211.0 (TID 142)
2019-06-11 09:24:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 211.0 (TID 141) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 211.0 (TID 142). 810 bytes result sent to driver
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 211.0 (TID 142) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 211.0, whose tasks have all completed, from pool 
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 211 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 213)
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 213 (MapPartitionsRDD[253] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:30,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_107 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:30,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_107_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:30,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_107_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:30,036  INFO [org.apache.spark.SparkContext] - Created broadcast 107 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 213 (MapPartitionsRDD[253] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:30,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 213.0 with 1 tasks
2019-06-11 09:24:30,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 213.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:30,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 213.0 (TID 143)
2019-06-11 09:24:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:30,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 213.0 (TID 143). 1009 bytes result sent to driver
2019-06-11 09:24:30,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 213.0 (TID 143) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:30,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 213.0, whose tasks have all completed, from pool 
2019-06-11 09:24:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 213 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 71 finished: print at Transform.scala:36, took 0.029775 s
2019-06-11 09:24:30,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:30,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 71 is 160 bytes
2019-06-11 09:24:30,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 70 is 83 bytes
2019-06-11 09:24:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 72 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 216 (print at Transform.scala:36)
2019-06-11 09:24:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 215, ShuffleMapStage 214)
2019-06-11 09:24:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 216 (MapPartitionsRDD[253] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:30,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_108 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:30,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_108_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:30,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_108_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:30,045  INFO [org.apache.spark.SparkContext] - Created broadcast 108 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:30,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[253] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:30,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 216.0 with 1 tasks
2019-06-11 09:24:30,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 216.0 (TID 144, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:30,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 216.0 (TID 144)
2019-06-11 09:24:30,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:30,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:30,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:30,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:30,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 216.0 (TID 144). 1009 bytes result sent to driver
2019-06-11 09:24:30,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 216.0 (TID 144) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:30,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2019-06-11 09:24:30,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 216 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:30,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 72 finished: print at Transform.scala:36, took 0.006680 s
2019-06-11 09:24:30,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216270000 ms.0 from job set of time 1560216270000 ms
2019-06-11 09:24:30,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216270000 ms (execution: 0.043 s)
2019-06-11 09:24:30,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 246 from persistence list
2019-06-11 09:24:30,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 246
2019-06-11 09:24:30,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 241 from persistence list
2019-06-11 09:24:30,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 241
2019-06-11 09:24:30,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 240 from persistence list
2019-06-11 09:24:30,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 240
2019-06-11 09:24:30,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[240] at socketTextStream at Transform.scala:18 of time 1560216270000 ms
2019-06-11 09:24:30,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216260000 ms
2019-06-11 09:24:30,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216260000 ms
2019-06-11 09:24:35,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216275000 ms
2019-06-11 09:24:35,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216275000 ms.0 from job set of time 1560216275000 ms
2019-06-11 09:24:35,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 255 (map at Transform.scala:20)
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 73 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 219 (print at Transform.scala:36)
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 217, ShuffleMapStage 218)
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 218)
2019-06-11 09:24:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 218 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:35,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_109 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:35,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_109_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:35,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_109_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:35,014  INFO [org.apache.spark.SparkContext] - Created broadcast 109 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:35,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 218 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:35,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 218.0 with 2 tasks
2019-06-11 09:24:35,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 218.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:35,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 218.0 (TID 145)
2019-06-11 09:24:35,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 218.0 (TID 145). 810 bytes result sent to driver
2019-06-11 09:24:35,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 218.0 (TID 146, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:35,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 218.0 (TID 146)
2019-06-11 09:24:35,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 218.0 (TID 145) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:35,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 218.0 (TID 146). 853 bytes result sent to driver
2019-06-11 09:24:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 218.0 (TID 146) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 218 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 219)
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 219 (MapPartitionsRDD[260] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:35,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_110 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_110_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_110_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:35,038  INFO [org.apache.spark.SparkContext] - Created broadcast 110 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 219 (MapPartitionsRDD[260] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:35,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 219.0 with 1 tasks
2019-06-11 09:24:35,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 219.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:35,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 219.0 (TID 147)
2019-06-11 09:24:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:35,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 219.0 (TID 147). 1009 bytes result sent to driver
2019-06-11 09:24:35,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 219.0 (TID 147) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:35,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 219.0, whose tasks have all completed, from pool 
2019-06-11 09:24:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 219 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 73 finished: print at Transform.scala:36, took 0.031365 s
2019-06-11 09:24:35,044  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:35,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 72 is 83 bytes
2019-06-11 09:24:35,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 73 is 160 bytes
2019-06-11 09:24:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 74 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 222 (print at Transform.scala:36)
2019-06-11 09:24:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 220, ShuffleMapStage 221)
2019-06-11 09:24:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 222 (MapPartitionsRDD[260] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:35,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_111 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:35,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_111_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:35,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_111_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:35,049  INFO [org.apache.spark.SparkContext] - Created broadcast 111 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:35,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[260] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:35,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 222.0 with 1 tasks
2019-06-11 09:24:35,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 222.0 (TID 148, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:35,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 222.0 (TID 148)
2019-06-11 09:24:35,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:35,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:24:35,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:35,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:35,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 222.0 (TID 148). 966 bytes result sent to driver
2019-06-11 09:24:35,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 222.0 (TID 148) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:35,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2019-06-11 09:24:35,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 222 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:35,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 74 finished: print at Transform.scala:36, took 0.007942 s
2019-06-11 09:24:35,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216275000 ms.0 from job set of time 1560216275000 ms
2019-06-11 09:24:35,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216275000 ms (execution: 0.044 s)
2019-06-11 09:24:35,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 253 from persistence list
2019-06-11 09:24:35,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 253
2019-06-11 09:24:35,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 248 from persistence list
2019-06-11 09:24:35,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 248
2019-06-11 09:24:35,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 247 from persistence list
2019-06-11 09:24:35,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 247
2019-06-11 09:24:35,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[247] at socketTextStream at Transform.scala:18 of time 1560216275000 ms
2019-06-11 09:24:35,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216265000 ms
2019-06-11 09:24:35,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216265000 ms
2019-06-11 09:24:40,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216280000 ms
2019-06-11 09:24:40,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216280000 ms.0 from job set of time 1560216280000 ms
2019-06-11 09:24:40,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 262 (map at Transform.scala:20)
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 75 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 225 (print at Transform.scala:36)
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 223, ShuffleMapStage 224)
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 224)
2019-06-11 09:24:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 224 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_112 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:40,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_112_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:40,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_112_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:40,012  INFO [org.apache.spark.SparkContext] - Created broadcast 112 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:40,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 224 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:40,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 224.0 with 2 tasks
2019-06-11 09:24:40,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 224.0 (TID 149, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:40,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 224.0 (TID 149)
2019-06-11 09:24:40,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 224.0 (TID 149). 853 bytes result sent to driver
2019-06-11 09:24:40,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 224.0 (TID 150, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:40,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 224.0 (TID 150)
2019-06-11 09:24:40,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 224.0 (TID 149) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 224.0 (TID 150). 896 bytes result sent to driver
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 224.0 (TID 150) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 224 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 225)
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 225 (MapPartitionsRDD[267] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:40,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_113 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:40,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_113_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:40,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_113_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:40,034  INFO [org.apache.spark.SparkContext] - Created broadcast 113 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[267] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:40,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 225.0 with 1 tasks
2019-06-11 09:24:40,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 225.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:40,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 225.0 (TID 151)
2019-06-11 09:24:40,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:24:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:40,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 225.0 (TID 151). 1009 bytes result sent to driver
2019-06-11 09:24:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 225.0 (TID 151) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 225.0, whose tasks have all completed, from pool 
2019-06-11 09:24:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 225 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 75 finished: print at Transform.scala:36, took 0.028025 s
2019-06-11 09:24:40,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:40,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 74 is 83 bytes
2019-06-11 09:24:40,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 75 is 160 bytes
2019-06-11 09:24:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 76 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 228 (print at Transform.scala:36)
2019-06-11 09:24:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 227, ShuffleMapStage 226)
2019-06-11 09:24:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 228 (MapPartitionsRDD[267] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:40,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_114 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:40,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_114_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:40,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_114_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:40,043  INFO [org.apache.spark.SparkContext] - Created broadcast 114 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:40,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 228 (MapPartitionsRDD[267] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:40,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 228.0 with 1 tasks
2019-06-11 09:24:40,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 228.0 (TID 152, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:40,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 228.0 (TID 152)
2019-06-11 09:24:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 228.0 (TID 152). 966 bytes result sent to driver
2019-06-11 09:24:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 228.0 (TID 152) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:40,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2019-06-11 09:24:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 228 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 76 finished: print at Transform.scala:36, took 0.005738 s
2019-06-11 09:24:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216280000 ms.0 from job set of time 1560216280000 ms
2019-06-11 09:24:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216280000 ms (execution: 0.038 s)
2019-06-11 09:24:40,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 260 from persistence list
2019-06-11 09:24:40,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 260
2019-06-11 09:24:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 255 from persistence list
2019-06-11 09:24:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 255
2019-06-11 09:24:40,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 254 from persistence list
2019-06-11 09:24:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 254
2019-06-11 09:24:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[254] at socketTextStream at Transform.scala:18 of time 1560216280000 ms
2019-06-11 09:24:40,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216270000 ms
2019-06-11 09:24:40,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216270000 ms
2019-06-11 09:24:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216285000 ms
2019-06-11 09:24:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216285000 ms.0 from job set of time 1560216285000 ms
2019-06-11 09:24:45,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 269 (map at Transform.scala:20)
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 77 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 231 (print at Transform.scala:36)
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 230, ShuffleMapStage 229)
2019-06-11 09:24:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 230)
2019-06-11 09:24:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 230 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:45,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_115 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:45,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_115_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:24:45,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_115_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:45,013  INFO [org.apache.spark.SparkContext] - Created broadcast 115 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 230 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:45,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 230.0 with 2 tasks
2019-06-11 09:24:45,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 230.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:45,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 230.0 (TID 153)
2019-06-11 09:24:45,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 230.0 (TID 153). 853 bytes result sent to driver
2019-06-11 09:24:45,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 230.0 (TID 154, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:45,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 230.0 (TID 154)
2019-06-11 09:24:45,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 230.0 (TID 153) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:45,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 230.0 (TID 154). 896 bytes result sent to driver
2019-06-11 09:24:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 230.0 (TID 154) in 17 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2019-06-11 09:24:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 230 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:24:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 231)
2019-06-11 09:24:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 231 (MapPartitionsRDD[274] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:45,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_116 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:45,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_116_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:45,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_116_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:45,042  INFO [org.apache.spark.SparkContext] - Created broadcast 116 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[274] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:45,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 231.0 with 1 tasks
2019-06-11 09:24:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 231.0 (TID 155, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:45,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 231.0 (TID 155)
2019-06-11 09:24:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:45,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:45,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 231.0 (TID 155). 1009 bytes result sent to driver
2019-06-11 09:24:45,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 231.0 (TID 155) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:45,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 231.0, whose tasks have all completed, from pool 
2019-06-11 09:24:45,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 231 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:24:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 77 finished: print at Transform.scala:36, took 0.035413 s
2019-06-11 09:24:45,049  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:45,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 76 is 83 bytes
2019-06-11 09:24:45,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 77 is 160 bytes
2019-06-11 09:24:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 78 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 234 (print at Transform.scala:36)
2019-06-11 09:24:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 233, ShuffleMapStage 232)
2019-06-11 09:24:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 234 (MapPartitionsRDD[274] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:45,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_117 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:45,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_117_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:45,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_117_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:45,052  INFO [org.apache.spark.SparkContext] - Created broadcast 117 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[274] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:45,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 234.0 with 1 tasks
2019-06-11 09:24:45,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 234.0 (TID 156, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:45,053  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 234.0 (TID 156)
2019-06-11 09:24:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:45,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:45,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 234.0 (TID 156). 966 bytes result sent to driver
2019-06-11 09:24:45,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 234.0 (TID 156) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:45,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2019-06-11 09:24:45,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 234 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:24:45,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 78 finished: print at Transform.scala:36, took 0.006080 s
2019-06-11 09:24:45,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216285000 ms.0 from job set of time 1560216285000 ms
2019-06-11 09:24:45,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.056 s for time 1560216285000 ms (execution: 0.049 s)
2019-06-11 09:24:45,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 267 from persistence list
2019-06-11 09:24:45,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 267
2019-06-11 09:24:45,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 262 from persistence list
2019-06-11 09:24:45,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 262
2019-06-11 09:24:45,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 261 from persistence list
2019-06-11 09:24:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 261
2019-06-11 09:24:45,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[261] at socketTextStream at Transform.scala:18 of time 1560216285000 ms
2019-06-11 09:24:45,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216275000 ms
2019-06-11 09:24:45,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216275000 ms
2019-06-11 09:24:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216290000 ms
2019-06-11 09:24:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216290000 ms.0 from job set of time 1560216290000 ms
2019-06-11 09:24:50,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 276 (map at Transform.scala:20)
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 79 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 237 (print at Transform.scala:36)
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 235, ShuffleMapStage 236)
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 236)
2019-06-11 09:24:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 236 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_118 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:50,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_118_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:24:50,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_118_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:50,012  INFO [org.apache.spark.SparkContext] - Created broadcast 118 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 236 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:50,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 236.0 with 2 tasks
2019-06-11 09:24:50,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 236.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:50,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 236.0 (TID 157)
2019-06-11 09:24:50,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 236.0 (TID 157). 810 bytes result sent to driver
2019-06-11 09:24:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 236.0 (TID 158, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:50,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 236.0 (TID 158)
2019-06-11 09:24:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 236.0 (TID 157) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:50,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 236.0 (TID 158). 810 bytes result sent to driver
2019-06-11 09:24:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 236.0 (TID 158) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 236 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 237)
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 237 (MapPartitionsRDD[281] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:50,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_119 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:24:50,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 67
2019-06-11 09:24:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_119_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:24:50,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 62
2019-06-11 09:24:50,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_119_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:50,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 68
2019-06-11 09:24:50,044  INFO [org.apache.spark.SparkContext] - Created broadcast 119 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 237 (MapPartitionsRDD[281] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 237.0 with 1 tasks
2019-06-11 09:24:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_115_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:50,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 237.0 (TID 159, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:50,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 237.0 (TID 159)
2019-06-11 09:24:50,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_97_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:24:50,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 70
2019-06-11 09:24:50,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:50,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:50,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:50,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:50,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_108_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:50,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 73
2019-06-11 09:24:50,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 237.0 (TID 159). 1009 bytes result sent to driver
2019-06-11 09:24:50,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 237.0 (TID 159) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:50,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_96_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:24:50,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 237.0, whose tasks have all completed, from pool 
2019-06-11 09:24:50,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 72
2019-06-11 09:24:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 237 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:24:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 79 finished: print at Transform.scala:36, took 0.039637 s
2019-06-11 09:24:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_102_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_101_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_103_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_109_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:50,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 75
2019-06-11 09:24:50,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_114_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 69
2019-06-11 09:24:50,056  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:50,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 78 is 83 bytes
2019-06-11 09:24:50,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_113_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 79 is 160 bytes
2019-06-11 09:24:50,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 65
2019-06-11 09:24:50,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 61
2019-06-11 09:24:50,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 80 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:50,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 240 (print at Transform.scala:36)
2019-06-11 09:24:50,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 238, ShuffleMapStage 239)
2019-06-11 09:24:50,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:50,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 240 (MapPartitionsRDD[281] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:50,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_99_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_120 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:50,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_105_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_120_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:50,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_120_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_110_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,061  INFO [org.apache.spark.SparkContext] - Created broadcast 120 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:50,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 240 (MapPartitionsRDD[281] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:50,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 240.0 with 1 tasks
2019-06-11 09:24:50,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 74
2019-06-11 09:24:50,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 240.0 (TID 160, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:50,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 240.0 (TID 160)
2019-06-11 09:24:50,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_98_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 66
2019-06-11 09:24:50,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 71
2019-06-11 09:24:50,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:50,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:50,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_100_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:50,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:50,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:50,066  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 240.0 (TID 160). 966 bytes result sent to driver
2019-06-11 09:24:50,066  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 240.0 (TID 160) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:50,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2019-06-11 09:24:50,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_117_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,066  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 240 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:24:50,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 80 finished: print at Transform.scala:36, took 0.010800 s
2019-06-11 09:24:50,067  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 60
2019-06-11 09:24:50,067  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216290000 ms.0 from job set of time 1560216290000 ms
2019-06-11 09:24:50,067  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.067 s for time 1560216290000 ms (execution: 0.060 s)
2019-06-11 09:24:50,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 274 from persistence list
2019-06-11 09:24:50,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 274
2019-06-11 09:24:50,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 269 from persistence list
2019-06-11 09:24:50,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_104_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 269
2019-06-11 09:24:50,068  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 268 from persistence list
2019-06-11 09:24:50,068  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 63
2019-06-11 09:24:50,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 268
2019-06-11 09:24:50,068  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[268] at socketTextStream at Transform.scala:18 of time 1560216290000 ms
2019-06-11 09:24:50,068  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216280000 ms
2019-06-11 09:24:50,069  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216280000 ms
2019-06-11 09:24:50,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_106_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:50,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_112_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:50,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_107_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,072  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_116_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:50,072  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 64
2019-06-11 09:24:50,073  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_111_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:55,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216295000 ms
2019-06-11 09:24:55,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216295000 ms.0 from job set of time 1560216295000 ms
2019-06-11 09:24:55,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:24:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 283 (map at Transform.scala:20)
2019-06-11 09:24:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 81 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 243 (print at Transform.scala:36)
2019-06-11 09:24:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 241, ShuffleMapStage 242)
2019-06-11 09:24:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 241)
2019-06-11 09:24:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 241 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:24:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_121 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:55,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_121_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:24:55,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_121_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:24:55,013  INFO [org.apache.spark.SparkContext] - Created broadcast 121 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 241 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:24:55,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 241.0 with 2 tasks
2019-06-11 09:24:55,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 241.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:55,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 241.0 (TID 161)
2019-06-11 09:24:55,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 241.0 (TID 161). 853 bytes result sent to driver
2019-06-11 09:24:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 241.0 (TID 162, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:24:55,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 241.0 (TID 162)
2019-06-11 09:24:55,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 241.0 (TID 161) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:24:55,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 241.0 (TID 162). 810 bytes result sent to driver
2019-06-11 09:24:55,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 241.0 (TID 162) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:24:55,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 241.0, whose tasks have all completed, from pool 
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 241 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 243)
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:24:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 243 (MapPartitionsRDD[288] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:55,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_122 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:55,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_122_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:55,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_122_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:55,034  INFO [org.apache.spark.SparkContext] - Created broadcast 122 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[288] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:24:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 243.0 with 1 tasks
2019-06-11 09:24:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 243.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:55,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 243.0 (TID 163)
2019-06-11 09:24:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:55,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 243.0 (TID 163). 966 bytes result sent to driver
2019-06-11 09:24:55,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 243.0 (TID 163) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:55,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 243.0, whose tasks have all completed, from pool 
2019-06-11 09:24:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 243 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 81 finished: print at Transform.scala:36, took 0.027634 s
2019-06-11 09:24:55,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:24:55,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 81 is 160 bytes
2019-06-11 09:24:55,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 80 is 83 bytes
2019-06-11 09:24:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 82 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:24:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 246 (print at Transform.scala:36)
2019-06-11 09:24:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 245, ShuffleMapStage 244)
2019-06-11 09:24:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:24:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 246 (MapPartitionsRDD[288] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:24:55,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_123 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:24:55,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_123_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:24:55,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_123_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:24:55,044  INFO [org.apache.spark.SparkContext] - Created broadcast 123 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:24:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 246 (MapPartitionsRDD[288] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:24:55,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 246.0 with 1 tasks
2019-06-11 09:24:55,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 246.0 (TID 164, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:24:55,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 246.0 (TID 164)
2019-06-11 09:24:55,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:24:55,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:55,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:24:55,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:24:55,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 246.0 (TID 164). 1009 bytes result sent to driver
2019-06-11 09:24:55,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 246.0 (TID 164) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:24:55,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 246.0, whose tasks have all completed, from pool 
2019-06-11 09:24:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 246 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:24:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 82 finished: print at Transform.scala:36, took 0.006650 s
2019-06-11 09:24:55,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216295000 ms.0 from job set of time 1560216295000 ms
2019-06-11 09:24:55,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560216295000 ms (execution: 0.040 s)
2019-06-11 09:24:55,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 281 from persistence list
2019-06-11 09:24:55,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 281
2019-06-11 09:24:55,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 276 from persistence list
2019-06-11 09:24:55,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 276
2019-06-11 09:24:55,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 275 from persistence list
2019-06-11 09:24:55,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 275
2019-06-11 09:24:55,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[275] at socketTextStream at Transform.scala:18 of time 1560216295000 ms
2019-06-11 09:24:55,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216285000 ms
2019-06-11 09:24:55,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216285000 ms
2019-06-11 09:25:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216300000 ms
2019-06-11 09:25:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216300000 ms.0 from job set of time 1560216300000 ms
2019-06-11 09:25:00,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 290 (map at Transform.scala:20)
2019-06-11 09:25:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 83 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 249 (print at Transform.scala:36)
2019-06-11 09:25:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 248, ShuffleMapStage 247)
2019-06-11 09:25:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 247)
2019-06-11 09:25:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 247 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_124 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:00,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_124_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:00,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_124_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:00,014  INFO [org.apache.spark.SparkContext] - Created broadcast 124 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 247 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:00,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 247.0 with 2 tasks
2019-06-11 09:25:00,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 247.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:00,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 247.0 (TID 165)
2019-06-11 09:25:00,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 247.0 (TID 165). 853 bytes result sent to driver
2019-06-11 09:25:00,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 247.0 (TID 166, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:00,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 247.0 (TID 166)
2019-06-11 09:25:00,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 247.0 (TID 165) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 247.0 (TID 166). 810 bytes result sent to driver
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 247.0 (TID 166) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 247.0, whose tasks have all completed, from pool 
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 247 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 249)
2019-06-11 09:25:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 249 (MapPartitionsRDD[295] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:00,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_125 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:00,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_125_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:00,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_125_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:00,036  INFO [org.apache.spark.SparkContext] - Created broadcast 125 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 249 (MapPartitionsRDD[295] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:00,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 249.0 with 1 tasks
2019-06-11 09:25:00,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 249.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:00,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 249.0 (TID 167)
2019-06-11 09:25:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:00,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 249.0 (TID 167). 1009 bytes result sent to driver
2019-06-11 09:25:00,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 249.0 (TID 167) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:00,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 249.0, whose tasks have all completed, from pool 
2019-06-11 09:25:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 249 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:25:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 83 finished: print at Transform.scala:36, took 0.027488 s
2019-06-11 09:25:00,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:00,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 83 is 160 bytes
2019-06-11 09:25:00,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 82 is 83 bytes
2019-06-11 09:25:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 84 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 252 (print at Transform.scala:36)
2019-06-11 09:25:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 251, ShuffleMapStage 250)
2019-06-11 09:25:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 252 (MapPartitionsRDD[295] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:00,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_126 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:00,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_126_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:00,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_126_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:00,045  INFO [org.apache.spark.SparkContext] - Created broadcast 126 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 252 (MapPartitionsRDD[295] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:00,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 252.0 with 1 tasks
2019-06-11 09:25:00,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 252.0 (TID 168, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:00,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 252.0 (TID 168)
2019-06-11 09:25:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:00,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 252.0 (TID 168). 1009 bytes result sent to driver
2019-06-11 09:25:00,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 252.0 (TID 168) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:00,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 252.0, whose tasks have all completed, from pool 
2019-06-11 09:25:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 252 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 84 finished: print at Transform.scala:36, took 0.007282 s
2019-06-11 09:25:00,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216300000 ms.0 from job set of time 1560216300000 ms
2019-06-11 09:25:00,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560216300000 ms (execution: 0.040 s)
2019-06-11 09:25:00,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 288 from persistence list
2019-06-11 09:25:00,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 288
2019-06-11 09:25:00,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 283 from persistence list
2019-06-11 09:25:00,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 283
2019-06-11 09:25:00,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 282 from persistence list
2019-06-11 09:25:00,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 282
2019-06-11 09:25:00,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[282] at socketTextStream at Transform.scala:18 of time 1560216300000 ms
2019-06-11 09:25:00,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216290000 ms
2019-06-11 09:25:00,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216290000 ms
2019-06-11 09:25:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216305000 ms
2019-06-11 09:25:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216305000 ms.0 from job set of time 1560216305000 ms
2019-06-11 09:25:05,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 297 (map at Transform.scala:20)
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 85 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 255 (print at Transform.scala:36)
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 253, ShuffleMapStage 254)
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 253)
2019-06-11 09:25:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 253 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:05,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_127 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:05,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_127_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:05,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_127_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:05,015  INFO [org.apache.spark.SparkContext] - Created broadcast 127 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:05,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 253 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:05,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 253.0 with 2 tasks
2019-06-11 09:25:05,017  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 253.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:05,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 253.0 (TID 169)
2019-06-11 09:25:05,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 253.0 (TID 169). 767 bytes result sent to driver
2019-06-11 09:25:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 253.0 (TID 170, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:05,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 253.0 (TID 170)
2019-06-11 09:25:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 253.0 (TID 169) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 253.0 (TID 170). 853 bytes result sent to driver
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 253.0 (TID 170) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 253.0, whose tasks have all completed, from pool 
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 253 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 255)
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 255 (MapPartitionsRDD[302] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:05,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_128 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:05,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_128_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:05,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_128_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:05,039  INFO [org.apache.spark.SparkContext] - Created broadcast 128 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 255 (MapPartitionsRDD[302] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 255.0 with 1 tasks
2019-06-11 09:25:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 255.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:05,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 255.0 (TID 171)
2019-06-11 09:25:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:05,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:05,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 255.0 (TID 171). 966 bytes result sent to driver
2019-06-11 09:25:05,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 255.0 (TID 171) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:05,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 255.0, whose tasks have all completed, from pool 
2019-06-11 09:25:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 255 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 85 finished: print at Transform.scala:36, took 0.033033 s
2019-06-11 09:25:05,046  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:05,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 85 is 160 bytes
2019-06-11 09:25:05,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 84 is 83 bytes
2019-06-11 09:25:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 86 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 258 (print at Transform.scala:36)
2019-06-11 09:25:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 256, ShuffleMapStage 257)
2019-06-11 09:25:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 258 (MapPartitionsRDD[302] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:05,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_129 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:05,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_129_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_129_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:05,050  INFO [org.apache.spark.SparkContext] - Created broadcast 129 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 258 (MapPartitionsRDD[302] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:05,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 258.0 with 1 tasks
2019-06-11 09:25:05,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 258.0 (TID 172, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:05,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 258.0 (TID 172)
2019-06-11 09:25:05,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:05,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:05,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:05,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:05,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 258.0 (TID 172). 1009 bytes result sent to driver
2019-06-11 09:25:05,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 258.0 (TID 172) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:05,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 258.0, whose tasks have all completed, from pool 
2019-06-11 09:25:05,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 258 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:05,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 86 finished: print at Transform.scala:36, took 0.007566 s
2019-06-11 09:25:05,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216305000 ms.0 from job set of time 1560216305000 ms
2019-06-11 09:25:05,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560216305000 ms (execution: 0.047 s)
2019-06-11 09:25:05,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 295 from persistence list
2019-06-11 09:25:05,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 295
2019-06-11 09:25:05,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 290 from persistence list
2019-06-11 09:25:05,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 290
2019-06-11 09:25:05,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 289 from persistence list
2019-06-11 09:25:05,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 289
2019-06-11 09:25:05,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[289] at socketTextStream at Transform.scala:18 of time 1560216305000 ms
2019-06-11 09:25:05,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216295000 ms
2019-06-11 09:25:05,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216295000 ms
2019-06-11 09:25:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216310000 ms
2019-06-11 09:25:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216310000 ms.0 from job set of time 1560216310000 ms
2019-06-11 09:25:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 304 (map at Transform.scala:20)
2019-06-11 09:25:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 87 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 261 (print at Transform.scala:36)
2019-06-11 09:25:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 259, ShuffleMapStage 260)
2019-06-11 09:25:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 260)
2019-06-11 09:25:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 260 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_130 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_130_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_130_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:10,012  INFO [org.apache.spark.SparkContext] - Created broadcast 130 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 260 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:10,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 260.0 with 2 tasks
2019-06-11 09:25:10,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 260.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 260.0 (TID 173)
2019-06-11 09:25:10,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 260.0 (TID 173). 853 bytes result sent to driver
2019-06-11 09:25:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 260.0 (TID 174, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:10,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 260.0 (TID 174)
2019-06-11 09:25:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 260.0 (TID 173) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:10,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 260.0 (TID 174). 767 bytes result sent to driver
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 260.0 (TID 174) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 260.0, whose tasks have all completed, from pool 
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 260 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 261)
2019-06-11 09:25:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 261 (MapPartitionsRDD[309] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:10,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_131 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:10,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_131_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:10,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_131_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:10,033  INFO [org.apache.spark.SparkContext] - Created broadcast 131 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 261 (MapPartitionsRDD[309] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 261.0 with 1 tasks
2019-06-11 09:25:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 261.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:10,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 261.0 (TID 175)
2019-06-11 09:25:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:10,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 261.0 (TID 175). 966 bytes result sent to driver
2019-06-11 09:25:10,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 261.0 (TID 175) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:10,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 261.0, whose tasks have all completed, from pool 
2019-06-11 09:25:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 261 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 87 finished: print at Transform.scala:36, took 0.027000 s
2019-06-11 09:25:10,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:10,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 86 is 83 bytes
2019-06-11 09:25:10,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 87 is 160 bytes
2019-06-11 09:25:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 88 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 264 (print at Transform.scala:36)
2019-06-11 09:25:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 263, ShuffleMapStage 262)
2019-06-11 09:25:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 264 (MapPartitionsRDD[309] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:10,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_132 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_132_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:10,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_132_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:10,042  INFO [org.apache.spark.SparkContext] - Created broadcast 132 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 264 (MapPartitionsRDD[309] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 264.0 with 1 tasks
2019-06-11 09:25:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 264.0 (TID 176, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:10,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 264.0 (TID 176)
2019-06-11 09:25:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:10,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 264.0 (TID 176). 966 bytes result sent to driver
2019-06-11 09:25:10,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 264.0 (TID 176) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:10,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 264.0, whose tasks have all completed, from pool 
2019-06-11 09:25:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 264 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:25:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 88 finished: print at Transform.scala:36, took 0.005737 s
2019-06-11 09:25:10,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216310000 ms.0 from job set of time 1560216310000 ms
2019-06-11 09:25:10,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216310000 ms (execution: 0.039 s)
2019-06-11 09:25:10,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 302 from persistence list
2019-06-11 09:25:10,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 302
2019-06-11 09:25:10,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 297 from persistence list
2019-06-11 09:25:10,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 297
2019-06-11 09:25:10,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 296 from persistence list
2019-06-11 09:25:10,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 296
2019-06-11 09:25:10,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[296] at socketTextStream at Transform.scala:18 of time 1560216310000 ms
2019-06-11 09:25:10,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216300000 ms
2019-06-11 09:25:10,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216300000 ms
2019-06-11 09:25:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216315000 ms
2019-06-11 09:25:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216315000 ms.0 from job set of time 1560216315000 ms
2019-06-11 09:25:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 311 (map at Transform.scala:20)
2019-06-11 09:25:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 89 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 267 (print at Transform.scala:36)
2019-06-11 09:25:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 266, ShuffleMapStage 265)
2019-06-11 09:25:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 265)
2019-06-11 09:25:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 265 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_133 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_133_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:15,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_133_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:15,011  INFO [org.apache.spark.SparkContext] - Created broadcast 133 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 265 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:15,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 265.0 with 2 tasks
2019-06-11 09:25:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 265.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 265.0 (TID 177)
2019-06-11 09:25:15,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 265.0 (TID 177). 853 bytes result sent to driver
2019-06-11 09:25:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 265.0 (TID 178, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:15,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 265.0 (TID 178)
2019-06-11 09:25:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 265.0 (TID 177) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:15,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 265.0 (TID 178). 810 bytes result sent to driver
2019-06-11 09:25:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 265.0 (TID 178) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 265.0, whose tasks have all completed, from pool 
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 265 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 267)
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 267 (MapPartitionsRDD[316] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:15,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_134 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:15,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_134_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:15,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_134_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:15,040  INFO [org.apache.spark.SparkContext] - Created broadcast 134 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[316] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 267.0 with 1 tasks
2019-06-11 09:25:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 267.0 (TID 179, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:15,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 267.0 (TID 179)
2019-06-11 09:25:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:15,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 267.0 (TID 179). 1009 bytes result sent to driver
2019-06-11 09:25:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 267.0 (TID 179) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:15,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 267.0, whose tasks have all completed, from pool 
2019-06-11 09:25:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 267 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 89 finished: print at Transform.scala:36, took 0.034528 s
2019-06-11 09:25:15,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:15,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 89 is 160 bytes
2019-06-11 09:25:15,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 88 is 83 bytes
2019-06-11 09:25:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 90 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 270 (print at Transform.scala:36)
2019-06-11 09:25:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 269, ShuffleMapStage 268)
2019-06-11 09:25:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:15,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 270 (MapPartitionsRDD[316] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:15,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_135 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:15,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_135_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:15,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_135_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:15,048  INFO [org.apache.spark.SparkContext] - Created broadcast 135 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[316] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:15,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 270.0 with 1 tasks
2019-06-11 09:25:15,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 270.0 (TID 180, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:15,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 270.0 (TID 180)
2019-06-11 09:25:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:15,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 270.0 (TID 180). 966 bytes result sent to driver
2019-06-11 09:25:15,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 270.0 (TID 180) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:15,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 270.0, whose tasks have all completed, from pool 
2019-06-11 09:25:15,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 270 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:15,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 90 finished: print at Transform.scala:36, took 0.006975 s
2019-06-11 09:25:15,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216315000 ms.0 from job set of time 1560216315000 ms
2019-06-11 09:25:15,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216315000 ms (execution: 0.046 s)
2019-06-11 09:25:15,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 309 from persistence list
2019-06-11 09:25:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 309
2019-06-11 09:25:15,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 304 from persistence list
2019-06-11 09:25:15,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 304
2019-06-11 09:25:15,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 303 from persistence list
2019-06-11 09:25:15,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 303
2019-06-11 09:25:15,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[303] at socketTextStream at Transform.scala:18 of time 1560216315000 ms
2019-06-11 09:25:15,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216305000 ms
2019-06-11 09:25:15,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216305000 ms
2019-06-11 09:25:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216320000 ms
2019-06-11 09:25:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216320000 ms.0 from job set of time 1560216320000 ms
2019-06-11 09:25:20,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 318 (map at Transform.scala:20)
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 91 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 273 (print at Transform.scala:36)
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 271, ShuffleMapStage 272)
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 272)
2019-06-11 09:25:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 272 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_136 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_136_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:25:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_136_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:20,012  INFO [org.apache.spark.SparkContext] - Created broadcast 136 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 272 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:20,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 272.0 with 2 tasks
2019-06-11 09:25:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 272.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 272.0 (TID 181)
2019-06-11 09:25:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 272.0 (TID 181). 853 bytes result sent to driver
2019-06-11 09:25:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 272.0 (TID 182, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:20,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 272.0 (TID 182)
2019-06-11 09:25:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 272.0 (TID 181) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:20,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 272.0 (TID 182). 767 bytes result sent to driver
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 272.0 (TID 182) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 272.0, whose tasks have all completed, from pool 
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 272 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 273)
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 273 (MapPartitionsRDD[323] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_137 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_137_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:20,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_137_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:20,032  INFO [org.apache.spark.SparkContext] - Created broadcast 137 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 273 (MapPartitionsRDD[323] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 273.0 with 1 tasks
2019-06-11 09:25:20,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 273.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:20,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 273.0 (TID 183)
2019-06-11 09:25:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 273.0 (TID 183). 1009 bytes result sent to driver
2019-06-11 09:25:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 273.0 (TID 183) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 273.0, whose tasks have all completed, from pool 
2019-06-11 09:25:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 273 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 91 finished: print at Transform.scala:36, took 0.026314 s
2019-06-11 09:25:20,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 90 is 83 bytes
2019-06-11 09:25:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 91 is 160 bytes
2019-06-11 09:25:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 92 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 276 (print at Transform.scala:36)
2019-06-11 09:25:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 274, ShuffleMapStage 275)
2019-06-11 09:25:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 276 (MapPartitionsRDD[323] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_138 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_138_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:20,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_138_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:20,041  INFO [org.apache.spark.SparkContext] - Created broadcast 138 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[323] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 276.0 with 1 tasks
2019-06-11 09:25:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 276.0 (TID 184, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:20,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 276.0 (TID 184)
2019-06-11 09:25:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:20,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 276.0 (TID 184). 1009 bytes result sent to driver
2019-06-11 09:25:20,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 276.0 (TID 184) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:20,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 276.0, whose tasks have all completed, from pool 
2019-06-11 09:25:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 276 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:25:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 92 finished: print at Transform.scala:36, took 0.006565 s
2019-06-11 09:25:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216320000 ms.0 from job set of time 1560216320000 ms
2019-06-11 09:25:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216320000 ms (execution: 0.038 s)
2019-06-11 09:25:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 316 from persistence list
2019-06-11 09:25:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 311 from persistence list
2019-06-11 09:25:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 316
2019-06-11 09:25:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 311
2019-06-11 09:25:20,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 310 from persistence list
2019-06-11 09:25:20,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 310
2019-06-11 09:25:20,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[310] at socketTextStream at Transform.scala:18 of time 1560216320000 ms
2019-06-11 09:25:20,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216310000 ms
2019-06-11 09:25:20,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216310000 ms
2019-06-11 09:25:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216325000 ms
2019-06-11 09:25:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216325000 ms.0 from job set of time 1560216325000 ms
2019-06-11 09:25:25,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:25,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 325 (map at Transform.scala:20)
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 93 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 279 (print at Transform.scala:36)
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 277, ShuffleMapStage 278)
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 278)
2019-06-11 09:25:25,116  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 278 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:25,117  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_139 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:25,117  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_139_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:25:25,118  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_139_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:25:25,118  INFO [org.apache.spark.SparkContext] - Created broadcast 139 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:25,118  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 278 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:25,118  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 278.0 with 2 tasks
2019-06-11 09:25:25,119  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 278.0 (TID 185, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:25,119  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 278.0 (TID 185)
2019-06-11 09:25:25,127  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 278.0 (TID 185). 810 bytes result sent to driver
2019-06-11 09:25:25,127  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 278.0 (TID 186, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:25,127  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 278.0 (TID 186)
2019-06-11 09:25:25,127  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 278.0 (TID 185) in 8 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:25,136  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 278.0 (TID 186). 810 bytes result sent to driver
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 278.0 (TID 186) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 278.0, whose tasks have all completed, from pool 
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 278 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 279)
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:25,137  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 279 (MapPartitionsRDD[330] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:25,138  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_140 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:25,139  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_140_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:25,139  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_140_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:25,139  INFO [org.apache.spark.SparkContext] - Created broadcast 140 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:25,139  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 279 (MapPartitionsRDD[330] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:25,139  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 279.0 with 1 tasks
2019-06-11 09:25:25,140  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 279.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:25,140  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 279.0 (TID 187)
2019-06-11 09:25:25,141  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:25,141  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:25,141  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:25,141  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:25,142  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 279.0 (TID 187). 1009 bytes result sent to driver
2019-06-11 09:25:25,142  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 279.0 (TID 187) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:25,142  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 279.0, whose tasks have all completed, from pool 
2019-06-11 09:25:25,142  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 279 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:25,143  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 93 finished: print at Transform.scala:36, took 0.135357 s
2019-06-11 09:25:25,145  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:25,145  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 92 is 83 bytes
2019-06-11 09:25:25,147  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 93 is 160 bytes
2019-06-11 09:25:25,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 94 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:25,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 282 (print at Transform.scala:36)
2019-06-11 09:25:25,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 281, ShuffleMapStage 280)
2019-06-11 09:25:25,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:25,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 282 (MapPartitionsRDD[330] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:25,148  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_141 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:25,155  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_141_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:25,156  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_141_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:25,158  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_122_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:25,159  INFO [org.apache.spark.SparkContext] - Created broadcast 141 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:25,160  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[330] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:25,160  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 282.0 with 1 tasks
2019-06-11 09:25:25,161  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_119_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:25,161  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 282.0 (TID 188, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:25,161  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 282.0 (TID 188)
2019-06-11 09:25:25,161  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_124_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:25:25,162  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:25,162  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 81
2019-06-11 09:25:25,162  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:25,162  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:25,162  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:25,163  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_126_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:25,163  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 89
2019-06-11 09:25:25,164  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 282.0 (TID 188). 1009 bytes result sent to driver
2019-06-11 09:25:25,164  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 282.0 (TID 188) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:25,164  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 282.0, whose tasks have all completed, from pool 
2019-06-11 09:25:25,164  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_121_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:25,165  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 282 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:25:25,165  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 94 finished: print at Transform.scala:36, took 0.019901 s
2019-06-11 09:25:25,165  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216325000 ms.0 from job set of time 1560216325000 ms
2019-06-11 09:25:25,165  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.165 s for time 1560216325000 ms (execution: 0.160 s)
2019-06-11 09:25:25,165  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 323 from persistence list
2019-06-11 09:25:25,165  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_134_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:25,166  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 323
2019-06-11 09:25:25,166  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 318 from persistence list
2019-06-11 09:25:25,166  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 318
2019-06-11 09:25:25,166  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 317 from persistence list
2019-06-11 09:25:25,166  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 317
2019-06-11 09:25:25,166  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[317] at socketTextStream at Transform.scala:18 of time 1560216325000 ms
2019-06-11 09:25:25,166  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_133_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:25,166  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216315000 ms
2019-06-11 09:25:25,166  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216315000 ms
2019-06-11 09:25:25,168  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_123_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:25,168  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 77
2019-06-11 09:25:25,168  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 76
2019-06-11 09:25:25,169  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_128_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:25,170  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 82
2019-06-11 09:25:25,170  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 88
2019-06-11 09:25:25,171  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_130_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:25,171  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_120_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:25,172  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_135_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:25,173  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_118_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:30,014  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216330000 ms
2019-06-11 09:25:30,014  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216330000 ms.0 from job set of time 1560216330000 ms
2019-06-11 09:25:30,017  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:30,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:30,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 332 (map at Transform.scala:20)
2019-06-11 09:25:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 95 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 285 (print at Transform.scala:36)
2019-06-11 09:25:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 284, ShuffleMapStage 283)
2019-06-11 09:25:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 283)
2019-06-11 09:25:30,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 283 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:30,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_142 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:30,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_142_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:30,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_142_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:30,019  INFO [org.apache.spark.SparkContext] - Created broadcast 142 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:30,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 283 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:30,020  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 283.0 with 2 tasks
2019-06-11 09:25:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 283.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:30,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 283.0 (TID 189)
2019-06-11 09:25:30,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 283.0 (TID 189). 810 bytes result sent to driver
2019-06-11 09:25:30,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 283.0 (TID 190, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:30,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 283.0 (TID 190)
2019-06-11 09:25:30,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 283.0 (TID 189) in 8 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:30,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 283.0 (TID 190). 853 bytes result sent to driver
2019-06-11 09:25:30,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 283.0 (TID 190) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:30,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 283.0, whose tasks have all completed, from pool 
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 283 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 285)
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 285 (MapPartitionsRDD[337] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_143 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_143_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:30,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_143_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:30,040  INFO [org.apache.spark.SparkContext] - Created broadcast 143 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 285 (MapPartitionsRDD[337] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 285.0 with 1 tasks
2019-06-11 09:25:30,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 285.0 (TID 191, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:30,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 285.0 (TID 191)
2019-06-11 09:25:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:30,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 285.0 (TID 191). 1009 bytes result sent to driver
2019-06-11 09:25:30,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 285.0 (TID 191) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:30,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 285.0, whose tasks have all completed, from pool 
2019-06-11 09:25:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 285 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 95 finished: print at Transform.scala:36, took 0.027364 s
2019-06-11 09:25:30,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:30,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 95 is 160 bytes
2019-06-11 09:25:30,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 94 is 83 bytes
2019-06-11 09:25:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 96 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 288 (print at Transform.scala:36)
2019-06-11 09:25:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 287, ShuffleMapStage 286)
2019-06-11 09:25:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 288 (MapPartitionsRDD[337] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:30,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_144 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:30,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_144_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_144_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:30,050  INFO [org.apache.spark.SparkContext] - Created broadcast 144 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:30,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 288 (MapPartitionsRDD[337] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:30,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 288.0 with 1 tasks
2019-06-11 09:25:30,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 288.0 (TID 192, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:30,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 288.0 (TID 192)
2019-06-11 09:25:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:30,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 288.0 (TID 192). 966 bytes result sent to driver
2019-06-11 09:25:30,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 288.0 (TID 192) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:30,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 288.0, whose tasks have all completed, from pool 
2019-06-11 09:25:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 288 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 96 finished: print at Transform.scala:36, took 0.007208 s
2019-06-11 09:25:30,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216330000 ms.0 from job set of time 1560216330000 ms
2019-06-11 09:25:30,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560216330000 ms (execution: 0.041 s)
2019-06-11 09:25:30,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 330 from persistence list
2019-06-11 09:25:30,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 330
2019-06-11 09:25:30,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 325 from persistence list
2019-06-11 09:25:30,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 325
2019-06-11 09:25:30,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 324 from persistence list
2019-06-11 09:25:30,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 324
2019-06-11 09:25:30,056  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[324] at socketTextStream at Transform.scala:18 of time 1560216330000 ms
2019-06-11 09:25:30,056  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216320000 ms
2019-06-11 09:25:30,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216320000 ms
2019-06-11 09:25:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216335000 ms
2019-06-11 09:25:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216335000 ms.0 from job set of time 1560216335000 ms
2019-06-11 09:25:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 339 (map at Transform.scala:20)
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 97 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 291 (print at Transform.scala:36)
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 289, ShuffleMapStage 290)
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 290)
2019-06-11 09:25:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 290 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_145 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_145_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:25:35,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_145_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 145 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 290 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 290.0 with 2 tasks
2019-06-11 09:25:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 290.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:35,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 290.0 (TID 193)
2019-06-11 09:25:35,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 290.0 (TID 193). 810 bytes result sent to driver
2019-06-11 09:25:35,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 290.0 (TID 194, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:35,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 290.0 (TID 194)
2019-06-11 09:25:35,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 290.0 (TID 193) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:35,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 290.0 (TID 194). 810 bytes result sent to driver
2019-06-11 09:25:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 290.0 (TID 194) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 290.0, whose tasks have all completed, from pool 
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 290 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 291)
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 291 (MapPartitionsRDD[344] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:35,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_146 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:35,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_146_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:35,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_146_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:35,035  INFO [org.apache.spark.SparkContext] - Created broadcast 146 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 291 (MapPartitionsRDD[344] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:35,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 291.0 with 1 tasks
2019-06-11 09:25:35,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 291.0 (TID 195, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:35,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 291.0 (TID 195)
2019-06-11 09:25:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:35,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 291.0 (TID 195). 966 bytes result sent to driver
2019-06-11 09:25:35,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 291.0 (TID 195) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 291.0, whose tasks have all completed, from pool 
2019-06-11 09:25:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 291 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:25:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 97 finished: print at Transform.scala:36, took 0.029155 s
2019-06-11 09:25:35,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 96 is 83 bytes
2019-06-11 09:25:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 97 is 160 bytes
2019-06-11 09:25:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 98 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 294 (print at Transform.scala:36)
2019-06-11 09:25:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 292, ShuffleMapStage 293)
2019-06-11 09:25:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 294 (MapPartitionsRDD[344] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_147 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:25:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_147_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:25:35,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_147_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:35,042  INFO [org.apache.spark.SparkContext] - Created broadcast 147 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 294 (MapPartitionsRDD[344] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:35,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 294.0 with 1 tasks
2019-06-11 09:25:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 294.0 (TID 196, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:35,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 294.0 (TID 196)
2019-06-11 09:25:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:35,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 294.0 (TID 196). 966 bytes result sent to driver
2019-06-11 09:25:35,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 294.0 (TID 196) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:35,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 294.0, whose tasks have all completed, from pool 
2019-06-11 09:25:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 294 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 98 finished: print at Transform.scala:36, took 0.005629 s
2019-06-11 09:25:35,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216335000 ms.0 from job set of time 1560216335000 ms
2019-06-11 09:25:35,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216335000 ms (execution: 0.039 s)
2019-06-11 09:25:35,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 337 from persistence list
2019-06-11 09:25:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 337
2019-06-11 09:25:35,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 332 from persistence list
2019-06-11 09:25:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 332
2019-06-11 09:25:35,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 331 from persistence list
2019-06-11 09:25:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 331
2019-06-11 09:25:35,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[331] at socketTextStream at Transform.scala:18 of time 1560216335000 ms
2019-06-11 09:25:35,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216325000 ms
2019-06-11 09:25:35,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216325000 ms
2019-06-11 09:25:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216340000 ms
2019-06-11 09:25:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216340000 ms.0 from job set of time 1560216340000 ms
2019-06-11 09:25:40,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 346 (map at Transform.scala:20)
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 99 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 297 (print at Transform.scala:36)
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 296, ShuffleMapStage 295)
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 296)
2019-06-11 09:25:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 296 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_148 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_148_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:25:40,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_148_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:25:40,012  INFO [org.apache.spark.SparkContext] - Created broadcast 148 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:40,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 296 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:40,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 296.0 with 2 tasks
2019-06-11 09:25:40,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 296.0 (TID 197, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:40,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 296.0 (TID 197)
2019-06-11 09:25:40,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 296.0 (TID 197). 853 bytes result sent to driver
2019-06-11 09:25:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 296.0 (TID 198, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:40,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 296.0 (TID 198)
2019-06-11 09:25:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 296.0 (TID 197) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:40,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 296.0 (TID 198). 810 bytes result sent to driver
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 296.0 (TID 198) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 296.0, whose tasks have all completed, from pool 
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 296 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 297)
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 297 (MapPartitionsRDD[351] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:40,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_149 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:40,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_149_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:40,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_149_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:25:40,032  INFO [org.apache.spark.SparkContext] - Created broadcast 149 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 297 (MapPartitionsRDD[351] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 297.0 with 1 tasks
2019-06-11 09:25:40,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 297.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:40,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 297.0 (TID 199)
2019-06-11 09:25:40,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:40,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:40,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:40,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:40,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 297.0 (TID 199). 966 bytes result sent to driver
2019-06-11 09:25:40,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 297.0 (TID 199) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 297.0, whose tasks have all completed, from pool 
2019-06-11 09:25:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 297 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:25:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 99 finished: print at Transform.scala:36, took 0.027534 s
2019-06-11 09:25:40,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:40,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 98 is 83 bytes
2019-06-11 09:25:40,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 99 is 160 bytes
2019-06-11 09:25:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 100 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 300 (print at Transform.scala:36)
2019-06-11 09:25:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 299, ShuffleMapStage 298)
2019-06-11 09:25:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 300 (MapPartitionsRDD[351] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:40,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_150 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:40,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_150_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:40,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_150_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:40,042  INFO [org.apache.spark.SparkContext] - Created broadcast 150 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:40,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 300 (MapPartitionsRDD[351] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:40,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 300.0 with 1 tasks
2019-06-11 09:25:40,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 300.0 (TID 200, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:40,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 300.0 (TID 200)
2019-06-11 09:25:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 300.0 (TID 200). 966 bytes result sent to driver
2019-06-11 09:25:40,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 300.0 (TID 200) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:40,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 300.0, whose tasks have all completed, from pool 
2019-06-11 09:25:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 300 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 100 finished: print at Transform.scala:36, took 0.006800 s
2019-06-11 09:25:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216340000 ms.0 from job set of time 1560216340000 ms
2019-06-11 09:25:40,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216340000 ms (execution: 0.039 s)
2019-06-11 09:25:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 344 from persistence list
2019-06-11 09:25:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 344
2019-06-11 09:25:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 339 from persistence list
2019-06-11 09:25:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 339
2019-06-11 09:25:40,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 338 from persistence list
2019-06-11 09:25:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 338
2019-06-11 09:25:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[338] at socketTextStream at Transform.scala:18 of time 1560216340000 ms
2019-06-11 09:25:40,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216330000 ms
2019-06-11 09:25:40,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216330000 ms
2019-06-11 09:25:45,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216345000 ms
2019-06-11 09:25:45,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216345000 ms.0 from job set of time 1560216345000 ms
2019-06-11 09:25:45,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 353 (map at Transform.scala:20)
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 101 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 303 (print at Transform.scala:36)
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 302, ShuffleMapStage 301)
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 302)
2019-06-11 09:25:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 302 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:45,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_151 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:45,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_151_piece0 stored as bytes in memory (estimated size 1308.0 B, free 1989.4 MB)
2019-06-11 09:25:45,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_151_piece0 in memory on 192.168.91.1:63518 (size: 1308.0 B, free: 1989.5 MB)
2019-06-11 09:25:45,016  INFO [org.apache.spark.SparkContext] - Created broadcast 151 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:45,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 302 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:45,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 302.0 with 2 tasks
2019-06-11 09:25:45,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 302.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:45,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 302.0 (TID 201)
2019-06-11 09:25:45,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 302.0 (TID 201). 810 bytes result sent to driver
2019-06-11 09:25:45,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 302.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:45,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 302.0 (TID 202)
2019-06-11 09:25:45,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 302.0 (TID 201) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:45,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 302.0 (TID 202). 853 bytes result sent to driver
2019-06-11 09:25:45,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 302.0 (TID 202) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:45,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 302.0, whose tasks have all completed, from pool 
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 302 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 303)
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 303 (MapPartitionsRDD[358] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_152 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:45,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_152_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:45,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_152_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:45,037  INFO [org.apache.spark.SparkContext] - Created broadcast 152 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 303 (MapPartitionsRDD[358] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:45,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 303.0 with 1 tasks
2019-06-11 09:25:45,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 303.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:45,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 303.0 (TID 203)
2019-06-11 09:25:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:45,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 303.0 (TID 203). 1009 bytes result sent to driver
2019-06-11 09:25:45,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 303.0 (TID 203) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:45,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 303.0, whose tasks have all completed, from pool 
2019-06-11 09:25:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 303 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 101 finished: print at Transform.scala:36, took 0.027309 s
2019-06-11 09:25:45,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:45,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 100 is 83 bytes
2019-06-11 09:25:45,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 101 is 160 bytes
2019-06-11 09:25:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 102 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 306 (print at Transform.scala:36)
2019-06-11 09:25:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 305, ShuffleMapStage 304)
2019-06-11 09:25:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 306 (MapPartitionsRDD[358] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:45,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_153 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:45,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_153_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:45,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_153_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:45,046  INFO [org.apache.spark.SparkContext] - Created broadcast 153 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 306 (MapPartitionsRDD[358] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 306.0 with 1 tasks
2019-06-11 09:25:45,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 306.0 (TID 204, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:45,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 306.0 (TID 204)
2019-06-11 09:25:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:45,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 306.0 (TID 204). 1009 bytes result sent to driver
2019-06-11 09:25:45,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 306.0 (TID 204) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:45,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 306.0, whose tasks have all completed, from pool 
2019-06-11 09:25:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 306 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 102 finished: print at Transform.scala:36, took 0.006279 s
2019-06-11 09:25:45,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216345000 ms.0 from job set of time 1560216345000 ms
2019-06-11 09:25:45,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560216345000 ms (execution: 0.038 s)
2019-06-11 09:25:45,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 351 from persistence list
2019-06-11 09:25:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 351
2019-06-11 09:25:45,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 346 from persistence list
2019-06-11 09:25:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 346
2019-06-11 09:25:45,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 345 from persistence list
2019-06-11 09:25:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 345
2019-06-11 09:25:45,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[345] at socketTextStream at Transform.scala:18 of time 1560216345000 ms
2019-06-11 09:25:45,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216335000 ms
2019-06-11 09:25:45,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216335000 ms
2019-06-11 09:25:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216350000 ms
2019-06-11 09:25:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216350000 ms.0 from job set of time 1560216350000 ms
2019-06-11 09:25:50,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 360 (map at Transform.scala:20)
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 103 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 309 (print at Transform.scala:36)
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 307, ShuffleMapStage 308)
2019-06-11 09:25:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 307)
2019-06-11 09:25:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 307 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_154 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_154_piece0 stored as bytes in memory (estimated size 1308.0 B, free 1989.4 MB)
2019-06-11 09:25:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_154_piece0 in memory on 192.168.91.1:63518 (size: 1308.0 B, free: 1989.5 MB)
2019-06-11 09:25:50,011  INFO [org.apache.spark.SparkContext] - Created broadcast 154 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 307 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:50,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 307.0 with 2 tasks
2019-06-11 09:25:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 307.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 307.0 (TID 205)
2019-06-11 09:25:50,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 307.0 (TID 205). 853 bytes result sent to driver
2019-06-11 09:25:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 307.0 (TID 206, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:50,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 307.0 (TID 206)
2019-06-11 09:25:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 307.0 (TID 205) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:50,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 307.0 (TID 206). 767 bytes result sent to driver
2019-06-11 09:25:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 307.0 (TID 206) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 307.0, whose tasks have all completed, from pool 
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 307 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 309)
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 309 (MapPartitionsRDD[365] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:50,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_155 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:50,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_155_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:50,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_155_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:50,032  INFO [org.apache.spark.SparkContext] - Created broadcast 155 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:50,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 309 (MapPartitionsRDD[365] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:50,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 309.0 with 1 tasks
2019-06-11 09:25:50,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 309.0 (TID 207, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:50,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 309.0 (TID 207)
2019-06-11 09:25:50,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:50,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:50,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:50,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:50,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 309.0 (TID 207). 1009 bytes result sent to driver
2019-06-11 09:25:50,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 309.0 (TID 207) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:50,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 309.0, whose tasks have all completed, from pool 
2019-06-11 09:25:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 309 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 103 finished: print at Transform.scala:36, took 0.027167 s
2019-06-11 09:25:50,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:50,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 103 is 160 bytes
2019-06-11 09:25:50,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 102 is 83 bytes
2019-06-11 09:25:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 104 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 312 (print at Transform.scala:36)
2019-06-11 09:25:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 310, ShuffleMapStage 311)
2019-06-11 09:25:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 312 (MapPartitionsRDD[365] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_156 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:50,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_156_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:50,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_156_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:50,041  INFO [org.apache.spark.SparkContext] - Created broadcast 156 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 312 (MapPartitionsRDD[365] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:50,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 312.0 with 1 tasks
2019-06-11 09:25:50,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 312.0 (TID 208, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:50,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 312.0 (TID 208)
2019-06-11 09:25:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:50,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 312.0 (TID 208). 1009 bytes result sent to driver
2019-06-11 09:25:50,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 312.0 (TID 208) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 312.0, whose tasks have all completed, from pool 
2019-06-11 09:25:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 312 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 104 finished: print at Transform.scala:36, took 0.006240 s
2019-06-11 09:25:50,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216350000 ms.0 from job set of time 1560216350000 ms
2019-06-11 09:25:50,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216350000 ms (execution: 0.038 s)
2019-06-11 09:25:50,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 358 from persistence list
2019-06-11 09:25:50,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 358
2019-06-11 09:25:50,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 353 from persistence list
2019-06-11 09:25:50,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 353
2019-06-11 09:25:50,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 352 from persistence list
2019-06-11 09:25:50,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 352
2019-06-11 09:25:50,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[352] at socketTextStream at Transform.scala:18 of time 1560216350000 ms
2019-06-11 09:25:50,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216340000 ms
2019-06-11 09:25:50,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216340000 ms
2019-06-11 09:25:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216355000 ms
2019-06-11 09:25:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216355000 ms.0 from job set of time 1560216355000 ms
2019-06-11 09:25:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:25:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 367 (map at Transform.scala:20)
2019-06-11 09:25:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 105 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 315 (print at Transform.scala:36)
2019-06-11 09:25:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 314, ShuffleMapStage 313)
2019-06-11 09:25:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 313)
2019-06-11 09:25:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 313 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:25:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_157 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_157_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:25:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_157_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:25:55,012  INFO [org.apache.spark.SparkContext] - Created broadcast 157 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:55,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 313 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:25:55,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 313.0 with 2 tasks
2019-06-11 09:25:55,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 313.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 313.0 (TID 209)
2019-06-11 09:25:55,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 313.0 (TID 209). 853 bytes result sent to driver
2019-06-11 09:25:55,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 313.0 (TID 210, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:25:55,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 313.0 (TID 210)
2019-06-11 09:25:55,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 313.0 (TID 209) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:25:55,036  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 313.0 (TID 210). 853 bytes result sent to driver
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 313.0 (TID 210) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 313.0, whose tasks have all completed, from pool 
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 313 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 315)
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:25:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 315 (MapPartitionsRDD[372] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_158 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_158_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:55,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_158_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:55,039  INFO [org.apache.spark.SparkContext] - Created broadcast 158 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 315 (MapPartitionsRDD[372] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:25:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 315.0 with 1 tasks
2019-06-11 09:25:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 315.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:55,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 315.0 (TID 211)
2019-06-11 09:25:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:55,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:25:55,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 315.0 (TID 211). 966 bytes result sent to driver
2019-06-11 09:25:55,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 315.0 (TID 211) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:55,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 315.0, whose tasks have all completed, from pool 
2019-06-11 09:25:55,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 315 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:55,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 105 finished: print at Transform.scala:36, took 0.034282 s
2019-06-11 09:25:55,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:25:55,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 105 is 160 bytes
2019-06-11 09:25:55,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 104 is 83 bytes
2019-06-11 09:25:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 106 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:25:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 318 (print at Transform.scala:36)
2019-06-11 09:25:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 317, ShuffleMapStage 316)
2019-06-11 09:25:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:25:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 318 (MapPartitionsRDD[372] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:25:55,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_159 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:25:55,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_159_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:25:55,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_159_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:25:55,049  INFO [org.apache.spark.SparkContext] - Created broadcast 159 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:25:55,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 318 (MapPartitionsRDD[372] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:25:55,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 318.0 with 1 tasks
2019-06-11 09:25:55,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 318.0 (TID 212, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:25:55,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 318.0 (TID 212)
2019-06-11 09:25:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:25:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:25:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:25:55,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 318.0 (TID 212). 1009 bytes result sent to driver
2019-06-11 09:25:55,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 318.0 (TID 212) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:25:55,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 318.0, whose tasks have all completed, from pool 
2019-06-11 09:25:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 318 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:25:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 106 finished: print at Transform.scala:36, took 0.006134 s
2019-06-11 09:25:55,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216355000 ms.0 from job set of time 1560216355000 ms
2019-06-11 09:25:55,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216355000 ms (execution: 0.045 s)
2019-06-11 09:25:55,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 365 from persistence list
2019-06-11 09:25:55,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 365
2019-06-11 09:25:55,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 360 from persistence list
2019-06-11 09:25:55,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 360
2019-06-11 09:25:55,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 359 from persistence list
2019-06-11 09:25:55,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 359
2019-06-11 09:25:55,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[359] at socketTextStream at Transform.scala:18 of time 1560216355000 ms
2019-06-11 09:25:55,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216345000 ms
2019-06-11 09:25:55,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216345000 ms
2019-06-11 09:26:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216360000 ms
2019-06-11 09:26:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216360000 ms.0 from job set of time 1560216360000 ms
2019-06-11 09:26:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 374 (map at Transform.scala:20)
2019-06-11 09:26:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 107 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 321 (print at Transform.scala:36)
2019-06-11 09:26:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 320, ShuffleMapStage 319)
2019-06-11 09:26:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 319)
2019-06-11 09:26:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 319 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_160 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_160_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:00,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_160_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:00,013  INFO [org.apache.spark.SparkContext] - Created broadcast 160 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 319 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:00,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 319.0 with 2 tasks
2019-06-11 09:26:00,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 319.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:00,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 319.0 (TID 213)
2019-06-11 09:26:00,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 319.0 (TID 213). 853 bytes result sent to driver
2019-06-11 09:26:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 319.0 (TID 214, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:00,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 319.0 (TID 214)
2019-06-11 09:26:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 319.0 (TID 213) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 319.0 (TID 214). 810 bytes result sent to driver
2019-06-11 09:26:00,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 319.0 (TID 214) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:00,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 319.0, whose tasks have all completed, from pool 
2019-06-11 09:26:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 319 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:26:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 321)
2019-06-11 09:26:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 321 (MapPartitionsRDD[379] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_161 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_161_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:00,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_161_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:00,032  INFO [org.apache.spark.SparkContext] - Created broadcast 161 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 321 (MapPartitionsRDD[379] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:00,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 321.0 with 1 tasks
2019-06-11 09:26:00,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 321.0 (TID 215, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:00,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 321.0 (TID 215)
2019-06-11 09:26:00,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:00,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:00,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:00,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:00,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 321.0 (TID 215). 966 bytes result sent to driver
2019-06-11 09:26:00,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 321.0 (TID 215) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:00,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 321.0, whose tasks have all completed, from pool 
2019-06-11 09:26:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 321 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 107 finished: print at Transform.scala:36, took 0.025940 s
2019-06-11 09:26:00,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:00,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 107 is 160 bytes
2019-06-11 09:26:00,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 106 is 83 bytes
2019-06-11 09:26:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 108 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 324 (print at Transform.scala:36)
2019-06-11 09:26:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 322, ShuffleMapStage 323)
2019-06-11 09:26:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 324 (MapPartitionsRDD[379] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:00,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_162 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:00,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_162_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:00,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_162_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:00,042  INFO [org.apache.spark.SparkContext] - Created broadcast 162 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 324 (MapPartitionsRDD[379] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:00,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 324.0 with 1 tasks
2019-06-11 09:26:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 324.0 (TID 216, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:00,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 324.0 (TID 216)
2019-06-11 09:26:00,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:00,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:26:00,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 324.0 (TID 216). 1009 bytes result sent to driver
2019-06-11 09:26:00,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 324.0 (TID 216) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:00,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 324.0, whose tasks have all completed, from pool 
2019-06-11 09:26:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 324 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 108 finished: print at Transform.scala:36, took 0.005207 s
2019-06-11 09:26:00,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216360000 ms.0 from job set of time 1560216360000 ms
2019-06-11 09:26:00,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216360000 ms (execution: 0.036 s)
2019-06-11 09:26:00,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 372 from persistence list
2019-06-11 09:26:00,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 372
2019-06-11 09:26:00,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 367 from persistence list
2019-06-11 09:26:00,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 367
2019-06-11 09:26:00,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 366 from persistence list
2019-06-11 09:26:00,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 366
2019-06-11 09:26:00,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[366] at socketTextStream at Transform.scala:18 of time 1560216360000 ms
2019-06-11 09:26:00,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216350000 ms
2019-06-11 09:26:00,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216350000 ms
2019-06-11 09:26:05,021  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216365000 ms
2019-06-11 09:26:05,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_144_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,023  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216365000 ms.0 from job set of time 1560216365000 ms
2019-06-11 09:26:05,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_151_piece0 on 192.168.91.1:63518 in memory (size: 1308.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 97
2019-06-11 09:26:05,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_158_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 92
2019-06-11 09:26:05,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 93
2019-06-11 09:26:05,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_148_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 100
2019-06-11 09:26:05,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_145_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,028  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:05,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 99
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 381 (map at Transform.scala:20)
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 109 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 327 (print at Transform.scala:36)
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 325, ShuffleMapStage 326)
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 326)
2019-06-11 09:26:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 326 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_160_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_163 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:05,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_156_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_163_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:05,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_150_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_163_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,032  INFO [org.apache.spark.SparkContext] - Created broadcast 163 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 326 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:05,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 326.0 with 2 tasks
2019-06-11 09:26:05,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_142_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 326.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:05,033  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 104
2019-06-11 09:26:05,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 326.0 (TID 217)
2019-06-11 09:26:05,033  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 105
2019-06-11 09:26:05,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 94
2019-06-11 09:26:05,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_162_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_155_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_152_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_157_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:05,037  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 101
2019-06-11 09:26:05,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 98
2019-06-11 09:26:05,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 96
2019-06-11 09:26:05,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_153_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:05,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_159_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_161_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_154_piece0 on 192.168.91.1:63518 in memory (size: 1308.0 B, free: 1989.6 MB)
2019-06-11 09:26:05,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_149_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 103
2019-06-11 09:26:05,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 95
2019-06-11 09:26:05,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_141_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 90
2019-06-11 09:26:05,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 102
2019-06-11 09:26:05,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_147_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_143_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 326.0 (TID 217). 767 bytes result sent to driver
2019-06-11 09:26:05,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 326.0 (TID 218, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:05,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_146_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,046  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 326.0 (TID 218)
2019-06-11 09:26:05,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 326.0 (TID 217) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:05,075  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 326.0 (TID 218). 853 bytes result sent to driver
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 326.0 (TID 218) in 30 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 326.0, whose tasks have all completed, from pool 
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 326 (parallelize at Transform.scala:16) finished in 0.042 s
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 327)
2019-06-11 09:26:05,075  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:05,076  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 327 (MapPartitionsRDD[386] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:05,076  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_164 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:05,077  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_164_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:05,077  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_164_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,078  INFO [org.apache.spark.SparkContext] - Created broadcast 164 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:05,078  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 327 (MapPartitionsRDD[386] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:05,078  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 327.0 with 1 tasks
2019-06-11 09:26:05,079  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 327.0 (TID 219, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:05,079  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 327.0 (TID 219)
2019-06-11 09:26:05,080  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:05,080  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:05,080  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:05,080  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:05,081  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 327.0 (TID 219). 1009 bytes result sent to driver
2019-06-11 09:26:05,081  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 327.0 (TID 219) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:05,081  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 327.0, whose tasks have all completed, from pool 
2019-06-11 09:26:05,081  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 327 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:05,081  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 109 finished: print at Transform.scala:36, took 0.053208 s
2019-06-11 09:26:05,084  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:05,084  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 108 is 83 bytes
2019-06-11 09:26:05,084  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 109 is 160 bytes
2019-06-11 09:26:05,084  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 110 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:05,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 330 (print at Transform.scala:36)
2019-06-11 09:26:05,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 328, ShuffleMapStage 329)
2019-06-11 09:26:05,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:05,085  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 330 (MapPartitionsRDD[386] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:05,085  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_165 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:05,086  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_165_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:05,087  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_165_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:05,087  INFO [org.apache.spark.SparkContext] - Created broadcast 165 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:05,087  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 330 (MapPartitionsRDD[386] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:05,087  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 330.0 with 1 tasks
2019-06-11 09:26:05,087  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 330.0 (TID 220, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:05,088  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 330.0 (TID 220)
2019-06-11 09:26:05,088  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:05,088  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:05,089  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:05,089  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:05,089  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 330.0 (TID 220). 966 bytes result sent to driver
2019-06-11 09:26:05,090  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 330.0 (TID 220) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:05,090  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 330.0, whose tasks have all completed, from pool 
2019-06-11 09:26:05,090  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 330 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:05,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 110 finished: print at Transform.scala:36, took 0.006165 s
2019-06-11 09:26:05,090  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216365000 ms.0 from job set of time 1560216365000 ms
2019-06-11 09:26:05,091  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.090 s for time 1560216365000 ms (execution: 0.067 s)
2019-06-11 09:26:05,091  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 379 from persistence list
2019-06-11 09:26:05,091  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 379
2019-06-11 09:26:05,091  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 374 from persistence list
2019-06-11 09:26:05,091  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 374
2019-06-11 09:26:05,091  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 373 from persistence list
2019-06-11 09:26:05,091  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 373
2019-06-11 09:26:05,091  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[373] at socketTextStream at Transform.scala:18 of time 1560216365000 ms
2019-06-11 09:26:05,092  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216355000 ms
2019-06-11 09:26:05,092  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216355000 ms
2019-06-11 09:26:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216370000 ms
2019-06-11 09:26:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216370000 ms.0 from job set of time 1560216370000 ms
2019-06-11 09:26:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 388 (map at Transform.scala:20)
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 111 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 333 (print at Transform.scala:36)
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 332, ShuffleMapStage 331)
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 332)
2019-06-11 09:26:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 332 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_166 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_166_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:26:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_166_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 166 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 332 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 332.0 with 2 tasks
2019-06-11 09:26:10,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 332.0 (TID 221, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 332.0 (TID 221)
2019-06-11 09:26:10,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 332.0 (TID 221). 767 bytes result sent to driver
2019-06-11 09:26:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 332.0 (TID 222, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:10,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 332.0 (TID 222)
2019-06-11 09:26:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 332.0 (TID 221) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:10,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 332.0 (TID 222). 853 bytes result sent to driver
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 332.0 (TID 222) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 332.0, whose tasks have all completed, from pool 
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 332 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 333)
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 333 (MapPartitionsRDD[393] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_167 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:10,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_167_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:10,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_167_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:10,035  INFO [org.apache.spark.SparkContext] - Created broadcast 167 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 333 (MapPartitionsRDD[393] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 333.0 with 1 tasks
2019-06-11 09:26:10,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 333.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:10,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 333.0 (TID 223)
2019-06-11 09:26:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:26:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:10,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 333.0 (TID 223). 966 bytes result sent to driver
2019-06-11 09:26:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 333.0 (TID 223) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:10,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 333.0, whose tasks have all completed, from pool 
2019-06-11 09:26:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 333 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 111 finished: print at Transform.scala:36, took 0.029333 s
2019-06-11 09:26:10,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 110 is 83 bytes
2019-06-11 09:26:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 111 is 160 bytes
2019-06-11 09:26:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 112 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 336 (print at Transform.scala:36)
2019-06-11 09:26:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 335, ShuffleMapStage 334)
2019-06-11 09:26:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 336 (MapPartitionsRDD[393] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_168 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_168_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_168_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:10,043  INFO [org.apache.spark.SparkContext] - Created broadcast 168 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 336 (MapPartitionsRDD[393] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:10,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 336.0 with 1 tasks
2019-06-11 09:26:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 336.0 (TID 224, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:10,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 336.0 (TID 224)
2019-06-11 09:26:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 336.0 (TID 224). 966 bytes result sent to driver
2019-06-11 09:26:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 336.0 (TID 224) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 336.0, whose tasks have all completed, from pool 
2019-06-11 09:26:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 336 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 112 finished: print at Transform.scala:36, took 0.005857 s
2019-06-11 09:26:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216370000 ms.0 from job set of time 1560216370000 ms
2019-06-11 09:26:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216370000 ms (execution: 0.040 s)
2019-06-11 09:26:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 386 from persistence list
2019-06-11 09:26:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 386
2019-06-11 09:26:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 381 from persistence list
2019-06-11 09:26:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 381
2019-06-11 09:26:10,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 380 from persistence list
2019-06-11 09:26:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 380
2019-06-11 09:26:10,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[380] at socketTextStream at Transform.scala:18 of time 1560216370000 ms
2019-06-11 09:26:10,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216360000 ms
2019-06-11 09:26:10,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216360000 ms
2019-06-11 09:26:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216375000 ms
2019-06-11 09:26:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216375000 ms.0 from job set of time 1560216375000 ms
2019-06-11 09:26:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 395 (map at Transform.scala:20)
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 113 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 339 (print at Transform.scala:36)
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 338, ShuffleMapStage 337)
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 337)
2019-06-11 09:26:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 337 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_169 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_169_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:26:15,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_169_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:15,011  INFO [org.apache.spark.SparkContext] - Created broadcast 169 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 337 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:15,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 337.0 with 2 tasks
2019-06-11 09:26:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 337.0 (TID 225, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:15,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 337.0 (TID 225)
2019-06-11 09:26:15,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 337.0 (TID 225). 853 bytes result sent to driver
2019-06-11 09:26:15,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 337.0 (TID 226, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:15,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 337.0 (TID 226)
2019-06-11 09:26:15,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 337.0 (TID 225) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:15,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 337.0 (TID 226). 767 bytes result sent to driver
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 337.0 (TID 226) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 337.0, whose tasks have all completed, from pool 
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 337 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 339)
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 339 (MapPartitionsRDD[400] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:15,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_170 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:15,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_170_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:15,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_170_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:15,033  INFO [org.apache.spark.SparkContext] - Created broadcast 170 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 339 (MapPartitionsRDD[400] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:15,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 339.0 with 1 tasks
2019-06-11 09:26:15,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 339.0 (TID 227, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:15,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 339.0 (TID 227)
2019-06-11 09:26:15,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:15,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:15,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:15,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:15,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 339.0 (TID 227). 1009 bytes result sent to driver
2019-06-11 09:26:15,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 339.0 (TID 227) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:15,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 339.0, whose tasks have all completed, from pool 
2019-06-11 09:26:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 339 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 113 finished: print at Transform.scala:36, took 0.027399 s
2019-06-11 09:26:15,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:15,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 113 is 160 bytes
2019-06-11 09:26:15,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 112 is 83 bytes
2019-06-11 09:26:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 114 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 342 (print at Transform.scala:36)
2019-06-11 09:26:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 340, ShuffleMapStage 341)
2019-06-11 09:26:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 342 (MapPartitionsRDD[400] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:15,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_171 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_171_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:15,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_171_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 171 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 342 (MapPartitionsRDD[400] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 342.0 with 1 tasks
2019-06-11 09:26:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 342.0 (TID 228, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:15,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 342.0 (TID 228)
2019-06-11 09:26:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:15,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 342.0 (TID 228). 1009 bytes result sent to driver
2019-06-11 09:26:15,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 342.0 (TID 228) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:15,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 342.0, whose tasks have all completed, from pool 
2019-06-11 09:26:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 342 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 114 finished: print at Transform.scala:36, took 0.005883 s
2019-06-11 09:26:15,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216375000 ms.0 from job set of time 1560216375000 ms
2019-06-11 09:26:15,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216375000 ms (execution: 0.038 s)
2019-06-11 09:26:15,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 393 from persistence list
2019-06-11 09:26:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 393
2019-06-11 09:26:15,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 388 from persistence list
2019-06-11 09:26:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 388
2019-06-11 09:26:15,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 387 from persistence list
2019-06-11 09:26:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 387
2019-06-11 09:26:15,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[387] at socketTextStream at Transform.scala:18 of time 1560216375000 ms
2019-06-11 09:26:15,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216365000 ms
2019-06-11 09:26:15,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216365000 ms
2019-06-11 09:26:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216380000 ms
2019-06-11 09:26:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216380000 ms.0 from job set of time 1560216380000 ms
2019-06-11 09:26:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 402 (map at Transform.scala:20)
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 115 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 345 (print at Transform.scala:36)
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 343, ShuffleMapStage 344)
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 344)
2019-06-11 09:26:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 344 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_172 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_172_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_172_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 172 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 344 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 344.0 with 2 tasks
2019-06-11 09:26:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 344.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 344.0 (TID 229)
2019-06-11 09:26:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 344.0 (TID 229). 810 bytes result sent to driver
2019-06-11 09:26:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 344.0 (TID 230, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:20,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 344.0 (TID 230)
2019-06-11 09:26:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 344.0 (TID 229) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:20,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 344.0 (TID 230). 810 bytes result sent to driver
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 344.0 (TID 230) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 344.0, whose tasks have all completed, from pool 
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 344 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 345)
2019-06-11 09:26:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 345 (MapPartitionsRDD[407] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_173 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_173_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:20,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_173_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:20,031  INFO [org.apache.spark.SparkContext] - Created broadcast 173 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 345 (MapPartitionsRDD[407] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 345.0 with 1 tasks
2019-06-11 09:26:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 345.0 (TID 231, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:20,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 345.0 (TID 231)
2019-06-11 09:26:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:20,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 345.0 (TID 231). 1009 bytes result sent to driver
2019-06-11 09:26:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 345.0 (TID 231) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 345.0, whose tasks have all completed, from pool 
2019-06-11 09:26:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 345 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 115 finished: print at Transform.scala:36, took 0.025847 s
2019-06-11 09:26:20,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 114 is 83 bytes
2019-06-11 09:26:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 115 is 160 bytes
2019-06-11 09:26:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 116 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 348 (print at Transform.scala:36)
2019-06-11 09:26:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 347, ShuffleMapStage 346)
2019-06-11 09:26:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 348 (MapPartitionsRDD[407] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_174 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:20,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_174_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:20,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_174_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:20,040  INFO [org.apache.spark.SparkContext] - Created broadcast 174 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 348 (MapPartitionsRDD[407] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 348.0 with 1 tasks
2019-06-11 09:26:20,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 348.0 (TID 232, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:20,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 348.0 (TID 232)
2019-06-11 09:26:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:20,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 348.0 (TID 232). 966 bytes result sent to driver
2019-06-11 09:26:20,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 348.0 (TID 232) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:20,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 348.0, whose tasks have all completed, from pool 
2019-06-11 09:26:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 348 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 116 finished: print at Transform.scala:36, took 0.005597 s
2019-06-11 09:26:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216380000 ms.0 from job set of time 1560216380000 ms
2019-06-11 09:26:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216380000 ms (execution: 0.038 s)
2019-06-11 09:26:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 400 from persistence list
2019-06-11 09:26:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 400
2019-06-11 09:26:20,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 395 from persistence list
2019-06-11 09:26:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 395
2019-06-11 09:26:20,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 394 from persistence list
2019-06-11 09:26:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 394
2019-06-11 09:26:20,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[394] at socketTextStream at Transform.scala:18 of time 1560216380000 ms
2019-06-11 09:26:20,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216370000 ms
2019-06-11 09:26:20,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216370000 ms
2019-06-11 09:26:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216385000 ms
2019-06-11 09:26:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216385000 ms.0 from job set of time 1560216385000 ms
2019-06-11 09:26:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 409 (map at Transform.scala:20)
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 117 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 351 (print at Transform.scala:36)
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 350, ShuffleMapStage 349)
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 349)
2019-06-11 09:26:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 349 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_175 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_175_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_175_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 175 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 349 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 349.0 with 2 tasks
2019-06-11 09:26:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 349.0 (TID 233, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 349.0 (TID 233)
2019-06-11 09:26:25,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 349.0 (TID 233). 810 bytes result sent to driver
2019-06-11 09:26:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 349.0 (TID 234, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 349.0 (TID 234)
2019-06-11 09:26:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 349.0 (TID 233) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 349.0 (TID 234). 810 bytes result sent to driver
2019-06-11 09:26:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 349.0 (TID 234) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:25,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 349.0, whose tasks have all completed, from pool 
2019-06-11 09:26:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 349 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:26:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 351)
2019-06-11 09:26:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 351 (MapPartitionsRDD[414] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_176 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_176_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_176_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:25,030  INFO [org.apache.spark.SparkContext] - Created broadcast 176 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:25,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 351 (MapPartitionsRDD[414] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:25,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 351.0 with 1 tasks
2019-06-11 09:26:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 351.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 351.0 (TID 235)
2019-06-11 09:26:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 351.0 (TID 235). 966 bytes result sent to driver
2019-06-11 09:26:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 351.0 (TID 235) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:25,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 351.0, whose tasks have all completed, from pool 
2019-06-11 09:26:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 351 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 117 finished: print at Transform.scala:36, took 0.025416 s
2019-06-11 09:26:25,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:25,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 117 is 160 bytes
2019-06-11 09:26:25,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 116 is 83 bytes
2019-06-11 09:26:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 118 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 354 (print at Transform.scala:36)
2019-06-11 09:26:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 353, ShuffleMapStage 352)
2019-06-11 09:26:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 354 (MapPartitionsRDD[414] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:25,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_177 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:25,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_177_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:25,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_177_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:25,039  INFO [org.apache.spark.SparkContext] - Created broadcast 177 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 354 (MapPartitionsRDD[414] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 354.0 with 1 tasks
2019-06-11 09:26:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 354.0 (TID 236, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:25,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 354.0 (TID 236)
2019-06-11 09:26:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:25,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 354.0 (TID 236). 1009 bytes result sent to driver
2019-06-11 09:26:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 354.0 (TID 236) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 354.0, whose tasks have all completed, from pool 
2019-06-11 09:26:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 354 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 118 finished: print at Transform.scala:36, took 0.005635 s
2019-06-11 09:26:25,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216385000 ms.0 from job set of time 1560216385000 ms
2019-06-11 09:26:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 407 from persistence list
2019-06-11 09:26:25,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216385000 ms (execution: 0.037 s)
2019-06-11 09:26:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 407
2019-06-11 09:26:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 402 from persistence list
2019-06-11 09:26:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 402
2019-06-11 09:26:25,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 401 from persistence list
2019-06-11 09:26:25,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 401
2019-06-11 09:26:25,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[401] at socketTextStream at Transform.scala:18 of time 1560216385000 ms
2019-06-11 09:26:25,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216375000 ms
2019-06-11 09:26:25,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216375000 ms
2019-06-11 09:26:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216390000 ms
2019-06-11 09:26:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216390000 ms.0 from job set of time 1560216390000 ms
2019-06-11 09:26:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 416 (map at Transform.scala:20)
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 119 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 357 (print at Transform.scala:36)
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 356, ShuffleMapStage 355)
2019-06-11 09:26:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 355)
2019-06-11 09:26:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 355 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_178 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:30,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_178_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_178_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:30,012  INFO [org.apache.spark.SparkContext] - Created broadcast 178 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:30,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 355 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:30,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 355.0 with 2 tasks
2019-06-11 09:26:30,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 355.0 (TID 237, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:30,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 355.0 (TID 237)
2019-06-11 09:26:30,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 355.0 (TID 237). 853 bytes result sent to driver
2019-06-11 09:26:30,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 355.0 (TID 238, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:30,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 355.0 (TID 238)
2019-06-11 09:26:30,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 355.0 (TID 237) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:30,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 355.0 (TID 238). 810 bytes result sent to driver
2019-06-11 09:26:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 355.0 (TID 238) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 355.0, whose tasks have all completed, from pool 
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 355 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 357)
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 357 (MapPartitionsRDD[421] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:30,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_179 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:30,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_179_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:30,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_179_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:30,032  INFO [org.apache.spark.SparkContext] - Created broadcast 179 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 357 (MapPartitionsRDD[421] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 357.0 with 1 tasks
2019-06-11 09:26:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 357.0 (TID 239, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:30,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 357.0 (TID 239)
2019-06-11 09:26:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:30,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 357.0 (TID 239). 1009 bytes result sent to driver
2019-06-11 09:26:30,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 357.0 (TID 239) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:30,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 357.0, whose tasks have all completed, from pool 
2019-06-11 09:26:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 357 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 119 finished: print at Transform.scala:36, took 0.026098 s
2019-06-11 09:26:30,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:30,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 119 is 160 bytes
2019-06-11 09:26:30,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 118 is 83 bytes
2019-06-11 09:26:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 120 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 360 (print at Transform.scala:36)
2019-06-11 09:26:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 358, ShuffleMapStage 359)
2019-06-11 09:26:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 360 (MapPartitionsRDD[421] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_180 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_180_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_180_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:30,041  INFO [org.apache.spark.SparkContext] - Created broadcast 180 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 360 (MapPartitionsRDD[421] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 360.0 with 1 tasks
2019-06-11 09:26:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 360.0 (TID 240, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:30,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 360.0 (TID 240)
2019-06-11 09:26:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:30,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 360.0 (TID 240). 1009 bytes result sent to driver
2019-06-11 09:26:30,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 360.0 (TID 240) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:30,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 360.0, whose tasks have all completed, from pool 
2019-06-11 09:26:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 360 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 120 finished: print at Transform.scala:36, took 0.006811 s
2019-06-11 09:26:30,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216390000 ms.0 from job set of time 1560216390000 ms
2019-06-11 09:26:30,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216390000 ms (execution: 0.038 s)
2019-06-11 09:26:30,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 414 from persistence list
2019-06-11 09:26:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 414
2019-06-11 09:26:30,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 409 from persistence list
2019-06-11 09:26:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 409
2019-06-11 09:26:30,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 408 from persistence list
2019-06-11 09:26:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 408
2019-06-11 09:26:30,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[408] at socketTextStream at Transform.scala:18 of time 1560216390000 ms
2019-06-11 09:26:30,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216380000 ms
2019-06-11 09:26:30,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216380000 ms
2019-06-11 09:26:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216395000 ms
2019-06-11 09:26:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216395000 ms.0 from job set of time 1560216395000 ms
2019-06-11 09:26:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 423 (map at Transform.scala:20)
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 121 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 363 (print at Transform.scala:36)
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 361, ShuffleMapStage 362)
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 361)
2019-06-11 09:26:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 361 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_181 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_181_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_181_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 181 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 361 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 361.0 with 2 tasks
2019-06-11 09:26:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 361.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:35,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 361.0 (TID 241)
2019-06-11 09:26:35,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 361.0 (TID 241). 810 bytes result sent to driver
2019-06-11 09:26:35,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 361.0 (TID 242, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:35,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 361.0 (TID 241) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:35,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 361.0 (TID 242)
2019-06-11 09:26:35,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 361.0 (TID 242). 810 bytes result sent to driver
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 361.0 (TID 242) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 361.0, whose tasks have all completed, from pool 
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 361 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 363)
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 363 (MapPartitionsRDD[428] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_182 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_182_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_182_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:35,037  INFO [org.apache.spark.SparkContext] - Created broadcast 182 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 363 (MapPartitionsRDD[428] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 363.0 with 1 tasks
2019-06-11 09:26:35,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 363.0 (TID 243, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:35,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 363.0 (TID 243)
2019-06-11 09:26:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:35,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 363.0 (TID 243). 1009 bytes result sent to driver
2019-06-11 09:26:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 363.0 (TID 243) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 363.0, whose tasks have all completed, from pool 
2019-06-11 09:26:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 363 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 121 finished: print at Transform.scala:36, took 0.031637 s
2019-06-11 09:26:35,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:35,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 121 is 160 bytes
2019-06-11 09:26:35,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 120 is 83 bytes
2019-06-11 09:26:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 122 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 366 (print at Transform.scala:36)
2019-06-11 09:26:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 365, ShuffleMapStage 364)
2019-06-11 09:26:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 366 (MapPartitionsRDD[428] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:35,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_183 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:35,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_183_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:35,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_183_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:35,045  INFO [org.apache.spark.SparkContext] - Created broadcast 183 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 366 (MapPartitionsRDD[428] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:35,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 366.0 with 1 tasks
2019-06-11 09:26:35,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 366.0 (TID 244, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:35,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 366.0 (TID 244)
2019-06-11 09:26:35,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:35,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:35,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:35,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:35,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 366.0 (TID 244). 1009 bytes result sent to driver
2019-06-11 09:26:35,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 366.0 (TID 244) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:35,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 366.0, whose tasks have all completed, from pool 
2019-06-11 09:26:35,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 366 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:35,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 122 finished: print at Transform.scala:36, took 0.006355 s
2019-06-11 09:26:35,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216395000 ms.0 from job set of time 1560216395000 ms
2019-06-11 09:26:35,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560216395000 ms (execution: 0.043 s)
2019-06-11 09:26:35,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 421 from persistence list
2019-06-11 09:26:35,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 421
2019-06-11 09:26:35,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 416 from persistence list
2019-06-11 09:26:35,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 416
2019-06-11 09:26:35,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 415 from persistence list
2019-06-11 09:26:35,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 415
2019-06-11 09:26:35,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[415] at socketTextStream at Transform.scala:18 of time 1560216395000 ms
2019-06-11 09:26:35,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216385000 ms
2019-06-11 09:26:35,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216385000 ms
2019-06-11 09:26:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216400000 ms
2019-06-11 09:26:40,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216400000 ms.0 from job set of time 1560216400000 ms
2019-06-11 09:26:40,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 430 (map at Transform.scala:20)
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 123 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 369 (print at Transform.scala:36)
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 368, ShuffleMapStage 367)
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 368)
2019-06-11 09:26:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 368 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_184 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:40,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_184_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:40,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_184_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_173_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,022  INFO [org.apache.spark.SparkContext] - Created broadcast 184 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:40,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 109
2019-06-11 09:26:40,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 368 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:40,024  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 368.0 with 2 tasks
2019-06-11 09:26:40,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 368.0 (TID 245, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:40,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_171_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,024  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 368.0 (TID 245)
2019-06-11 09:26:40,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 116
2019-06-11 09:26:40,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_170_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 117
2019-06-11 09:26:40,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_178_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_175_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_169_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 107
2019-06-11 09:26:40,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 119
2019-06-11 09:26:40,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_183_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_179_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_176_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 113
2019-06-11 09:26:40,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_172_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 115
2019-06-11 09:26:40,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 112
2019-06-11 09:26:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_181_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_167_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:40,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_174_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,039  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 108
2019-06-11 09:26:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 368.0 (TID 245). 810 bytes result sent to driver
2019-06-11 09:26:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 368.0 (TID 246, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:40,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_166_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:40,039  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 368.0 (TID 246)
2019-06-11 09:26:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 368.0 (TID 245) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:40,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 118
2019-06-11 09:26:40,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_163_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:40,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_164_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 114
2019-06-11 09:26:40,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 106
2019-06-11 09:26:40,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_180_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 110
2019-06-11 09:26:40,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 111
2019-06-11 09:26:40,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_165_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_168_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_177_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_182_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,052  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 368.0 (TID 246). 853 bytes result sent to driver
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 368.0 (TID 246) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 368.0, whose tasks have all completed, from pool 
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 368 (parallelize at Transform.scala:16) finished in 0.029 s
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 369)
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:40,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 369 (MapPartitionsRDD[435] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:40,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_185 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:40,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_185_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:40,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_185_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,055  INFO [org.apache.spark.SparkContext] - Created broadcast 185 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:40,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 369 (MapPartitionsRDD[435] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:40,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 369.0 with 1 tasks
2019-06-11 09:26:40,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 369.0 (TID 247, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:40,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 369.0 (TID 247)
2019-06-11 09:26:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:40,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:40,058  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 369.0 (TID 247). 1009 bytes result sent to driver
2019-06-11 09:26:40,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 369.0 (TID 247) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:40,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 369.0, whose tasks have all completed, from pool 
2019-06-11 09:26:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 369 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:40,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 123 finished: print at Transform.scala:36, took 0.048939 s
2019-06-11 09:26:40,061  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:40,062  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 122 is 83 bytes
2019-06-11 09:26:40,062  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 123 is 160 bytes
2019-06-11 09:26:40,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 124 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:40,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 372 (print at Transform.scala:36)
2019-06-11 09:26:40,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 371, ShuffleMapStage 370)
2019-06-11 09:26:40,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:40,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 372 (MapPartitionsRDD[435] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:40,063  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_186 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:40,064  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_186_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:40,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_186_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:40,065  INFO [org.apache.spark.SparkContext] - Created broadcast 186 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:40,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 372 (MapPartitionsRDD[435] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:40,065  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 372.0 with 1 tasks
2019-06-11 09:26:40,065  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 372.0 (TID 248, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:40,065  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 372.0 (TID 248)
2019-06-11 09:26:40,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:40,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:40,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:40,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:40,067  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 372.0 (TID 248). 1009 bytes result sent to driver
2019-06-11 09:26:40,068  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 372.0 (TID 248) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:40,068  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 372.0, whose tasks have all completed, from pool 
2019-06-11 09:26:40,068  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 372 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:40,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 124 finished: print at Transform.scala:36, took 0.006745 s
2019-06-11 09:26:40,069  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216400000 ms.0 from job set of time 1560216400000 ms
2019-06-11 09:26:40,069  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.069 s for time 1560216400000 ms (execution: 0.061 s)
2019-06-11 09:26:40,069  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 428 from persistence list
2019-06-11 09:26:40,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 428
2019-06-11 09:26:40,069  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 423 from persistence list
2019-06-11 09:26:40,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 423
2019-06-11 09:26:40,069  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 422 from persistence list
2019-06-11 09:26:40,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 422
2019-06-11 09:26:40,069  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[422] at socketTextStream at Transform.scala:18 of time 1560216400000 ms
2019-06-11 09:26:40,070  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216390000 ms
2019-06-11 09:26:40,070  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216390000 ms
2019-06-11 09:26:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216405000 ms
2019-06-11 09:26:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216405000 ms.0 from job set of time 1560216405000 ms
2019-06-11 09:26:45,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 437 (map at Transform.scala:20)
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 125 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 375 (print at Transform.scala:36)
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 374, ShuffleMapStage 373)
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 374)
2019-06-11 09:26:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 374 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_187 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:45,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_187_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:26:45,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_187_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:45,011  INFO [org.apache.spark.SparkContext] - Created broadcast 187 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 374 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:45,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 374.0 with 2 tasks
2019-06-11 09:26:45,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 374.0 (TID 249, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:45,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 374.0 (TID 249)
2019-06-11 09:26:45,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 374.0 (TID 249). 810 bytes result sent to driver
2019-06-11 09:26:45,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 374.0 (TID 250, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:45,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 374.0 (TID 250)
2019-06-11 09:26:45,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 374.0 (TID 249) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:45,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 374.0 (TID 250). 853 bytes result sent to driver
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 374.0 (TID 250) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 374.0, whose tasks have all completed, from pool 
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 374 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 375)
2019-06-11 09:26:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 375 (MapPartitionsRDD[442] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:45,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_188 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_188_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:45,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_188_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:45,038  INFO [org.apache.spark.SparkContext] - Created broadcast 188 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 375 (MapPartitionsRDD[442] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:45,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 375.0 with 1 tasks
2019-06-11 09:26:45,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 375.0 (TID 251, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:45,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 375.0 (TID 251)
2019-06-11 09:26:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:26:45,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 375.0 (TID 251). 1009 bytes result sent to driver
2019-06-11 09:26:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 375.0 (TID 251) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 375.0, whose tasks have all completed, from pool 
2019-06-11 09:26:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 375 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 125 finished: print at Transform.scala:36, took 0.032386 s
2019-06-11 09:26:45,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:45,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 124 is 83 bytes
2019-06-11 09:26:45,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 125 is 160 bytes
2019-06-11 09:26:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 126 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 378 (print at Transform.scala:36)
2019-06-11 09:26:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 376, ShuffleMapStage 377)
2019-06-11 09:26:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 378 (MapPartitionsRDD[442] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:45,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_189 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:45,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_189_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:45,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_189_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:45,046  INFO [org.apache.spark.SparkContext] - Created broadcast 189 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 378 (MapPartitionsRDD[442] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 378.0 with 1 tasks
2019-06-11 09:26:45,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 378.0 (TID 252, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:45,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 378.0 (TID 252)
2019-06-11 09:26:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:45,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 378.0 (TID 252). 966 bytes result sent to driver
2019-06-11 09:26:45,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 378.0 (TID 252) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:45,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 378.0, whose tasks have all completed, from pool 
2019-06-11 09:26:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 378 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 126 finished: print at Transform.scala:36, took 0.006474 s
2019-06-11 09:26:45,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216405000 ms.0 from job set of time 1560216405000 ms
2019-06-11 09:26:45,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216405000 ms (execution: 0.043 s)
2019-06-11 09:26:45,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 435 from persistence list
2019-06-11 09:26:45,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 435
2019-06-11 09:26:45,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 430 from persistence list
2019-06-11 09:26:45,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 430
2019-06-11 09:26:45,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 429 from persistence list
2019-06-11 09:26:45,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 429
2019-06-11 09:26:45,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[429] at socketTextStream at Transform.scala:18 of time 1560216405000 ms
2019-06-11 09:26:45,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216395000 ms
2019-06-11 09:26:45,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216395000 ms
2019-06-11 09:26:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216410000 ms
2019-06-11 09:26:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216410000 ms.0 from job set of time 1560216410000 ms
2019-06-11 09:26:50,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 444 (map at Transform.scala:20)
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 127 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 381 (print at Transform.scala:36)
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 379, ShuffleMapStage 380)
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 379)
2019-06-11 09:26:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 379 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_190 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:26:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_190_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:26:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_190_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:26:50,012  INFO [org.apache.spark.SparkContext] - Created broadcast 190 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 379 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:50,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 379.0 with 2 tasks
2019-06-11 09:26:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 379.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 379.0 (TID 253)
2019-06-11 09:26:50,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 379.0 (TID 253). 853 bytes result sent to driver
2019-06-11 09:26:50,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 379.0 (TID 254, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:50,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 379.0 (TID 253) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:50,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 379.0 (TID 254)
2019-06-11 09:26:50,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 379.0 (TID 254). 810 bytes result sent to driver
2019-06-11 09:26:50,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 379.0 (TID 254) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 379.0, whose tasks have all completed, from pool 
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 379 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 381)
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 381 (MapPartitionsRDD[449] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:50,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_191 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:26:50,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_191_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:50,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_191_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:50,041  INFO [org.apache.spark.SparkContext] - Created broadcast 191 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 381 (MapPartitionsRDD[449] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:50,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 381.0 with 1 tasks
2019-06-11 09:26:50,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 381.0 (TID 255, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:50,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 381.0 (TID 255)
2019-06-11 09:26:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:50,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:50,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 381.0 (TID 255). 966 bytes result sent to driver
2019-06-11 09:26:50,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 381.0 (TID 255) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 381.0, whose tasks have all completed, from pool 
2019-06-11 09:26:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 381 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:26:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 127 finished: print at Transform.scala:36, took 0.035413 s
2019-06-11 09:26:50,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:50,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 127 is 160 bytes
2019-06-11 09:26:50,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 126 is 83 bytes
2019-06-11 09:26:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 128 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 384 (print at Transform.scala:36)
2019-06-11 09:26:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 383, ShuffleMapStage 382)
2019-06-11 09:26:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 384 (MapPartitionsRDD[449] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:50,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_192 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:50,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_192_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_192_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:26:50,051  INFO [org.apache.spark.SparkContext] - Created broadcast 192 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 384 (MapPartitionsRDD[449] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:50,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 384.0 with 1 tasks
2019-06-11 09:26:50,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 384.0 (TID 256, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:50,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 384.0 (TID 256)
2019-06-11 09:26:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:50,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 384.0 (TID 256). 1009 bytes result sent to driver
2019-06-11 09:26:50,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 384.0 (TID 256) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:50,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 384.0, whose tasks have all completed, from pool 
2019-06-11 09:26:50,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 384 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:26:50,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 128 finished: print at Transform.scala:36, took 0.008395 s
2019-06-11 09:26:50,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216410000 ms.0 from job set of time 1560216410000 ms
2019-06-11 09:26:50,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.056 s for time 1560216410000 ms (execution: 0.050 s)
2019-06-11 09:26:50,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 442 from persistence list
2019-06-11 09:26:50,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 442
2019-06-11 09:26:50,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 437 from persistence list
2019-06-11 09:26:50,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 437
2019-06-11 09:26:50,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 436 from persistence list
2019-06-11 09:26:50,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 436
2019-06-11 09:26:50,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[436] at socketTextStream at Transform.scala:18 of time 1560216410000 ms
2019-06-11 09:26:50,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216400000 ms
2019-06-11 09:26:50,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216400000 ms
2019-06-11 09:26:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216415000 ms
2019-06-11 09:26:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216415000 ms.0 from job set of time 1560216415000 ms
2019-06-11 09:26:55,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 451 (map at Transform.scala:20)
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 129 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 387 (print at Transform.scala:36)
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 386, ShuffleMapStage 385)
2019-06-11 09:26:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 386)
2019-06-11 09:26:55,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 386 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:26:55,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_193 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:55,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_193_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:26:55,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_193_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:26:55,016  INFO [org.apache.spark.SparkContext] - Created broadcast 193 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:55,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 386 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:26:55,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 386.0 with 2 tasks
2019-06-11 09:26:55,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 386.0 (TID 257, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:55,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 386.0 (TID 257)
2019-06-11 09:26:55,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 386.0 (TID 257). 810 bytes result sent to driver
2019-06-11 09:26:55,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 386.0 (TID 258, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:26:55,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 386.0 (TID 258)
2019-06-11 09:26:55,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 386.0 (TID 257) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:26:55,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 386.0 (TID 258). 853 bytes result sent to driver
2019-06-11 09:26:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 386.0 (TID 258) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:26:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 386.0, whose tasks have all completed, from pool 
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 386 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 387)
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:26:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 387 (MapPartitionsRDD[456] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_194 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:55,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_194_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:55,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_194_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:55,037  INFO [org.apache.spark.SparkContext] - Created broadcast 194 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 387 (MapPartitionsRDD[456] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:26:55,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 387.0 with 1 tasks
2019-06-11 09:26:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 387.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:55,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 387.0 (TID 259)
2019-06-11 09:26:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:55,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 387.0 (TID 259). 1009 bytes result sent to driver
2019-06-11 09:26:55,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 387.0 (TID 259) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:55,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 387.0, whose tasks have all completed, from pool 
2019-06-11 09:26:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 387 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:26:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 129 finished: print at Transform.scala:36, took 0.027964 s
2019-06-11 09:26:55,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:26:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 128 is 83 bytes
2019-06-11 09:26:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 129 is 160 bytes
2019-06-11 09:26:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 130 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:26:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 390 (print at Transform.scala:36)
2019-06-11 09:26:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 389, ShuffleMapStage 388)
2019-06-11 09:26:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:26:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 390 (MapPartitionsRDD[456] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:26:55,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_195 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:26:55,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_195_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:26:55,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_195_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:26:55,046  INFO [org.apache.spark.SparkContext] - Created broadcast 195 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:26:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 390 (MapPartitionsRDD[456] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:26:55,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 390.0 with 1 tasks
2019-06-11 09:26:55,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 390.0 (TID 260, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:26:55,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 390.0 (TID 260)
2019-06-11 09:26:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:26:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:26:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:26:55,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 390.0 (TID 260). 966 bytes result sent to driver
2019-06-11 09:26:55,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 390.0 (TID 260) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:26:55,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 390.0, whose tasks have all completed, from pool 
2019-06-11 09:26:55,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 390 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:26:55,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 130 finished: print at Transform.scala:36, took 0.005941 s
2019-06-11 09:26:55,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216415000 ms.0 from job set of time 1560216415000 ms
2019-06-11 09:26:55,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216415000 ms (execution: 0.039 s)
2019-06-11 09:26:55,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 449 from persistence list
2019-06-11 09:26:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 449
2019-06-11 09:26:55,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 444 from persistence list
2019-06-11 09:26:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 444
2019-06-11 09:26:55,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 443 from persistence list
2019-06-11 09:26:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 443
2019-06-11 09:26:55,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[443] at socketTextStream at Transform.scala:18 of time 1560216415000 ms
2019-06-11 09:26:55,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216405000 ms
2019-06-11 09:26:55,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216405000 ms
2019-06-11 09:27:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216420000 ms
2019-06-11 09:27:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216420000 ms.0 from job set of time 1560216420000 ms
2019-06-11 09:27:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 458 (map at Transform.scala:20)
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 131 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 393 (print at Transform.scala:36)
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 391, ShuffleMapStage 392)
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 391)
2019-06-11 09:27:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 391 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:00,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_196 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_196_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:00,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_196_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:00,012  INFO [org.apache.spark.SparkContext] - Created broadcast 196 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 391 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:00,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 391.0 with 2 tasks
2019-06-11 09:27:00,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 391.0 (TID 261, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:00,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 391.0 (TID 261)
2019-06-11 09:27:00,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 391.0 (TID 261). 810 bytes result sent to driver
2019-06-11 09:27:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 391.0 (TID 262, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:00,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 391.0 (TID 262)
2019-06-11 09:27:00,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 391.0 (TID 261) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 391.0 (TID 262). 810 bytes result sent to driver
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 391.0 (TID 262) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 391.0, whose tasks have all completed, from pool 
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 391 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 393)
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 393 (MapPartitionsRDD[463] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_197 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_197_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:00,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_197_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:00,033  INFO [org.apache.spark.SparkContext] - Created broadcast 197 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 393 (MapPartitionsRDD[463] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 393.0 with 1 tasks
2019-06-11 09:27:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 393.0 (TID 263, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:00,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 393.0 (TID 263)
2019-06-11 09:27:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:00,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 393.0 (TID 263). 1009 bytes result sent to driver
2019-06-11 09:27:00,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 393.0 (TID 263) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:00,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 393.0, whose tasks have all completed, from pool 
2019-06-11 09:27:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 393 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 131 finished: print at Transform.scala:36, took 0.026352 s
2019-06-11 09:27:00,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:00,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 131 is 160 bytes
2019-06-11 09:27:00,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 130 is 83 bytes
2019-06-11 09:27:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 132 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 396 (print at Transform.scala:36)
2019-06-11 09:27:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 394, ShuffleMapStage 395)
2019-06-11 09:27:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 396 (MapPartitionsRDD[463] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:00,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_198 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:00,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_198_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:00,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_198_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:00,041  INFO [org.apache.spark.SparkContext] - Created broadcast 198 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 396 (MapPartitionsRDD[463] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:00,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 396.0 with 1 tasks
2019-06-11 09:27:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 396.0 (TID 264, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:00,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 396.0 (TID 264)
2019-06-11 09:27:00,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:00,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:00,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:00,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:00,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 396.0 (TID 264). 966 bytes result sent to driver
2019-06-11 09:27:00,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 396.0 (TID 264) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:00,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 396.0, whose tasks have all completed, from pool 
2019-06-11 09:27:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 396 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:00,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 132 finished: print at Transform.scala:36, took 0.005610 s
2019-06-11 09:27:00,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216420000 ms.0 from job set of time 1560216420000 ms
2019-06-11 09:27:00,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216420000 ms (execution: 0.037 s)
2019-06-11 09:27:00,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 456 from persistence list
2019-06-11 09:27:00,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 456
2019-06-11 09:27:00,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 451 from persistence list
2019-06-11 09:27:00,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 451
2019-06-11 09:27:00,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 450 from persistence list
2019-06-11 09:27:00,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 450
2019-06-11 09:27:00,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[450] at socketTextStream at Transform.scala:18 of time 1560216420000 ms
2019-06-11 09:27:00,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216410000 ms
2019-06-11 09:27:00,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216410000 ms
2019-06-11 09:27:05,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216425000 ms
2019-06-11 09:27:05,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216425000 ms.0 from job set of time 1560216425000 ms
2019-06-11 09:27:05,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 465 (map at Transform.scala:20)
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 133 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 399 (print at Transform.scala:36)
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 397, ShuffleMapStage 398)
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 397)
2019-06-11 09:27:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 397 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:05,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_199 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:05,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_199_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:05,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_199_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:05,014  INFO [org.apache.spark.SparkContext] - Created broadcast 199 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:05,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 397 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:05,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 397.0 with 2 tasks
2019-06-11 09:27:05,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 397.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:05,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 397.0 (TID 265)
2019-06-11 09:27:05,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 397.0 (TID 265). 810 bytes result sent to driver
2019-06-11 09:27:05,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 397.0 (TID 266, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:05,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 397.0 (TID 266)
2019-06-11 09:27:05,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 397.0 (TID 265) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 397.0 (TID 266). 853 bytes result sent to driver
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 397.0 (TID 266) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 397.0, whose tasks have all completed, from pool 
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 397 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 399)
2019-06-11 09:27:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 399 (MapPartitionsRDD[470] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:05,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_200 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:05,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_200_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:05,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_200_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:05,033  INFO [org.apache.spark.SparkContext] - Created broadcast 200 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 399 (MapPartitionsRDD[470] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:05,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 399.0 with 1 tasks
2019-06-11 09:27:05,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 399.0 (TID 267, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:05,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 399.0 (TID 267)
2019-06-11 09:27:05,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:05,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:05,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:05,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 399.0 (TID 267). 966 bytes result sent to driver
2019-06-11 09:27:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 399.0 (TID 267) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:05,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 399.0, whose tasks have all completed, from pool 
2019-06-11 09:27:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 399 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 133 finished: print at Transform.scala:36, took 0.024050 s
2019-06-11 09:27:05,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:05,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 133 is 160 bytes
2019-06-11 09:27:05,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 132 is 83 bytes
2019-06-11 09:27:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 134 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 402 (print at Transform.scala:36)
2019-06-11 09:27:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 401, ShuffleMapStage 400)
2019-06-11 09:27:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 402 (MapPartitionsRDD[470] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:05,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_201 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:05,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_201_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:05,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_201_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:05,042  INFO [org.apache.spark.SparkContext] - Created broadcast 201 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 402 (MapPartitionsRDD[470] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:05,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 402.0 with 1 tasks
2019-06-11 09:27:05,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 402.0 (TID 268, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:05,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 402.0 (TID 268)
2019-06-11 09:27:05,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:05,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:05,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:05,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:05,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 402.0 (TID 268). 966 bytes result sent to driver
2019-06-11 09:27:05,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 402.0 (TID 268) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:05,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 402.0, whose tasks have all completed, from pool 
2019-06-11 09:27:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 402 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 134 finished: print at Transform.scala:36, took 0.005075 s
2019-06-11 09:27:05,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216425000 ms.0 from job set of time 1560216425000 ms
2019-06-11 09:27:05,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216425000 ms (execution: 0.036 s)
2019-06-11 09:27:05,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 463 from persistence list
2019-06-11 09:27:05,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 463
2019-06-11 09:27:05,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 458 from persistence list
2019-06-11 09:27:05,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 458
2019-06-11 09:27:05,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 457 from persistence list
2019-06-11 09:27:05,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 457
2019-06-11 09:27:05,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[457] at socketTextStream at Transform.scala:18 of time 1560216425000 ms
2019-06-11 09:27:05,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216415000 ms
2019-06-11 09:27:05,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216415000 ms
2019-06-11 09:27:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216430000 ms
2019-06-11 09:27:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216430000 ms.0 from job set of time 1560216430000 ms
2019-06-11 09:27:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 472 (map at Transform.scala:20)
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 135 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 405 (print at Transform.scala:36)
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 404, ShuffleMapStage 403)
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 404)
2019-06-11 09:27:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 404 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_202 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_202_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_202_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 202 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 404 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 404.0 with 2 tasks
2019-06-11 09:27:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 404.0 (TID 269, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 404.0 (TID 269)
2019-06-11 09:27:10,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 404.0 (TID 269). 767 bytes result sent to driver
2019-06-11 09:27:10,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 404.0 (TID 270, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:10,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 404.0 (TID 270)
2019-06-11 09:27:10,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 404.0 (TID 269) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:10,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 404.0 (TID 270). 853 bytes result sent to driver
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 404.0 (TID 270) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 404.0, whose tasks have all completed, from pool 
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 404 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 405)
2019-06-11 09:27:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 405 (MapPartitionsRDD[477] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:10,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_203 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:10,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_203_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:10,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_203_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:10,036  INFO [org.apache.spark.SparkContext] - Created broadcast 203 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 405 (MapPartitionsRDD[477] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:10,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 405.0 with 1 tasks
2019-06-11 09:27:10,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 405.0 (TID 271, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:10,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 405.0 (TID 271)
2019-06-11 09:27:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:10,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 405.0 (TID 271). 966 bytes result sent to driver
2019-06-11 09:27:10,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 405.0 (TID 271) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:10,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 405.0, whose tasks have all completed, from pool 
2019-06-11 09:27:10,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 405 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:10,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 135 finished: print at Transform.scala:36, took 0.030598 s
2019-06-11 09:27:10,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:10,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 134 is 83 bytes
2019-06-11 09:27:10,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 135 is 160 bytes
2019-06-11 09:27:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 136 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 408 (print at Transform.scala:36)
2019-06-11 09:27:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 407, ShuffleMapStage 406)
2019-06-11 09:27:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 408 (MapPartitionsRDD[477] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_204 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_204_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_204_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:10,044  INFO [org.apache.spark.SparkContext] - Created broadcast 204 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:10,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 408 (MapPartitionsRDD[477] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 408.0 with 1 tasks
2019-06-11 09:27:10,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 408.0 (TID 272, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:10,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 408.0 (TID 272)
2019-06-11 09:27:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 408.0 (TID 272). 923 bytes result sent to driver
2019-06-11 09:27:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 408.0 (TID 272) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 408.0, whose tasks have all completed, from pool 
2019-06-11 09:27:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 408 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 136 finished: print at Transform.scala:36, took 0.005507 s
2019-06-11 09:27:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216430000 ms.0 from job set of time 1560216430000 ms
2019-06-11 09:27:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560216430000 ms (execution: 0.041 s)
2019-06-11 09:27:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 470 from persistence list
2019-06-11 09:27:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 470
2019-06-11 09:27:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 465 from persistence list
2019-06-11 09:27:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 465
2019-06-11 09:27:10,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 464 from persistence list
2019-06-11 09:27:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 464
2019-06-11 09:27:10,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[464] at socketTextStream at Transform.scala:18 of time 1560216430000 ms
2019-06-11 09:27:10,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216420000 ms
2019-06-11 09:27:10,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216420000 ms
2019-06-11 09:27:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216435000 ms
2019-06-11 09:27:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216435000 ms.0 from job set of time 1560216435000 ms
2019-06-11 09:27:15,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 479 (map at Transform.scala:20)
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 137 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 411 (print at Transform.scala:36)
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 409, ShuffleMapStage 410)
2019-06-11 09:27:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 410)
2019-06-11 09:27:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 410 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_205 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:15,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_205_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:15,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_205_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 129
2019-06-11 09:27:15,018  INFO [org.apache.spark.SparkContext] - Created broadcast 205 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:15,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_191_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 410 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:15,020  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 410.0 with 2 tasks
2019-06-11 09:27:15,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 133
2019-06-11 09:27:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 410.0 (TID 273, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:15,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 410.0 (TID 273)
2019-06-11 09:27:15,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_204_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 125
2019-06-11 09:27:15,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 124
2019-06-11 09:27:15,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_195_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_194_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 130
2019-06-11 09:27:15,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_184_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_190_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_198_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_202_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_185_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 131
2019-06-11 09:27:15,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_199_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 123
2019-06-11 09:27:15,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_201_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:15,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 122
2019-06-11 09:27:15,033  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 120
2019-06-11 09:27:15,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_193_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:15,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 410.0 (TID 273). 810 bytes result sent to driver
2019-06-11 09:27:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 410.0 (TID 274, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:15,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_200_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,034  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 410.0 (TID 274)
2019-06-11 09:27:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 410.0 (TID 273) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:15,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 132
2019-06-11 09:27:15,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_203_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_192_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,036  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 128
2019-06-11 09:27:15,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_189_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_188_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_196_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:27:15,039  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 121
2019-06-11 09:27:15,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 127
2019-06-11 09:27:15,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 126
2019-06-11 09:27:15,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_187_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:27:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_197_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_186_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,049  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 410.0 (TID 274). 810 bytes result sent to driver
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 410.0 (TID 274) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 410.0, whose tasks have all completed, from pool 
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 410 (parallelize at Transform.scala:16) finished in 0.029 s
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 411)
2019-06-11 09:27:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 411 (MapPartitionsRDD[484] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:15,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_206 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:27:15,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_206_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:15,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_206_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,053  INFO [org.apache.spark.SparkContext] - Created broadcast 206 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:15,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 411 (MapPartitionsRDD[484] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:15,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 411.0 with 1 tasks
2019-06-11 09:27:15,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 411.0 (TID 275, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:15,053  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 411.0 (TID 275)
2019-06-11 09:27:15,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:15,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:15,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:15,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:15,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 411.0 (TID 275). 966 bytes result sent to driver
2019-06-11 09:27:15,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 411.0 (TID 275) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:15,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 411.0, whose tasks have all completed, from pool 
2019-06-11 09:27:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 411 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 137 finished: print at Transform.scala:36, took 0.048264 s
2019-06-11 09:27:15,058  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:15,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 136 is 83 bytes
2019-06-11 09:27:15,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 137 is 160 bytes
2019-06-11 09:27:15,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 138 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:15,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 414 (print at Transform.scala:36)
2019-06-11 09:27:15,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 412, ShuffleMapStage 413)
2019-06-11 09:27:15,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:15,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 414 (MapPartitionsRDD[484] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:15,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_207 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:27:15,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_207_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:15,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_207_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:15,060  INFO [org.apache.spark.SparkContext] - Created broadcast 207 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:15,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 414 (MapPartitionsRDD[484] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:15,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 414.0 with 1 tasks
2019-06-11 09:27:15,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 414.0 (TID 276, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:15,060  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 414.0 (TID 276)
2019-06-11 09:27:15,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:15,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:15,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:15,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:15,062  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 414.0 (TID 276). 1052 bytes result sent to driver
2019-06-11 09:27:15,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 414.0 (TID 276) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:15,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 414.0, whose tasks have all completed, from pool 
2019-06-11 09:27:15,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 414 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:15,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 138 finished: print at Transform.scala:36, took 0.004874 s
2019-06-11 09:27:15,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216435000 ms.0 from job set of time 1560216435000 ms
2019-06-11 09:27:15,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.063 s for time 1560216435000 ms (execution: 0.058 s)
2019-06-11 09:27:15,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 477 from persistence list
2019-06-11 09:27:15,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 472 from persistence list
2019-06-11 09:27:15,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 477
2019-06-11 09:27:15,063  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 471 from persistence list
2019-06-11 09:27:15,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 472
2019-06-11 09:27:15,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 471
2019-06-11 09:27:15,064  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[471] at socketTextStream at Transform.scala:18 of time 1560216435000 ms
2019-06-11 09:27:15,064  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216425000 ms
2019-06-11 09:27:15,064  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216425000 ms
2019-06-11 09:27:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216440000 ms
2019-06-11 09:27:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216440000 ms.0 from job set of time 1560216440000 ms
2019-06-11 09:27:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 486 (map at Transform.scala:20)
2019-06-11 09:27:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 139 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 417 (print at Transform.scala:36)
2019-06-11 09:27:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 416, ShuffleMapStage 415)
2019-06-11 09:27:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 415)
2019-06-11 09:27:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 415 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_208 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_208_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:27:20,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_208_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:27:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 208 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 415 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 415.0 with 2 tasks
2019-06-11 09:27:20,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 415.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:20,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 415.0 (TID 277)
2019-06-11 09:27:20,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 415.0 (TID 277). 810 bytes result sent to driver
2019-06-11 09:27:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 415.0 (TID 278, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:20,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 415.0 (TID 278)
2019-06-11 09:27:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 415.0 (TID 277) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:20,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 415.0 (TID 278). 767 bytes result sent to driver
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 415.0 (TID 278) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 415.0, whose tasks have all completed, from pool 
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 415 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 417)
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 417 (MapPartitionsRDD[491] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_209 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:27:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_209_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:20,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_209_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:20,031  INFO [org.apache.spark.SparkContext] - Created broadcast 209 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 417 (MapPartitionsRDD[491] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 417.0 with 1 tasks
2019-06-11 09:27:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 417.0 (TID 279, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:20,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 417.0 (TID 279)
2019-06-11 09:27:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:20,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 417.0 (TID 279). 1009 bytes result sent to driver
2019-06-11 09:27:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 417.0 (TID 279) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 417.0, whose tasks have all completed, from pool 
2019-06-11 09:27:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 417 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 139 finished: print at Transform.scala:36, took 0.026491 s
2019-06-11 09:27:20,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:20,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 139 is 160 bytes
2019-06-11 09:27:20,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 138 is 83 bytes
2019-06-11 09:27:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 140 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 420 (print at Transform.scala:36)
2019-06-11 09:27:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 419, ShuffleMapStage 418)
2019-06-11 09:27:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 420 (MapPartitionsRDD[491] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:20,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_210 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:27:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_210_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:20,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_210_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:20,040  INFO [org.apache.spark.SparkContext] - Created broadcast 210 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 420 (MapPartitionsRDD[491] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 420.0 with 1 tasks
2019-06-11 09:27:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 420.0 (TID 280, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:20,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 420.0 (TID 280)
2019-06-11 09:27:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:20,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 420.0 (TID 280). 966 bytes result sent to driver
2019-06-11 09:27:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 420.0 (TID 280) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 420.0, whose tasks have all completed, from pool 
2019-06-11 09:27:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 420 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 140 finished: print at Transform.scala:36, took 0.005288 s
2019-06-11 09:27:20,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216440000 ms.0 from job set of time 1560216440000 ms
2019-06-11 09:27:20,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216440000 ms (execution: 0.036 s)
2019-06-11 09:27:20,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 484 from persistence list
2019-06-11 09:27:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 484
2019-06-11 09:27:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 479 from persistence list
2019-06-11 09:27:20,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 478 from persistence list
2019-06-11 09:27:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 479
2019-06-11 09:27:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 478
2019-06-11 09:27:20,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[478] at socketTextStream at Transform.scala:18 of time 1560216440000 ms
2019-06-11 09:27:20,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216430000 ms
2019-06-11 09:27:20,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216430000 ms
2019-06-11 09:27:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216445000 ms
2019-06-11 09:27:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216445000 ms.0 from job set of time 1560216445000 ms
2019-06-11 09:27:25,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 493 (map at Transform.scala:20)
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 141 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 423 (print at Transform.scala:36)
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 422, ShuffleMapStage 421)
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 421)
2019-06-11 09:27:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 421 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_211 stored as values in memory (estimated size 2.0 KB, free 1989.5 MB)
2019-06-11 09:27:25,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_211_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.5 MB)
2019-06-11 09:27:25,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_211_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.6 MB)
2019-06-11 09:27:25,011  INFO [org.apache.spark.SparkContext] - Created broadcast 211 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 421 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:25,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 421.0 with 2 tasks
2019-06-11 09:27:25,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 421.0 (TID 281, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:25,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 421.0 (TID 281)
2019-06-11 09:27:25,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 421.0 (TID 281). 853 bytes result sent to driver
2019-06-11 09:27:25,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 421.0 (TID 282, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:25,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 421.0 (TID 282)
2019-06-11 09:27:25,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 421.0 (TID 281) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:25,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 421.0 (TID 282). 767 bytes result sent to driver
2019-06-11 09:27:25,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 421.0 (TID 282) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:25,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 421.0, whose tasks have all completed, from pool 
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 421 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 423)
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 423 (MapPartitionsRDD[498] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_212 stored as values in memory (estimated size 3.7 KB, free 1989.5 MB)
2019-06-11 09:27:25,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_212_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:25,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_212_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:25,032  INFO [org.apache.spark.SparkContext] - Created broadcast 212 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 423 (MapPartitionsRDD[498] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 423.0 with 1 tasks
2019-06-11 09:27:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 423.0 (TID 283, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:25,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 423.0 (TID 283)
2019-06-11 09:27:25,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:25,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:25,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:25,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:25,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 423.0 (TID 283). 966 bytes result sent to driver
2019-06-11 09:27:25,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 423.0 (TID 283) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:25,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 423.0, whose tasks have all completed, from pool 
2019-06-11 09:27:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 423 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 141 finished: print at Transform.scala:36, took 0.025372 s
2019-06-11 09:27:25,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:25,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 141 is 160 bytes
2019-06-11 09:27:25,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 140 is 83 bytes
2019-06-11 09:27:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 142 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 426 (print at Transform.scala:36)
2019-06-11 09:27:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 425, ShuffleMapStage 424)
2019-06-11 09:27:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 426 (MapPartitionsRDD[498] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:25,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_213 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:25,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_213_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:25,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_213_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.6 MB)
2019-06-11 09:27:25,040  INFO [org.apache.spark.SparkContext] - Created broadcast 213 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 426 (MapPartitionsRDD[498] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:25,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 426.0 with 1 tasks
2019-06-11 09:27:25,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 426.0 (TID 284, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:25,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 426.0 (TID 284)
2019-06-11 09:27:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:25,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 426.0 (TID 284). 966 bytes result sent to driver
2019-06-11 09:27:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 426.0 (TID 284) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 426.0, whose tasks have all completed, from pool 
2019-06-11 09:27:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 426 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 142 finished: print at Transform.scala:36, took 0.005509 s
2019-06-11 09:27:25,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216445000 ms.0 from job set of time 1560216445000 ms
2019-06-11 09:27:25,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216445000 ms (execution: 0.037 s)
2019-06-11 09:27:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 491 from persistence list
2019-06-11 09:27:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 491
2019-06-11 09:27:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 486 from persistence list
2019-06-11 09:27:25,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 486
2019-06-11 09:27:25,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 485 from persistence list
2019-06-11 09:27:25,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 485
2019-06-11 09:27:25,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[485] at socketTextStream at Transform.scala:18 of time 1560216445000 ms
2019-06-11 09:27:25,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216435000 ms
2019-06-11 09:27:25,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216435000 ms
2019-06-11 09:27:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216450000 ms
2019-06-11 09:27:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216450000 ms.0 from job set of time 1560216450000 ms
2019-06-11 09:27:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 500 (map at Transform.scala:20)
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 143 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 429 (print at Transform.scala:36)
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 427, ShuffleMapStage 428)
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 427)
2019-06-11 09:27:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 427 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_214 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_214_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_214_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 214 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 427 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 427.0 with 2 tasks
2019-06-11 09:27:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 427.0 (TID 285, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 427.0 (TID 285)
2019-06-11 09:27:30,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 427.0 (TID 285). 853 bytes result sent to driver
2019-06-11 09:27:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 427.0 (TID 286, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:30,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 427.0 (TID 286)
2019-06-11 09:27:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 427.0 (TID 285) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:30,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 427.0 (TID 286). 810 bytes result sent to driver
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 427.0 (TID 286) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 427.0, whose tasks have all completed, from pool 
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 427 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 429)
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 429 (MapPartitionsRDD[505] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_215 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:30,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_215_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:30,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_215_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:30,032  INFO [org.apache.spark.SparkContext] - Created broadcast 215 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:30,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 429 (MapPartitionsRDD[505] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:30,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 429.0 with 1 tasks
2019-06-11 09:27:30,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 429.0 (TID 287, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:30,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 429.0 (TID 287)
2019-06-11 09:27:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:30,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 429.0 (TID 287). 966 bytes result sent to driver
2019-06-11 09:27:30,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 429.0 (TID 287) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:30,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 429.0, whose tasks have all completed, from pool 
2019-06-11 09:27:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 429 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 143 finished: print at Transform.scala:36, took 0.025423 s
2019-06-11 09:27:30,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:30,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 143 is 160 bytes
2019-06-11 09:27:30,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 142 is 83 bytes
2019-06-11 09:27:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 144 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 432 (print at Transform.scala:36)
2019-06-11 09:27:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 430, ShuffleMapStage 431)
2019-06-11 09:27:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 432 (MapPartitionsRDD[505] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_216 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_216_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:30,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_216_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:30,040  INFO [org.apache.spark.SparkContext] - Created broadcast 216 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 432 (MapPartitionsRDD[505] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:30,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 432.0 with 1 tasks
2019-06-11 09:27:30,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 432.0 (TID 288, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:30,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 432.0 (TID 288)
2019-06-11 09:27:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:30,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 432.0 (TID 288). 1009 bytes result sent to driver
2019-06-11 09:27:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 432.0 (TID 288) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:30,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 432.0, whose tasks have all completed, from pool 
2019-06-11 09:27:30,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 432 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:30,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 144 finished: print at Transform.scala:36, took 0.006141 s
2019-06-11 09:27:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216450000 ms.0 from job set of time 1560216450000 ms
2019-06-11 09:27:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216450000 ms (execution: 0.037 s)
2019-06-11 09:27:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 498 from persistence list
2019-06-11 09:27:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 498
2019-06-11 09:27:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 493 from persistence list
2019-06-11 09:27:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 493
2019-06-11 09:27:30,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 492 from persistence list
2019-06-11 09:27:30,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 492
2019-06-11 09:27:30,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[492] at socketTextStream at Transform.scala:18 of time 1560216450000 ms
2019-06-11 09:27:30,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216440000 ms
2019-06-11 09:27:30,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216440000 ms
2019-06-11 09:27:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216455000 ms
2019-06-11 09:27:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216455000 ms.0 from job set of time 1560216455000 ms
2019-06-11 09:27:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 507 (map at Transform.scala:20)
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 145 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 435 (print at Transform.scala:36)
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 434, ShuffleMapStage 433)
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 434)
2019-06-11 09:27:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 434 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_217 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_217_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:35,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_217_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 217 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 434 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 434.0 with 2 tasks
2019-06-11 09:27:35,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 434.0 (TID 289, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:35,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 434.0 (TID 289)
2019-06-11 09:27:35,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 434.0 (TID 289). 810 bytes result sent to driver
2019-06-11 09:27:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 434.0 (TID 290, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:35,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 434.0 (TID 290)
2019-06-11 09:27:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 434.0 (TID 289) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:35,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 434.0 (TID 290). 810 bytes result sent to driver
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 434.0 (TID 290) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 434.0, whose tasks have all completed, from pool 
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 434 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 435)
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 435 (MapPartitionsRDD[512] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:35,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_218 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_218_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:35,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_218_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:35,031  INFO [org.apache.spark.SparkContext] - Created broadcast 218 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 435 (MapPartitionsRDD[512] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:35,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 435.0 with 1 tasks
2019-06-11 09:27:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 435.0 (TID 291, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:35,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 435.0 (TID 291)
2019-06-11 09:27:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:35,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 435.0 (TID 291). 1009 bytes result sent to driver
2019-06-11 09:27:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 435.0 (TID 291) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 435.0, whose tasks have all completed, from pool 
2019-06-11 09:27:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 435 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 145 finished: print at Transform.scala:36, took 0.025844 s
2019-06-11 09:27:35,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 144 is 83 bytes
2019-06-11 09:27:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 145 is 160 bytes
2019-06-11 09:27:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 146 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 438 (print at Transform.scala:36)
2019-06-11 09:27:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 437, ShuffleMapStage 436)
2019-06-11 09:27:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 438 (MapPartitionsRDD[512] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:35,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_219 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:35,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_219_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:35,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_219_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:35,039  INFO [org.apache.spark.SparkContext] - Created broadcast 219 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 438 (MapPartitionsRDD[512] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:35,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 438.0 with 1 tasks
2019-06-11 09:27:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 438.0 (TID 292, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:35,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 438.0 (TID 292)
2019-06-11 09:27:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:35,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:35,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 438.0 (TID 292). 966 bytes result sent to driver
2019-06-11 09:27:35,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 438.0 (TID 292) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:35,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 438.0, whose tasks have all completed, from pool 
2019-06-11 09:27:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 438 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 146 finished: print at Transform.scala:36, took 0.004975 s
2019-06-11 09:27:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216455000 ms.0 from job set of time 1560216455000 ms
2019-06-11 09:27:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216455000 ms (execution: 0.036 s)
2019-06-11 09:27:35,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 505 from persistence list
2019-06-11 09:27:35,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 505
2019-06-11 09:27:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 500 from persistence list
2019-06-11 09:27:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 500
2019-06-11 09:27:35,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 499 from persistence list
2019-06-11 09:27:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 499
2019-06-11 09:27:35,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[499] at socketTextStream at Transform.scala:18 of time 1560216455000 ms
2019-06-11 09:27:35,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216445000 ms
2019-06-11 09:27:35,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216445000 ms
2019-06-11 09:27:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216460000 ms
2019-06-11 09:27:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216460000 ms.0 from job set of time 1560216460000 ms
2019-06-11 09:27:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 514 (map at Transform.scala:20)
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 147 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 441 (print at Transform.scala:36)
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 440, ShuffleMapStage 439)
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 440)
2019-06-11 09:27:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 440 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_220 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_220_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_220_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 220 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 440 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 440.0 with 2 tasks
2019-06-11 09:27:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 440.0 (TID 293, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 440.0 (TID 293)
2019-06-11 09:27:40,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 440.0 (TID 293). 810 bytes result sent to driver
2019-06-11 09:27:40,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 440.0 (TID 294, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:40,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 440.0 (TID 294)
2019-06-11 09:27:40,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 440.0 (TID 293) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 440.0 (TID 294). 810 bytes result sent to driver
2019-06-11 09:27:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 440.0 (TID 294) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 440.0, whose tasks have all completed, from pool 
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 440 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 441)
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 441 (MapPartitionsRDD[519] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:40,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_221 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_221_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:40,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_221_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:40,035  INFO [org.apache.spark.SparkContext] - Created broadcast 221 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 441 (MapPartitionsRDD[519] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:40,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 441.0 with 1 tasks
2019-06-11 09:27:40,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 441.0 (TID 295, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:40,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 441.0 (TID 295)
2019-06-11 09:27:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:40,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 441.0 (TID 295). 1009 bytes result sent to driver
2019-06-11 09:27:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 441.0 (TID 295) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 441.0, whose tasks have all completed, from pool 
2019-06-11 09:27:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 441 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 147 finished: print at Transform.scala:36, took 0.029320 s
2019-06-11 09:27:40,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:40,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 146 is 83 bytes
2019-06-11 09:27:40,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 147 is 160 bytes
2019-06-11 09:27:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 148 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 444 (print at Transform.scala:36)
2019-06-11 09:27:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 442, ShuffleMapStage 443)
2019-06-11 09:27:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 444 (MapPartitionsRDD[519] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:40,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_222 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:40,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_222_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:40,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_222_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:40,043  INFO [org.apache.spark.SparkContext] - Created broadcast 222 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:40,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 444 (MapPartitionsRDD[519] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:40,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 444.0 with 1 tasks
2019-06-11 09:27:40,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 444.0 (TID 296, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:40,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 444.0 (TID 296)
2019-06-11 09:27:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:40,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 444.0 (TID 296). 1009 bytes result sent to driver
2019-06-11 09:27:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 444.0 (TID 296) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:40,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 444.0, whose tasks have all completed, from pool 
2019-06-11 09:27:40,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 444 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:40,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 148 finished: print at Transform.scala:36, took 0.005088 s
2019-06-11 09:27:40,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216460000 ms.0 from job set of time 1560216460000 ms
2019-06-11 09:27:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216460000 ms (execution: 0.039 s)
2019-06-11 09:27:40,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 512 from persistence list
2019-06-11 09:27:40,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 512
2019-06-11 09:27:40,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 507 from persistence list
2019-06-11 09:27:40,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 507
2019-06-11 09:27:40,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 506 from persistence list
2019-06-11 09:27:40,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 506
2019-06-11 09:27:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[506] at socketTextStream at Transform.scala:18 of time 1560216460000 ms
2019-06-11 09:27:40,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216450000 ms
2019-06-11 09:27:40,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216450000 ms
2019-06-11 09:27:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216465000 ms
2019-06-11 09:27:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216465000 ms.0 from job set of time 1560216465000 ms
2019-06-11 09:27:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 521 (map at Transform.scala:20)
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 149 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 447 (print at Transform.scala:36)
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 445, ShuffleMapStage 446)
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 446)
2019-06-11 09:27:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 446 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_223 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_223_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_223_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:45,010  INFO [org.apache.spark.SparkContext] - Created broadcast 223 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 446 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:45,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 446.0 with 2 tasks
2019-06-11 09:27:45,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 446.0 (TID 297, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 446.0 (TID 297)
2019-06-11 09:27:45,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 446.0 (TID 297). 810 bytes result sent to driver
2019-06-11 09:27:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 446.0 (TID 298, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:45,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 446.0 (TID 298)
2019-06-11 09:27:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 446.0 (TID 297) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:45,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 446.0 (TID 298). 767 bytes result sent to driver
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 446.0 (TID 298) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 446.0, whose tasks have all completed, from pool 
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 446 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 447)
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 447 (MapPartitionsRDD[526] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:45,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_224 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_224_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:45,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_224_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:45,030  INFO [org.apache.spark.SparkContext] - Created broadcast 224 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 447 (MapPartitionsRDD[526] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:45,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 447.0 with 1 tasks
2019-06-11 09:27:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 447.0 (TID 299, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:45,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 447.0 (TID 299)
2019-06-11 09:27:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:27:45,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 447.0 (TID 299). 966 bytes result sent to driver
2019-06-11 09:27:45,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 447.0 (TID 299) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:45,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 447.0, whose tasks have all completed, from pool 
2019-06-11 09:27:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 447 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 149 finished: print at Transform.scala:36, took 0.025378 s
2019-06-11 09:27:45,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 148 is 83 bytes
2019-06-11 09:27:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 149 is 160 bytes
2019-06-11 09:27:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 150 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 450 (print at Transform.scala:36)
2019-06-11 09:27:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 448, ShuffleMapStage 449)
2019-06-11 09:27:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 450 (MapPartitionsRDD[526] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_225 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_225_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:45,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_225_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:45,038  INFO [org.apache.spark.SparkContext] - Created broadcast 225 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 450 (MapPartitionsRDD[526] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:45,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 450.0 with 1 tasks
2019-06-11 09:27:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 450.0 (TID 300, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:45,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 450.0 (TID 300)
2019-06-11 09:27:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:45,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 450.0 (TID 300). 1009 bytes result sent to driver
2019-06-11 09:27:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 450.0 (TID 300) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 450.0, whose tasks have all completed, from pool 
2019-06-11 09:27:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 450 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 150 finished: print at Transform.scala:36, took 0.005605 s
2019-06-11 09:27:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216465000 ms.0 from job set of time 1560216465000 ms
2019-06-11 09:27:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216465000 ms (execution: 0.037 s)
2019-06-11 09:27:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 519 from persistence list
2019-06-11 09:27:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 519
2019-06-11 09:27:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 514 from persistence list
2019-06-11 09:27:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 514
2019-06-11 09:27:45,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 513 from persistence list
2019-06-11 09:27:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 513
2019-06-11 09:27:45,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[513] at socketTextStream at Transform.scala:18 of time 1560216465000 ms
2019-06-11 09:27:45,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216455000 ms
2019-06-11 09:27:45,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216455000 ms
2019-06-11 09:27:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216470000 ms
2019-06-11 09:27:50,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216470000 ms.0 from job set of time 1560216470000 ms
2019-06-11 09:27:50,012  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 140
2019-06-11 09:27:50,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_205_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:50,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_222_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:50,018  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:50,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:50,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 528 (map at Transform.scala:20)
2019-06-11 09:27:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 151 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 453 (print at Transform.scala:36)
2019-06-11 09:27:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 452, ShuffleMapStage 451)
2019-06-11 09:27:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 451)
2019-06-11 09:27:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 451 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:50,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_226 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:50,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_226_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_226_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:50,020  INFO [org.apache.spark.SparkContext] - Created broadcast 226 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:50,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 451 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:50,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 451.0 with 2 tasks
2019-06-11 09:27:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 451.0 (TID 301, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:50,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 451.0 (TID 301)
2019-06-11 09:27:50,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 451.0 (TID 301). 853 bytes result sent to driver
2019-06-11 09:27:50,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 451.0 (TID 302, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:50,035  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 451.0 (TID 302)
2019-06-11 09:27:50,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 451.0 (TID 301) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:50,044  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 451.0 (TID 302). 810 bytes result sent to driver
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 451.0 (TID 302) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 451.0, whose tasks have all completed, from pool 
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 451 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 453)
2019-06-11 09:27:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 453 (MapPartitionsRDD[533] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:50,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_227 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:50,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_227_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:50,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_227_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:50,046  INFO [org.apache.spark.SparkContext] - Created broadcast 227 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 453 (MapPartitionsRDD[533] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:50,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 453.0 with 1 tasks
2019-06-11 09:27:50,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 453.0 (TID 303, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:50,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 453.0 (TID 303)
2019-06-11 09:27:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:50,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 453.0 (TID 303). 966 bytes result sent to driver
2019-06-11 09:27:50,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 453.0 (TID 303) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:50,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 453.0, whose tasks have all completed, from pool 
2019-06-11 09:27:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 453 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 151 finished: print at Transform.scala:36, took 0.031494 s
2019-06-11 09:27:50,052  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:50,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 151 is 160 bytes
2019-06-11 09:27:50,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 150 is 83 bytes
2019-06-11 09:27:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 152 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 456 (print at Transform.scala:36)
2019-06-11 09:27:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 455, ShuffleMapStage 454)
2019-06-11 09:27:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 456 (MapPartitionsRDD[533] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:50,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_228 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:50,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_228_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:50,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_228_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:50,055  INFO [org.apache.spark.SparkContext] - Created broadcast 228 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:50,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 456 (MapPartitionsRDD[533] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:50,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 456.0 with 1 tasks
2019-06-11 09:27:50,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 456.0 (TID 304, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:50,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 456.0 (TID 304)
2019-06-11 09:27:50,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:50,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:50,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:50,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:50,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 456.0 (TID 304). 1009 bytes result sent to driver
2019-06-11 09:27:50,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 456.0 (TID 304) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:50,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 456.0, whose tasks have all completed, from pool 
2019-06-11 09:27:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 456 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:27:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 152 finished: print at Transform.scala:36, took 0.005611 s
2019-06-11 09:27:50,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216470000 ms.0 from job set of time 1560216470000 ms
2019-06-11 09:27:50,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560216470000 ms (execution: 0.048 s)
2019-06-11 09:27:50,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 526 from persistence list
2019-06-11 09:27:50,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 526
2019-06-11 09:27:50,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 521 from persistence list
2019-06-11 09:27:50,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 521
2019-06-11 09:27:50,058  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 520 from persistence list
2019-06-11 09:27:50,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 520
2019-06-11 09:27:50,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[520] at socketTextStream at Transform.scala:18 of time 1560216470000 ms
2019-06-11 09:27:50,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216460000 ms
2019-06-11 09:27:50,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216460000 ms
2019-06-11 09:27:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216475000 ms
2019-06-11 09:27:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216475000 ms.0 from job set of time 1560216475000 ms
2019-06-11 09:27:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 535 (map at Transform.scala:20)
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 153 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 459 (print at Transform.scala:36)
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 458, ShuffleMapStage 457)
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 458)
2019-06-11 09:27:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 458 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:27:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_229 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_229_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:27:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_229_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:27:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 229 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 458 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:27:55,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 458.0 with 2 tasks
2019-06-11 09:27:55,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 458.0 (TID 305, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 458.0 (TID 305)
2019-06-11 09:27:55,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 458.0 (TID 305). 853 bytes result sent to driver
2019-06-11 09:27:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 458.0 (TID 306, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:27:55,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 458.0 (TID 306)
2019-06-11 09:27:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 458.0 (TID 305) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:27:55,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 458.0 (TID 306). 853 bytes result sent to driver
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 458.0 (TID 306) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 458.0, whose tasks have all completed, from pool 
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 458 (parallelize at Transform.scala:16) finished in 0.028 s
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 459)
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:27:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 459 (MapPartitionsRDD[540] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:55,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_230 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:55,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_230_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:55,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_230_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:55,041  INFO [org.apache.spark.SparkContext] - Created broadcast 230 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 459 (MapPartitionsRDD[540] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:27:55,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 459.0 with 1 tasks
2019-06-11 09:27:55,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 459.0 (TID 307, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:55,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 459.0 (TID 307)
2019-06-11 09:27:55,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:55,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:55,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 459.0 (TID 307). 966 bytes result sent to driver
2019-06-11 09:27:55,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 459.0 (TID 307) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:55,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 459.0, whose tasks have all completed, from pool 
2019-06-11 09:27:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 459 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 153 finished: print at Transform.scala:36, took 0.035697 s
2019-06-11 09:27:55,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:27:55,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 152 is 83 bytes
2019-06-11 09:27:55,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 153 is 160 bytes
2019-06-11 09:27:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 154 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:27:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 462 (print at Transform.scala:36)
2019-06-11 09:27:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 460, ShuffleMapStage 461)
2019-06-11 09:27:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:27:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 462 (MapPartitionsRDD[540] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:27:55,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_231 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:27:55,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_231_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:27:55,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_231_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:27:55,050  INFO [org.apache.spark.SparkContext] - Created broadcast 231 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:27:55,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 462 (MapPartitionsRDD[540] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:27:55,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 462.0 with 1 tasks
2019-06-11 09:27:55,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 462.0 (TID 308, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:27:55,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 462.0 (TID 308)
2019-06-11 09:27:55,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:27:55,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:55,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:27:55,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:27:55,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 462.0 (TID 308). 1009 bytes result sent to driver
2019-06-11 09:27:55,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 462.0 (TID 308) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:27:55,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 462.0, whose tasks have all completed, from pool 
2019-06-11 09:27:55,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 462 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:27:55,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 154 finished: print at Transform.scala:36, took 0.006920 s
2019-06-11 09:27:55,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216475000 ms.0 from job set of time 1560216475000 ms
2019-06-11 09:27:55,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560216475000 ms (execution: 0.048 s)
2019-06-11 09:27:55,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 533 from persistence list
2019-06-11 09:27:55,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 533
2019-06-11 09:27:55,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 528 from persistence list
2019-06-11 09:27:55,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 528
2019-06-11 09:27:55,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 527 from persistence list
2019-06-11 09:27:55,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 527
2019-06-11 09:27:55,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[527] at socketTextStream at Transform.scala:18 of time 1560216475000 ms
2019-06-11 09:27:55,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216465000 ms
2019-06-11 09:27:55,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216465000 ms
2019-06-11 09:28:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216480000 ms
2019-06-11 09:28:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216480000 ms.0 from job set of time 1560216480000 ms
2019-06-11 09:28:00,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 542 (map at Transform.scala:20)
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 155 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 465 (print at Transform.scala:36)
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 463, ShuffleMapStage 464)
2019-06-11 09:28:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 463)
2019-06-11 09:28:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 463 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:00,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_232 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_232_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:28:00,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_232_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:00,014  INFO [org.apache.spark.SparkContext] - Created broadcast 232 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:00,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 463 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:00,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 463.0 with 2 tasks
2019-06-11 09:28:00,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 463.0 (TID 309, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:00,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 463.0 (TID 309)
2019-06-11 09:28:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 463.0 (TID 309). 810 bytes result sent to driver
2019-06-11 09:28:00,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 463.0 (TID 310, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:00,030  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 463.0 (TID 310)
2019-06-11 09:28:00,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 463.0 (TID 309) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:00,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 463.0 (TID 310). 810 bytes result sent to driver
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 463.0 (TID 310) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 463.0, whose tasks have all completed, from pool 
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 463 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 465)
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 465 (MapPartitionsRDD[547] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:00,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_233 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:00,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_233_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:00,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_233_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:00,042  INFO [org.apache.spark.SparkContext] - Created broadcast 233 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 465 (MapPartitionsRDD[547] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:00,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 465.0 with 1 tasks
2019-06-11 09:28:00,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 465.0 (TID 311, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:00,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 465.0 (TID 311)
2019-06-11 09:28:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:00,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:00,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 465.0 (TID 311). 966 bytes result sent to driver
2019-06-11 09:28:00,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 465.0 (TID 311) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:00,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 465.0, whose tasks have all completed, from pool 
2019-06-11 09:28:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 465 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 155 finished: print at Transform.scala:36, took 0.032873 s
2019-06-11 09:28:00,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:00,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 155 is 160 bytes
2019-06-11 09:28:00,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 154 is 83 bytes
2019-06-11 09:28:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 156 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 468 (print at Transform.scala:36)
2019-06-11 09:28:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 466, ShuffleMapStage 467)
2019-06-11 09:28:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 468 (MapPartitionsRDD[547] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:00,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_234 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:00,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_234_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:00,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_234_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:00,050  INFO [org.apache.spark.SparkContext] - Created broadcast 234 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 468 (MapPartitionsRDD[547] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:00,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 468.0 with 1 tasks
2019-06-11 09:28:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 468.0 (TID 312, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:00,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 468.0 (TID 312)
2019-06-11 09:28:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:00,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 468.0 (TID 312). 966 bytes result sent to driver
2019-06-11 09:28:00,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 468.0 (TID 312) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:00,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 468.0, whose tasks have all completed, from pool 
2019-06-11 09:28:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 468 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 156 finished: print at Transform.scala:36, took 0.005542 s
2019-06-11 09:28:00,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216480000 ms.0 from job set of time 1560216480000 ms
2019-06-11 09:28:00,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.053 s for time 1560216480000 ms (execution: 0.044 s)
2019-06-11 09:28:00,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 540 from persistence list
2019-06-11 09:28:00,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 540
2019-06-11 09:28:00,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 535 from persistence list
2019-06-11 09:28:00,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 535
2019-06-11 09:28:00,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 534 from persistence list
2019-06-11 09:28:00,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 534
2019-06-11 09:28:00,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[534] at socketTextStream at Transform.scala:18 of time 1560216480000 ms
2019-06-11 09:28:00,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216470000 ms
2019-06-11 09:28:00,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216470000 ms
2019-06-11 09:28:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216485000 ms
2019-06-11 09:28:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216485000 ms.0 from job set of time 1560216485000 ms
2019-06-11 09:28:05,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 549 (map at Transform.scala:20)
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 157 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 471 (print at Transform.scala:36)
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 470, ShuffleMapStage 469)
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 470)
2019-06-11 09:28:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 470 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:05,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_235 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:05,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_235_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:05,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_235_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:05,011  INFO [org.apache.spark.SparkContext] - Created broadcast 235 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 470 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:05,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 470.0 with 2 tasks
2019-06-11 09:28:05,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 470.0 (TID 313, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:05,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 470.0 (TID 313)
2019-06-11 09:28:05,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 470.0 (TID 313). 767 bytes result sent to driver
2019-06-11 09:28:05,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 470.0 (TID 314, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:05,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 470.0 (TID 314)
2019-06-11 09:28:05,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 470.0 (TID 313) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:05,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 470.0 (TID 314). 810 bytes result sent to driver
2019-06-11 09:28:05,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 470.0 (TID 314) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:05,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 470.0, whose tasks have all completed, from pool 
2019-06-11 09:28:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 470 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:28:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 471)
2019-06-11 09:28:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 471 (MapPartitionsRDD[554] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_236 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_236_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_236_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:05,036  INFO [org.apache.spark.SparkContext] - Created broadcast 236 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:05,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 471 (MapPartitionsRDD[554] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 471.0 with 1 tasks
2019-06-11 09:28:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 471.0 (TID 315, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 471.0 (TID 315)
2019-06-11 09:28:05,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:28:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:05,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 471.0 (TID 315). 966 bytes result sent to driver
2019-06-11 09:28:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 471.0 (TID 315) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 471.0, whose tasks have all completed, from pool 
2019-06-11 09:28:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 471 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 157 finished: print at Transform.scala:36, took 0.029791 s
2019-06-11 09:28:05,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:05,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 156 is 83 bytes
2019-06-11 09:28:05,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 157 is 160 bytes
2019-06-11 09:28:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 158 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 474 (print at Transform.scala:36)
2019-06-11 09:28:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 473, ShuffleMapStage 472)
2019-06-11 09:28:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 474 (MapPartitionsRDD[554] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:05,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_237 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:05,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_237_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:05,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_237_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:05,043  INFO [org.apache.spark.SparkContext] - Created broadcast 237 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 474 (MapPartitionsRDD[554] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:05,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 474.0 with 1 tasks
2019-06-11 09:28:05,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 474.0 (TID 316, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:05,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 474.0 (TID 316)
2019-06-11 09:28:05,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:05,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:05,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:05,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:05,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 474.0 (TID 316). 966 bytes result sent to driver
2019-06-11 09:28:05,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 474.0 (TID 316) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:05,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 474.0, whose tasks have all completed, from pool 
2019-06-11 09:28:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 474 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 158 finished: print at Transform.scala:36, took 0.004752 s
2019-06-11 09:28:05,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216485000 ms.0 from job set of time 1560216485000 ms
2019-06-11 09:28:05,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216485000 ms (execution: 0.039 s)
2019-06-11 09:28:05,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 547 from persistence list
2019-06-11 09:28:05,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 547
2019-06-11 09:28:05,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 542 from persistence list
2019-06-11 09:28:05,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 542
2019-06-11 09:28:05,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 541 from persistence list
2019-06-11 09:28:05,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 541
2019-06-11 09:28:05,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[541] at socketTextStream at Transform.scala:18 of time 1560216485000 ms
2019-06-11 09:28:05,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216475000 ms
2019-06-11 09:28:05,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216475000 ms
2019-06-11 09:28:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216490000 ms
2019-06-11 09:28:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216490000 ms.0 from job set of time 1560216490000 ms
2019-06-11 09:28:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 556 (map at Transform.scala:20)
2019-06-11 09:28:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 159 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 477 (print at Transform.scala:36)
2019-06-11 09:28:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 476, ShuffleMapStage 475)
2019-06-11 09:28:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 476)
2019-06-11 09:28:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 476 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_238 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_238_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_238_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:10,010  INFO [org.apache.spark.SparkContext] - Created broadcast 238 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 476 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 476.0 with 2 tasks
2019-06-11 09:28:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 476.0 (TID 317, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 476.0 (TID 317)
2019-06-11 09:28:10,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 476.0 (TID 317). 810 bytes result sent to driver
2019-06-11 09:28:10,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 476.0 (TID 318, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:10,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 476.0 (TID 318)
2019-06-11 09:28:10,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 476.0 (TID 317) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:10,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 476.0 (TID 318). 853 bytes result sent to driver
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 476.0 (TID 318) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 476.0, whose tasks have all completed, from pool 
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 476 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 477)
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 477 (MapPartitionsRDD[561] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_239 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:10,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_239_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:10,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_239_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:10,035  INFO [org.apache.spark.SparkContext] - Created broadcast 239 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 477 (MapPartitionsRDD[561] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:10,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 477.0 with 1 tasks
2019-06-11 09:28:10,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 477.0 (TID 319, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:10,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 477.0 (TID 319)
2019-06-11 09:28:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:10,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 477.0 (TID 319). 1009 bytes result sent to driver
2019-06-11 09:28:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 477.0 (TID 319) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:10,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 477.0, whose tasks have all completed, from pool 
2019-06-11 09:28:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 477 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 159 finished: print at Transform.scala:36, took 0.030009 s
2019-06-11 09:28:10,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 158 is 83 bytes
2019-06-11 09:28:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 159 is 160 bytes
2019-06-11 09:28:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 160 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 480 (print at Transform.scala:36)
2019-06-11 09:28:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 478, ShuffleMapStage 479)
2019-06-11 09:28:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 480 (MapPartitionsRDD[561] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_240 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_240_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_240_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:10,044  INFO [org.apache.spark.SparkContext] - Created broadcast 240 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:10,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 480 (MapPartitionsRDD[561] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 480.0 with 1 tasks
2019-06-11 09:28:10,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 480.0 (TID 320, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:10,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 480.0 (TID 320)
2019-06-11 09:28:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 480.0 (TID 320). 1009 bytes result sent to driver
2019-06-11 09:28:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 480.0 (TID 320) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 480.0, whose tasks have all completed, from pool 
2019-06-11 09:28:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 480 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 160 finished: print at Transform.scala:36, took 0.006468 s
2019-06-11 09:28:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216490000 ms.0 from job set of time 1560216490000 ms
2019-06-11 09:28:10,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560216490000 ms (execution: 0.042 s)
2019-06-11 09:28:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 554 from persistence list
2019-06-11 09:28:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 554
2019-06-11 09:28:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 549 from persistence list
2019-06-11 09:28:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 549
2019-06-11 09:28:10,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 548 from persistence list
2019-06-11 09:28:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 548
2019-06-11 09:28:10,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[548] at socketTextStream at Transform.scala:18 of time 1560216490000 ms
2019-06-11 09:28:10,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216480000 ms
2019-06-11 09:28:10,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216480000 ms
2019-06-11 09:28:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216495000 ms
2019-06-11 09:28:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216495000 ms.0 from job set of time 1560216495000 ms
2019-06-11 09:28:15,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 563 (map at Transform.scala:20)
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 161 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 483 (print at Transform.scala:36)
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 481, ShuffleMapStage 482)
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 482)
2019-06-11 09:28:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 482 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_241 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_241_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:15,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_241_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:15,009  INFO [org.apache.spark.SparkContext] - Created broadcast 241 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 482 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:15,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 482.0 with 2 tasks
2019-06-11 09:28:15,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 482.0 (TID 321, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:15,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 482.0 (TID 321)
2019-06-11 09:28:15,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 482.0 (TID 321). 810 bytes result sent to driver
2019-06-11 09:28:15,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 482.0 (TID 322, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:15,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 482.0 (TID 322)
2019-06-11 09:28:15,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 482.0 (TID 321) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:15,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 482.0 (TID 322). 767 bytes result sent to driver
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 482.0 (TID 322) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 482.0, whose tasks have all completed, from pool 
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 482 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 483)
2019-06-11 09:28:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 483 (MapPartitionsRDD[568] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:15,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_242 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:15,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_242_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:15,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_242_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:15,030  INFO [org.apache.spark.SparkContext] - Created broadcast 242 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 483 (MapPartitionsRDD[568] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 483.0 with 1 tasks
2019-06-11 09:28:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 483.0 (TID 323, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:15,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 483.0 (TID 323)
2019-06-11 09:28:15,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:15,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:15,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:15,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:15,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 483.0 (TID 323). 1009 bytes result sent to driver
2019-06-11 09:28:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 483.0 (TID 323) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:15,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 483.0, whose tasks have all completed, from pool 
2019-06-11 09:28:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 483 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 161 finished: print at Transform.scala:36, took 0.026728 s
2019-06-11 09:28:15,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:15,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 160 is 83 bytes
2019-06-11 09:28:15,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 161 is 160 bytes
2019-06-11 09:28:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 162 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 486 (print at Transform.scala:36)
2019-06-11 09:28:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 484, ShuffleMapStage 485)
2019-06-11 09:28:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 486 (MapPartitionsRDD[568] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:15,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_243 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:15,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_243_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:15,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_243_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:15,038  INFO [org.apache.spark.SparkContext] - Created broadcast 243 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 486 (MapPartitionsRDD[568] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:15,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 486.0 with 1 tasks
2019-06-11 09:28:15,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 486.0 (TID 324, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:15,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 486.0 (TID 324)
2019-06-11 09:28:15,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:15,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:15,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:15,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 486.0 (TID 324). 966 bytes result sent to driver
2019-06-11 09:28:15,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 486.0 (TID 324) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:15,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 486.0, whose tasks have all completed, from pool 
2019-06-11 09:28:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 486 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 162 finished: print at Transform.scala:36, took 0.004677 s
2019-06-11 09:28:15,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216495000 ms.0 from job set of time 1560216495000 ms
2019-06-11 09:28:15,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216495000 ms (execution: 0.036 s)
2019-06-11 09:28:15,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 561 from persistence list
2019-06-11 09:28:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 561
2019-06-11 09:28:15,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 556 from persistence list
2019-06-11 09:28:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 556
2019-06-11 09:28:15,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 555 from persistence list
2019-06-11 09:28:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 555
2019-06-11 09:28:15,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[555] at socketTextStream at Transform.scala:18 of time 1560216495000 ms
2019-06-11 09:28:15,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216485000 ms
2019-06-11 09:28:15,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216485000 ms
2019-06-11 09:28:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216500000 ms
2019-06-11 09:28:20,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216500000 ms.0 from job set of time 1560216500000 ms
2019-06-11 09:28:20,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 570 (map at Transform.scala:20)
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 163 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 489 (print at Transform.scala:36)
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 488, ShuffleMapStage 487)
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 487)
2019-06-11 09:28:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 487 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_244 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_244_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_244_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 244 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 487 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 487.0 with 2 tasks
2019-06-11 09:28:20,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 487.0 (TID 325, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 487.0 (TID 325)
2019-06-11 09:28:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 487.0 (TID 325). 853 bytes result sent to driver
2019-06-11 09:28:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 487.0 (TID 326, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:20,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 487.0 (TID 326)
2019-06-11 09:28:20,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 487.0 (TID 325) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:20,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 487.0 (TID 326). 767 bytes result sent to driver
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 487.0 (TID 326) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 487.0, whose tasks have all completed, from pool 
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 487 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 489)
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 489 (MapPartitionsRDD[575] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_245 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_245_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:20,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_245_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,032  INFO [org.apache.spark.SparkContext] - Created broadcast 245 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 489 (MapPartitionsRDD[575] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 489.0 with 1 tasks
2019-06-11 09:28:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 489.0 (TID 327, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:20,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 489.0 (TID 327)
2019-06-11 09:28:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:20,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 489.0 (TID 327). 966 bytes result sent to driver
2019-06-11 09:28:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 489.0 (TID 327) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 489.0, whose tasks have all completed, from pool 
2019-06-11 09:28:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 489 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 163 finished: print at Transform.scala:36, took 0.025058 s
2019-06-11 09:28:20,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 163 is 160 bytes
2019-06-11 09:28:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 162 is 83 bytes
2019-06-11 09:28:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 164 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 492 (print at Transform.scala:36)
2019-06-11 09:28:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 491, ShuffleMapStage 490)
2019-06-11 09:28:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 492 (MapPartitionsRDD[575] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:20,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_246 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_246_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:20,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_246_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,039  INFO [org.apache.spark.SparkContext] - Created broadcast 246 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 492 (MapPartitionsRDD[575] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 492.0 with 1 tasks
2019-06-11 09:28:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 492.0 (TID 328, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:20,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 492.0 (TID 328)
2019-06-11 09:28:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:28:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 5 ms
2019-06-11 09:28:20,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_241_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_227_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 492.0 (TID 328). 1052 bytes result sent to driver
2019-06-11 09:28:20,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 492.0 (TID 328) in 14 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:20,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 492.0, whose tasks have all completed, from pool 
2019-06-11 09:28:20,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 157
2019-06-11 09:28:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 492 (print at Transform.scala:36) finished in 0.015 s
2019-06-11 09:28:20,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 164 finished: print at Transform.scala:36, took 0.017562 s
2019-06-11 09:28:20,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_235_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216500000 ms.0 from job set of time 1560216500000 ms
2019-06-11 09:28:20,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560216500000 ms (execution: 0.048 s)
2019-06-11 09:28:20,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 568 from persistence list
2019-06-11 09:28:20,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 568
2019-06-11 09:28:20,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 563 from persistence list
2019-06-11 09:28:20,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 563
2019-06-11 09:28:20,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 562 from persistence list
2019-06-11 09:28:20,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 562
2019-06-11 09:28:20,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[562] at socketTextStream at Transform.scala:18 of time 1560216500000 ms
2019-06-11 09:28:20,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216490000 ms
2019-06-11 09:28:20,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216490000 ms
2019-06-11 09:28:20,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_243_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 159
2019-06-11 09:28:20,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_231_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_229_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_242_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_237_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 155
2019-06-11 09:28:20,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_239_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 154
2019-06-11 09:28:20,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_238_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_234_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 153
2019-06-11 09:28:20,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 156
2019-06-11 09:28:20,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_230_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_244_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_245_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_240_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_228_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,067  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 151
2019-06-11 09:28:20,068  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 152
2019-06-11 09:28:20,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_236_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_226_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,070  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 158
2019-06-11 09:28:20,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_232_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:20,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_233_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:20,071  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 150
2019-06-11 09:28:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216505000 ms
2019-06-11 09:28:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216505000 ms.0 from job set of time 1560216505000 ms
2019-06-11 09:28:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 577 (map at Transform.scala:20)
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 165 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 495 (print at Transform.scala:36)
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 494, ShuffleMapStage 493)
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 494)
2019-06-11 09:28:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 494 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_247 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_247_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:28:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_247_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 247 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 494 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 494.0 with 2 tasks
2019-06-11 09:28:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 494.0 (TID 329, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 494.0 (TID 329)
2019-06-11 09:28:25,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 494.0 (TID 329). 810 bytes result sent to driver
2019-06-11 09:28:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 494.0 (TID 330, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 494.0 (TID 330)
2019-06-11 09:28:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 494.0 (TID 329) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 494.0 (TID 330). 810 bytes result sent to driver
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 494.0 (TID 330) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 494.0, whose tasks have all completed, from pool 
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 494 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 495)
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 495 (MapPartitionsRDD[582] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_248 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_248_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:25,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_248_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:25,031  INFO [org.apache.spark.SparkContext] - Created broadcast 248 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:25,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 495 (MapPartitionsRDD[582] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:25,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 495.0 with 1 tasks
2019-06-11 09:28:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 495.0 (TID 331, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 495.0 (TID 331)
2019-06-11 09:28:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 495.0 (TID 331). 966 bytes result sent to driver
2019-06-11 09:28:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 495.0 (TID 331) in 2 ms on localhost (executor driver) (1/1)
