2019-06-11 09:28:25,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 495.0, whose tasks have all completed, from pool 
2019-06-11 09:28:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 495 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:28:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 165 finished: print at Transform.scala:36, took 0.027847 s
2019-06-11 09:28:25,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:25,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 164 is 83 bytes
2019-06-11 09:28:25,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 165 is 160 bytes
2019-06-11 09:28:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 166 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 498 (print at Transform.scala:36)
2019-06-11 09:28:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 496, ShuffleMapStage 497)
2019-06-11 09:28:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 498 (MapPartitionsRDD[582] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:25,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_249 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:25,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_249_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:25,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_249_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:25,042  INFO [org.apache.spark.SparkContext] - Created broadcast 249 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 498 (MapPartitionsRDD[582] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 498.0 with 1 tasks
2019-06-11 09:28:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 498.0 (TID 332, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:25,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 498.0 (TID 332)
2019-06-11 09:28:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:25,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 498.0 (TID 332). 966 bytes result sent to driver
2019-06-11 09:28:25,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 498.0 (TID 332) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:25,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 498.0, whose tasks have all completed, from pool 
2019-06-11 09:28:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 498 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:25,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 166 finished: print at Transform.scala:36, took 0.005776 s
2019-06-11 09:28:25,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216505000 ms.0 from job set of time 1560216505000 ms
2019-06-11 09:28:25,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216505000 ms (execution: 0.039 s)
2019-06-11 09:28:25,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 575 from persistence list
2019-06-11 09:28:25,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 575
2019-06-11 09:28:25,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 570 from persistence list
2019-06-11 09:28:25,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 570
2019-06-11 09:28:25,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 569 from persistence list
2019-06-11 09:28:25,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 569
2019-06-11 09:28:25,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[569] at socketTextStream at Transform.scala:18 of time 1560216505000 ms
2019-06-11 09:28:25,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216495000 ms
2019-06-11 09:28:25,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216495000 ms
2019-06-11 09:28:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216510000 ms
2019-06-11 09:28:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216510000 ms.0 from job set of time 1560216510000 ms
2019-06-11 09:28:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 584 (map at Transform.scala:20)
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 167 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 501 (print at Transform.scala:36)
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 499, ShuffleMapStage 500)
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 500)
2019-06-11 09:28:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 500 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_250 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_250_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:28:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_250_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 250 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 500 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 500.0 with 2 tasks
2019-06-11 09:28:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 500.0 (TID 333, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:30,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 500.0 (TID 333)
2019-06-11 09:28:30,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 500.0 (TID 333). 810 bytes result sent to driver
2019-06-11 09:28:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 500.0 (TID 334, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:30,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 500.0 (TID 334)
2019-06-11 09:28:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 500.0 (TID 333) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:30,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 500.0 (TID 334). 810 bytes result sent to driver
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 500.0 (TID 334) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 500.0, whose tasks have all completed, from pool 
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 500 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 501)
2019-06-11 09:28:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 501 (MapPartitionsRDD[589] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:30,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_251 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_251_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:30,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_251_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:30,031  INFO [org.apache.spark.SparkContext] - Created broadcast 251 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 501 (MapPartitionsRDD[589] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 501.0 with 1 tasks
2019-06-11 09:28:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 501.0 (TID 335, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:30,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 501.0 (TID 335)
2019-06-11 09:28:30,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:28:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:30,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 501.0 (TID 335). 1009 bytes result sent to driver
2019-06-11 09:28:30,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 501.0 (TID 335) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:30,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 501.0, whose tasks have all completed, from pool 
2019-06-11 09:28:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 501 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 167 finished: print at Transform.scala:36, took 0.026348 s
2019-06-11 09:28:30,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:30,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 166 is 83 bytes
2019-06-11 09:28:30,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 167 is 160 bytes
2019-06-11 09:28:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 168 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 504 (print at Transform.scala:36)
2019-06-11 09:28:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 502, ShuffleMapStage 503)
2019-06-11 09:28:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 504 (MapPartitionsRDD[589] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_252 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_252_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:30,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_252_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:30,040  INFO [org.apache.spark.SparkContext] - Created broadcast 252 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 504 (MapPartitionsRDD[589] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:30,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 504.0 with 1 tasks
2019-06-11 09:28:30,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 504.0 (TID 336, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:30,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 504.0 (TID 336)
2019-06-11 09:28:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:30,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 504.0 (TID 336). 1009 bytes result sent to driver
2019-06-11 09:28:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 504.0 (TID 336) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:30,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 504.0, whose tasks have all completed, from pool 
2019-06-11 09:28:30,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 504 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 168 finished: print at Transform.scala:36, took 0.005746 s
2019-06-11 09:28:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216510000 ms.0 from job set of time 1560216510000 ms
2019-06-11 09:28:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216510000 ms (execution: 0.036 s)
2019-06-11 09:28:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 582 from persistence list
2019-06-11 09:28:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 582
2019-06-11 09:28:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 577 from persistence list
2019-06-11 09:28:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 577
2019-06-11 09:28:30,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 576 from persistence list
2019-06-11 09:28:30,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 576
2019-06-11 09:28:30,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[576] at socketTextStream at Transform.scala:18 of time 1560216510000 ms
2019-06-11 09:28:30,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216500000 ms
2019-06-11 09:28:30,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216500000 ms
2019-06-11 09:28:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216515000 ms
2019-06-11 09:28:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216515000 ms.0 from job set of time 1560216515000 ms
2019-06-11 09:28:35,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 591 (map at Transform.scala:20)
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 169 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 507 (print at Transform.scala:36)
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 506, ShuffleMapStage 505)
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 506)
2019-06-11 09:28:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 506 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_253 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_253_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:28:35,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_253_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:35,012  INFO [org.apache.spark.SparkContext] - Created broadcast 253 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:35,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 506 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:35,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 506.0 with 2 tasks
2019-06-11 09:28:35,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 506.0 (TID 337, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:35,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 506.0 (TID 337)
2019-06-11 09:28:35,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 506.0 (TID 337). 853 bytes result sent to driver
2019-06-11 09:28:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 506.0 (TID 338, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:35,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 506.0 (TID 338)
2019-06-11 09:28:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 506.0 (TID 337) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:35,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 506.0 (TID 338). 810 bytes result sent to driver
2019-06-11 09:28:35,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 506.0 (TID 338) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:35,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 506.0, whose tasks have all completed, from pool 
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 506 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 507)
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 507 (MapPartitionsRDD[596] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:35,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_254 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:28:35,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_254_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:28:35,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_254_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:35,034  INFO [org.apache.spark.SparkContext] - Created broadcast 254 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 507 (MapPartitionsRDD[596] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:35,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 507.0 with 1 tasks
2019-06-11 09:28:35,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 507.0 (TID 339, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:35,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 507.0 (TID 339)
2019-06-11 09:28:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:35,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 507.0 (TID 339). 1009 bytes result sent to driver
2019-06-11 09:28:35,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 507.0 (TID 339) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 507.0, whose tasks have all completed, from pool 
2019-06-11 09:28:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 507 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 169 finished: print at Transform.scala:36, took 0.030173 s
2019-06-11 09:28:35,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 168 is 83 bytes
2019-06-11 09:28:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 169 is 160 bytes
2019-06-11 09:28:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 170 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 510 (print at Transform.scala:36)
2019-06-11 09:28:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 509, ShuffleMapStage 508)
2019-06-11 09:28:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 510 (MapPartitionsRDD[596] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_255 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:35,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_255_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:35,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_255_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:35,043  INFO [org.apache.spark.SparkContext] - Created broadcast 255 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 510 (MapPartitionsRDD[596] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:35,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 510.0 with 1 tasks
2019-06-11 09:28:35,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 510.0 (TID 340, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:35,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 510.0 (TID 340)
2019-06-11 09:28:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:35,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 510.0 (TID 340). 966 bytes result sent to driver
2019-06-11 09:28:35,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 510.0 (TID 340) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:35,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 510.0, whose tasks have all completed, from pool 
2019-06-11 09:28:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 510 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 170 finished: print at Transform.scala:36, took 0.006358 s
2019-06-11 09:28:35,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216515000 ms.0 from job set of time 1560216515000 ms
2019-06-11 09:28:35,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216515000 ms (execution: 0.041 s)
2019-06-11 09:28:35,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 589 from persistence list
2019-06-11 09:28:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 589
2019-06-11 09:28:35,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 584 from persistence list
2019-06-11 09:28:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 584
2019-06-11 09:28:35,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 583 from persistence list
2019-06-11 09:28:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 583
2019-06-11 09:28:35,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[583] at socketTextStream at Transform.scala:18 of time 1560216515000 ms
2019-06-11 09:28:35,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216505000 ms
2019-06-11 09:28:35,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216505000 ms
2019-06-11 09:28:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216520000 ms
2019-06-11 09:28:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216520000 ms.0 from job set of time 1560216520000 ms
2019-06-11 09:28:40,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 598 (map at Transform.scala:20)
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 171 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 513 (print at Transform.scala:36)
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 511, ShuffleMapStage 512)
2019-06-11 09:28:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 511)
2019-06-11 09:28:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 511 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_256 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:40,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_256_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:40,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_256_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:40,012  INFO [org.apache.spark.SparkContext] - Created broadcast 256 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:40,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 511 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:40,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 511.0 with 2 tasks
2019-06-11 09:28:40,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 511.0 (TID 341, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:40,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 511.0 (TID 341)
2019-06-11 09:28:40,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 511.0 (TID 341). 810 bytes result sent to driver
2019-06-11 09:28:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 511.0 (TID 342, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:40,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 511.0 (TID 342)
2019-06-11 09:28:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 511.0 (TID 341) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 511.0 (TID 342). 810 bytes result sent to driver
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 511.0 (TID 342) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 511.0, whose tasks have all completed, from pool 
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 511 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 513)
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 513 (MapPartitionsRDD[603] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:40,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_257 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_257_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:40,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_257_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:40,035  INFO [org.apache.spark.SparkContext] - Created broadcast 257 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 513 (MapPartitionsRDD[603] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 513.0 with 1 tasks
2019-06-11 09:28:40,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 513.0 (TID 343, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:40,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 513.0 (TID 343)
2019-06-11 09:28:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:40,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 513.0 (TID 343). 1009 bytes result sent to driver
2019-06-11 09:28:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 513.0 (TID 343) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 513.0, whose tasks have all completed, from pool 
2019-06-11 09:28:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 513 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 171 finished: print at Transform.scala:36, took 0.028899 s
2019-06-11 09:28:40,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:40,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 171 is 160 bytes
2019-06-11 09:28:40,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 170 is 83 bytes
2019-06-11 09:28:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 172 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 516 (print at Transform.scala:36)
2019-06-11 09:28:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 514, ShuffleMapStage 515)
2019-06-11 09:28:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 516 (MapPartitionsRDD[603] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:40,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_258 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:40,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_258_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:40,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_258_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:40,043  INFO [org.apache.spark.SparkContext] - Created broadcast 258 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 516 (MapPartitionsRDD[603] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:40,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 516.0 with 1 tasks
2019-06-11 09:28:40,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 516.0 (TID 344, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:40,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 516.0 (TID 344)
2019-06-11 09:28:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 516.0 (TID 344). 966 bytes result sent to driver
2019-06-11 09:28:40,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 516.0 (TID 344) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:40,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 516.0, whose tasks have all completed, from pool 
2019-06-11 09:28:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 516 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 172 finished: print at Transform.scala:36, took 0.005442 s
2019-06-11 09:28:40,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216520000 ms.0 from job set of time 1560216520000 ms
2019-06-11 09:28:40,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216520000 ms (execution: 0.040 s)
2019-06-11 09:28:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 596 from persistence list
2019-06-11 09:28:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 596
2019-06-11 09:28:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 591 from persistence list
2019-06-11 09:28:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 591
2019-06-11 09:28:40,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 590 from persistence list
2019-06-11 09:28:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 590
2019-06-11 09:28:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[590] at socketTextStream at Transform.scala:18 of time 1560216520000 ms
2019-06-11 09:28:40,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216510000 ms
2019-06-11 09:28:40,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216510000 ms
2019-06-11 09:28:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216525000 ms
2019-06-11 09:28:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216525000 ms.0 from job set of time 1560216525000 ms
2019-06-11 09:28:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 605 (map at Transform.scala:20)
2019-06-11 09:28:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 173 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 519 (print at Transform.scala:36)
2019-06-11 09:28:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 517, ShuffleMapStage 518)
2019-06-11 09:28:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 518)
2019-06-11 09:28:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 518 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_259 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_259_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_259_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:45,011  INFO [org.apache.spark.SparkContext] - Created broadcast 259 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 518 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:45,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 518.0 with 2 tasks
2019-06-11 09:28:45,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 518.0 (TID 345, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 518.0 (TID 345)
2019-06-11 09:28:45,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 518.0 (TID 345). 853 bytes result sent to driver
2019-06-11 09:28:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 518.0 (TID 346, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:45,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 518.0 (TID 346)
2019-06-11 09:28:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 518.0 (TID 345) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:45,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 518.0 (TID 346). 767 bytes result sent to driver
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 518.0 (TID 346) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 518.0, whose tasks have all completed, from pool 
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 518 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 519)
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 519 (MapPartitionsRDD[610] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_260 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_260_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:45,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_260_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:45,032  INFO [org.apache.spark.SparkContext] - Created broadcast 260 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 519 (MapPartitionsRDD[610] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:45,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 519.0 with 1 tasks
2019-06-11 09:28:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 519.0 (TID 347, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:45,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 519.0 (TID 347)
2019-06-11 09:28:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:45,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 519.0 (TID 347). 1009 bytes result sent to driver
2019-06-11 09:28:45,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 519.0 (TID 347) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:45,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 519.0, whose tasks have all completed, from pool 
2019-06-11 09:28:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 519 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 173 finished: print at Transform.scala:36, took 0.026220 s
2019-06-11 09:28:45,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:45,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 172 is 83 bytes
2019-06-11 09:28:45,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 173 is 160 bytes
2019-06-11 09:28:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 174 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 522 (print at Transform.scala:36)
2019-06-11 09:28:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 520, ShuffleMapStage 521)
2019-06-11 09:28:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 522 (MapPartitionsRDD[610] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_261 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:45,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_261_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:45,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_261_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:45,040  INFO [org.apache.spark.SparkContext] - Created broadcast 261 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 522 (MapPartitionsRDD[610] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:45,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 522.0 with 1 tasks
2019-06-11 09:28:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 522.0 (TID 348, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:45,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 522.0 (TID 348)
2019-06-11 09:28:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:45,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 522.0 (TID 348). 966 bytes result sent to driver
2019-06-11 09:28:45,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 522.0 (TID 348) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:45,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 522.0, whose tasks have all completed, from pool 
2019-06-11 09:28:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 522 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 174 finished: print at Transform.scala:36, took 0.005657 s
2019-06-11 09:28:45,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216525000 ms.0 from job set of time 1560216525000 ms
2019-06-11 09:28:45,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216525000 ms (execution: 0.037 s)
2019-06-11 09:28:45,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 603 from persistence list
2019-06-11 09:28:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 603
2019-06-11 09:28:45,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 598 from persistence list
2019-06-11 09:28:45,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 598
2019-06-11 09:28:45,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 597 from persistence list
2019-06-11 09:28:45,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 597
2019-06-11 09:28:45,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[597] at socketTextStream at Transform.scala:18 of time 1560216525000 ms
2019-06-11 09:28:45,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216515000 ms
2019-06-11 09:28:45,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216515000 ms
2019-06-11 09:28:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216530000 ms
2019-06-11 09:28:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216530000 ms.0 from job set of time 1560216530000 ms
2019-06-11 09:28:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 612 (map at Transform.scala:20)
2019-06-11 09:28:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 175 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 525 (print at Transform.scala:36)
2019-06-11 09:28:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 524, ShuffleMapStage 523)
2019-06-11 09:28:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 524)
2019-06-11 09:28:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 524 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_262 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_262_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_262_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:50,011  INFO [org.apache.spark.SparkContext] - Created broadcast 262 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 524 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:50,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 524.0 with 2 tasks
2019-06-11 09:28:50,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 524.0 (TID 349, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:50,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 524.0 (TID 349)
2019-06-11 09:28:50,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 524.0 (TID 349). 767 bytes result sent to driver
2019-06-11 09:28:50,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 524.0 (TID 350, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:50,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 524.0 (TID 350)
2019-06-11 09:28:50,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 524.0 (TID 349) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:50,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 524.0 (TID 350). 853 bytes result sent to driver
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 524.0 (TID 350) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 524.0, whose tasks have all completed, from pool 
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 524 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 525)
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 525 (MapPartitionsRDD[617] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_263 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_263_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:50,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_263_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:50,037  INFO [org.apache.spark.SparkContext] - Created broadcast 263 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 525 (MapPartitionsRDD[617] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 525.0 with 1 tasks
2019-06-11 09:28:50,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 525.0 (TID 351, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:50,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 525.0 (TID 351)
2019-06-11 09:28:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:50,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 525.0 (TID 351). 966 bytes result sent to driver
2019-06-11 09:28:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 525.0 (TID 351) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:50,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 525.0, whose tasks have all completed, from pool 
2019-06-11 09:28:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 525 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:28:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 175 finished: print at Transform.scala:36, took 0.031723 s
2019-06-11 09:28:50,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:50,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 174 is 83 bytes
2019-06-11 09:28:50,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 175 is 160 bytes
2019-06-11 09:28:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 176 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 528 (print at Transform.scala:36)
2019-06-11 09:28:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 527, ShuffleMapStage 526)
2019-06-11 09:28:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 528 (MapPartitionsRDD[617] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:50,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_264 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:50,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_264_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:50,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_264_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:50,046  INFO [org.apache.spark.SparkContext] - Created broadcast 264 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 528 (MapPartitionsRDD[617] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:50,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 528.0 with 1 tasks
2019-06-11 09:28:50,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 528.0 (TID 352, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:50,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 528.0 (TID 352)
2019-06-11 09:28:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:50,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:50,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 528.0 (TID 352). 1009 bytes result sent to driver
2019-06-11 09:28:50,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 528.0 (TID 352) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:50,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 528.0, whose tasks have all completed, from pool 
2019-06-11 09:28:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 528 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:28:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 176 finished: print at Transform.scala:36, took 0.006243 s
2019-06-11 09:28:50,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216530000 ms.0 from job set of time 1560216530000 ms
2019-06-11 09:28:50,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216530000 ms (execution: 0.044 s)
2019-06-11 09:28:50,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 610 from persistence list
2019-06-11 09:28:50,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 610
2019-06-11 09:28:50,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 605 from persistence list
2019-06-11 09:28:50,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 605
2019-06-11 09:28:50,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 604 from persistence list
2019-06-11 09:28:50,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 604
2019-06-11 09:28:50,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[604] at socketTextStream at Transform.scala:18 of time 1560216530000 ms
2019-06-11 09:28:50,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216520000 ms
2019-06-11 09:28:50,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216520000 ms
2019-06-11 09:28:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216535000 ms
2019-06-11 09:28:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216535000 ms.0 from job set of time 1560216535000 ms
2019-06-11 09:28:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 619 (map at Transform.scala:20)
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 177 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 531 (print at Transform.scala:36)
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 529, ShuffleMapStage 530)
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 529)
2019-06-11 09:28:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 529 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:28:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_265 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_265_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:28:55,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_265_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,010  INFO [org.apache.spark.SparkContext] - Created broadcast 265 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 529 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:28:55,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 529.0 with 2 tasks
2019-06-11 09:28:55,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 529.0 (TID 353, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 529.0 (TID 353)
2019-06-11 09:28:55,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 529.0 (TID 353). 810 bytes result sent to driver
2019-06-11 09:28:55,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 529.0 (TID 354, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:28:55,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 529.0 (TID 354)
2019-06-11 09:28:55,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 529.0 (TID 353) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:28:55,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 529.0 (TID 354). 853 bytes result sent to driver
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 529.0 (TID 354) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 529.0, whose tasks have all completed, from pool 
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 529 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 531)
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:28:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 531 (MapPartitionsRDD[624] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:55,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_266 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:55,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 162
2019-06-11 09:28:55,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_266_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:55,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 163
2019-06-11 09:28:55,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_266_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 170
2019-06-11 09:28:55,045  INFO [org.apache.spark.SparkContext] - Created broadcast 266 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 531 (MapPartitionsRDD[624] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:28:55,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_251_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 531.0 with 1 tasks
2019-06-11 09:28:55,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 531.0 (TID 355, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:55,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 531.0 (TID 355)
2019-06-11 09:28:55,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_263_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 173
2019-06-11 09:28:55,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 172
2019-06-11 09:28:55,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 171
2019-06-11 09:28:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:55,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_253_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:55,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_247_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 531.0 (TID 355). 1009 bytes result sent to driver
2019-06-11 09:28:55,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 531.0 (TID 355) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:55,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 531.0, whose tasks have all completed, from pool 
2019-06-11 09:28:55,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_248_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 531 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:28:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 177 finished: print at Transform.scala:36, took 0.044591 s
2019-06-11 09:28:55,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_262_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_254_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_249_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_260_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_257_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,056  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:28:55,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 177 is 160 bytes
2019-06-11 09:28:55,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 167
2019-06-11 09:28:55,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 176 is 83 bytes
2019-06-11 09:28:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 178 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:28:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 534 (print at Transform.scala:36)
2019-06-11 09:28:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 532, ShuffleMapStage 533)
2019-06-11 09:28:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:28:55,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_256_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 534 (MapPartitionsRDD[624] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:28:55,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_267 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:28:55,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_258_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_267_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:28:55,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_267_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_246_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,060  INFO [org.apache.spark.SparkContext] - Created broadcast 267 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:28:55,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 160
2019-06-11 09:28:55,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 534 (MapPartitionsRDD[624] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:28:55,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 534.0 with 1 tasks
2019-06-11 09:28:55,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 165
2019-06-11 09:28:55,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 169
2019-06-11 09:28:55,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 534.0 (TID 356, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:28:55,063  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 534.0 (TID 356)
2019-06-11 09:28:55,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_250_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:28:55,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 161
2019-06-11 09:28:55,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:28:55,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:55,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_255_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:28:55,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:28:55,065  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 166
2019-06-11 09:28:55,065  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 534.0 (TID 356). 1009 bytes result sent to driver
2019-06-11 09:28:55,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_264_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,066  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 534.0 (TID 356) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:28:55,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 534.0, whose tasks have all completed, from pool 
2019-06-11 09:28:55,066  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 534 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:28:55,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 178 finished: print at Transform.scala:36, took 0.009832 s
2019-06-11 09:28:55,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216535000 ms.0 from job set of time 1560216535000 ms
2019-06-11 09:28:55,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.066 s for time 1560216535000 ms (execution: 0.061 s)
2019-06-11 09:28:55,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_252_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 617 from persistence list
2019-06-11 09:28:55,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 612 from persistence list
2019-06-11 09:28:55,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 617
2019-06-11 09:28:55,067  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 168
2019-06-11 09:28:55,067  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 611 from persistence list
2019-06-11 09:28:55,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 612
2019-06-11 09:28:55,067  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[611] at socketTextStream at Transform.scala:18 of time 1560216535000 ms
2019-06-11 09:28:55,067  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216525000 ms
2019-06-11 09:28:55,067  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216525000 ms
2019-06-11 09:28:55,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 611
2019-06-11 09:28:55,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_261_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:28:55,068  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 164
2019-06-11 09:28:55,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_259_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216540000 ms
2019-06-11 09:29:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216540000 ms.0 from job set of time 1560216540000 ms
2019-06-11 09:29:00,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 626 (map at Transform.scala:20)
2019-06-11 09:29:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 179 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 537 (print at Transform.scala:36)
2019-06-11 09:29:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 535, ShuffleMapStage 536)
2019-06-11 09:29:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 535)
2019-06-11 09:29:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 535 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_268 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:00,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_268_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:29:00,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_268_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:00,016  INFO [org.apache.spark.SparkContext] - Created broadcast 268 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 535 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:00,017  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 535.0 with 2 tasks
2019-06-11 09:29:00,017  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 535.0 (TID 357, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:00,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 535.0 (TID 357)
2019-06-11 09:29:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 535.0 (TID 357). 853 bytes result sent to driver
2019-06-11 09:29:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 535.0 (TID 358, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:00,033  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 535.0 (TID 358)
2019-06-11 09:29:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 535.0 (TID 357) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:00,045  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 535.0 (TID 358). 767 bytes result sent to driver
2019-06-11 09:29:00,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 535.0 (TID 358) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:00,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 535.0, whose tasks have all completed, from pool 
2019-06-11 09:29:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 535 (parallelize at Transform.scala:16) finished in 0.028 s
2019-06-11 09:29:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 537)
2019-06-11 09:29:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 537 (MapPartitionsRDD[631] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:00,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_269 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:00,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_269_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:00,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_269_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:00,049  INFO [org.apache.spark.SparkContext] - Created broadcast 269 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 537 (MapPartitionsRDD[631] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:00,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 537.0 with 1 tasks
2019-06-11 09:29:00,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 537.0 (TID 359, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:00,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 537.0 (TID 359)
2019-06-11 09:29:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:29:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:00,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 537.0 (TID 359). 966 bytes result sent to driver
2019-06-11 09:29:00,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 537.0 (TID 359) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:00,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 537.0, whose tasks have all completed, from pool 
2019-06-11 09:29:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 537 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 179 finished: print at Transform.scala:36, took 0.039197 s
2019-06-11 09:29:00,055  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:00,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 179 is 160 bytes
2019-06-11 09:29:00,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 178 is 83 bytes
2019-06-11 09:29:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 180 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 540 (print at Transform.scala:36)
2019-06-11 09:29:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 538, ShuffleMapStage 539)
2019-06-11 09:29:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 540 (MapPartitionsRDD[631] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:00,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_270 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:00,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_270_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:00,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_270_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:00,059  INFO [org.apache.spark.SparkContext] - Created broadcast 270 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 540 (MapPartitionsRDD[631] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:00,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 540.0 with 1 tasks
2019-06-11 09:29:00,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 540.0 (TID 360, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:00,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 540.0 (TID 360)
2019-06-11 09:29:00,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:00,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:00,062  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 540.0 (TID 360). 1052 bytes result sent to driver
2019-06-11 09:29:00,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 540.0 (TID 360) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:00,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 540.0, whose tasks have all completed, from pool 
2019-06-11 09:29:00,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 540 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:00,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 180 finished: print at Transform.scala:36, took 0.007673 s
2019-06-11 09:29:00,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216540000 ms.0 from job set of time 1560216540000 ms
2019-06-11 09:29:00,063  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.063 s for time 1560216540000 ms (execution: 0.053 s)
2019-06-11 09:29:00,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 624 from persistence list
2019-06-11 09:29:00,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 624
2019-06-11 09:29:00,063  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 619 from persistence list
2019-06-11 09:29:00,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 619
2019-06-11 09:29:00,063  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 618 from persistence list
2019-06-11 09:29:00,064  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 618
2019-06-11 09:29:00,064  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[618] at socketTextStream at Transform.scala:18 of time 1560216540000 ms
2019-06-11 09:29:00,064  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216530000 ms
2019-06-11 09:29:00,064  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216530000 ms
2019-06-11 09:29:05,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216545000 ms
2019-06-11 09:29:05,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216545000 ms.0 from job set of time 1560216545000 ms
2019-06-11 09:29:05,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 633 (map at Transform.scala:20)
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 181 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 543 (print at Transform.scala:36)
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 542, ShuffleMapStage 541)
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 541)
2019-06-11 09:29:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 541 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:05,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_271 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:05,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_271_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:29:05,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_271_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:05,011  INFO [org.apache.spark.SparkContext] - Created broadcast 271 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 541 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:05,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 541.0 with 2 tasks
2019-06-11 09:29:05,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 541.0 (TID 361, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:05,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 541.0 (TID 361)
2019-06-11 09:29:05,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 541.0 (TID 361). 853 bytes result sent to driver
2019-06-11 09:29:05,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 541.0 (TID 362, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:05,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 541.0 (TID 362)
2019-06-11 09:29:05,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 541.0 (TID 361) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 541.0 (TID 362). 853 bytes result sent to driver
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 541.0 (TID 362) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 541.0, whose tasks have all completed, from pool 
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 541 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 543)
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 543 (MapPartitionsRDD[638] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_272 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:05,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_272_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_272_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:05,038  INFO [org.apache.spark.SparkContext] - Created broadcast 272 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:05,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 543 (MapPartitionsRDD[638] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:05,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 543.0 with 1 tasks
2019-06-11 09:29:05,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 543.0 (TID 363, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:05,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 543.0 (TID 363)
2019-06-11 09:29:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:05,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 543.0 (TID 363). 1009 bytes result sent to driver
2019-06-11 09:29:05,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 543.0 (TID 363) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:05,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 543.0, whose tasks have all completed, from pool 
2019-06-11 09:29:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 543 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 181 finished: print at Transform.scala:36, took 0.030953 s
2019-06-11 09:29:05,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:05,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 181 is 160 bytes
2019-06-11 09:29:05,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 180 is 83 bytes
2019-06-11 09:29:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 182 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 546 (print at Transform.scala:36)
2019-06-11 09:29:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 545, ShuffleMapStage 544)
2019-06-11 09:29:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 546 (MapPartitionsRDD[638] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:05,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_273 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:05,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_273_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:05,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_273_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:05,044  INFO [org.apache.spark.SparkContext] - Created broadcast 273 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 546 (MapPartitionsRDD[638] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:05,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 546.0 with 1 tasks
2019-06-11 09:29:05,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 546.0 (TID 364, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:05,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 546.0 (TID 364)
2019-06-11 09:29:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:05,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 546.0 (TID 364). 1009 bytes result sent to driver
2019-06-11 09:29:05,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 546.0 (TID 364) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:05,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 546.0, whose tasks have all completed, from pool 
2019-06-11 09:29:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 546 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 182 finished: print at Transform.scala:36, took 0.004655 s
2019-06-11 09:29:05,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216545000 ms.0 from job set of time 1560216545000 ms
2019-06-11 09:29:05,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560216545000 ms (execution: 0.039 s)
2019-06-11 09:29:05,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 631 from persistence list
2019-06-11 09:29:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 631
2019-06-11 09:29:05,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 626 from persistence list
2019-06-11 09:29:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 626
2019-06-11 09:29:05,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 625 from persistence list
2019-06-11 09:29:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 625
2019-06-11 09:29:05,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[625] at socketTextStream at Transform.scala:18 of time 1560216545000 ms
2019-06-11 09:29:05,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216535000 ms
2019-06-11 09:29:05,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216535000 ms
2019-06-11 09:29:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216550000 ms
2019-06-11 09:29:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216550000 ms.0 from job set of time 1560216550000 ms
2019-06-11 09:29:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 640 (map at Transform.scala:20)
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 183 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 549 (print at Transform.scala:36)
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 547, ShuffleMapStage 548)
2019-06-11 09:29:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 548)
2019-06-11 09:29:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 548 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_274 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_274_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_274_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 274 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 548 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 548.0 with 2 tasks
2019-06-11 09:29:10,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 548.0 (TID 365, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 548.0 (TID 365)
2019-06-11 09:29:10,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 548.0 (TID 365). 810 bytes result sent to driver
2019-06-11 09:29:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 548.0 (TID 366, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:10,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 548.0 (TID 366)
2019-06-11 09:29:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 548.0 (TID 365) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:10,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 548.0 (TID 366). 853 bytes result sent to driver
2019-06-11 09:29:10,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 548.0 (TID 366) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 548.0, whose tasks have all completed, from pool 
2019-06-11 09:29:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 548 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:29:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 549)
2019-06-11 09:29:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 549 (MapPartitionsRDD[645] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:10,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_275 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:10,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_275_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:10,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_275_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:10,038  INFO [org.apache.spark.SparkContext] - Created broadcast 275 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 549 (MapPartitionsRDD[645] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:10,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 549.0 with 1 tasks
2019-06-11 09:29:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 549.0 (TID 367, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:10,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 549.0 (TID 367)
2019-06-11 09:29:10,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:10,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:10,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:10,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:10,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 549.0 (TID 367). 1009 bytes result sent to driver
2019-06-11 09:29:10,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 549.0 (TID 367) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:10,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 549.0, whose tasks have all completed, from pool 
2019-06-11 09:29:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 549 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 183 finished: print at Transform.scala:36, took 0.031085 s
2019-06-11 09:29:10,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:10,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 182 is 83 bytes
2019-06-11 09:29:10,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 183 is 160 bytes
2019-06-11 09:29:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 184 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 552 (print at Transform.scala:36)
2019-06-11 09:29:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 550, ShuffleMapStage 551)
2019-06-11 09:29:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 552 (MapPartitionsRDD[645] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_276 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:10,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_276_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_276_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:10,044  INFO [org.apache.spark.SparkContext] - Created broadcast 276 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:10,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 552 (MapPartitionsRDD[645] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 552.0 with 1 tasks
2019-06-11 09:29:10,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 552.0 (TID 368, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:10,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 552.0 (TID 368)
2019-06-11 09:29:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:10,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 552.0 (TID 368). 1052 bytes result sent to driver
2019-06-11 09:29:10,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 552.0 (TID 368) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:10,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 552.0, whose tasks have all completed, from pool 
2019-06-11 09:29:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 552 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:10,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 184 finished: print at Transform.scala:36, took 0.005664 s
2019-06-11 09:29:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216550000 ms.0 from job set of time 1560216550000 ms
2019-06-11 09:29:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560216550000 ms (execution: 0.042 s)
2019-06-11 09:29:10,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 638 from persistence list
2019-06-11 09:29:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 638
2019-06-11 09:29:10,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 633 from persistence list
2019-06-11 09:29:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 633
2019-06-11 09:29:10,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 632 from persistence list
2019-06-11 09:29:10,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 632
2019-06-11 09:29:10,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[632] at socketTextStream at Transform.scala:18 of time 1560216550000 ms
2019-06-11 09:29:10,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216540000 ms
2019-06-11 09:29:10,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216540000 ms
2019-06-11 09:29:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216555000 ms
2019-06-11 09:29:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216555000 ms.0 from job set of time 1560216555000 ms
2019-06-11 09:29:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 647 (map at Transform.scala:20)
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 185 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 555 (print at Transform.scala:36)
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 553, ShuffleMapStage 554)
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 554)
2019-06-11 09:29:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 554 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_277 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_277_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_277_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 277 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 554 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 554.0 with 2 tasks
2019-06-11 09:29:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 554.0 (TID 369, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 554.0 (TID 369)
2019-06-11 09:29:15,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 554.0 (TID 369). 810 bytes result sent to driver
2019-06-11 09:29:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 554.0 (TID 370, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:15,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 554.0 (TID 370)
2019-06-11 09:29:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 554.0 (TID 369) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:15,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 554.0 (TID 370). 853 bytes result sent to driver
2019-06-11 09:29:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 554.0 (TID 370) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:15,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 554.0, whose tasks have all completed, from pool 
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 554 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 555)
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 555 (MapPartitionsRDD[652] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_278 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_278_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:15,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_278_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:15,036  INFO [org.apache.spark.SparkContext] - Created broadcast 278 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 555 (MapPartitionsRDD[652] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 555.0 with 1 tasks
2019-06-11 09:29:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 555.0 (TID 371, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:15,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 555.0 (TID 371)
2019-06-11 09:29:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:29:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 555.0 (TID 371). 966 bytes result sent to driver
2019-06-11 09:29:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 555.0 (TID 371) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 555.0, whose tasks have all completed, from pool 
2019-06-11 09:29:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 555 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 185 finished: print at Transform.scala:36, took 0.031965 s
2019-06-11 09:29:15,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:15,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 184 is 83 bytes
2019-06-11 09:29:15,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 185 is 160 bytes
2019-06-11 09:29:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 186 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 558 (print at Transform.scala:36)
2019-06-11 09:29:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 556, ShuffleMapStage 557)
2019-06-11 09:29:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 558 (MapPartitionsRDD[652] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:15,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_279 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:15,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_279_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:15,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_279_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:15,045  INFO [org.apache.spark.SparkContext] - Created broadcast 279 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 558 (MapPartitionsRDD[652] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:15,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 558.0 with 1 tasks
2019-06-11 09:29:15,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 558.0 (TID 372, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:15,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 558.0 (TID 372)
2019-06-11 09:29:15,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:15,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:15,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:15,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:15,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 558.0 (TID 372). 1052 bytes result sent to driver
2019-06-11 09:29:15,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 558.0 (TID 372) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:15,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 558.0, whose tasks have all completed, from pool 
2019-06-11 09:29:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 558 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 186 finished: print at Transform.scala:36, took 0.006538 s
2019-06-11 09:29:15,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216555000 ms.0 from job set of time 1560216555000 ms
2019-06-11 09:29:15,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560216555000 ms (execution: 0.043 s)
2019-06-11 09:29:15,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 645 from persistence list
2019-06-11 09:29:15,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 645
2019-06-11 09:29:15,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 640 from persistence list
2019-06-11 09:29:15,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 640
2019-06-11 09:29:15,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 639 from persistence list
2019-06-11 09:29:15,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 639
2019-06-11 09:29:15,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[639] at socketTextStream at Transform.scala:18 of time 1560216555000 ms
2019-06-11 09:29:15,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216545000 ms
2019-06-11 09:29:15,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216545000 ms
2019-06-11 09:29:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216560000 ms
2019-06-11 09:29:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216560000 ms.0 from job set of time 1560216560000 ms
2019-06-11 09:29:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 654 (map at Transform.scala:20)
2019-06-11 09:29:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 187 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 561 (print at Transform.scala:36)
2019-06-11 09:29:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 560, ShuffleMapStage 559)
2019-06-11 09:29:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 560)
2019-06-11 09:29:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 560 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_280 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_280_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_280_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 280 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 560 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 560.0 with 2 tasks
2019-06-11 09:29:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 560.0 (TID 373, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 560.0 (TID 373)
2019-06-11 09:29:20,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 560.0 (TID 373). 810 bytes result sent to driver
2019-06-11 09:29:20,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 560.0 (TID 374, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:20,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 560.0 (TID 374)
2019-06-11 09:29:20,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 560.0 (TID 373) in 8 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:20,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 560.0 (TID 374). 810 bytes result sent to driver
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 560.0 (TID 374) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 560.0, whose tasks have all completed, from pool 
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 560 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 561)
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 561 (MapPartitionsRDD[659] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_281 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_281_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:20,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_281_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:20,031  INFO [org.apache.spark.SparkContext] - Created broadcast 281 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 561 (MapPartitionsRDD[659] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 561.0 with 1 tasks
2019-06-11 09:29:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 561.0 (TID 375, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:20,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 561.0 (TID 375)
2019-06-11 09:29:20,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:20,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:20,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:20,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:20,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 561.0 (TID 375). 966 bytes result sent to driver
2019-06-11 09:29:20,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 561.0 (TID 375) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:20,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 561.0, whose tasks have all completed, from pool 
2019-06-11 09:29:20,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 561 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:20,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 187 finished: print at Transform.scala:36, took 0.024991 s
2019-06-11 09:29:20,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 186 is 83 bytes
2019-06-11 09:29:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 187 is 160 bytes
2019-06-11 09:29:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 188 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 564 (print at Transform.scala:36)
2019-06-11 09:29:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 562, ShuffleMapStage 563)
2019-06-11 09:29:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 564 (MapPartitionsRDD[659] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:20,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_282 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:20,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_282_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:20,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_282_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:20,039  INFO [org.apache.spark.SparkContext] - Created broadcast 282 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 564 (MapPartitionsRDD[659] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 564.0 with 1 tasks
2019-06-11 09:29:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 564.0 (TID 376, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:20,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 564.0 (TID 376)
2019-06-11 09:29:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:20,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 564.0 (TID 376). 966 bytes result sent to driver
2019-06-11 09:29:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 564.0 (TID 376) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 564.0, whose tasks have all completed, from pool 
2019-06-11 09:29:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 564 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 188 finished: print at Transform.scala:36, took 0.006514 s
2019-06-11 09:29:20,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216560000 ms.0 from job set of time 1560216560000 ms
2019-06-11 09:29:20,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216560000 ms (execution: 0.035 s)
2019-06-11 09:29:20,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 652 from persistence list
2019-06-11 09:29:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 652
2019-06-11 09:29:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 647 from persistence list
2019-06-11 09:29:20,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 646 from persistence list
2019-06-11 09:29:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 647
2019-06-11 09:29:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 646
2019-06-11 09:29:20,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[646] at socketTextStream at Transform.scala:18 of time 1560216560000 ms
2019-06-11 09:29:20,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216550000 ms
2019-06-11 09:29:20,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216550000 ms
2019-06-11 09:29:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216565000 ms
2019-06-11 09:29:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216565000 ms.0 from job set of time 1560216565000 ms
2019-06-11 09:29:25,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 661 (map at Transform.scala:20)
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 189 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 567 (print at Transform.scala:36)
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 565, ShuffleMapStage 566)
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 566)
2019-06-11 09:29:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 566 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:25,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_283 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_283_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:25,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_283_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,009  INFO [org.apache.spark.SparkContext] - Created broadcast 283 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 566 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:25,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 566.0 with 2 tasks
2019-06-11 09:29:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 566.0 (TID 377, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:25,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 566.0 (TID 377)
2019-06-11 09:29:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 566.0 (TID 377). 810 bytes result sent to driver
2019-06-11 09:29:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 566.0 (TID 378, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:25,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 566.0 (TID 378)
2019-06-11 09:29:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 566.0 (TID 377) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:25,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 566.0 (TID 378). 767 bytes result sent to driver
2019-06-11 09:29:25,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 566.0 (TID 378) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:25,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 566.0, whose tasks have all completed, from pool 
2019-06-11 09:29:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 566 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:29:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 567)
2019-06-11 09:29:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 567 (MapPartitionsRDD[666] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:25,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_284 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_284_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:25,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_284_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,029  INFO [org.apache.spark.SparkContext] - Created broadcast 284 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 567 (MapPartitionsRDD[666] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 567.0 with 1 tasks
2019-06-11 09:29:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 567.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:25,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 567.0 (TID 379)
2019-06-11 09:29:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 567.0 (TID 379). 1009 bytes result sent to driver
2019-06-11 09:29:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 567.0 (TID 379) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 567.0, whose tasks have all completed, from pool 
2019-06-11 09:29:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 567 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 189 finished: print at Transform.scala:36, took 0.024641 s
2019-06-11 09:29:25,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:25,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 188 is 83 bytes
2019-06-11 09:29:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 189 is 160 bytes
2019-06-11 09:29:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 190 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 570 (print at Transform.scala:36)
2019-06-11 09:29:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 568, ShuffleMapStage 569)
2019-06-11 09:29:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 570 (MapPartitionsRDD[666] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:25,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_285 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_285_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_285_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,037  INFO [org.apache.spark.SparkContext] - Created broadcast 285 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 570 (MapPartitionsRDD[666] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:25,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 570.0 with 1 tasks
2019-06-11 09:29:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 570.0 (TID 380, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:25,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 570.0 (TID 380)
2019-06-11 09:29:25,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 185
2019-06-11 09:29:25,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:25,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:29:25,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_268_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:25,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:29:25,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_274_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 570.0 (TID 380). 1052 bytes result sent to driver
2019-06-11 09:29:25,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 179
2019-06-11 09:29:25,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 570.0 (TID 380) in 14 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:25,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 570.0, whose tasks have all completed, from pool 
2019-06-11 09:29:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 570 (print at Transform.scala:36) finished in 0.015 s
2019-06-11 09:29:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 190 finished: print at Transform.scala:36, took 0.017849 s
2019-06-11 09:29:25,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_279_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216565000 ms.0 from job set of time 1560216565000 ms
2019-06-11 09:29:25,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216565000 ms (execution: 0.046 s)
2019-06-11 09:29:25,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 659 from persistence list
2019-06-11 09:29:25,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 659
2019-06-11 09:29:25,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 654 from persistence list
2019-06-11 09:29:25,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 654
2019-06-11 09:29:25,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 653 from persistence list
2019-06-11 09:29:25,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 653
2019-06-11 09:29:25,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[653] at socketTextStream at Transform.scala:18 of time 1560216565000 ms
2019-06-11 09:29:25,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216555000 ms
2019-06-11 09:29:25,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216555000 ms
2019-06-11 09:29:25,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_276_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 176
2019-06-11 09:29:25,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 184
2019-06-11 09:29:25,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 182
2019-06-11 09:29:25,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_272_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 177
2019-06-11 09:29:25,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 175
2019-06-11 09:29:25,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_273_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_266_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_270_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_282_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_275_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,059  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 183
2019-06-11 09:29:25,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 174
2019-06-11 09:29:25,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 180
2019-06-11 09:29:25,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_281_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_284_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 181
2019-06-11 09:29:25,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 178
2019-06-11 09:29:25,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_277_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_278_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_283_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_269_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_280_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_271_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:25,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_267_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:25,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_265_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216570000 ms
2019-06-11 09:29:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216570000 ms.0 from job set of time 1560216570000 ms
2019-06-11 09:29:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 668 (map at Transform.scala:20)
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 191 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 573 (print at Transform.scala:36)
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 571, ShuffleMapStage 572)
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 572)
2019-06-11 09:29:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 572 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_286 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:30,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_286_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:29:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_286_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 286 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 572 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 572.0 with 2 tasks
2019-06-11 09:29:30,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 572.0 (TID 381, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:30,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 572.0 (TID 381)
2019-06-11 09:29:30,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 572.0 (TID 381). 810 bytes result sent to driver
2019-06-11 09:29:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 572.0 (TID 382, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:30,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 572.0 (TID 382)
2019-06-11 09:29:30,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 572.0 (TID 381) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:30,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 572.0 (TID 382). 767 bytes result sent to driver
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 572.0 (TID 382) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 572.0, whose tasks have all completed, from pool 
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 572 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 573)
2019-06-11 09:29:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 573 (MapPartitionsRDD[673] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:30,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_287 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:30,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_287_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:30,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_287_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:30,032  INFO [org.apache.spark.SparkContext] - Created broadcast 287 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:30,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 573 (MapPartitionsRDD[673] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 573.0 with 1 tasks
2019-06-11 09:29:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 573.0 (TID 383, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:30,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 573.0 (TID 383)
2019-06-11 09:29:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:30,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 573.0 (TID 383). 966 bytes result sent to driver
2019-06-11 09:29:30,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 573.0 (TID 383) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:30,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 573.0, whose tasks have all completed, from pool 
2019-06-11 09:29:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 573 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 191 finished: print at Transform.scala:36, took 0.026705 s
2019-06-11 09:29:30,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:30,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 190 is 83 bytes
2019-06-11 09:29:30,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 191 is 160 bytes
2019-06-11 09:29:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 192 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 576 (print at Transform.scala:36)
2019-06-11 09:29:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 574, ShuffleMapStage 575)
2019-06-11 09:29:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 576 (MapPartitionsRDD[673] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_288 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:30,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_288_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:30,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_288_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:30,042  INFO [org.apache.spark.SparkContext] - Created broadcast 288 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:30,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 576 (MapPartitionsRDD[673] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:30,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 576.0 with 1 tasks
2019-06-11 09:29:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 576.0 (TID 384, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:30,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 576.0 (TID 384)
2019-06-11 09:29:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:30,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:30,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:30,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 576.0 (TID 384). 1009 bytes result sent to driver
2019-06-11 09:29:30,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 576.0 (TID 384) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:30,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 576.0, whose tasks have all completed, from pool 
2019-06-11 09:29:30,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 576 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:30,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 192 finished: print at Transform.scala:36, took 0.006942 s
2019-06-11 09:29:30,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216570000 ms.0 from job set of time 1560216570000 ms
2019-06-11 09:29:30,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216570000 ms (execution: 0.038 s)
2019-06-11 09:29:30,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 666 from persistence list
2019-06-11 09:29:30,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 666
2019-06-11 09:29:30,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 661 from persistence list
2019-06-11 09:29:30,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 661
2019-06-11 09:29:30,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 660 from persistence list
2019-06-11 09:29:30,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 660
2019-06-11 09:29:30,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[660] at socketTextStream at Transform.scala:18 of time 1560216570000 ms
2019-06-11 09:29:30,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216560000 ms
2019-06-11 09:29:30,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216560000 ms
2019-06-11 09:29:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216575000 ms
2019-06-11 09:29:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216575000 ms.0 from job set of time 1560216575000 ms
2019-06-11 09:29:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 675 (map at Transform.scala:20)
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 193 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 579 (print at Transform.scala:36)
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 578, ShuffleMapStage 577)
2019-06-11 09:29:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 578)
2019-06-11 09:29:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 578 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_289 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_289_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:29:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_289_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 289 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 578 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 578.0 with 2 tasks
2019-06-11 09:29:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 578.0 (TID 385, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:35,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 578.0 (TID 385)
2019-06-11 09:29:35,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 578.0 (TID 385). 853 bytes result sent to driver
2019-06-11 09:29:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 578.0 (TID 386, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:35,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 578.0 (TID 386)
2019-06-11 09:29:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 578.0 (TID 385) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:35,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 578.0 (TID 386). 767 bytes result sent to driver
2019-06-11 09:29:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 578.0 (TID 386) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:35,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 578.0, whose tasks have all completed, from pool 
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 578 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 579)
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 579 (MapPartitionsRDD[680] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:35,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_290 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_290_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:35,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_290_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:35,031  INFO [org.apache.spark.SparkContext] - Created broadcast 290 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 579 (MapPartitionsRDD[680] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 579.0 with 1 tasks
2019-06-11 09:29:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 579.0 (TID 387, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:35,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 579.0 (TID 387)
2019-06-11 09:29:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:35,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 579.0 (TID 387). 966 bytes result sent to driver
2019-06-11 09:29:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 579.0 (TID 387) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 579.0, whose tasks have all completed, from pool 
2019-06-11 09:29:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 579 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 193 finished: print at Transform.scala:36, took 0.026274 s
2019-06-11 09:29:35,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 192 is 83 bytes
2019-06-11 09:29:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 193 is 160 bytes
2019-06-11 09:29:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 194 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 582 (print at Transform.scala:36)
2019-06-11 09:29:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 580, ShuffleMapStage 581)
2019-06-11 09:29:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 582 (MapPartitionsRDD[680] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_291 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:35,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_291_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:35,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_291_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:35,039  INFO [org.apache.spark.SparkContext] - Created broadcast 291 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 582 (MapPartitionsRDD[680] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 582.0 with 1 tasks
2019-06-11 09:29:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 582.0 (TID 388, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:35,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 582.0 (TID 388)
2019-06-11 09:29:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:35,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 582.0 (TID 388). 966 bytes result sent to driver
2019-06-11 09:29:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 582.0 (TID 388) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:35,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 582.0, whose tasks have all completed, from pool 
2019-06-11 09:29:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 582 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 194 finished: print at Transform.scala:36, took 0.005899 s
2019-06-11 09:29:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216575000 ms.0 from job set of time 1560216575000 ms
2019-06-11 09:29:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216575000 ms (execution: 0.037 s)
2019-06-11 09:29:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 673 from persistence list
2019-06-11 09:29:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 673
2019-06-11 09:29:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 668 from persistence list
2019-06-11 09:29:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 668
2019-06-11 09:29:35,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 667 from persistence list
2019-06-11 09:29:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 667
2019-06-11 09:29:35,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[667] at socketTextStream at Transform.scala:18 of time 1560216575000 ms
2019-06-11 09:29:35,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216565000 ms
2019-06-11 09:29:35,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216565000 ms
2019-06-11 09:29:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216580000 ms
2019-06-11 09:29:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216580000 ms.0 from job set of time 1560216580000 ms
2019-06-11 09:29:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 682 (map at Transform.scala:20)
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 195 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 585 (print at Transform.scala:36)
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 583, ShuffleMapStage 584)
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 583)
2019-06-11 09:29:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 583 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_292 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_292_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:29:40,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_292_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 292 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 583 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 583.0 with 2 tasks
2019-06-11 09:29:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 583.0 (TID 389, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:40,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 583.0 (TID 389)
2019-06-11 09:29:40,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 583.0 (TID 389). 853 bytes result sent to driver
2019-06-11 09:29:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 583.0 (TID 390, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 583.0 (TID 390)
2019-06-11 09:29:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 583.0 (TID 389) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:40,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 583.0 (TID 390). 767 bytes result sent to driver
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 583.0 (TID 390) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 583.0, whose tasks have all completed, from pool 
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 583 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 585)
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 585 (MapPartitionsRDD[687] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_293 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:29:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_293_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:29:40,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_293_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:40,029  INFO [org.apache.spark.SparkContext] - Created broadcast 293 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 585 (MapPartitionsRDD[687] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 585.0 with 1 tasks
2019-06-11 09:29:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 585.0 (TID 391, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:40,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 585.0 (TID 391)
2019-06-11 09:29:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 585.0 (TID 391). 1009 bytes result sent to driver
2019-06-11 09:29:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 585.0 (TID 391) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 585.0, whose tasks have all completed, from pool 
2019-06-11 09:29:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 585 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 195 finished: print at Transform.scala:36, took 0.024939 s
2019-06-11 09:29:40,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 195 is 160 bytes
2019-06-11 09:29:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 194 is 83 bytes
2019-06-11 09:29:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 196 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 588 (print at Transform.scala:36)
2019-06-11 09:29:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 586, ShuffleMapStage 587)
2019-06-11 09:29:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 588 (MapPartitionsRDD[687] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_294 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_294_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_294_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 294 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 588 (MapPartitionsRDD[687] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 588.0 with 1 tasks
2019-06-11 09:29:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 588.0 (TID 392, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 588.0 (TID 392)
2019-06-11 09:29:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 588.0 (TID 392). 966 bytes result sent to driver
2019-06-11 09:29:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 588.0 (TID 392) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 588.0, whose tasks have all completed, from pool 
2019-06-11 09:29:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 588 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 196 finished: print at Transform.scala:36, took 0.006335 s
2019-06-11 09:29:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216580000 ms.0 from job set of time 1560216580000 ms
2019-06-11 09:29:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216580000 ms (execution: 0.035 s)
2019-06-11 09:29:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 680 from persistence list
2019-06-11 09:29:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 680
2019-06-11 09:29:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 675 from persistence list
2019-06-11 09:29:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 675
2019-06-11 09:29:40,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 674 from persistence list
2019-06-11 09:29:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 674
2019-06-11 09:29:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[674] at socketTextStream at Transform.scala:18 of time 1560216580000 ms
2019-06-11 09:29:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216570000 ms
2019-06-11 09:29:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216570000 ms
2019-06-11 09:29:45,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216585000 ms
2019-06-11 09:29:45,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216585000 ms.0 from job set of time 1560216585000 ms
2019-06-11 09:29:45,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 689 (map at Transform.scala:20)
2019-06-11 09:29:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 197 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 591 (print at Transform.scala:36)
2019-06-11 09:29:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 589, ShuffleMapStage 590)
2019-06-11 09:29:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 590)
2019-06-11 09:29:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 590 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:45,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_295 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:45,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_295_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:45,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_295_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:45,013  INFO [org.apache.spark.SparkContext] - Created broadcast 295 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:45,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 590 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:45,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 590.0 with 2 tasks
2019-06-11 09:29:45,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 590.0 (TID 393, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:45,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 590.0 (TID 393)
2019-06-11 09:29:45,027  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 590.0 (TID 393). 810 bytes result sent to driver
2019-06-11 09:29:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 590.0 (TID 394, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:45,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 590.0 (TID 394)
2019-06-11 09:29:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 590.0 (TID 393) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:45,036  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 590.0 (TID 394). 810 bytes result sent to driver
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 590.0 (TID 394) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 590.0, whose tasks have all completed, from pool 
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 590 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 591)
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 591 (MapPartitionsRDD[694] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_296 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_296_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:45,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_296_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:45,038  INFO [org.apache.spark.SparkContext] - Created broadcast 296 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 591 (MapPartitionsRDD[694] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:45,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 591.0 with 1 tasks
2019-06-11 09:29:45,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 591.0 (TID 395, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:45,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 591.0 (TID 395)
2019-06-11 09:29:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:45,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 591.0 (TID 395). 966 bytes result sent to driver
2019-06-11 09:29:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 591.0 (TID 395) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 591.0, whose tasks have all completed, from pool 
2019-06-11 09:29:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 591 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 197 finished: print at Transform.scala:36, took 0.030031 s
2019-06-11 09:29:45,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:45,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 196 is 83 bytes
2019-06-11 09:29:45,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 197 is 160 bytes
2019-06-11 09:29:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 198 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 594 (print at Transform.scala:36)
2019-06-11 09:29:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 592, ShuffleMapStage 593)
2019-06-11 09:29:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 594 (MapPartitionsRDD[694] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:45,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_297 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:45,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_297_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:45,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_297_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:45,046  INFO [org.apache.spark.SparkContext] - Created broadcast 297 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 594 (MapPartitionsRDD[694] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 594.0 with 1 tasks
2019-06-11 09:29:45,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 594.0 (TID 396, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:45,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 594.0 (TID 396)
2019-06-11 09:29:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:45,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 594.0 (TID 396). 1009 bytes result sent to driver
2019-06-11 09:29:45,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 594.0 (TID 396) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:45,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 594.0, whose tasks have all completed, from pool 
2019-06-11 09:29:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 594 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:29:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 198 finished: print at Transform.scala:36, took 0.006344 s
2019-06-11 09:29:45,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216585000 ms.0 from job set of time 1560216585000 ms
2019-06-11 09:29:45,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216585000 ms (execution: 0.040 s)
2019-06-11 09:29:45,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 687 from persistence list
2019-06-11 09:29:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 687
2019-06-11 09:29:45,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 682 from persistence list
2019-06-11 09:29:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 682
2019-06-11 09:29:45,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 681 from persistence list
2019-06-11 09:29:45,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 681
2019-06-11 09:29:45,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[681] at socketTextStream at Transform.scala:18 of time 1560216585000 ms
2019-06-11 09:29:45,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216575000 ms
2019-06-11 09:29:45,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216575000 ms
2019-06-11 09:29:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216590000 ms
2019-06-11 09:29:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216590000 ms.0 from job set of time 1560216590000 ms
2019-06-11 09:29:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 696 (map at Transform.scala:20)
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 199 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 597 (print at Transform.scala:36)
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 596, ShuffleMapStage 595)
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 596)
2019-06-11 09:29:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 596 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_298 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_298_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_298_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:50,012  INFO [org.apache.spark.SparkContext] - Created broadcast 298 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 596 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:50,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 596.0 with 2 tasks
2019-06-11 09:29:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 596.0 (TID 397, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 596.0 (TID 397)
2019-06-11 09:29:50,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 596.0 (TID 397). 810 bytes result sent to driver
2019-06-11 09:29:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 596.0 (TID 398, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:50,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 596.0 (TID 398)
2019-06-11 09:29:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 596.0 (TID 397) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:50,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 596.0 (TID 398). 810 bytes result sent to driver
2019-06-11 09:29:50,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 596.0 (TID 398) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:50,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 596.0, whose tasks have all completed, from pool 
2019-06-11 09:29:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 596 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:29:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 597)
2019-06-11 09:29:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 597 (MapPartitionsRDD[701] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:50,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_299 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:50,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_299_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:50,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_299_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:50,031  INFO [org.apache.spark.SparkContext] - Created broadcast 299 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 597 (MapPartitionsRDD[701] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:50,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 597.0 with 1 tasks
2019-06-11 09:29:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 597.0 (TID 399, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:50,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 597.0 (TID 399)
2019-06-11 09:29:50,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:50,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:50,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:50,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:50,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 597.0 (TID 399). 966 bytes result sent to driver
2019-06-11 09:29:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 597.0 (TID 399) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:50,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 597.0, whose tasks have all completed, from pool 
2019-06-11 09:29:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 597 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 199 finished: print at Transform.scala:36, took 0.025814 s
2019-06-11 09:29:50,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 198 is 83 bytes
2019-06-11 09:29:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 199 is 160 bytes
2019-06-11 09:29:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 200 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 600 (print at Transform.scala:36)
2019-06-11 09:29:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 598, ShuffleMapStage 599)
2019-06-11 09:29:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 600 (MapPartitionsRDD[701] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:50,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_300 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_300_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:50,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_300_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:50,041  INFO [org.apache.spark.SparkContext] - Created broadcast 300 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 600 (MapPartitionsRDD[701] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:50,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 600.0 with 1 tasks
2019-06-11 09:29:50,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 600.0 (TID 400, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:50,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 600.0 (TID 400)
2019-06-11 09:29:50,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:50,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:50,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:50,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:50,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 600.0 (TID 400). 966 bytes result sent to driver
2019-06-11 09:29:50,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 600.0 (TID 400) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:50,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 600.0, whose tasks have all completed, from pool 
2019-06-11 09:29:50,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 600 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:50,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 200 finished: print at Transform.scala:36, took 0.006949 s
2019-06-11 09:29:50,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216590000 ms.0 from job set of time 1560216590000 ms
2019-06-11 09:29:50,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216590000 ms (execution: 0.037 s)
2019-06-11 09:29:50,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 694 from persistence list
2019-06-11 09:29:50,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 694
2019-06-11 09:29:50,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 689 from persistence list
2019-06-11 09:29:50,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 689
2019-06-11 09:29:50,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 688 from persistence list
2019-06-11 09:29:50,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 688
2019-06-11 09:29:50,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[688] at socketTextStream at Transform.scala:18 of time 1560216590000 ms
2019-06-11 09:29:50,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216580000 ms
2019-06-11 09:29:50,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216580000 ms
2019-06-11 09:29:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216595000 ms
2019-06-11 09:29:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216595000 ms.0 from job set of time 1560216595000 ms
2019-06-11 09:29:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 703 (map at Transform.scala:20)
2019-06-11 09:29:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:29:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 201 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 603 (print at Transform.scala:36)
2019-06-11 09:29:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 601, ShuffleMapStage 602)
2019-06-11 09:29:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 602)
2019-06-11 09:29:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 602 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:29:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_301 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_301_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:29:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_301_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:29:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 301 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 602 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:29:55,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 602.0 with 2 tasks
2019-06-11 09:29:55,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 602.0 (TID 401, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:55,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 602.0 (TID 401)
2019-06-11 09:29:55,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 602.0 (TID 401). 853 bytes result sent to driver
2019-06-11 09:29:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 602.0 (TID 402, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:29:55,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 602.0 (TID 402)
2019-06-11 09:29:55,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 602.0 (TID 401) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:29:55,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 602.0 (TID 402). 767 bytes result sent to driver
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 602.0 (TID 402) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 602.0, whose tasks have all completed, from pool 
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 602 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 603)
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:29:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 603 (MapPartitionsRDD[708] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:55,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_302 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:55,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_302_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:55,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_302_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:55,032  INFO [org.apache.spark.SparkContext] - Created broadcast 302 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 603 (MapPartitionsRDD[708] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:29:55,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 603.0 with 1 tasks
2019-06-11 09:29:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 603.0 (TID 403, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:55,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 603.0 (TID 403)
2019-06-11 09:29:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:55,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 603.0 (TID 403). 966 bytes result sent to driver
2019-06-11 09:29:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 603.0 (TID 403) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 603.0, whose tasks have all completed, from pool 
2019-06-11 09:29:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 603 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 201 finished: print at Transform.scala:36, took 0.028132 s
2019-06-11 09:29:55,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:29:55,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 200 is 83 bytes
2019-06-11 09:29:55,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 201 is 160 bytes
2019-06-11 09:29:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 202 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:29:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 606 (print at Transform.scala:36)
2019-06-11 09:29:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 604, ShuffleMapStage 605)
2019-06-11 09:29:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:29:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 606 (MapPartitionsRDD[708] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:29:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_303 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:29:55,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_303_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:29:55,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_303_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:29:55,041  INFO [org.apache.spark.SparkContext] - Created broadcast 303 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:29:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 606 (MapPartitionsRDD[708] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:29:55,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 606.0 with 1 tasks
2019-06-11 09:29:55,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 606.0 (TID 404, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:29:55,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 606.0 (TID 404)
2019-06-11 09:29:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:29:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:29:55,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:29:55,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 606.0 (TID 404). 966 bytes result sent to driver
2019-06-11 09:29:55,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 606.0 (TID 404) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:29:55,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 606.0, whose tasks have all completed, from pool 
2019-06-11 09:29:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 606 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:29:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 202 finished: print at Transform.scala:36, took 0.005551 s
2019-06-11 09:29:55,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216595000 ms.0 from job set of time 1560216595000 ms
2019-06-11 09:29:55,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216595000 ms (execution: 0.038 s)
2019-06-11 09:29:55,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 701 from persistence list
2019-06-11 09:29:55,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 701
2019-06-11 09:29:55,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 696 from persistence list
2019-06-11 09:29:55,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 696
2019-06-11 09:29:55,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 695 from persistence list
2019-06-11 09:29:55,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 695
2019-06-11 09:29:55,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[695] at socketTextStream at Transform.scala:18 of time 1560216595000 ms
2019-06-11 09:29:55,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216585000 ms
2019-06-11 09:29:55,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216585000 ms
2019-06-11 09:30:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216600000 ms
2019-06-11 09:30:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216600000 ms.0 from job set of time 1560216600000 ms
2019-06-11 09:30:00,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 710 (map at Transform.scala:20)
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 203 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 609 (print at Transform.scala:36)
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 607, ShuffleMapStage 608)
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 608)
2019-06-11 09:30:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 608 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:00,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_304 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_304_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_304_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,021  INFO [org.apache.spark.SparkContext] - Created broadcast 304 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:00,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_302_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 608 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:00,024  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 608.0 with 2 tasks
2019-06-11 09:30:00,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 608.0 (TID 405, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:00,025  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 608.0 (TID 405)
2019-06-11 09:30:00,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_287_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_295_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 198
2019-06-11 09:30:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 196
2019-06-11 09:30:00,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 189
2019-06-11 09:30:00,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_296_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 199
2019-06-11 09:30:00,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 193
2019-06-11 09:30:00,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_301_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_290_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_299_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_289_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 197
2019-06-11 09:30:00,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 186
2019-06-11 09:30:00,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 190
2019-06-11 09:30:00,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_288_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,036  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 192
2019-06-11 09:30:00,036  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 188
2019-06-11 09:30:00,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_294_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_300_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 195
2019-06-11 09:30:00,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_293_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_298_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_285_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 194
2019-06-11 09:30:00,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_291_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_292_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 608.0 (TID 405). 810 bytes result sent to driver
2019-06-11 09:30:00,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 608.0 (TID 406, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:00,043  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 608.0 (TID 406)
2019-06-11 09:30:00,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 608.0 (TID 405) in 18 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:00,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_297_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 191
2019-06-11 09:30:00,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_286_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:00,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 187
2019-06-11 09:30:00,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_303_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,056  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 608.0 (TID 406). 853 bytes result sent to driver
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 608.0 (TID 406) in 13 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 608.0, whose tasks have all completed, from pool 
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 608 (parallelize at Transform.scala:16) finished in 0.031 s
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 609)
2019-06-11 09:30:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:00,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 609 (MapPartitionsRDD[715] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:00,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_305 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:00,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_305_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:00,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_305_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,059  INFO [org.apache.spark.SparkContext] - Created broadcast 305 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 609 (MapPartitionsRDD[715] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:00,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 609.0 with 1 tasks
2019-06-11 09:30:00,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 609.0 (TID 407, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:00,060  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 609.0 (TID 407)
2019-06-11 09:30:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:00,061  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:00,062  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 609.0 (TID 407). 966 bytes result sent to driver
2019-06-11 09:30:00,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 609.0 (TID 407) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:00,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 609.0, whose tasks have all completed, from pool 
2019-06-11 09:30:00,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 609 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:00,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 203 finished: print at Transform.scala:36, took 0.050554 s
2019-06-11 09:30:00,064  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:00,064  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 202 is 83 bytes
2019-06-11 09:30:00,065  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 203 is 160 bytes
2019-06-11 09:30:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 204 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 612 (print at Transform.scala:36)
2019-06-11 09:30:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 610, ShuffleMapStage 611)
2019-06-11 09:30:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:00,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 612 (MapPartitionsRDD[715] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:00,065  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_306 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:00,067  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_306_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:00,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_306_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:00,067  INFO [org.apache.spark.SparkContext] - Created broadcast 306 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:00,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 612 (MapPartitionsRDD[715] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:00,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 612.0 with 1 tasks
2019-06-11 09:30:00,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 612.0 (TID 408, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:00,068  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 612.0 (TID 408)
2019-06-11 09:30:00,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:00,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:00,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:00,069  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:00,070  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 612.0 (TID 408). 966 bytes result sent to driver
2019-06-11 09:30:00,070  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 612.0 (TID 408) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:00,070  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 612.0, whose tasks have all completed, from pool 
2019-06-11 09:30:00,070  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 612 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:00,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 204 finished: print at Transform.scala:36, took 0.006119 s
2019-06-11 09:30:00,071  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216600000 ms.0 from job set of time 1560216600000 ms
2019-06-11 09:30:00,071  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.071 s for time 1560216600000 ms (execution: 0.062 s)
2019-06-11 09:30:00,071  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 708 from persistence list
2019-06-11 09:30:00,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 708
2019-06-11 09:30:00,071  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 703 from persistence list
2019-06-11 09:30:00,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 703
2019-06-11 09:30:00,071  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 702 from persistence list
2019-06-11 09:30:00,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 702
2019-06-11 09:30:00,071  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[702] at socketTextStream at Transform.scala:18 of time 1560216600000 ms
2019-06-11 09:30:00,071  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216590000 ms
2019-06-11 09:30:00,071  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216590000 ms
2019-06-11 09:30:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216605000 ms
2019-06-11 09:30:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216605000 ms.0 from job set of time 1560216605000 ms
2019-06-11 09:30:05,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 717 (map at Transform.scala:20)
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 205 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 615 (print at Transform.scala:36)
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 614, ShuffleMapStage 613)
2019-06-11 09:30:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 614)
2019-06-11 09:30:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 614 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:05,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_307 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:05,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_307_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:30:05,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_307_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:05,012  INFO [org.apache.spark.SparkContext] - Created broadcast 307 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 614 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:05,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 614.0 with 2 tasks
2019-06-11 09:30:05,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 614.0 (TID 409, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:05,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 614.0 (TID 409)
2019-06-11 09:30:05,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 614.0 (TID 409). 767 bytes result sent to driver
2019-06-11 09:30:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 614.0 (TID 410, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:05,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 614.0 (TID 410)
2019-06-11 09:30:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 614.0 (TID 409) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:05,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 614.0 (TID 410). 853 bytes result sent to driver
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 614.0 (TID 410) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 614.0, whose tasks have all completed, from pool 
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 614 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 615)
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 615 (MapPartitionsRDD[722] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_308 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_308_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_308_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:05,036  INFO [org.apache.spark.SparkContext] - Created broadcast 308 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 615 (MapPartitionsRDD[722] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 615.0 with 1 tasks
2019-06-11 09:30:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 615.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 615.0 (TID 411)
2019-06-11 09:30:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:05,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 615.0 (TID 411). 1009 bytes result sent to driver
2019-06-11 09:30:05,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 615.0 (TID 411) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:05,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 615.0, whose tasks have all completed, from pool 
2019-06-11 09:30:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 615 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 205 finished: print at Transform.scala:36, took 0.031596 s
2019-06-11 09:30:05,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:05,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 204 is 83 bytes
2019-06-11 09:30:05,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 205 is 160 bytes
2019-06-11 09:30:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 206 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 618 (print at Transform.scala:36)
2019-06-11 09:30:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 616, ShuffleMapStage 617)
2019-06-11 09:30:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 618 (MapPartitionsRDD[722] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:05,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_309 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:05,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_309_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:05,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_309_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:05,046  INFO [org.apache.spark.SparkContext] - Created broadcast 309 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 618 (MapPartitionsRDD[722] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:05,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 618.0 with 1 tasks
2019-06-11 09:30:05,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 618.0 (TID 412, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:05,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 618.0 (TID 412)
2019-06-11 09:30:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:05,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 618.0 (TID 412). 966 bytes result sent to driver
2019-06-11 09:30:05,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 618.0 (TID 412) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:05,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 618.0, whose tasks have all completed, from pool 
2019-06-11 09:30:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 618 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:30:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 206 finished: print at Transform.scala:36, took 0.006874 s
2019-06-11 09:30:05,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216605000 ms.0 from job set of time 1560216605000 ms
2019-06-11 09:30:05,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216605000 ms (execution: 0.043 s)
2019-06-11 09:30:05,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 715 from persistence list
2019-06-11 09:30:05,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 715
2019-06-11 09:30:05,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 710 from persistence list
2019-06-11 09:30:05,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 710
2019-06-11 09:30:05,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 709 from persistence list
2019-06-11 09:30:05,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 709
2019-06-11 09:30:05,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[709] at socketTextStream at Transform.scala:18 of time 1560216605000 ms
2019-06-11 09:30:05,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216595000 ms
2019-06-11 09:30:05,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216595000 ms
2019-06-11 09:30:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216610000 ms
2019-06-11 09:30:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216610000 ms.0 from job set of time 1560216610000 ms
2019-06-11 09:30:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 724 (map at Transform.scala:20)
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 207 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 621 (print at Transform.scala:36)
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 619, ShuffleMapStage 620)
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 620)
2019-06-11 09:30:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 620 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_310 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_310_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:30:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_310_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 310 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 620 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:10,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 620.0 with 2 tasks
2019-06-11 09:30:10,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 620.0 (TID 413, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 620.0 (TID 413)
2019-06-11 09:30:10,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 620.0 (TID 413). 853 bytes result sent to driver
2019-06-11 09:30:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 620.0 (TID 414, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:10,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 620.0 (TID 414)
2019-06-11 09:30:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 620.0 (TID 413) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:10,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 620.0 (TID 414). 810 bytes result sent to driver
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 620.0 (TID 414) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 620.0, whose tasks have all completed, from pool 
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 620 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 621)
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 621 (MapPartitionsRDD[729] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:10,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_311 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:10,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_311_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:10,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_311_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:10,032  INFO [org.apache.spark.SparkContext] - Created broadcast 311 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 621 (MapPartitionsRDD[729] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 621.0 with 1 tasks
2019-06-11 09:30:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 621.0 (TID 415, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:10,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 621.0 (TID 415)
2019-06-11 09:30:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:10,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 621.0 (TID 415). 966 bytes result sent to driver
2019-06-11 09:30:10,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 621.0 (TID 415) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 621.0, whose tasks have all completed, from pool 
2019-06-11 09:30:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 621 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 207 finished: print at Transform.scala:36, took 0.026472 s
2019-06-11 09:30:10,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:10,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 206 is 83 bytes
2019-06-11 09:30:10,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 207 is 160 bytes
2019-06-11 09:30:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 208 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 624 (print at Transform.scala:36)
2019-06-11 09:30:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 622, ShuffleMapStage 623)
2019-06-11 09:30:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 624 (MapPartitionsRDD[729] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:10,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_312 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_312_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:10,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_312_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:10,042  INFO [org.apache.spark.SparkContext] - Created broadcast 312 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 624 (MapPartitionsRDD[729] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 624.0 with 1 tasks
2019-06-11 09:30:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 624.0 (TID 416, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:10,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 624.0 (TID 416)
2019-06-11 09:30:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:10,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 624.0 (TID 416). 966 bytes result sent to driver
2019-06-11 09:30:10,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 624.0 (TID 416) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 624.0, whose tasks have all completed, from pool 
2019-06-11 09:30:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 624 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 208 finished: print at Transform.scala:36, took 0.005704 s
2019-06-11 09:30:10,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216610000 ms.0 from job set of time 1560216610000 ms
2019-06-11 09:30:10,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216610000 ms (execution: 0.038 s)
2019-06-11 09:30:10,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 722 from persistence list
2019-06-11 09:30:10,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 722
2019-06-11 09:30:10,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 717 from persistence list
2019-06-11 09:30:10,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 717
2019-06-11 09:30:10,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 716 from persistence list
2019-06-11 09:30:10,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 716
2019-06-11 09:30:10,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[716] at socketTextStream at Transform.scala:18 of time 1560216610000 ms
2019-06-11 09:30:10,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216600000 ms
2019-06-11 09:30:10,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216600000 ms
2019-06-11 09:30:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216615000 ms
2019-06-11 09:30:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216615000 ms.0 from job set of time 1560216615000 ms
2019-06-11 09:30:15,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 731 (map at Transform.scala:20)
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 209 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 627 (print at Transform.scala:36)
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 625, ShuffleMapStage 626)
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 625)
2019-06-11 09:30:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 625 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_313 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:15,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_313_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:15,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_313_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:15,013  INFO [org.apache.spark.SparkContext] - Created broadcast 313 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 625 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:15,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 625.0 with 2 tasks
2019-06-11 09:30:15,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 625.0 (TID 417, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:15,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 625.0 (TID 417)
2019-06-11 09:30:15,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 625.0 (TID 417). 810 bytes result sent to driver
2019-06-11 09:30:15,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 625.0 (TID 418, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:15,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 625.0 (TID 418)
2019-06-11 09:30:15,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 625.0 (TID 417) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:15,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 625.0 (TID 418). 810 bytes result sent to driver
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 625.0 (TID 418) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 625.0, whose tasks have all completed, from pool 
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 625 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 627)
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 627 (MapPartitionsRDD[736] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:15,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_314 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:15,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_314_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:15,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_314_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:15,040  INFO [org.apache.spark.SparkContext] - Created broadcast 314 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 627 (MapPartitionsRDD[736] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 627.0 with 1 tasks
2019-06-11 09:30:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 627.0 (TID 419, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:15,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 627.0 (TID 419)
2019-06-11 09:30:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:15,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 627.0 (TID 419). 966 bytes result sent to driver
2019-06-11 09:30:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 627.0 (TID 419) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 627.0, whose tasks have all completed, from pool 
2019-06-11 09:30:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 627 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 209 finished: print at Transform.scala:36, took 0.032319 s
2019-06-11 09:30:15,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:15,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 209 is 160 bytes
2019-06-11 09:30:15,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 208 is 83 bytes
2019-06-11 09:30:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 210 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 630 (print at Transform.scala:36)
2019-06-11 09:30:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 628, ShuffleMapStage 629)
2019-06-11 09:30:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 630 (MapPartitionsRDD[736] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:15,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_315 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:15,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_315_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:15,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_315_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:15,048  INFO [org.apache.spark.SparkContext] - Created broadcast 315 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:15,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 630 (MapPartitionsRDD[736] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:15,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 630.0 with 1 tasks
2019-06-11 09:30:15,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 630.0 (TID 420, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:15,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 630.0 (TID 420)
2019-06-11 09:30:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:15,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 630.0 (TID 420). 966 bytes result sent to driver
2019-06-11 09:30:15,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 630.0 (TID 420) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:15,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 630.0, whose tasks have all completed, from pool 
2019-06-11 09:30:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 630 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 210 finished: print at Transform.scala:36, took 0.006292 s
2019-06-11 09:30:15,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216615000 ms.0 from job set of time 1560216615000 ms
2019-06-11 09:30:15,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.051 s for time 1560216615000 ms (execution: 0.044 s)
2019-06-11 09:30:15,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 729 from persistence list
2019-06-11 09:30:15,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 729
2019-06-11 09:30:15,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 724 from persistence list
2019-06-11 09:30:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 724
2019-06-11 09:30:15,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 723 from persistence list
2019-06-11 09:30:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 723
2019-06-11 09:30:15,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[723] at socketTextStream at Transform.scala:18 of time 1560216615000 ms
2019-06-11 09:30:15,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216605000 ms
2019-06-11 09:30:15,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216605000 ms
2019-06-11 09:30:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216620000 ms
2019-06-11 09:30:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216620000 ms.0 from job set of time 1560216620000 ms
2019-06-11 09:30:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 738 (map at Transform.scala:20)
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 211 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 633 (print at Transform.scala:36)
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 631, ShuffleMapStage 632)
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 632)
2019-06-11 09:30:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 632 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_316 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_316_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_316_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 316 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 632 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:20,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 632.0 with 2 tasks
2019-06-11 09:30:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 632.0 (TID 421, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 632.0 (TID 421)
2019-06-11 09:30:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 632.0 (TID 421). 853 bytes result sent to driver
2019-06-11 09:30:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 632.0 (TID 422, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:20,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 632.0 (TID 422)
2019-06-11 09:30:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 632.0 (TID 421) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:20,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 632.0 (TID 422). 767 bytes result sent to driver
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 632.0 (TID 422) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 632.0, whose tasks have all completed, from pool 
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 632 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 633)
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 633 (MapPartitionsRDD[743] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_317 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_317_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:20,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_317_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:20,032  INFO [org.apache.spark.SparkContext] - Created broadcast 317 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 633 (MapPartitionsRDD[743] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 633.0 with 1 tasks
2019-06-11 09:30:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 633.0 (TID 423, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:20,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 633.0 (TID 423)
2019-06-11 09:30:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:20,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 633.0 (TID 423). 1009 bytes result sent to driver
2019-06-11 09:30:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 633.0 (TID 423) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 633.0, whose tasks have all completed, from pool 
2019-06-11 09:30:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 633 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 211 finished: print at Transform.scala:36, took 0.025967 s
2019-06-11 09:30:20,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:20,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 210 is 83 bytes
2019-06-11 09:30:20,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 211 is 160 bytes
2019-06-11 09:30:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 212 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 636 (print at Transform.scala:36)
2019-06-11 09:30:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 634, ShuffleMapStage 635)
2019-06-11 09:30:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 636 (MapPartitionsRDD[743] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:20,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_318 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_318_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:20,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_318_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:20,040  INFO [org.apache.spark.SparkContext] - Created broadcast 318 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 636 (MapPartitionsRDD[743] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 636.0 with 1 tasks
2019-06-11 09:30:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 636.0 (TID 424, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:20,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 636.0 (TID 424)
2019-06-11 09:30:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:20,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 636.0 (TID 424). 1009 bytes result sent to driver
2019-06-11 09:30:20,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 636.0 (TID 424) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:20,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 636.0, whose tasks have all completed, from pool 
2019-06-11 09:30:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 636 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 212 finished: print at Transform.scala:36, took 0.006508 s
2019-06-11 09:30:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216620000 ms.0 from job set of time 1560216620000 ms
2019-06-11 09:30:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216620000 ms (execution: 0.038 s)
2019-06-11 09:30:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 736 from persistence list
2019-06-11 09:30:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 736
2019-06-11 09:30:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 731 from persistence list
2019-06-11 09:30:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 731
2019-06-11 09:30:20,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 730 from persistence list
2019-06-11 09:30:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 730
2019-06-11 09:30:20,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[730] at socketTextStream at Transform.scala:18 of time 1560216620000 ms
2019-06-11 09:30:20,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216610000 ms
2019-06-11 09:30:20,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216610000 ms
2019-06-11 09:30:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216625000 ms
2019-06-11 09:30:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216625000 ms.0 from job set of time 1560216625000 ms
2019-06-11 09:30:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 745 (map at Transform.scala:20)
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 213 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 639 (print at Transform.scala:36)
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 637, ShuffleMapStage 638)
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 637)
2019-06-11 09:30:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 637 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_319 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_319_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_319_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 319 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 637 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 637.0 with 2 tasks
2019-06-11 09:30:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 637.0 (TID 425, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 637.0 (TID 425)
2019-06-11 09:30:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 637.0 (TID 425). 810 bytes result sent to driver
2019-06-11 09:30:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 637.0 (TID 426, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 637.0 (TID 426)
2019-06-11 09:30:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 637.0 (TID 425) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:25,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 637.0 (TID 426). 767 bytes result sent to driver
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 637.0 (TID 426) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 637.0, whose tasks have all completed, from pool 
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 637 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 639)
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 639 (MapPartitionsRDD[750] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_320 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_320_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_320_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:25,030  INFO [org.apache.spark.SparkContext] - Created broadcast 320 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 639 (MapPartitionsRDD[750] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 639.0 with 1 tasks
2019-06-11 09:30:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 639.0 (TID 427, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 639.0 (TID 427)
2019-06-11 09:30:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:30:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 639.0 (TID 427). 966 bytes result sent to driver
2019-06-11 09:30:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 639.0 (TID 427) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 639.0, whose tasks have all completed, from pool 
2019-06-11 09:30:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 639 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 213 finished: print at Transform.scala:36, took 0.024693 s
2019-06-11 09:30:25,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 213 is 160 bytes
2019-06-11 09:30:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 212 is 83 bytes
2019-06-11 09:30:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 214 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 642 (print at Transform.scala:36)
2019-06-11 09:30:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 640, ShuffleMapStage 641)
2019-06-11 09:30:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 642 (MapPartitionsRDD[750] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_321 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:25,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_321_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_321_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:25,038  INFO [org.apache.spark.SparkContext] - Created broadcast 321 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 642 (MapPartitionsRDD[750] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:25,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 642.0 with 1 tasks
2019-06-11 09:30:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 642.0 (TID 428, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:25,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 642.0 (TID 428)
2019-06-11 09:30:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:25,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 642.0 (TID 428). 1009 bytes result sent to driver
2019-06-11 09:30:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 642.0 (TID 428) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 642.0, whose tasks have all completed, from pool 
2019-06-11 09:30:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 642 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 214 finished: print at Transform.scala:36, took 0.005711 s
2019-06-11 09:30:25,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216625000 ms.0 from job set of time 1560216625000 ms
2019-06-11 09:30:25,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216625000 ms (execution: 0.035 s)
2019-06-11 09:30:25,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 743 from persistence list
2019-06-11 09:30:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 743
2019-06-11 09:30:25,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 738 from persistence list
2019-06-11 09:30:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 738
2019-06-11 09:30:25,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 737 from persistence list
2019-06-11 09:30:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 737
2019-06-11 09:30:25,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[737] at socketTextStream at Transform.scala:18 of time 1560216625000 ms
2019-06-11 09:30:25,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216615000 ms
2019-06-11 09:30:25,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216615000 ms
2019-06-11 09:30:30,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216630000 ms
2019-06-11 09:30:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216630000 ms.0 from job set of time 1560216630000 ms
2019-06-11 09:30:30,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 752 (map at Transform.scala:20)
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 215 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 645 (print at Transform.scala:36)
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 643, ShuffleMapStage 644)
2019-06-11 09:30:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 643)
2019-06-11 09:30:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 643 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:30,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_322 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_322_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:30,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_322_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,009  INFO [org.apache.spark.SparkContext] - Created broadcast 322 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 643 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:30,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 643.0 with 2 tasks
2019-06-11 09:30:30,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 643.0 (TID 429, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:30,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 643.0 (TID 429)
2019-06-11 09:30:30,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 643.0 (TID 429). 810 bytes result sent to driver
2019-06-11 09:30:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 643.0 (TID 430, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:30,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 643.0 (TID 430)
2019-06-11 09:30:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 643.0 (TID 429) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:30,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 643.0 (TID 430). 810 bytes result sent to driver
2019-06-11 09:30:30,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 643.0 (TID 430) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:30,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 643.0, whose tasks have all completed, from pool 
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 643 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 645)
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 645 (MapPartitionsRDD[757] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:30,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_323 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_323_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:30,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_323_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_313_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,043  INFO [org.apache.spark.SparkContext] - Created broadcast 323 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:30,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 645 (MapPartitionsRDD[757] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:30,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 645.0 with 1 tasks
2019-06-11 09:30:30,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 645.0 (TID 431, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:30,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 645.0 (TID 431)
2019-06-11 09:30:30,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_308_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 204
2019-06-11 09:30:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:30,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_312_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:30,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 206
2019-06-11 09:30:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 205
2019-06-11 09:30:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 200
2019-06-11 09:30:30,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_318_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 645.0 (TID 431). 1052 bytes result sent to driver
2019-06-11 09:30:30,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 645.0 (TID 431) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:30,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 645.0, whose tasks have all completed, from pool 
2019-06-11 09:30:30,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 645 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:30:30,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_307_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 215 finished: print at Transform.scala:36, took 0.041894 s
2019-06-11 09:30:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_315_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_316_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_317_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 203
2019-06-11 09:30:30,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 202
2019-06-11 09:30:30,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 209
2019-06-11 09:30:30,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_309_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 208
2019-06-11 09:30:30,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 207
2019-06-11 09:30:30,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_306_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,057  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:30,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_320_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 215 is 160 bytes
2019-06-11 09:30:30,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 214 is 83 bytes
2019-06-11 09:30:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 216 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:30,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_314_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 648 (print at Transform.scala:36)
2019-06-11 09:30:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 647, ShuffleMapStage 646)
2019-06-11 09:30:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 648 (MapPartitionsRDD[757] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:30,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_324 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:30,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_321_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_310_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_324_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:30,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 210
2019-06-11 09:30:30,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_324_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 211
2019-06-11 09:30:30,061  INFO [org.apache.spark.SparkContext] - Created broadcast 324 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:30,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 648 (MapPartitionsRDD[757] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:30,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 648.0 with 1 tasks
2019-06-11 09:30:30,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_311_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 648.0 (TID 432, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:30,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 648.0 (TID 432)
2019-06-11 09:30:30,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_304_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_305_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:30,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:30,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 201
2019-06-11 09:30:30,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_319_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:30,064  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 648.0 (TID 432). 1009 bytes result sent to driver
2019-06-11 09:30:30,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 648.0 (TID 432) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:30,065  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 648.0, whose tasks have all completed, from pool 
2019-06-11 09:30:30,065  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 648 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:30,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 216 finished: print at Transform.scala:36, took 0.007636 s
2019-06-11 09:30:30,065  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216630000 ms.0 from job set of time 1560216630000 ms
2019-06-11 09:30:30,065  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.065 s for time 1560216630000 ms (execution: 0.059 s)
2019-06-11 09:30:30,065  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 750 from persistence list
2019-06-11 09:30:30,065  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 750
2019-06-11 09:30:30,065  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 745 from persistence list
2019-06-11 09:30:30,065  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 745
2019-06-11 09:30:30,066  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 744 from persistence list
2019-06-11 09:30:30,066  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 744
2019-06-11 09:30:30,066  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[744] at socketTextStream at Transform.scala:18 of time 1560216630000 ms
2019-06-11 09:30:30,066  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216620000 ms
2019-06-11 09:30:30,066  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216620000 ms
2019-06-11 09:30:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216635000 ms
2019-06-11 09:30:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216635000 ms.0 from job set of time 1560216635000 ms
2019-06-11 09:30:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 759 (map at Transform.scala:20)
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 217 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 651 (print at Transform.scala:36)
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 649, ShuffleMapStage 650)
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 650)
2019-06-11 09:30:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 650 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_325 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_325_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:30:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_325_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 325 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 650 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 650.0 with 2 tasks
2019-06-11 09:30:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 650.0 (TID 433, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:35,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 650.0 (TID 433)
2019-06-11 09:30:35,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 650.0 (TID 433). 810 bytes result sent to driver
2019-06-11 09:30:35,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 650.0 (TID 434, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:35,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 650.0 (TID 434)
2019-06-11 09:30:35,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 650.0 (TID 433) in 15 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:35,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 650.0 (TID 434). 810 bytes result sent to driver
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 650.0 (TID 434) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 650.0, whose tasks have all completed, from pool 
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 650 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 651)
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 651 (MapPartitionsRDD[764] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:35,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_326 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:35,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_326_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:35,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_326_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:35,036  INFO [org.apache.spark.SparkContext] - Created broadcast 326 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 651 (MapPartitionsRDD[764] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:35,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 651.0 with 1 tasks
2019-06-11 09:30:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 651.0 (TID 435, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:35,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 651.0 (TID 435)
2019-06-11 09:30:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:30:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:35,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 651.0 (TID 435). 1009 bytes result sent to driver
2019-06-11 09:30:35,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 651.0 (TID 435) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:35,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 651.0, whose tasks have all completed, from pool 
2019-06-11 09:30:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 651 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 217 finished: print at Transform.scala:36, took 0.030809 s
2019-06-11 09:30:35,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:35,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 216 is 83 bytes
2019-06-11 09:30:35,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 217 is 160 bytes
2019-06-11 09:30:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 218 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 654 (print at Transform.scala:36)
2019-06-11 09:30:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 652, ShuffleMapStage 653)
2019-06-11 09:30:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 654 (MapPartitionsRDD[764] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:35,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_327 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:35,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_327_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:35,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_327_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:35,044  INFO [org.apache.spark.SparkContext] - Created broadcast 327 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:35,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 654 (MapPartitionsRDD[764] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:35,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 654.0 with 1 tasks
2019-06-11 09:30:35,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 654.0 (TID 436, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:35,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 654.0 (TID 436)
2019-06-11 09:30:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:35,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:35,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 654.0 (TID 436). 966 bytes result sent to driver
2019-06-11 09:30:35,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 654.0 (TID 436) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:35,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 654.0, whose tasks have all completed, from pool 
2019-06-11 09:30:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 654 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 218 finished: print at Transform.scala:36, took 0.004587 s
2019-06-11 09:30:35,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216635000 ms.0 from job set of time 1560216635000 ms
2019-06-11 09:30:35,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216635000 ms (execution: 0.040 s)
2019-06-11 09:30:35,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 757 from persistence list
2019-06-11 09:30:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 757
2019-06-11 09:30:35,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 752 from persistence list
2019-06-11 09:30:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 752
2019-06-11 09:30:35,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 751 from persistence list
2019-06-11 09:30:35,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 751
2019-06-11 09:30:35,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[751] at socketTextStream at Transform.scala:18 of time 1560216635000 ms
2019-06-11 09:30:35,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216625000 ms
2019-06-11 09:30:35,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216625000 ms
2019-06-11 09:30:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216640000 ms
2019-06-11 09:30:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216640000 ms.0 from job set of time 1560216640000 ms
2019-06-11 09:30:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 766 (map at Transform.scala:20)
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 219 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 657 (print at Transform.scala:36)
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 655, ShuffleMapStage 656)
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 656)
2019-06-11 09:30:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 656 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_328 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_328_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:30:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_328_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 328 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 656 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 656.0 with 2 tasks
2019-06-11 09:30:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 656.0 (TID 437, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 656.0 (TID 437)
2019-06-11 09:30:40,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 656.0 (TID 437). 853 bytes result sent to driver
2019-06-11 09:30:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 656.0 (TID 438, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 656.0 (TID 438)
2019-06-11 09:30:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 656.0 (TID 437) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:40,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 656.0 (TID 438). 810 bytes result sent to driver
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 656.0 (TID 438) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 656.0, whose tasks have all completed, from pool 
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 656 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 657)
2019-06-11 09:30:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 657 (MapPartitionsRDD[771] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_329 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:40,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_329_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:40,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_329_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:40,030  INFO [org.apache.spark.SparkContext] - Created broadcast 329 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 657 (MapPartitionsRDD[771] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 657.0 with 1 tasks
2019-06-11 09:30:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 657.0 (TID 439, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:40,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 657.0 (TID 439)
2019-06-11 09:30:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 657.0 (TID 439). 966 bytes result sent to driver
2019-06-11 09:30:40,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 657.0 (TID 439) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:40,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 657.0, whose tasks have all completed, from pool 
2019-06-11 09:30:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 657 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 219 finished: print at Transform.scala:36, took 0.024863 s
2019-06-11 09:30:40,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:40,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 218 is 83 bytes
2019-06-11 09:30:40,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 219 is 160 bytes
2019-06-11 09:30:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 220 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 660 (print at Transform.scala:36)
2019-06-11 09:30:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 658, ShuffleMapStage 659)
2019-06-11 09:30:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 660 (MapPartitionsRDD[771] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_330 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:30:40,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_330_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:30:40,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_330_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:40,039  INFO [org.apache.spark.SparkContext] - Created broadcast 330 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 660 (MapPartitionsRDD[771] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 660.0 with 1 tasks
2019-06-11 09:30:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 660.0 (TID 440, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:40,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 660.0 (TID 440)
2019-06-11 09:30:40,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:40,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:40,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:40,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:40,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 660.0 (TID 440). 966 bytes result sent to driver
2019-06-11 09:30:40,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 660.0 (TID 440) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:40,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 660.0, whose tasks have all completed, from pool 
2019-06-11 09:30:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 660 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 220 finished: print at Transform.scala:36, took 0.006372 s
2019-06-11 09:30:40,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216640000 ms.0 from job set of time 1560216640000 ms
2019-06-11 09:30:40,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216640000 ms (execution: 0.036 s)
2019-06-11 09:30:40,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 764 from persistence list
2019-06-11 09:30:40,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 764
2019-06-11 09:30:40,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 759 from persistence list
2019-06-11 09:30:40,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 759
2019-06-11 09:30:40,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 758 from persistence list
2019-06-11 09:30:40,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 758
2019-06-11 09:30:40,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[758] at socketTextStream at Transform.scala:18 of time 1560216640000 ms
2019-06-11 09:30:40,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216630000 ms
2019-06-11 09:30:40,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216630000 ms
2019-06-11 09:30:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216645000 ms
2019-06-11 09:30:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216645000 ms.0 from job set of time 1560216645000 ms
2019-06-11 09:30:45,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 773 (map at Transform.scala:20)
2019-06-11 09:30:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 221 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 663 (print at Transform.scala:36)
2019-06-11 09:30:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 661, ShuffleMapStage 662)
2019-06-11 09:30:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 661)
2019-06-11 09:30:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 661 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:45,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_331 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_331_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:45,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_331_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:45,009  INFO [org.apache.spark.SparkContext] - Created broadcast 331 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 661 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:45,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 661.0 with 2 tasks
2019-06-11 09:30:45,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 661.0 (TID 441, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:45,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 661.0 (TID 441)
2019-06-11 09:30:45,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 661.0 (TID 441). 810 bytes result sent to driver
2019-06-11 09:30:45,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 661.0 (TID 442, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:45,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 661.0 (TID 442)
2019-06-11 09:30:45,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 661.0 (TID 441) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:45,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 661.0 (TID 442). 767 bytes result sent to driver
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 661.0 (TID 442) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 661.0, whose tasks have all completed, from pool 
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 661 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 663)
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 663 (MapPartitionsRDD[778] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:45,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_332 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:45,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_332_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:45,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_332_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:45,029  INFO [org.apache.spark.SparkContext] - Created broadcast 332 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 663 (MapPartitionsRDD[778] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:45,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 663.0 with 1 tasks
2019-06-11 09:30:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 663.0 (TID 443, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:45,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 663.0 (TID 443)
2019-06-11 09:30:45,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:45,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:45,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:45,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:45,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 663.0 (TID 443). 1009 bytes result sent to driver
2019-06-11 09:30:45,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 663.0 (TID 443) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:45,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 663.0, whose tasks have all completed, from pool 
2019-06-11 09:30:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 663 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 221 finished: print at Transform.scala:36, took 0.024365 s
2019-06-11 09:30:45,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:45,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 221 is 160 bytes
2019-06-11 09:30:45,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 220 is 83 bytes
2019-06-11 09:30:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 222 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 666 (print at Transform.scala:36)
2019-06-11 09:30:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 665, ShuffleMapStage 664)
2019-06-11 09:30:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 666 (MapPartitionsRDD[778] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_333 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_333_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:45,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_333_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:45,036  INFO [org.apache.spark.SparkContext] - Created broadcast 333 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 666 (MapPartitionsRDD[778] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:45,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 666.0 with 1 tasks
2019-06-11 09:30:45,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 666.0 (TID 444, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:45,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 666.0 (TID 444)
2019-06-11 09:30:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:45,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 666.0 (TID 444). 1009 bytes result sent to driver
2019-06-11 09:30:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 666.0 (TID 444) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 666.0, whose tasks have all completed, from pool 
2019-06-11 09:30:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 666 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 222 finished: print at Transform.scala:36, took 0.005556 s
2019-06-11 09:30:45,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216645000 ms.0 from job set of time 1560216645000 ms
2019-06-11 09:30:45,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216645000 ms (execution: 0.034 s)
2019-06-11 09:30:45,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 771 from persistence list
2019-06-11 09:30:45,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 771
2019-06-11 09:30:45,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 766 from persistence list
2019-06-11 09:30:45,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 766
2019-06-11 09:30:45,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 765 from persistence list
2019-06-11 09:30:45,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 765
2019-06-11 09:30:45,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[765] at socketTextStream at Transform.scala:18 of time 1560216645000 ms
2019-06-11 09:30:45,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216635000 ms
2019-06-11 09:30:45,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216635000 ms
2019-06-11 09:30:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216650000 ms
2019-06-11 09:30:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216650000 ms.0 from job set of time 1560216650000 ms
2019-06-11 09:30:50,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 780 (map at Transform.scala:20)
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 223 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 669 (print at Transform.scala:36)
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 667, ShuffleMapStage 668)
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 668)
2019-06-11 09:30:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 668 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_334 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_334_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_334_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:50,011  INFO [org.apache.spark.SparkContext] - Created broadcast 334 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 668 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:50,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 668.0 with 2 tasks
2019-06-11 09:30:50,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 668.0 (TID 445, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:50,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 668.0 (TID 445)
2019-06-11 09:30:50,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 668.0 (TID 445). 810 bytes result sent to driver
2019-06-11 09:30:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 668.0 (TID 446, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:50,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 668.0 (TID 446)
2019-06-11 09:30:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 668.0 (TID 445) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:50,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 668.0 (TID 446). 767 bytes result sent to driver
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 668.0 (TID 446) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 668.0, whose tasks have all completed, from pool 
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 668 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 669)
2019-06-11 09:30:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 669 (MapPartitionsRDD[785] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_335 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:50,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_335_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:50,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_335_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:50,030  INFO [org.apache.spark.SparkContext] - Created broadcast 335 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 669 (MapPartitionsRDD[785] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 669.0 with 1 tasks
2019-06-11 09:30:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 669.0 (TID 447, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:50,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 669.0 (TID 447)
2019-06-11 09:30:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:50,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 669.0 (TID 447). 966 bytes result sent to driver
2019-06-11 09:30:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 669.0 (TID 447) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:50,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 669.0, whose tasks have all completed, from pool 
2019-06-11 09:30:50,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 669 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:50,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 223 finished: print at Transform.scala:36, took 0.024235 s
2019-06-11 09:30:50,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 222 is 83 bytes
2019-06-11 09:30:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 223 is 160 bytes
2019-06-11 09:30:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 224 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 672 (print at Transform.scala:36)
2019-06-11 09:30:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 670, ShuffleMapStage 671)
2019-06-11 09:30:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 672 (MapPartitionsRDD[785] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:50,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_336 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:50,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_336_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:50,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_336_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:50,038  INFO [org.apache.spark.SparkContext] - Created broadcast 336 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 672 (MapPartitionsRDD[785] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:50,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 672.0 with 1 tasks
2019-06-11 09:30:50,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 672.0 (TID 448, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:50,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 672.0 (TID 448)
2019-06-11 09:30:50,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:50,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:50,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:50,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:50,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 672.0 (TID 448). 966 bytes result sent to driver
2019-06-11 09:30:50,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 672.0 (TID 448) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:50,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 672.0, whose tasks have all completed, from pool 
2019-06-11 09:30:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 672 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 224 finished: print at Transform.scala:36, took 0.005163 s
2019-06-11 09:30:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216650000 ms.0 from job set of time 1560216650000 ms
2019-06-11 09:30:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216650000 ms (execution: 0.034 s)
2019-06-11 09:30:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 778 from persistence list
2019-06-11 09:30:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 778
2019-06-11 09:30:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 773 from persistence list
2019-06-11 09:30:50,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 773
2019-06-11 09:30:50,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 772 from persistence list
2019-06-11 09:30:50,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 772
2019-06-11 09:30:50,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[772] at socketTextStream at Transform.scala:18 of time 1560216650000 ms
2019-06-11 09:30:50,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216640000 ms
2019-06-11 09:30:50,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216640000 ms
2019-06-11 09:30:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216655000 ms
2019-06-11 09:30:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216655000 ms.0 from job set of time 1560216655000 ms
2019-06-11 09:30:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 787 (map at Transform.scala:20)
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 225 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 675 (print at Transform.scala:36)
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 673, ShuffleMapStage 674)
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 674)
2019-06-11 09:30:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 674 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:30:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_337 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_337_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:30:55,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_337_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:30:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 337 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:55,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 674 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:30:55,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 674.0 with 2 tasks
2019-06-11 09:30:55,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 674.0 (TID 449, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 674.0 (TID 449)
2019-06-11 09:30:55,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 674.0 (TID 449). 810 bytes result sent to driver
2019-06-11 09:30:55,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 674.0 (TID 450, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:30:55,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 674.0 (TID 450)
2019-06-11 09:30:55,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 674.0 (TID 449) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:30:55,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 674.0 (TID 450). 810 bytes result sent to driver
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 674.0 (TID 450) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 674.0, whose tasks have all completed, from pool 
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 674 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 675)
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:30:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 675 (MapPartitionsRDD[792] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:55,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_338 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:55,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_338_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:55,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_338_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:55,031  INFO [org.apache.spark.SparkContext] - Created broadcast 338 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 675 (MapPartitionsRDD[792] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:30:55,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 675.0 with 1 tasks
2019-06-11 09:30:55,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 675.0 (TID 451, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:55,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 675.0 (TID 451)
2019-06-11 09:30:55,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:55,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:30:55,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 675.0 (TID 451). 966 bytes result sent to driver
2019-06-11 09:30:55,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 675.0 (TID 451) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:55,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 675.0, whose tasks have all completed, from pool 
2019-06-11 09:30:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 675 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:30:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 225 finished: print at Transform.scala:36, took 0.026232 s
2019-06-11 09:30:55,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:30:55,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 224 is 83 bytes
2019-06-11 09:30:55,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 225 is 160 bytes
2019-06-11 09:30:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 226 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:30:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 678 (print at Transform.scala:36)
2019-06-11 09:30:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 676, ShuffleMapStage 677)
2019-06-11 09:30:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:30:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 678 (MapPartitionsRDD[792] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:30:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_339 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:30:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_339_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:30:55,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_339_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:30:55,039  INFO [org.apache.spark.SparkContext] - Created broadcast 339 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:30:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 678 (MapPartitionsRDD[792] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:30:55,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 678.0 with 1 tasks
2019-06-11 09:30:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 678.0 (TID 452, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:30:55,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 678.0 (TID 452)
2019-06-11 09:30:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:30:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:30:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:30:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:30:55,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 678.0 (TID 452). 966 bytes result sent to driver
2019-06-11 09:30:55,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 678.0 (TID 452) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:30:55,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 678.0, whose tasks have all completed, from pool 
2019-06-11 09:30:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 678 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:30:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 226 finished: print at Transform.scala:36, took 0.004931 s
2019-06-11 09:30:55,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216655000 ms.0 from job set of time 1560216655000 ms
2019-06-11 09:30:55,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216655000 ms (execution: 0.037 s)
2019-06-11 09:30:55,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 785 from persistence list
2019-06-11 09:30:55,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 785
2019-06-11 09:30:55,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 780 from persistence list
2019-06-11 09:30:55,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 780
2019-06-11 09:30:55,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 779 from persistence list
2019-06-11 09:30:55,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 779
2019-06-11 09:30:55,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[779] at socketTextStream at Transform.scala:18 of time 1560216655000 ms
2019-06-11 09:30:55,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216645000 ms
2019-06-11 09:30:55,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216645000 ms
2019-06-11 09:31:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216660000 ms
2019-06-11 09:31:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216660000 ms.0 from job set of time 1560216660000 ms
2019-06-11 09:31:00,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 794 (map at Transform.scala:20)
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 227 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 681 (print at Transform.scala:36)
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 679, ShuffleMapStage 680)
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 679)
2019-06-11 09:31:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 679 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_340 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:00,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_340_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:00,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_340_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,014  INFO [org.apache.spark.SparkContext] - Created broadcast 340 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 679 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:00,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 679.0 with 2 tasks
2019-06-11 09:31:00,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 679.0 (TID 453, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:00,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 679.0 (TID 453)
2019-06-11 09:31:00,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 679.0 (TID 453). 853 bytes result sent to driver
2019-06-11 09:31:00,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 679.0 (TID 454, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:00,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 679.0 (TID 454)
2019-06-11 09:31:00,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 679.0 (TID 453) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:00,038  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 679.0 (TID 454). 767 bytes result sent to driver
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 679.0 (TID 454) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 679.0, whose tasks have all completed, from pool 
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 679 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 681)
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 681 (MapPartitionsRDD[799] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:00,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_341 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:00,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_341_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:00,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 212
2019-06-11 09:31:00,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_341_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,049  INFO [org.apache.spark.SparkContext] - Created broadcast 341 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:00,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_333_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 681 (MapPartitionsRDD[799] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:00,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 681.0 with 1 tasks
2019-06-11 09:31:00,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 218
2019-06-11 09:31:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 681.0 (TID 455, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:00,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 681.0 (TID 455)
2019-06-11 09:31:00,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_326_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 216
2019-06-11 09:31:00,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_327_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:31:00,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_336_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 681.0 (TID 455). 966 bytes result sent to driver
2019-06-11 09:31:00,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 681.0 (TID 455) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:00,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_324_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 681.0, whose tasks have all completed, from pool 
2019-06-11 09:31:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 681 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 227 finished: print at Transform.scala:36, took 0.041054 s
2019-06-11 09:31:00,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_322_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_337_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_331_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 223
2019-06-11 09:31:00,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 217
2019-06-11 09:31:00,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 219
2019-06-11 09:31:00,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 214
2019-06-11 09:31:00,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 222
2019-06-11 09:31:00,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_335_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 215
2019-06-11 09:31:00,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 221
2019-06-11 09:31:00,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_329_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,058  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:00,059  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 227 is 160 bytes
2019-06-11 09:31:00,059  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 226 is 83 bytes
2019-06-11 09:31:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 228 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 684 (print at Transform.scala:36)
2019-06-11 09:31:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 682, ShuffleMapStage 683)
2019-06-11 09:31:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 684 (MapPartitionsRDD[799] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:00,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_342 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:00,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_342_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:00,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_342_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,062  INFO [org.apache.spark.SparkContext] - Created broadcast 342 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:00,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_334_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 684 (MapPartitionsRDD[799] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:00,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 684.0 with 1 tasks
2019-06-11 09:31:00,063  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 684.0 (TID 456, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:00,063  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 684.0 (TID 456)
2019-06-11 09:31:00,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_338_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,064  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 213
2019-06-11 09:31:00,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_328_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:00,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:00,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_339_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:00,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:00,066  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 220
2019-06-11 09:31:00,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_323_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,067  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 684.0 (TID 456). 1009 bytes result sent to driver
2019-06-11 09:31:00,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_330_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:00,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 684.0 (TID 456) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:00,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 684.0, whose tasks have all completed, from pool 
2019-06-11 09:31:00,067  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 684 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:31:00,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 228 finished: print at Transform.scala:36, took 0.008685 s
2019-06-11 09:31:00,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_325_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:00,067  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216660000 ms.0 from job set of time 1560216660000 ms
2019-06-11 09:31:00,068  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.067 s for time 1560216660000 ms (execution: 0.058 s)
2019-06-11 09:31:00,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 792 from persistence list
2019-06-11 09:31:00,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 792
2019-06-11 09:31:00,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 787 from persistence list
2019-06-11 09:31:00,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 787
2019-06-11 09:31:00,068  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 786 from persistence list
2019-06-11 09:31:00,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 786
2019-06-11 09:31:00,068  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[786] at socketTextStream at Transform.scala:18 of time 1560216660000 ms
2019-06-11 09:31:00,068  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216650000 ms
2019-06-11 09:31:00,068  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216650000 ms
2019-06-11 09:31:00,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_332_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216665000 ms
2019-06-11 09:31:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216665000 ms.0 from job set of time 1560216665000 ms
2019-06-11 09:31:05,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 801 (map at Transform.scala:20)
2019-06-11 09:31:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 229 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 687 (print at Transform.scala:36)
2019-06-11 09:31:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 685, ShuffleMapStage 686)
2019-06-11 09:31:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 686)
2019-06-11 09:31:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 686 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_343 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:05,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_343_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:31:05,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_343_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:05,010  INFO [org.apache.spark.SparkContext] - Created broadcast 343 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 686 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:05,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 686.0 with 2 tasks
2019-06-11 09:31:05,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 686.0 (TID 457, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:05,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 686.0 (TID 457)
2019-06-11 09:31:05,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 686.0 (TID 457). 810 bytes result sent to driver
2019-06-11 09:31:05,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 686.0 (TID 458, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:05,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 686.0 (TID 458)
2019-06-11 09:31:05,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 686.0 (TID 457) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:05,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 686.0 (TID 458). 810 bytes result sent to driver
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 686.0 (TID 458) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 686.0, whose tasks have all completed, from pool 
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 686 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 687)
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 687 (MapPartitionsRDD[806] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_344 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:05,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_344_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:05,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_344_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:05,030  INFO [org.apache.spark.SparkContext] - Created broadcast 344 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:05,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 687 (MapPartitionsRDD[806] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:05,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 687.0 with 1 tasks
2019-06-11 09:31:05,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 687.0 (TID 459, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:05,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 687.0 (TID 459)
2019-06-11 09:31:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:05,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 687.0 (TID 459). 966 bytes result sent to driver
2019-06-11 09:31:05,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 687.0 (TID 459) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:05,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 687.0, whose tasks have all completed, from pool 
2019-06-11 09:31:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 687 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 229 finished: print at Transform.scala:36, took 0.024379 s
2019-06-11 09:31:05,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 228 is 83 bytes
2019-06-11 09:31:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 229 is 160 bytes
2019-06-11 09:31:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 230 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 690 (print at Transform.scala:36)
2019-06-11 09:31:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 688, ShuffleMapStage 689)
2019-06-11 09:31:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 690 (MapPartitionsRDD[806] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_345 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_345_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_345_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:05,037  INFO [org.apache.spark.SparkContext] - Created broadcast 345 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:05,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 690 (MapPartitionsRDD[806] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 690.0 with 1 tasks
2019-06-11 09:31:05,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 690.0 (TID 460, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:05,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 690.0 (TID 460)
2019-06-11 09:31:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:31:05,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 690.0 (TID 460). 966 bytes result sent to driver
2019-06-11 09:31:05,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 690.0 (TID 460) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:05,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 690.0, whose tasks have all completed, from pool 
2019-06-11 09:31:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 690 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 230 finished: print at Transform.scala:36, took 0.005659 s
2019-06-11 09:31:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216665000 ms.0 from job set of time 1560216665000 ms
2019-06-11 09:31:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216665000 ms (execution: 0.034 s)
2019-06-11 09:31:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 799 from persistence list
2019-06-11 09:31:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 799
2019-06-11 09:31:05,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 794 from persistence list
2019-06-11 09:31:05,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 794
2019-06-11 09:31:05,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 793 from persistence list
2019-06-11 09:31:05,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 793
2019-06-11 09:31:05,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[793] at socketTextStream at Transform.scala:18 of time 1560216665000 ms
2019-06-11 09:31:05,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216655000 ms
2019-06-11 09:31:05,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216655000 ms
2019-06-11 09:31:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216670000 ms
2019-06-11 09:31:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216670000 ms.0 from job set of time 1560216670000 ms
2019-06-11 09:31:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 808 (map at Transform.scala:20)
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 231 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 693 (print at Transform.scala:36)
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 691, ShuffleMapStage 692)
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 691)
2019-06-11 09:31:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 691 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_346 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_346_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:31:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_346_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:10,010  INFO [org.apache.spark.SparkContext] - Created broadcast 346 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 691 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:10,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 691.0 with 2 tasks
2019-06-11 09:31:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 691.0 (TID 461, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 691.0 (TID 461)
2019-06-11 09:31:10,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 691.0 (TID 461). 810 bytes result sent to driver
2019-06-11 09:31:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 691.0 (TID 462, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:10,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 691.0 (TID 462)
2019-06-11 09:31:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 691.0 (TID 461) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:10,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 691.0 (TID 462). 767 bytes result sent to driver
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 691.0 (TID 462) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 691.0, whose tasks have all completed, from pool 
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 691 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 693)
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 693 (MapPartitionsRDD[813] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:10,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_347 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:10,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_347_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:10,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_347_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:10,032  INFO [org.apache.spark.SparkContext] - Created broadcast 347 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 693 (MapPartitionsRDD[813] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:10,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 693.0 with 1 tasks
2019-06-11 09:31:10,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 693.0 (TID 463, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:10,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 693.0 (TID 463)
2019-06-11 09:31:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:10,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 693.0 (TID 463). 966 bytes result sent to driver
2019-06-11 09:31:10,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 693.0 (TID 463) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:10,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 693.0, whose tasks have all completed, from pool 
2019-06-11 09:31:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 693 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 231 finished: print at Transform.scala:36, took 0.026104 s
2019-06-11 09:31:10,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:10,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 231 is 160 bytes
2019-06-11 09:31:10,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 230 is 83 bytes
2019-06-11 09:31:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 232 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 696 (print at Transform.scala:36)
2019-06-11 09:31:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 694, ShuffleMapStage 695)
2019-06-11 09:31:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 696 (MapPartitionsRDD[813] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_348 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:10,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_348_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:10,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_348_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:10,039  INFO [org.apache.spark.SparkContext] - Created broadcast 348 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 696 (MapPartitionsRDD[813] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:10,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 696.0 with 1 tasks
2019-06-11 09:31:10,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 696.0 (TID 464, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:10,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 696.0 (TID 464)
2019-06-11 09:31:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:10,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 696.0 (TID 464). 966 bytes result sent to driver
2019-06-11 09:31:10,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 696.0 (TID 464) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 696.0, whose tasks have all completed, from pool 
2019-06-11 09:31:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 696 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 232 finished: print at Transform.scala:36, took 0.004792 s
2019-06-11 09:31:10,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216670000 ms.0 from job set of time 1560216670000 ms
2019-06-11 09:31:10,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216670000 ms (execution: 0.036 s)
2019-06-11 09:31:10,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 806 from persistence list
2019-06-11 09:31:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 806
2019-06-11 09:31:10,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 801 from persistence list
2019-06-11 09:31:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 801
2019-06-11 09:31:10,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 800 from persistence list
2019-06-11 09:31:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 800
2019-06-11 09:31:10,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[800] at socketTextStream at Transform.scala:18 of time 1560216670000 ms
2019-06-11 09:31:10,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216660000 ms
2019-06-11 09:31:10,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216660000 ms
2019-06-11 09:31:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216675000 ms
2019-06-11 09:31:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216675000 ms.0 from job set of time 1560216675000 ms
2019-06-11 09:31:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 815 (map at Transform.scala:20)
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 233 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 699 (print at Transform.scala:36)
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 698, ShuffleMapStage 697)
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 697)
2019-06-11 09:31:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 697 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_349 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_349_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_349_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:15,011  INFO [org.apache.spark.SparkContext] - Created broadcast 349 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 697 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:15,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 697.0 with 2 tasks
2019-06-11 09:31:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 697.0 (TID 465, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 697.0 (TID 465)
2019-06-11 09:31:15,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 697.0 (TID 465). 810 bytes result sent to driver
2019-06-11 09:31:15,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 697.0 (TID 466, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:15,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 697.0 (TID 466)
2019-06-11 09:31:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 697.0 (TID 465) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:15,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 697.0 (TID 466). 810 bytes result sent to driver
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 697.0 (TID 466) in 15 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 697.0, whose tasks have all completed, from pool 
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 697 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 699)
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 699 (MapPartitionsRDD[820] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_350 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_350_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:15,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_350_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:15,037  INFO [org.apache.spark.SparkContext] - Created broadcast 350 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 699 (MapPartitionsRDD[820] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 699.0 with 1 tasks
2019-06-11 09:31:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 699.0 (TID 467, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:15,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 699.0 (TID 467)
2019-06-11 09:31:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 699.0 (TID 467). 1009 bytes result sent to driver
2019-06-11 09:31:15,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 699.0 (TID 467) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:15,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 699.0, whose tasks have all completed, from pool 
2019-06-11 09:31:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 699 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:31:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 233 finished: print at Transform.scala:36, took 0.032759 s
2019-06-11 09:31:15,044  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:15,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 233 is 160 bytes
2019-06-11 09:31:15,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 232 is 83 bytes
2019-06-11 09:31:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 234 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 702 (print at Transform.scala:36)
2019-06-11 09:31:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 700, ShuffleMapStage 701)
2019-06-11 09:31:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 702 (MapPartitionsRDD[820] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:15,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_351 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:15,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_351_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:15,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_351_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:15,047  INFO [org.apache.spark.SparkContext] - Created broadcast 351 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 702 (MapPartitionsRDD[820] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:15,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 702.0 with 1 tasks
2019-06-11 09:31:15,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 702.0 (TID 468, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:15,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 702.0 (TID 468)
2019-06-11 09:31:15,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:15,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:15,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:15,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 702.0 (TID 468). 966 bytes result sent to driver
2019-06-11 09:31:15,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 702.0 (TID 468) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:15,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 702.0, whose tasks have all completed, from pool 
2019-06-11 09:31:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 702 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 234 finished: print at Transform.scala:36, took 0.006388 s
2019-06-11 09:31:15,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216675000 ms.0 from job set of time 1560216675000 ms
2019-06-11 09:31:15,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216675000 ms (execution: 0.044 s)
2019-06-11 09:31:15,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 813 from persistence list
2019-06-11 09:31:15,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 813
2019-06-11 09:31:15,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 808 from persistence list
2019-06-11 09:31:15,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 808
2019-06-11 09:31:15,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 807 from persistence list
2019-06-11 09:31:15,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 807
2019-06-11 09:31:15,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[807] at socketTextStream at Transform.scala:18 of time 1560216675000 ms
2019-06-11 09:31:15,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216665000 ms
2019-06-11 09:31:15,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216665000 ms
2019-06-11 09:31:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216680000 ms
2019-06-11 09:31:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216680000 ms.0 from job set of time 1560216680000 ms
2019-06-11 09:31:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 822 (map at Transform.scala:20)
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 235 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 705 (print at Transform.scala:36)
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 703, ShuffleMapStage 704)
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 703)
2019-06-11 09:31:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 703 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_352 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_352_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_352_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 352 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 703 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 703.0 with 2 tasks
2019-06-11 09:31:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 703.0 (TID 469, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 703.0 (TID 469)
2019-06-11 09:31:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 703.0 (TID 469). 810 bytes result sent to driver
2019-06-11 09:31:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 703.0 (TID 470, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:20,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 703.0 (TID 470)
2019-06-11 09:31:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 703.0 (TID 469) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 703.0 (TID 470). 810 bytes result sent to driver
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 703.0 (TID 470) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 703.0, whose tasks have all completed, from pool 
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 703 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 705)
2019-06-11 09:31:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 705 (MapPartitionsRDD[827] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:20,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_353 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:20,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_353_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:20,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_353_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:20,035  INFO [org.apache.spark.SparkContext] - Created broadcast 353 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 705 (MapPartitionsRDD[827] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 705.0 with 1 tasks
2019-06-11 09:31:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 705.0 (TID 471, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:20,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 705.0 (TID 471)
2019-06-11 09:31:20,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:20,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:20,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:20,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:20,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 705.0 (TID 471). 966 bytes result sent to driver
2019-06-11 09:31:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 705.0 (TID 471) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 705.0, whose tasks have all completed, from pool 
2019-06-11 09:31:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 705 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 235 finished: print at Transform.scala:36, took 0.029011 s
2019-06-11 09:31:20,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:20,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 235 is 160 bytes
2019-06-11 09:31:20,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 234 is 83 bytes
2019-06-11 09:31:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 236 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 708 (print at Transform.scala:36)
2019-06-11 09:31:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 706, ShuffleMapStage 707)
2019-06-11 09:31:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 708 (MapPartitionsRDD[827] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_354 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_354_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:20,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_354_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:20,042  INFO [org.apache.spark.SparkContext] - Created broadcast 354 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 708 (MapPartitionsRDD[827] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 708.0 with 1 tasks
2019-06-11 09:31:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 708.0 (TID 472, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:20,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 708.0 (TID 472)
2019-06-11 09:31:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:20,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 708.0 (TID 472). 1009 bytes result sent to driver
2019-06-11 09:31:20,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 708.0 (TID 472) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:20,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 708.0, whose tasks have all completed, from pool 
2019-06-11 09:31:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 708 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 236 finished: print at Transform.scala:36, took 0.005067 s
2019-06-11 09:31:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216680000 ms.0 from job set of time 1560216680000 ms
2019-06-11 09:31:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560216680000 ms (execution: 0.038 s)
2019-06-11 09:31:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 820 from persistence list
2019-06-11 09:31:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 820
2019-06-11 09:31:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 815 from persistence list
2019-06-11 09:31:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 815
2019-06-11 09:31:20,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 814 from persistence list
2019-06-11 09:31:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 814
2019-06-11 09:31:20,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[814] at socketTextStream at Transform.scala:18 of time 1560216680000 ms
2019-06-11 09:31:20,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216670000 ms
2019-06-11 09:31:20,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216670000 ms
2019-06-11 09:31:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216685000 ms
2019-06-11 09:31:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216685000 ms.0 from job set of time 1560216685000 ms
2019-06-11 09:31:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 829 (map at Transform.scala:20)
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 237 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 711 (print at Transform.scala:36)
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 709, ShuffleMapStage 710)
2019-06-11 09:31:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 709)
2019-06-11 09:31:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 709 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_355 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_355_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_355_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 355 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 709 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 709.0 with 2 tasks
2019-06-11 09:31:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 709.0 (TID 473, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 709.0 (TID 473)
2019-06-11 09:31:25,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 709.0 (TID 473). 767 bytes result sent to driver
2019-06-11 09:31:25,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 709.0 (TID 474, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:25,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 709.0 (TID 474)
2019-06-11 09:31:25,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 709.0 (TID 473) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:25,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 709.0 (TID 474). 810 bytes result sent to driver
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 709.0 (TID 474) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 709.0, whose tasks have all completed, from pool 
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 709 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 711)
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 711 (MapPartitionsRDD[834] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:25,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_356 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_356_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_356_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:25,037  INFO [org.apache.spark.SparkContext] - Created broadcast 356 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 711 (MapPartitionsRDD[834] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:25,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 711.0 with 1 tasks
2019-06-11 09:31:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 711.0 (TID 475, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:25,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 711.0 (TID 475)
2019-06-11 09:31:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:25,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 711.0 (TID 475). 1009 bytes result sent to driver
2019-06-11 09:31:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 711.0 (TID 475) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 711.0, whose tasks have all completed, from pool 
2019-06-11 09:31:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 711 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 237 finished: print at Transform.scala:36, took 0.031879 s
2019-06-11 09:31:25,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:25,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 237 is 160 bytes
2019-06-11 09:31:25,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 236 is 83 bytes
2019-06-11 09:31:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 238 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 714 (print at Transform.scala:36)
2019-06-11 09:31:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 712, ShuffleMapStage 713)
2019-06-11 09:31:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 714 (MapPartitionsRDD[834] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:25,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_357 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:25,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_357_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:25,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_357_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:25,045  INFO [org.apache.spark.SparkContext] - Created broadcast 357 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 714 (MapPartitionsRDD[834] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:25,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 714.0 with 1 tasks
2019-06-11 09:31:25,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 714.0 (TID 476, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:25,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 714.0 (TID 476)
2019-06-11 09:31:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:25,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 714.0 (TID 476). 1009 bytes result sent to driver
2019-06-11 09:31:25,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 714.0 (TID 476) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:25,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 714.0, whose tasks have all completed, from pool 
2019-06-11 09:31:25,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 714 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:25,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 238 finished: print at Transform.scala:36, took 0.006534 s
2019-06-11 09:31:25,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216685000 ms.0 from job set of time 1560216685000 ms
2019-06-11 09:31:25,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216685000 ms (execution: 0.044 s)
2019-06-11 09:31:25,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 827 from persistence list
2019-06-11 09:31:25,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 827
2019-06-11 09:31:25,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 822 from persistence list
2019-06-11 09:31:25,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 822
2019-06-11 09:31:25,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 821 from persistence list
2019-06-11 09:31:25,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 821
2019-06-11 09:31:25,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[821] at socketTextStream at Transform.scala:18 of time 1560216685000 ms
2019-06-11 09:31:25,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216675000 ms
2019-06-11 09:31:25,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216675000 ms
2019-06-11 09:31:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216690000 ms
2019-06-11 09:31:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216690000 ms.0 from job set of time 1560216690000 ms
2019-06-11 09:31:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 836 (map at Transform.scala:20)
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 239 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 717 (print at Transform.scala:36)
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 716, ShuffleMapStage 715)
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 715)
2019-06-11 09:31:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 715 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_358 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_358_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:30,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_358_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,010  INFO [org.apache.spark.SparkContext] - Created broadcast 358 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 715 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:30,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 715.0 with 2 tasks
2019-06-11 09:31:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 715.0 (TID 477, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 715.0 (TID 477)
2019-06-11 09:31:30,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 715.0 (TID 477). 810 bytes result sent to driver
2019-06-11 09:31:30,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 715.0 (TID 478, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:30,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 715.0 (TID 478)
2019-06-11 09:31:30,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 715.0 (TID 477) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 715.0 (TID 478). 810 bytes result sent to driver
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 715.0 (TID 478) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 715.0, whose tasks have all completed, from pool 
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 715 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 717)
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 717 (MapPartitionsRDD[841] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:30,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_359 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_359_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:30,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_359_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_346_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,044  INFO [org.apache.spark.SparkContext] - Created broadcast 359 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:30,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 717 (MapPartitionsRDD[841] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:30,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 717.0 with 1 tasks
2019-06-11 09:31:30,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_351_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 717.0 (TID 479, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:30,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 717.0 (TID 479)
2019-06-11 09:31:30,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_344_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 226
2019-06-11 09:31:30,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:31:30,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 228
2019-06-11 09:31:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:30,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:30,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 232
2019-06-11 09:31:30,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 234
2019-06-11 09:31:30,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_354_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 717.0 (TID 479). 1009 bytes result sent to driver
2019-06-11 09:31:30,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 717.0 (TID 479) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:30,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 717.0, whose tasks have all completed, from pool 
2019-06-11 09:31:30,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_355_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 717 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:31:30,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 239 finished: print at Transform.scala:36, took 0.043751 s
2019-06-11 09:31:30,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 224
2019-06-11 09:31:30,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 225
2019-06-11 09:31:30,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_348_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_349_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_352_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 229
2019-06-11 09:31:30,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 227
2019-06-11 09:31:30,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_340_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_353_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_343_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:30,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 231
2019-06-11 09:31:30,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_356_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_357_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_350_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,059  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:30,060  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 239 is 160 bytes
2019-06-11 09:31:30,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_342_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,060  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 238 is 83 bytes
2019-06-11 09:31:30,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 240 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:30,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 720 (print at Transform.scala:36)
2019-06-11 09:31:30,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 718, ShuffleMapStage 719)
2019-06-11 09:31:30,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:30,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 720 (MapPartitionsRDD[841] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:30,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_347_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 233
2019-06-11 09:31:30,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 230
2019-06-11 09:31:30,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_360 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:30,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 235
2019-06-11 09:31:30,062  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_360_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:30,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_360_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_341_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,062  INFO [org.apache.spark.SparkContext] - Created broadcast 360 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:30,063  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 720 (MapPartitionsRDD[841] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:30,063  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 720.0 with 1 tasks
2019-06-11 09:31:30,063  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 720.0 (TID 480, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:30,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_345_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:30,063  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 720.0 (TID 480)
2019-06-11 09:31:30,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:30,064  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:30,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:30,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:30,066  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 720.0 (TID 480). 966 bytes result sent to driver
2019-06-11 09:31:30,066  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 720.0 (TID 480) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:30,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 720.0, whose tasks have all completed, from pool 
2019-06-11 09:31:30,066  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 720 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:30,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 240 finished: print at Transform.scala:36, took 0.006979 s
2019-06-11 09:31:30,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216690000 ms.0 from job set of time 1560216690000 ms
2019-06-11 09:31:30,066  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.066 s for time 1560216690000 ms (execution: 0.060 s)
2019-06-11 09:31:30,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 834 from persistence list
2019-06-11 09:31:30,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 834
2019-06-11 09:31:30,067  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 829 from persistence list
2019-06-11 09:31:30,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 829
2019-06-11 09:31:30,067  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 828 from persistence list
2019-06-11 09:31:30,067  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 828
2019-06-11 09:31:30,067  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[828] at socketTextStream at Transform.scala:18 of time 1560216690000 ms
2019-06-11 09:31:30,067  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216680000 ms
2019-06-11 09:31:30,067  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216680000 ms
2019-06-11 09:31:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216695000 ms
2019-06-11 09:31:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216695000 ms.0 from job set of time 1560216695000 ms
2019-06-11 09:31:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 843 (map at Transform.scala:20)
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 241 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 723 (print at Transform.scala:36)
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 721, ShuffleMapStage 722)
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 721)
2019-06-11 09:31:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 721 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_361 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_361_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:31:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_361_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 361 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 721 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 721.0 with 2 tasks
2019-06-11 09:31:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 721.0 (TID 481, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 721.0 (TID 481)
2019-06-11 09:31:35,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 721.0 (TID 481). 853 bytes result sent to driver
2019-06-11 09:31:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 721.0 (TID 482, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:35,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 721.0 (TID 482)
2019-06-11 09:31:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 721.0 (TID 481) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:35,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 721.0 (TID 482). 810 bytes result sent to driver
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 721.0 (TID 482) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 721.0, whose tasks have all completed, from pool 
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 721 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 723)
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 723 (MapPartitionsRDD[848] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_362 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_362_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:35,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_362_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:35,032  INFO [org.apache.spark.SparkContext] - Created broadcast 362 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 723 (MapPartitionsRDD[848] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 723.0 with 1 tasks
2019-06-11 09:31:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 723.0 (TID 483, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:35,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 723.0 (TID 483)
2019-06-11 09:31:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:35,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:35,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 723.0 (TID 483). 966 bytes result sent to driver
2019-06-11 09:31:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 723.0 (TID 483) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 723.0, whose tasks have all completed, from pool 
2019-06-11 09:31:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 723 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 241 finished: print at Transform.scala:36, took 0.026666 s
2019-06-11 09:31:35,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 241 is 160 bytes
2019-06-11 09:31:35,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 240 is 83 bytes
2019-06-11 09:31:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 242 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 726 (print at Transform.scala:36)
2019-06-11 09:31:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 724, ShuffleMapStage 725)
2019-06-11 09:31:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 726 (MapPartitionsRDD[848] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:35,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_363 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:35,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_363_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:35,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_363_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:35,040  INFO [org.apache.spark.SparkContext] - Created broadcast 363 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 726 (MapPartitionsRDD[848] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 726.0 with 1 tasks
2019-06-11 09:31:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 726.0 (TID 484, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:35,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 726.0 (TID 484)
2019-06-11 09:31:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:35,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:35,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 726.0 (TID 484). 966 bytes result sent to driver
2019-06-11 09:31:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 726.0 (TID 484) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:35,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 726.0, whose tasks have all completed, from pool 
2019-06-11 09:31:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 726 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 242 finished: print at Transform.scala:36, took 0.005325 s
2019-06-11 09:31:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216695000 ms.0 from job set of time 1560216695000 ms
2019-06-11 09:31:35,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216695000 ms (execution: 0.036 s)
2019-06-11 09:31:35,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 841 from persistence list
2019-06-11 09:31:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 841
2019-06-11 09:31:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 836 from persistence list
2019-06-11 09:31:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 836
2019-06-11 09:31:35,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 835 from persistence list
2019-06-11 09:31:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 835
2019-06-11 09:31:35,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[835] at socketTextStream at Transform.scala:18 of time 1560216695000 ms
2019-06-11 09:31:35,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216685000 ms
2019-06-11 09:31:35,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216685000 ms
2019-06-11 09:31:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216700000 ms
2019-06-11 09:31:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216700000 ms.0 from job set of time 1560216700000 ms
2019-06-11 09:31:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 850 (map at Transform.scala:20)
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 243 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 729 (print at Transform.scala:36)
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 727, ShuffleMapStage 728)
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 728)
2019-06-11 09:31:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 728 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_364 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_364_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:31:40,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_364_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:40,009  INFO [org.apache.spark.SparkContext] - Created broadcast 364 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 728 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:40,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 728.0 with 2 tasks
2019-06-11 09:31:40,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 728.0 (TID 485, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:40,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 728.0 (TID 485)
2019-06-11 09:31:40,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 728.0 (TID 485). 853 bytes result sent to driver
2019-06-11 09:31:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 728.0 (TID 486, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 728.0 (TID 486)
2019-06-11 09:31:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 728.0 (TID 485) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:40,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 728.0 (TID 486). 767 bytes result sent to driver
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 728.0 (TID 486) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 728.0, whose tasks have all completed, from pool 
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 728 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 729)
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 729 (MapPartitionsRDD[855] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_365 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_365_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:40,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_365_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:40,030  INFO [org.apache.spark.SparkContext] - Created broadcast 365 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 729 (MapPartitionsRDD[855] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 729.0 with 1 tasks
2019-06-11 09:31:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 729.0 (TID 487, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:40,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 729.0 (TID 487)
2019-06-11 09:31:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 729.0 (TID 487). 1009 bytes result sent to driver
2019-06-11 09:31:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 729.0 (TID 487) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 729.0, whose tasks have all completed, from pool 
2019-06-11 09:31:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 729 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 243 finished: print at Transform.scala:36, took 0.025071 s
2019-06-11 09:31:40,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 242 is 83 bytes
2019-06-11 09:31:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 243 is 160 bytes
2019-06-11 09:31:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 244 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 732 (print at Transform.scala:36)
2019-06-11 09:31:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 730, ShuffleMapStage 731)
2019-06-11 09:31:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 732 (MapPartitionsRDD[855] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_366 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:31:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_366_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:31:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_366_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 366 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 732 (MapPartitionsRDD[855] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 732.0 with 1 tasks
2019-06-11 09:31:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 732.0 (TID 488, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 732.0 (TID 488)
2019-06-11 09:31:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 732.0 (TID 488). 966 bytes result sent to driver
2019-06-11 09:31:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 732.0 (TID 488) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 732.0, whose tasks have all completed, from pool 
2019-06-11 09:31:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 732 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:31:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 244 finished: print at Transform.scala:36, took 0.005400 s
2019-06-11 09:31:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216700000 ms.0 from job set of time 1560216700000 ms
2019-06-11 09:31:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216700000 ms (execution: 0.035 s)
2019-06-11 09:31:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 848 from persistence list
2019-06-11 09:31:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 848
2019-06-11 09:31:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 843 from persistence list
2019-06-11 09:31:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 843
2019-06-11 09:31:40,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 842 from persistence list
2019-06-11 09:31:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 842
2019-06-11 09:31:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[842] at socketTextStream at Transform.scala:18 of time 1560216700000 ms
2019-06-11 09:31:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216690000 ms
2019-06-11 09:31:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216690000 ms
2019-06-11 09:31:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216705000 ms
2019-06-11 09:31:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216705000 ms.0 from job set of time 1560216705000 ms
2019-06-11 09:31:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 857 (map at Transform.scala:20)
2019-06-11 09:31:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 245 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 735 (print at Transform.scala:36)
2019-06-11 09:31:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 734, ShuffleMapStage 733)
2019-06-11 09:31:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 733)
2019-06-11 09:31:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 733 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_367 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_367_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_367_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:45,010  INFO [org.apache.spark.SparkContext] - Created broadcast 367 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:45,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 733 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:45,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 733.0 with 2 tasks
2019-06-11 09:31:45,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 733.0 (TID 489, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 733.0 (TID 489)
2019-06-11 09:31:45,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 733.0 (TID 489). 810 bytes result sent to driver
2019-06-11 09:31:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 733.0 (TID 490, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:45,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 733.0 (TID 490)
2019-06-11 09:31:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 733.0 (TID 489) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:45,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 733.0 (TID 490). 767 bytes result sent to driver
2019-06-11 09:31:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 733.0 (TID 490) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:45,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 733.0, whose tasks have all completed, from pool 
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 733 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 735)
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 735 (MapPartitionsRDD[862] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_368 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_368_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:45,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_368_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:45,031  INFO [org.apache.spark.SparkContext] - Created broadcast 368 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 735 (MapPartitionsRDD[862] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:45,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 735.0 with 1 tasks
2019-06-11 09:31:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 735.0 (TID 491, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:45,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 735.0 (TID 491)
2019-06-11 09:31:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:45,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 735.0 (TID 491). 966 bytes result sent to driver
2019-06-11 09:31:45,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 735.0 (TID 491) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:45,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 735.0, whose tasks have all completed, from pool 
2019-06-11 09:31:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 735 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 245 finished: print at Transform.scala:36, took 0.025696 s
2019-06-11 09:31:45,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:45,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 245 is 160 bytes
2019-06-11 09:31:45,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 244 is 83 bytes
2019-06-11 09:31:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 246 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 738 (print at Transform.scala:36)
2019-06-11 09:31:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 736, ShuffleMapStage 737)
2019-06-11 09:31:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 738 (MapPartitionsRDD[862] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_369 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:45,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_369_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:45,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_369_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:45,039  INFO [org.apache.spark.SparkContext] - Created broadcast 369 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 738 (MapPartitionsRDD[862] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 738.0 with 1 tasks
2019-06-11 09:31:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 738.0 (TID 492, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:45,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 738.0 (TID 492)
2019-06-11 09:31:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:45,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 738.0 (TID 492). 1009 bytes result sent to driver
2019-06-11 09:31:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 738.0 (TID 492) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 738.0, whose tasks have all completed, from pool 
2019-06-11 09:31:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 738 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 246 finished: print at Transform.scala:36, took 0.004555 s
2019-06-11 09:31:45,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216705000 ms.0 from job set of time 1560216705000 ms
2019-06-11 09:31:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216705000 ms (execution: 0.036 s)
2019-06-11 09:31:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 855 from persistence list
2019-06-11 09:31:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 855
2019-06-11 09:31:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 850 from persistence list
2019-06-11 09:31:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 850
2019-06-11 09:31:45,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 849 from persistence list
2019-06-11 09:31:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 849
2019-06-11 09:31:45,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[849] at socketTextStream at Transform.scala:18 of time 1560216705000 ms
2019-06-11 09:31:45,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216695000 ms
2019-06-11 09:31:45,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216695000 ms
2019-06-11 09:31:50,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216710000 ms
2019-06-11 09:31:50,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216710000 ms.0 from job set of time 1560216710000 ms
2019-06-11 09:31:50,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 864 (map at Transform.scala:20)
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 247 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 741 (print at Transform.scala:36)
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 739, ShuffleMapStage 740)
2019-06-11 09:31:50,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 740)
2019-06-11 09:31:50,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 740 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:50,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_370 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:50,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_370_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:50,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_370_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:50,014  INFO [org.apache.spark.SparkContext] - Created broadcast 370 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:50,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 740 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:50,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 740.0 with 2 tasks
2019-06-11 09:31:50,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 740.0 (TID 493, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:50,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 740.0 (TID 493)
2019-06-11 09:31:50,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 740.0 (TID 493). 810 bytes result sent to driver
2019-06-11 09:31:50,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 740.0 (TID 494, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:50,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 740.0 (TID 494)
2019-06-11 09:31:50,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 740.0 (TID 493) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:50,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 740.0 (TID 494). 810 bytes result sent to driver
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 740.0 (TID 494) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 740.0, whose tasks have all completed, from pool 
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 740 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 741)
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 741 (MapPartitionsRDD[869] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_371 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:50,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_371_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:50,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_371_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:50,042  INFO [org.apache.spark.SparkContext] - Created broadcast 371 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:50,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 741 (MapPartitionsRDD[869] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:50,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 741.0 with 1 tasks
2019-06-11 09:31:50,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 741.0 (TID 495, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:50,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 741.0 (TID 495)
2019-06-11 09:31:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:50,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 741.0 (TID 495). 966 bytes result sent to driver
2019-06-11 09:31:50,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 741.0 (TID 495) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:50,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 741.0, whose tasks have all completed, from pool 
2019-06-11 09:31:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 741 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 247 finished: print at Transform.scala:36, took 0.032700 s
2019-06-11 09:31:50,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:50,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 246 is 83 bytes
2019-06-11 09:31:50,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 247 is 160 bytes
2019-06-11 09:31:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 248 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 744 (print at Transform.scala:36)
2019-06-11 09:31:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 742, ShuffleMapStage 743)
2019-06-11 09:31:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 744 (MapPartitionsRDD[869] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:50,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_372 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:50,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_372_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_372_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:50,050  INFO [org.apache.spark.SparkContext] - Created broadcast 372 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 744 (MapPartitionsRDD[869] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:50,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 744.0 with 1 tasks
2019-06-11 09:31:50,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 744.0 (TID 496, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:50,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 744.0 (TID 496)
2019-06-11 09:31:50,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:50,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:50,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:50,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:50,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 744.0 (TID 496). 966 bytes result sent to driver
2019-06-11 09:31:50,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 744.0 (TID 496) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:50,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 744.0, whose tasks have all completed, from pool 
2019-06-11 09:31:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 744 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 248 finished: print at Transform.scala:36, took 0.005629 s
2019-06-11 09:31:50,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216710000 ms.0 from job set of time 1560216710000 ms
2019-06-11 09:31:50,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.053 s for time 1560216710000 ms (execution: 0.043 s)
2019-06-11 09:31:50,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 862 from persistence list
2019-06-11 09:31:50,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 862
2019-06-11 09:31:50,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 857 from persistence list
2019-06-11 09:31:50,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 857
2019-06-11 09:31:50,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 856 from persistence list
2019-06-11 09:31:50,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 856
2019-06-11 09:31:50,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[856] at socketTextStream at Transform.scala:18 of time 1560216710000 ms
2019-06-11 09:31:50,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216700000 ms
2019-06-11 09:31:50,054  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216700000 ms
2019-06-11 09:31:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216715000 ms
2019-06-11 09:31:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216715000 ms.0 from job set of time 1560216715000 ms
2019-06-11 09:31:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 871 (map at Transform.scala:20)
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 249 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 747 (print at Transform.scala:36)
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 745, ShuffleMapStage 746)
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 746)
2019-06-11 09:31:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 746 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:31:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_373 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_373_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:31:55,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_373_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:31:55,010  INFO [org.apache.spark.SparkContext] - Created broadcast 373 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 746 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:31:55,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 746.0 with 2 tasks
2019-06-11 09:31:55,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 746.0 (TID 497, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 746.0 (TID 497)
2019-06-11 09:31:55,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 746.0 (TID 497). 810 bytes result sent to driver
2019-06-11 09:31:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 746.0 (TID 498, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:31:55,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 746.0 (TID 498)
2019-06-11 09:31:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 746.0 (TID 497) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:31:55,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 746.0 (TID 498). 810 bytes result sent to driver
2019-06-11 09:31:55,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 746.0 (TID 498) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:31:55,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 746.0, whose tasks have all completed, from pool 
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 746 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 747)
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:31:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 747 (MapPartitionsRDD[876] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:55,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_374 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:55,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_374_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:55,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_374_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:55,029  INFO [org.apache.spark.SparkContext] - Created broadcast 374 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 747 (MapPartitionsRDD[876] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:31:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 747.0 with 1 tasks
2019-06-11 09:31:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 747.0 (TID 499, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:55,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 747.0 (TID 499)
2019-06-11 09:31:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:55,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 747.0 (TID 499). 1009 bytes result sent to driver
2019-06-11 09:31:55,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 747.0 (TID 499) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:55,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 747.0, whose tasks have all completed, from pool 
2019-06-11 09:31:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 747 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 249 finished: print at Transform.scala:36, took 0.024067 s
2019-06-11 09:31:55,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:31:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 248 is 83 bytes
2019-06-11 09:31:55,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 249 is 160 bytes
2019-06-11 09:31:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 250 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:31:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 750 (print at Transform.scala:36)
2019-06-11 09:31:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 748, ShuffleMapStage 749)
2019-06-11 09:31:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:31:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 750 (MapPartitionsRDD[876] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:31:55,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_375 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:31:55,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_375_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:31:55,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_375_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:31:55,038  INFO [org.apache.spark.SparkContext] - Created broadcast 375 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:31:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 750 (MapPartitionsRDD[876] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:31:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 750.0 with 1 tasks
2019-06-11 09:31:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 750.0 (TID 500, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:31:55,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 750.0 (TID 500)
2019-06-11 09:31:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:31:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:31:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:31:55,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 750.0 (TID 500). 966 bytes result sent to driver
2019-06-11 09:31:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 750.0 (TID 500) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:31:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 750.0, whose tasks have all completed, from pool 
2019-06-11 09:31:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 750 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:31:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 250 finished: print at Transform.scala:36, took 0.005957 s
2019-06-11 09:31:55,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216715000 ms.0 from job set of time 1560216715000 ms
2019-06-11 09:31:55,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216715000 ms (execution: 0.034 s)
2019-06-11 09:31:55,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 869 from persistence list
2019-06-11 09:31:55,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 869
2019-06-11 09:31:55,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 864 from persistence list
2019-06-11 09:31:55,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 864
2019-06-11 09:31:55,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 863 from persistence list
2019-06-11 09:31:55,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 863
2019-06-11 09:31:55,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[863] at socketTextStream at Transform.scala:18 of time 1560216715000 ms
2019-06-11 09:31:55,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216705000 ms
2019-06-11 09:31:55,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216705000 ms
2019-06-11 09:32:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216720000 ms
2019-06-11 09:32:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216720000 ms.0 from job set of time 1560216720000 ms
2019-06-11 09:32:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 878 (map at Transform.scala:20)
2019-06-11 09:32:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 251 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 753 (print at Transform.scala:36)
2019-06-11 09:32:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 751, ShuffleMapStage 752)
2019-06-11 09:32:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 751)
2019-06-11 09:32:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 751 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_376 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_376_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:32:00,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_376_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,012  INFO [org.apache.spark.SparkContext] - Created broadcast 376 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 751 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:00,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 751.0 with 2 tasks
2019-06-11 09:32:00,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 751.0 (TID 501, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:00,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 751.0 (TID 501)
2019-06-11 09:32:00,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_360_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 241
2019-06-11 09:32:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_370_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_372_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_368_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 243
2019-06-11 09:32:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 247
2019-06-11 09:32:00,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_364_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_369_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_375_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 245
2019-06-11 09:32:00,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_365_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_358_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 237
2019-06-11 09:32:00,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_371_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_366_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_374_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 751.0 (TID 501). 853 bytes result sent to driver
2019-06-11 09:32:00,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_359_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 751.0 (TID 502, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:00,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 751.0 (TID 501) in 23 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:00,036  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 751.0 (TID 502)
2019-06-11 09:32:00,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_361_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_363_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 239
2019-06-11 09:32:00,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 240
2019-06-11 09:32:00,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 236
2019-06-11 09:32:00,038  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 244
2019-06-11 09:32:00,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_367_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_362_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 242
2019-06-11 09:32:00,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 246
2019-06-11 09:32:00,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 238
2019-06-11 09:32:00,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_373_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:00,046  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 751.0 (TID 502). 810 bytes result sent to driver
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 751.0 (TID 502) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 751.0, whose tasks have all completed, from pool 
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 751 (parallelize at Transform.scala:16) finished in 0.034 s
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 753)
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 753 (MapPartitionsRDD[883] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:00,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_377 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:00,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_377_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:00,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_377_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,049  INFO [org.apache.spark.SparkContext] - Created broadcast 377 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:00,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 753 (MapPartitionsRDD[883] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:00,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 753.0 with 1 tasks
2019-06-11 09:32:00,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 753.0 (TID 503, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:00,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 753.0 (TID 503)
2019-06-11 09:32:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:00,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:00,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 753.0 (TID 503). 966 bytes result sent to driver
2019-06-11 09:32:00,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 753.0 (TID 503) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:00,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 753.0, whose tasks have all completed, from pool 
2019-06-11 09:32:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 753 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 251 finished: print at Transform.scala:36, took 0.042100 s
2019-06-11 09:32:00,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:00,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 251 is 160 bytes
2019-06-11 09:32:00,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 250 is 83 bytes
2019-06-11 09:32:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 252 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 756 (print at Transform.scala:36)
2019-06-11 09:32:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 754, ShuffleMapStage 755)
2019-06-11 09:32:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:00,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 756 (MapPartitionsRDD[883] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:00,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_378 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:00,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_378_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:00,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_378_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:00,057  INFO [org.apache.spark.SparkContext] - Created broadcast 378 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:00,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 756 (MapPartitionsRDD[883] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:00,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 756.0 with 1 tasks
2019-06-11 09:32:00,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 756.0 (TID 504, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:00,057  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 756.0 (TID 504)
2019-06-11 09:32:00,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:00,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:00,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:00,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:00,058  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 756.0 (TID 504). 966 bytes result sent to driver
2019-06-11 09:32:00,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 756.0 (TID 504) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:00,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 756.0, whose tasks have all completed, from pool 
2019-06-11 09:32:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 756 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 252 finished: print at Transform.scala:36, took 0.004723 s
2019-06-11 09:32:00,059  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216720000 ms.0 from job set of time 1560216720000 ms
2019-06-11 09:32:00,059  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.059 s for time 1560216720000 ms (execution: 0.051 s)
2019-06-11 09:32:00,059  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 876 from persistence list
2019-06-11 09:32:00,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 876
2019-06-11 09:32:00,060  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 871 from persistence list
2019-06-11 09:32:00,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 871
2019-06-11 09:32:00,060  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 870 from persistence list
2019-06-11 09:32:00,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 870
2019-06-11 09:32:00,060  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[870] at socketTextStream at Transform.scala:18 of time 1560216720000 ms
2019-06-11 09:32:00,060  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216710000 ms
2019-06-11 09:32:00,060  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216710000 ms
2019-06-11 09:32:05,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216725000 ms
2019-06-11 09:32:05,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216725000 ms.0 from job set of time 1560216725000 ms
2019-06-11 09:32:05,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 885 (map at Transform.scala:20)
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 253 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 759 (print at Transform.scala:36)
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 757, ShuffleMapStage 758)
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 757)
2019-06-11 09:32:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 757 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:05,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_379 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:05,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_379_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:32:05,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_379_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:05,013  INFO [org.apache.spark.SparkContext] - Created broadcast 379 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 757 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:05,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 757.0 with 2 tasks
2019-06-11 09:32:05,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 757.0 (TID 505, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:05,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 757.0 (TID 505)
2019-06-11 09:32:05,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 757.0 (TID 505). 853 bytes result sent to driver
2019-06-11 09:32:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 757.0 (TID 506, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:05,027  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 757.0 (TID 506)
2019-06-11 09:32:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 757.0 (TID 505) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 757.0 (TID 506). 810 bytes result sent to driver
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 757.0 (TID 506) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 757.0, whose tasks have all completed, from pool 
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 757 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 759)
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 759 (MapPartitionsRDD[890] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_380 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_380_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_380_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:05,037  INFO [org.apache.spark.SparkContext] - Created broadcast 380 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:05,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 759 (MapPartitionsRDD[890] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 759.0 with 1 tasks
2019-06-11 09:32:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 759.0 (TID 507, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 759.0 (TID 507)
2019-06-11 09:32:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:05,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 759.0 (TID 507). 966 bytes result sent to driver
2019-06-11 09:32:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 759.0 (TID 507) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 759.0, whose tasks have all completed, from pool 
2019-06-11 09:32:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 759 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 253 finished: print at Transform.scala:36, took 0.028926 s
2019-06-11 09:32:05,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:05,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 253 is 160 bytes
2019-06-11 09:32:05,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 252 is 83 bytes
2019-06-11 09:32:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 254 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 762 (print at Transform.scala:36)
2019-06-11 09:32:05,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 760, ShuffleMapStage 761)
2019-06-11 09:32:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 762 (MapPartitionsRDD[890] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:05,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_381 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:05,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_381_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:05,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_381_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:05,044  INFO [org.apache.spark.SparkContext] - Created broadcast 381 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 762 (MapPartitionsRDD[890] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:05,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 762.0 with 1 tasks
2019-06-11 09:32:05,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 762.0 (TID 508, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:05,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 762.0 (TID 508)
2019-06-11 09:32:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:05,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:05,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 762.0 (TID 508). 1009 bytes result sent to driver
2019-06-11 09:32:05,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 762.0 (TID 508) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:05,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 762.0, whose tasks have all completed, from pool 
2019-06-11 09:32:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 762 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 254 finished: print at Transform.scala:36, took 0.005123 s
2019-06-11 09:32:05,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216725000 ms.0 from job set of time 1560216725000 ms
2019-06-11 09:32:05,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560216725000 ms (execution: 0.038 s)
2019-06-11 09:32:05,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 883 from persistence list
2019-06-11 09:32:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 883
2019-06-11 09:32:05,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 878 from persistence list
2019-06-11 09:32:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 878
2019-06-11 09:32:05,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 877 from persistence list
2019-06-11 09:32:05,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 877
2019-06-11 09:32:05,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[877] at socketTextStream at Transform.scala:18 of time 1560216725000 ms
2019-06-11 09:32:05,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216715000 ms
2019-06-11 09:32:05,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216715000 ms
2019-06-11 09:32:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216730000 ms
2019-06-11 09:32:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216730000 ms.0 from job set of time 1560216730000 ms
2019-06-11 09:32:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 892 (map at Transform.scala:20)
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 255 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 765 (print at Transform.scala:36)
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 763, ShuffleMapStage 764)
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 764)
2019-06-11 09:32:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 764 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_382 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_382_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.4 MB)
2019-06-11 09:32:10,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_382_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:10,012  INFO [org.apache.spark.SparkContext] - Created broadcast 382 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 764 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:10,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 764.0 with 2 tasks
2019-06-11 09:32:10,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 764.0 (TID 509, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:10,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 764.0 (TID 509)
2019-06-11 09:32:10,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 764.0 (TID 509). 810 bytes result sent to driver
2019-06-11 09:32:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 764.0 (TID 510, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:10,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 764.0 (TID 510)
2019-06-11 09:32:10,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 764.0 (TID 509) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:10,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 764.0 (TID 510). 810 bytes result sent to driver
2019-06-11 09:32:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 764.0 (TID 510) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:10,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 764.0, whose tasks have all completed, from pool 
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 764 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 765)
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 765 (MapPartitionsRDD[897] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_383 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_383_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:10,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_383_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:10,034  INFO [org.apache.spark.SparkContext] - Created broadcast 383 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 765 (MapPartitionsRDD[897] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:10,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 765.0 with 1 tasks
2019-06-11 09:32:10,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 765.0 (TID 511, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:10,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 765.0 (TID 511)
2019-06-11 09:32:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:10,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:32:10,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 765.0 (TID 511). 966 bytes result sent to driver
2019-06-11 09:32:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 765.0 (TID 511) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:10,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 765.0, whose tasks have all completed, from pool 
2019-06-11 09:32:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 765 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:32:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 255 finished: print at Transform.scala:36, took 0.028858 s
2019-06-11 09:32:10,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 254 is 83 bytes
2019-06-11 09:32:10,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 255 is 160 bytes
2019-06-11 09:32:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 256 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 768 (print at Transform.scala:36)
2019-06-11 09:32:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 767, ShuffleMapStage 766)
2019-06-11 09:32:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 768 (MapPartitionsRDD[897] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_384 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_384_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_384_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:10,043  INFO [org.apache.spark.SparkContext] - Created broadcast 384 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 768 (MapPartitionsRDD[897] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 768.0 with 1 tasks
2019-06-11 09:32:10,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 768.0 (TID 512, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:10,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 768.0 (TID 512)
2019-06-11 09:32:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 768.0 (TID 512). 1052 bytes result sent to driver
2019-06-11 09:32:10,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 768.0 (TID 512) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:10,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 768.0, whose tasks have all completed, from pool 
2019-06-11 09:32:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 768 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:32:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 256 finished: print at Transform.scala:36, took 0.006750 s
2019-06-11 09:32:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216730000 ms.0 from job set of time 1560216730000 ms
2019-06-11 09:32:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560216730000 ms (execution: 0.041 s)
2019-06-11 09:32:10,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 890 from persistence list
2019-06-11 09:32:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 890
2019-06-11 09:32:10,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 885 from persistence list
2019-06-11 09:32:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 885
2019-06-11 09:32:10,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 884 from persistence list
2019-06-11 09:32:10,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 884
2019-06-11 09:32:10,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[884] at socketTextStream at Transform.scala:18 of time 1560216730000 ms
2019-06-11 09:32:10,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216720000 ms
2019-06-11 09:32:10,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216720000 ms
2019-06-11 09:32:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216735000 ms
2019-06-11 09:32:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216735000 ms.0 from job set of time 1560216735000 ms
2019-06-11 09:32:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 899 (map at Transform.scala:20)
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 257 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 771 (print at Transform.scala:36)
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 769, ShuffleMapStage 770)
2019-06-11 09:32:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 769)
2019-06-11 09:32:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 769 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_385 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_385_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_385_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 385 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:15,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 769 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:15,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 769.0 with 2 tasks
2019-06-11 09:32:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 769.0 (TID 513, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 769.0 (TID 513)
2019-06-11 09:32:15,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 769.0 (TID 513). 853 bytes result sent to driver
2019-06-11 09:32:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 769.0 (TID 514, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:15,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 769.0 (TID 514)
2019-06-11 09:32:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 769.0 (TID 513) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:15,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 769.0 (TID 514). 767 bytes result sent to driver
2019-06-11 09:32:15,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 769.0 (TID 514) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:15,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 769.0, whose tasks have all completed, from pool 
2019-06-11 09:32:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 769 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:32:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 771)
2019-06-11 09:32:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 771 (MapPartitionsRDD[904] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:15,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_386 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:15,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_386_piece0 stored as bytes in memory (estimated size 2041.0 B, free 1989.3 MB)
2019-06-11 09:32:15,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_386_piece0 in memory on 192.168.91.1:63518 (size: 2041.0 B, free: 1989.5 MB)
2019-06-11 09:32:15,031  INFO [org.apache.spark.SparkContext] - Created broadcast 386 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 771 (MapPartitionsRDD[904] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:15,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 771.0 with 1 tasks
2019-06-11 09:32:15,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 771.0 (TID 515, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:15,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 771.0 (TID 515)
2019-06-11 09:32:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:15,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 771.0 (TID 515). 966 bytes result sent to driver
2019-06-11 09:32:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 771.0 (TID 515) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:15,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 771.0, whose tasks have all completed, from pool 
2019-06-11 09:32:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 771 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 257 finished: print at Transform.scala:36, took 0.025746 s
2019-06-11 09:32:15,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:15,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 257 is 160 bytes
2019-06-11 09:32:15,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 256 is 83 bytes
2019-06-11 09:32:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 258 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 774 (print at Transform.scala:36)
2019-06-11 09:32:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 772, ShuffleMapStage 773)
2019-06-11 09:32:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 774 (MapPartitionsRDD[904] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:15,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_387 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:15,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_387_piece0 stored as bytes in memory (estimated size 2041.0 B, free 1989.3 MB)
2019-06-11 09:32:15,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_387_piece0 in memory on 192.168.91.1:63518 (size: 2041.0 B, free: 1989.5 MB)
2019-06-11 09:32:15,039  INFO [org.apache.spark.SparkContext] - Created broadcast 387 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 774 (MapPartitionsRDD[904] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 774.0 with 1 tasks
2019-06-11 09:32:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 774.0 (TID 516, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:15,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 774.0 (TID 516)
2019-06-11 09:32:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:15,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 774.0 (TID 516). 1009 bytes result sent to driver
2019-06-11 09:32:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 774.0 (TID 516) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 774.0, whose tasks have all completed, from pool 
2019-06-11 09:32:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 774 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 258 finished: print at Transform.scala:36, took 0.005956 s
2019-06-11 09:32:15,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216735000 ms.0 from job set of time 1560216735000 ms
2019-06-11 09:32:15,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216735000 ms (execution: 0.036 s)
2019-06-11 09:32:15,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 897 from persistence list
2019-06-11 09:32:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 897
2019-06-11 09:32:15,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 892 from persistence list
2019-06-11 09:32:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 892
2019-06-11 09:32:15,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 891 from persistence list
2019-06-11 09:32:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 891
2019-06-11 09:32:15,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[891] at socketTextStream at Transform.scala:18 of time 1560216735000 ms
2019-06-11 09:32:15,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216725000 ms
2019-06-11 09:32:15,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216725000 ms
2019-06-11 09:32:20,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216740000 ms
2019-06-11 09:32:20,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216740000 ms.0 from job set of time 1560216740000 ms
2019-06-11 09:32:20,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 906 (map at Transform.scala:20)
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 259 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 777 (print at Transform.scala:36)
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 775, ShuffleMapStage 776)
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 775)
2019-06-11 09:32:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 775 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:20,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_388 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:20,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_388_piece0 stored as bytes in memory (estimated size 1309.0 B, free 1989.3 MB)
2019-06-11 09:32:20,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_388_piece0 in memory on 192.168.91.1:63518 (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:20,014  INFO [org.apache.spark.SparkContext] - Created broadcast 388 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:20,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 775 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:20,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 775.0 with 2 tasks
2019-06-11 09:32:20,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 775.0 (TID 517, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:20,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 775.0 (TID 517)
2019-06-11 09:32:20,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 775.0 (TID 517). 853 bytes result sent to driver
2019-06-11 09:32:20,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 775.0 (TID 518, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:20,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 775.0 (TID 518)
2019-06-11 09:32:20,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 775.0 (TID 517) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 775.0 (TID 518). 810 bytes result sent to driver
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 775.0 (TID 518) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 775.0, whose tasks have all completed, from pool 
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 775 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 777)
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 777 (MapPartitionsRDD[911] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:20,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_389 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:20,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_389_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:20,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_389_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:20,033  INFO [org.apache.spark.SparkContext] - Created broadcast 389 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 777 (MapPartitionsRDD[911] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 777.0 with 1 tasks
2019-06-11 09:32:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 777.0 (TID 519, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:20,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 777.0 (TID 519)
2019-06-11 09:32:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:32:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 777.0 (TID 519). 966 bytes result sent to driver
2019-06-11 09:32:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 777.0 (TID 519) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 777.0, whose tasks have all completed, from pool 
2019-06-11 09:32:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 777 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 259 finished: print at Transform.scala:36, took 0.024381 s
2019-06-11 09:32:20,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 259 is 160 bytes
2019-06-11 09:32:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 258 is 83 bytes
2019-06-11 09:32:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 260 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 780 (print at Transform.scala:36)
2019-06-11 09:32:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 778, ShuffleMapStage 779)
2019-06-11 09:32:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 780 (MapPartitionsRDD[911] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:20,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_390 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_390_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:20,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_390_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:20,041  INFO [org.apache.spark.SparkContext] - Created broadcast 390 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 780 (MapPartitionsRDD[911] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:20,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 780.0 with 1 tasks
2019-06-11 09:32:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 780.0 (TID 520, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:20,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 780.0 (TID 520)
2019-06-11 09:32:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:32:20,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 780.0 (TID 520). 966 bytes result sent to driver
2019-06-11 09:32:20,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 780.0 (TID 520) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:20,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 780.0, whose tasks have all completed, from pool 
2019-06-11 09:32:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 780 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 260 finished: print at Transform.scala:36, took 0.004654 s
2019-06-11 09:32:20,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216740000 ms.0 from job set of time 1560216740000 ms
2019-06-11 09:32:20,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216740000 ms (execution: 0.034 s)
2019-06-11 09:32:20,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 904 from persistence list
2019-06-11 09:32:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 904
2019-06-11 09:32:20,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 899 from persistence list
2019-06-11 09:32:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 899
2019-06-11 09:32:20,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 898 from persistence list
2019-06-11 09:32:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 898
2019-06-11 09:32:20,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[898] at socketTextStream at Transform.scala:18 of time 1560216740000 ms
2019-06-11 09:32:20,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216730000 ms
2019-06-11 09:32:20,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216730000 ms
2019-06-11 09:32:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216745000 ms
2019-06-11 09:32:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216745000 ms.0 from job set of time 1560216745000 ms
2019-06-11 09:32:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 913 (map at Transform.scala:20)
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 261 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 783 (print at Transform.scala:36)
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 781, ShuffleMapStage 782)
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 781)
2019-06-11 09:32:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 781 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_391 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_391_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_391_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 391 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 781 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 781.0 with 2 tasks
2019-06-11 09:32:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 781.0 (TID 521, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 781.0 (TID 521)
2019-06-11 09:32:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 781.0 (TID 521). 810 bytes result sent to driver
2019-06-11 09:32:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 781.0 (TID 522, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 781.0 (TID 522)
2019-06-11 09:32:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 781.0 (TID 521) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 781.0 (TID 522). 767 bytes result sent to driver
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 781.0 (TID 522) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 781.0, whose tasks have all completed, from pool 
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 781 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 783)
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 783 (MapPartitionsRDD[918] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_392 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_392_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_392_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:25,030  INFO [org.apache.spark.SparkContext] - Created broadcast 392 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 783 (MapPartitionsRDD[918] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 783.0 with 1 tasks
2019-06-11 09:32:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 783.0 (TID 523, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:25,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 783.0 (TID 523)
2019-06-11 09:32:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 783.0 (TID 523). 1052 bytes result sent to driver
2019-06-11 09:32:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 783.0 (TID 523) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 783.0, whose tasks have all completed, from pool 
2019-06-11 09:32:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 783 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 261 finished: print at Transform.scala:36, took 0.024481 s
2019-06-11 09:32:25,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 261 is 160 bytes
2019-06-11 09:32:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 260 is 83 bytes
2019-06-11 09:32:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 262 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 786 (print at Transform.scala:36)
2019-06-11 09:32:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 785, ShuffleMapStage 784)
2019-06-11 09:32:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 786 (MapPartitionsRDD[918] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_393 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:25,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_393_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_393_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:25,038  INFO [org.apache.spark.SparkContext] - Created broadcast 393 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 786 (MapPartitionsRDD[918] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:25,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 786.0 with 1 tasks
2019-06-11 09:32:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 786.0 (TID 524, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:25,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 786.0 (TID 524)
2019-06-11 09:32:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:25,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 786.0 (TID 524). 966 bytes result sent to driver
2019-06-11 09:32:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 786.0 (TID 524) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 786.0, whose tasks have all completed, from pool 
2019-06-11 09:32:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 786 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 262 finished: print at Transform.scala:36, took 0.004786 s
2019-06-11 09:32:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216745000 ms.0 from job set of time 1560216745000 ms
2019-06-11 09:32:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216745000 ms (execution: 0.035 s)
2019-06-11 09:32:25,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 911 from persistence list
2019-06-11 09:32:25,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 911
2019-06-11 09:32:25,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 906 from persistence list
2019-06-11 09:32:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 906
2019-06-11 09:32:25,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 905 from persistence list
2019-06-11 09:32:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 905
2019-06-11 09:32:25,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[905] at socketTextStream at Transform.scala:18 of time 1560216745000 ms
2019-06-11 09:32:25,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216735000 ms
2019-06-11 09:32:25,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216735000 ms
2019-06-11 09:32:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216750000 ms
2019-06-11 09:32:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216750000 ms.0 from job set of time 1560216750000 ms
2019-06-11 09:32:30,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 920 (map at Transform.scala:20)
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 263 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 789 (print at Transform.scala:36)
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 787, ShuffleMapStage 788)
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 788)
2019-06-11 09:32:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 788 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:30,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_394 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:30,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_394_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:30,013  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 251
2019-06-11 09:32:30,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_394_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,017  INFO [org.apache.spark.SparkContext] - Created broadcast 394 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:30,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_384_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 788 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:30,020  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 252
2019-06-11 09:32:30,020  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 788.0 with 2 tasks
2019-06-11 09:32:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 788.0 (TID 525, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:30,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 788.0 (TID 525)
2019-06-11 09:32:30,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_382_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_386_piece0 on 192.168.91.1:63518 in memory (size: 2041.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_385_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 257
2019-06-11 09:32:30,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 259
2019-06-11 09:32:30,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 253
2019-06-11 09:32:30,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 258
2019-06-11 09:32:30,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_379_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_383_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 250
2019-06-11 09:32:30,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_380_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_390_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_387_piece0 on 192.168.91.1:63518 in memory (size: 2041.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_391_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_376_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 249
2019-06-11 09:32:30,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_378_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 248
2019-06-11 09:32:30,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_388_piece0 on 192.168.91.1:63518 in memory (size: 1309.0 B, free: 1989.5 MB)
2019-06-11 09:32:30,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_381_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_392_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 254
2019-06-11 09:32:30,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_389_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 256
2019-06-11 09:32:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 788.0 (TID 525). 853 bytes result sent to driver
2019-06-11 09:32:30,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_377_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 788.0 (TID 526, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:30,033  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 788.0 (TID 526)
2019-06-11 09:32:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 788.0 (TID 525) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:30,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_393_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 255
2019-06-11 09:32:30,042  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 788.0 (TID 526). 767 bytes result sent to driver
2019-06-11 09:32:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 788.0 (TID 526) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:30,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 788.0, whose tasks have all completed, from pool 
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 788 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 789)
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 789 (MapPartitionsRDD[925] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:30,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_395 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:30,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_395_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:30,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_395_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,045  INFO [org.apache.spark.SparkContext] - Created broadcast 395 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:30,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 789 (MapPartitionsRDD[925] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:30,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 789.0 with 1 tasks
2019-06-11 09:32:30,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 789.0 (TID 527, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:30,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 789.0 (TID 527)
2019-06-11 09:32:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:30,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:30,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 789.0 (TID 527). 1009 bytes result sent to driver
2019-06-11 09:32:30,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 789.0 (TID 527) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:30,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 789.0, whose tasks have all completed, from pool 
2019-06-11 09:32:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 789 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:32:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 263 finished: print at Transform.scala:36, took 0.040682 s
2019-06-11 09:32:30,052  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:30,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 262 is 83 bytes
2019-06-11 09:32:30,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 263 is 160 bytes
2019-06-11 09:32:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 264 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 792 (print at Transform.scala:36)
2019-06-11 09:32:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 790, ShuffleMapStage 791)
2019-06-11 09:32:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 792 (MapPartitionsRDD[925] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:30,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_396 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:30,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_396_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:30,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_396_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:30,054  INFO [org.apache.spark.SparkContext] - Created broadcast 396 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 792 (MapPartitionsRDD[925] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:30,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 792.0 with 1 tasks
2019-06-11 09:32:30,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 792.0 (TID 528, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:30,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 792.0 (TID 528)
2019-06-11 09:32:30,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:30,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:30,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:30,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:30,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 792.0 (TID 528). 966 bytes result sent to driver
2019-06-11 09:32:30,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 792.0 (TID 528) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:30,057  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 792.0, whose tasks have all completed, from pool 
2019-06-11 09:32:30,057  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 792 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:32:30,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 264 finished: print at Transform.scala:36, took 0.005416 s
2019-06-11 09:32:30,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216750000 ms.0 from job set of time 1560216750000 ms
2019-06-11 09:32:30,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.057 s for time 1560216750000 ms (execution: 0.051 s)
2019-06-11 09:32:30,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 918 from persistence list
2019-06-11 09:32:30,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 918
2019-06-11 09:32:30,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 913 from persistence list
2019-06-11 09:32:30,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 913
2019-06-11 09:32:30,058  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 912 from persistence list
2019-06-11 09:32:30,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 912
2019-06-11 09:32:30,058  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[912] at socketTextStream at Transform.scala:18 of time 1560216750000 ms
2019-06-11 09:32:30,058  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216740000 ms
2019-06-11 09:32:30,058  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216740000 ms
2019-06-11 09:32:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216755000 ms
2019-06-11 09:32:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216755000 ms.0 from job set of time 1560216755000 ms
2019-06-11 09:32:35,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 927 (map at Transform.scala:20)
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 265 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 795 (print at Transform.scala:36)
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 793, ShuffleMapStage 794)
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 794)
2019-06-11 09:32:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 794 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:35,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_397 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_397_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:32:35,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_397_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:35,009  INFO [org.apache.spark.SparkContext] - Created broadcast 397 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 794 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:35,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 794.0 with 2 tasks
2019-06-11 09:32:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 794.0 (TID 529, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 794.0 (TID 529)
2019-06-11 09:32:35,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 794.0 (TID 529). 810 bytes result sent to driver
2019-06-11 09:32:35,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 794.0 (TID 530, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:35,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 794.0 (TID 530)
2019-06-11 09:32:35,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 794.0 (TID 529) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:35,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 794.0 (TID 530). 810 bytes result sent to driver
2019-06-11 09:32:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 794.0 (TID 530) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 794.0, whose tasks have all completed, from pool 
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 794 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 795)
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 795 (MapPartitionsRDD[932] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:35,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_398 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_398_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:35,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_398_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:35,032  INFO [org.apache.spark.SparkContext] - Created broadcast 398 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 795 (MapPartitionsRDD[932] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 795.0 with 1 tasks
2019-06-11 09:32:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 795.0 (TID 531, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:35,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 795.0 (TID 531)
2019-06-11 09:32:35,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:35,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:35,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:35,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:35,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 795.0 (TID 531). 1009 bytes result sent to driver
2019-06-11 09:32:35,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 795.0 (TID 531) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:35,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 795.0, whose tasks have all completed, from pool 
2019-06-11 09:32:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 795 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:32:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 265 finished: print at Transform.scala:36, took 0.028078 s
2019-06-11 09:32:35,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:35,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 264 is 83 bytes
2019-06-11 09:32:35,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 265 is 160 bytes
2019-06-11 09:32:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 266 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 798 (print at Transform.scala:36)
2019-06-11 09:32:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 796, ShuffleMapStage 797)
2019-06-11 09:32:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 798 (MapPartitionsRDD[932] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:35,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_399 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:35,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_399_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:35,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_399_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:35,040  INFO [org.apache.spark.SparkContext] - Created broadcast 399 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 798 (MapPartitionsRDD[932] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 798.0 with 1 tasks
2019-06-11 09:32:35,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 798.0 (TID 532, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:35,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 798.0 (TID 532)
2019-06-11 09:32:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:35,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 798.0 (TID 532). 966 bytes result sent to driver
2019-06-11 09:32:35,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 798.0 (TID 532) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:35,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 798.0, whose tasks have all completed, from pool 
2019-06-11 09:32:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 798 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 266 finished: print at Transform.scala:36, took 0.005161 s
2019-06-11 09:32:35,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216755000 ms.0 from job set of time 1560216755000 ms
2019-06-11 09:32:35,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216755000 ms (execution: 0.038 s)
2019-06-11 09:32:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 925 from persistence list
2019-06-11 09:32:35,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 925
2019-06-11 09:32:35,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 920 from persistence list
2019-06-11 09:32:35,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 920
2019-06-11 09:32:35,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 919 from persistence list
2019-06-11 09:32:35,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 919
2019-06-11 09:32:35,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[919] at socketTextStream at Transform.scala:18 of time 1560216755000 ms
2019-06-11 09:32:35,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216745000 ms
2019-06-11 09:32:35,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216745000 ms
2019-06-11 09:32:40,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216760000 ms
2019-06-11 09:32:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216760000 ms.0 from job set of time 1560216760000 ms
2019-06-11 09:32:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 934 (map at Transform.scala:20)
2019-06-11 09:32:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 267 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 801 (print at Transform.scala:36)
2019-06-11 09:32:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 799, ShuffleMapStage 800)
2019-06-11 09:32:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 799)
2019-06-11 09:32:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 799 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_400 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_400_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:32:40,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_400_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:40,009  INFO [org.apache.spark.SparkContext] - Created broadcast 400 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 799 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:40,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 799.0 with 2 tasks
2019-06-11 09:32:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 799.0 (TID 533, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:40,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 799.0 (TID 533)
2019-06-11 09:32:40,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 799.0 (TID 533). 810 bytes result sent to driver
2019-06-11 09:32:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 799.0 (TID 534, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 799.0 (TID 534)
2019-06-11 09:32:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 799.0 (TID 533) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:40,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 799.0 (TID 534). 810 bytes result sent to driver
2019-06-11 09:32:40,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 799.0 (TID 534) in 13 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:40,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 799.0, whose tasks have all completed, from pool 
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 799 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 801)
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 801 (MapPartitionsRDD[939] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_401 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_401_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:40,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_401_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:40,036  INFO [org.apache.spark.SparkContext] - Created broadcast 401 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 801 (MapPartitionsRDD[939] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 801.0 with 1 tasks
2019-06-11 09:32:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 801.0 (TID 535, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:40,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 801.0 (TID 535)
2019-06-11 09:32:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 801.0 (TID 535). 1009 bytes result sent to driver
2019-06-11 09:32:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 801.0 (TID 535) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 801.0, whose tasks have all completed, from pool 
2019-06-11 09:32:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 801 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 267 finished: print at Transform.scala:36, took 0.032093 s
2019-06-11 09:32:40,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:40,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 267 is 160 bytes
2019-06-11 09:32:40,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 266 is 83 bytes
2019-06-11 09:32:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 268 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 804 (print at Transform.scala:36)
2019-06-11 09:32:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 802, ShuffleMapStage 803)
2019-06-11 09:32:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 804 (MapPartitionsRDD[939] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:40,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_402 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:32:40,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_402_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:32:40,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_402_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:40,044  INFO [org.apache.spark.SparkContext] - Created broadcast 402 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 804 (MapPartitionsRDD[939] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:40,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 804.0 with 1 tasks
2019-06-11 09:32:40,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 804.0 (TID 536, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:40,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 804.0 (TID 536)
2019-06-11 09:32:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:40,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 804.0 (TID 536). 966 bytes result sent to driver
2019-06-11 09:32:40,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 804.0 (TID 536) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:40,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 804.0, whose tasks have all completed, from pool 
2019-06-11 09:32:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 804 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 268 finished: print at Transform.scala:36, took 0.004692 s
2019-06-11 09:32:40,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216760000 ms.0 from job set of time 1560216760000 ms
2019-06-11 09:32:40,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560216760000 ms (execution: 0.043 s)
2019-06-11 09:32:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 932 from persistence list
2019-06-11 09:32:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 932
2019-06-11 09:32:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 927 from persistence list
2019-06-11 09:32:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 927
2019-06-11 09:32:40,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 926 from persistence list
2019-06-11 09:32:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 926
2019-06-11 09:32:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[926] at socketTextStream at Transform.scala:18 of time 1560216760000 ms
2019-06-11 09:32:40,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216750000 ms
2019-06-11 09:32:40,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216750000 ms
2019-06-11 09:32:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216765000 ms
2019-06-11 09:32:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216765000 ms.0 from job set of time 1560216765000 ms
2019-06-11 09:32:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 941 (map at Transform.scala:20)
2019-06-11 09:32:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 269 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 807 (print at Transform.scala:36)
2019-06-11 09:32:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 805, ShuffleMapStage 806)
2019-06-11 09:32:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 806)
2019-06-11 09:32:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 806 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_403 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_403_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_403_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:45,011  INFO [org.apache.spark.SparkContext] - Created broadcast 403 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 806 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:45,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 806.0 with 2 tasks
2019-06-11 09:32:45,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 806.0 (TID 537, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 806.0 (TID 537)
2019-06-11 09:32:45,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 806.0 (TID 537). 853 bytes result sent to driver
2019-06-11 09:32:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 806.0 (TID 538, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:45,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 806.0 (TID 538)
2019-06-11 09:32:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 806.0 (TID 537) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:45,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 806.0 (TID 538). 767 bytes result sent to driver
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 806.0 (TID 538) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 806.0, whose tasks have all completed, from pool 
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 806 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 807)
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 807 (MapPartitionsRDD[946] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_404 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_404_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:45,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_404_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:45,031  INFO [org.apache.spark.SparkContext] - Created broadcast 404 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 807 (MapPartitionsRDD[946] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:45,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 807.0 with 1 tasks
2019-06-11 09:32:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 807.0 (TID 539, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:45,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 807.0 (TID 539)
2019-06-11 09:32:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:45,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 807.0 (TID 539). 966 bytes result sent to driver
2019-06-11 09:32:45,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 807.0 (TID 539) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:45,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 807.0, whose tasks have all completed, from pool 
2019-06-11 09:32:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 807 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 269 finished: print at Transform.scala:36, took 0.025164 s
2019-06-11 09:32:45,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 268 is 83 bytes
2019-06-11 09:32:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 269 is 160 bytes
2019-06-11 09:32:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 270 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 810 (print at Transform.scala:36)
2019-06-11 09:32:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 808, ShuffleMapStage 809)
2019-06-11 09:32:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 810 (MapPartitionsRDD[946] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_405 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_405_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:45,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_405_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:45,039  INFO [org.apache.spark.SparkContext] - Created broadcast 405 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 810 (MapPartitionsRDD[946] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 810.0 with 1 tasks
2019-06-11 09:32:45,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 810.0 (TID 540, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:45,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 810.0 (TID 540)
2019-06-11 09:32:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:45,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 810.0 (TID 540). 966 bytes result sent to driver
2019-06-11 09:32:45,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 810.0 (TID 540) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:45,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 810.0, whose tasks have all completed, from pool 
2019-06-11 09:32:45,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 810 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:45,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 270 finished: print at Transform.scala:36, took 0.006302 s
2019-06-11 09:32:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216765000 ms.0 from job set of time 1560216765000 ms
2019-06-11 09:32:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216765000 ms (execution: 0.035 s)
2019-06-11 09:32:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 939 from persistence list
2019-06-11 09:32:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 939
2019-06-11 09:32:45,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 934 from persistence list
2019-06-11 09:32:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 934
2019-06-11 09:32:45,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 933 from persistence list
2019-06-11 09:32:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 933
2019-06-11 09:32:45,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[933] at socketTextStream at Transform.scala:18 of time 1560216765000 ms
2019-06-11 09:32:45,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216755000 ms
2019-06-11 09:32:45,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216755000 ms
2019-06-11 09:32:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216770000 ms
2019-06-11 09:32:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216770000 ms.0 from job set of time 1560216770000 ms
2019-06-11 09:32:50,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 948 (map at Transform.scala:20)
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 271 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 813 (print at Transform.scala:36)
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 811, ShuffleMapStage 812)
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 811)
2019-06-11 09:32:50,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 811 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:50,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_406 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:50,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_406_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:50,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_406_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:50,009  INFO [org.apache.spark.SparkContext] - Created broadcast 406 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 811 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:50,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 811.0 with 2 tasks
2019-06-11 09:32:50,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 811.0 (TID 541, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:50,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 811.0 (TID 541)
2019-06-11 09:32:50,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 811.0 (TID 541). 853 bytes result sent to driver
2019-06-11 09:32:50,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 811.0 (TID 542, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:50,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 811.0 (TID 542)
2019-06-11 09:32:50,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 811.0 (TID 541) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:50,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 811.0 (TID 542). 810 bytes result sent to driver
2019-06-11 09:32:50,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 811.0 (TID 542) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:50,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 811.0, whose tasks have all completed, from pool 
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 811 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 813)
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 813 (MapPartitionsRDD[953] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:50,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_407 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_407_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:50,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_407_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:50,029  INFO [org.apache.spark.SparkContext] - Created broadcast 407 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 813 (MapPartitionsRDD[953] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 813.0 with 1 tasks
2019-06-11 09:32:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 813.0 (TID 543, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:50,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 813.0 (TID 543)
2019-06-11 09:32:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:50,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 813.0 (TID 543). 1009 bytes result sent to driver
2019-06-11 09:32:50,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 813.0 (TID 543) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:50,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 813.0, whose tasks have all completed, from pool 
2019-06-11 09:32:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 813 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:32:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 271 finished: print at Transform.scala:36, took 0.026880 s
2019-06-11 09:32:50,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 271 is 160 bytes
2019-06-11 09:32:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 270 is 83 bytes
2019-06-11 09:32:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 272 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 816 (print at Transform.scala:36)
2019-06-11 09:32:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 814, ShuffleMapStage 815)
2019-06-11 09:32:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 816 (MapPartitionsRDD[953] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:50,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_408 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:50,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_408_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:50,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_408_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:50,038  INFO [org.apache.spark.SparkContext] - Created broadcast 408 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 816 (MapPartitionsRDD[953] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:50,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 816.0 with 1 tasks
2019-06-11 09:32:50,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 816.0 (TID 544, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:50,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 816.0 (TID 544)
2019-06-11 09:32:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:50,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 816.0 (TID 544). 966 bytes result sent to driver
2019-06-11 09:32:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 816.0 (TID 544) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:50,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 816.0, whose tasks have all completed, from pool 
2019-06-11 09:32:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 816 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 272 finished: print at Transform.scala:36, took 0.004517 s
2019-06-11 09:32:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216770000 ms.0 from job set of time 1560216770000 ms
2019-06-11 09:32:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216770000 ms (execution: 0.036 s)
2019-06-11 09:32:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 946 from persistence list
2019-06-11 09:32:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 946
2019-06-11 09:32:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 941 from persistence list
2019-06-11 09:32:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 941
2019-06-11 09:32:50,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 940 from persistence list
2019-06-11 09:32:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 940
2019-06-11 09:32:50,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[940] at socketTextStream at Transform.scala:18 of time 1560216770000 ms
2019-06-11 09:32:50,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216760000 ms
2019-06-11 09:32:50,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216760000 ms
2019-06-11 09:32:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216775000 ms
2019-06-11 09:32:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216775000 ms.0 from job set of time 1560216775000 ms
2019-06-11 09:32:55,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:55,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 955 (map at Transform.scala:20)
2019-06-11 09:32:55,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:32:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 273 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 819 (print at Transform.scala:36)
2019-06-11 09:32:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 818, ShuffleMapStage 817)
2019-06-11 09:32:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 818)
2019-06-11 09:32:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 818 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:32:55,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_409 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_409_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:32:55,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_409_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,009  INFO [org.apache.spark.SparkContext] - Created broadcast 409 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 818 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:32:55,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 818.0 with 2 tasks
2019-06-11 09:32:55,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 818.0 (TID 545, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 818.0 (TID 545)
2019-06-11 09:32:55,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 818.0 (TID 545). 810 bytes result sent to driver
2019-06-11 09:32:55,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 818.0 (TID 546, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:32:55,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 818.0 (TID 546)
2019-06-11 09:32:55,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 818.0 (TID 545) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:32:55,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 818.0 (TID 546). 810 bytes result sent to driver
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 818.0 (TID 546) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 818.0, whose tasks have all completed, from pool 
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 818 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 819)
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:32:55,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 819 (MapPartitionsRDD[960] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:55,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_410 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:55,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_410_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:55,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_410_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,029  INFO [org.apache.spark.SparkContext] - Created broadcast 410 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 819 (MapPartitionsRDD[960] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:32:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 819.0 with 1 tasks
2019-06-11 09:32:55,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 819.0 (TID 547, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:55,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 819.0 (TID 547)
2019-06-11 09:32:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:55,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 819.0 (TID 547). 966 bytes result sent to driver
2019-06-11 09:32:55,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 819.0 (TID 547) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:55,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 819.0, whose tasks have all completed, from pool 
2019-06-11 09:32:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 819 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:32:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 273 finished: print at Transform.scala:36, took 0.024529 s
2019-06-11 09:32:55,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:32:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 272 is 83 bytes
2019-06-11 09:32:55,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 273 is 160 bytes
2019-06-11 09:32:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 274 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:32:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 822 (print at Transform.scala:36)
2019-06-11 09:32:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 820, ShuffleMapStage 821)
2019-06-11 09:32:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:32:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 822 (MapPartitionsRDD[960] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:32:55,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_411 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:32:55,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_411_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:32:55,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_409_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_411_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,047  INFO [org.apache.spark.SparkContext] - Created broadcast 411 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:32:55,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 269
2019-06-11 09:32:55,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 822 (MapPartitionsRDD[960] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:32:55,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 822.0 with 1 tasks
2019-06-11 09:32:55,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 822.0 (TID 548, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:32:55,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_402_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 822.0 (TID 548)
2019-06-11 09:32:55,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_394_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:32:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:32:55,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:32:55,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_406_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_410_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 822.0 (TID 548). 966 bytes result sent to driver
2019-06-11 09:32:55,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 822.0 (TID 548) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:32:55,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 822.0, whose tasks have all completed, from pool 
2019-06-11 09:32:55,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 267
2019-06-11 09:32:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 822 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:32:55,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 274 finished: print at Transform.scala:36, took 0.018330 s
2019-06-11 09:32:55,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216775000 ms.0 from job set of time 1560216775000 ms
2019-06-11 09:32:55,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216775000 ms (execution: 0.047 s)
2019-06-11 09:32:55,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_404_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 953 from persistence list
2019-06-11 09:32:55,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 953
2019-06-11 09:32:55,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 948 from persistence list
2019-06-11 09:32:55,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 948
2019-06-11 09:32:55,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 947 from persistence list
2019-06-11 09:32:55,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 261
2019-06-11 09:32:55,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 947
2019-06-11 09:32:55,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[947] at socketTextStream at Transform.scala:18 of time 1560216775000 ms
2019-06-11 09:32:55,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216765000 ms
2019-06-11 09:32:55,054  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216765000 ms
2019-06-11 09:32:55,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_408_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 265
2019-06-11 09:32:55,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_397_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_403_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_407_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_398_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 264
2019-06-11 09:32:55,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 268
2019-06-11 09:32:55,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_405_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,059  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 263
2019-06-11 09:32:55,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_400_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:32:55,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 266
2019-06-11 09:32:55,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_399_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_395_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_401_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:32:55,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 262
2019-06-11 09:32:55,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 260
2019-06-11 09:32:55,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_396_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216780000 ms
2019-06-11 09:33:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216780000 ms.0 from job set of time 1560216780000 ms
2019-06-11 09:33:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 962 (map at Transform.scala:20)
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 275 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 825 (print at Transform.scala:36)
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 823, ShuffleMapStage 824)
2019-06-11 09:33:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 823)
2019-06-11 09:33:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 823 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:00,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_412 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_412_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:00,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_412_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:00,011  INFO [org.apache.spark.SparkContext] - Created broadcast 412 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 823 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:00,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 823.0 with 2 tasks
2019-06-11 09:33:00,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 823.0 (TID 549, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:00,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 823.0 (TID 549)
2019-06-11 09:33:00,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 823.0 (TID 549). 810 bytes result sent to driver
2019-06-11 09:33:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 823.0 (TID 550, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:00,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 823.0 (TID 550)
2019-06-11 09:33:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 823.0 (TID 549) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 823.0 (TID 550). 810 bytes result sent to driver
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 823.0 (TID 550) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 823.0, whose tasks have all completed, from pool 
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 823 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 825)
2019-06-11 09:33:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 825 (MapPartitionsRDD[967] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_413 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_413_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:00,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_413_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:00,032  INFO [org.apache.spark.SparkContext] - Created broadcast 413 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:00,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 825 (MapPartitionsRDD[967] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:00,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 825.0 with 1 tasks
2019-06-11 09:33:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 825.0 (TID 551, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:00,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 825.0 (TID 551)
2019-06-11 09:33:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:00,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 825.0 (TID 551). 966 bytes result sent to driver
2019-06-11 09:33:00,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 825.0 (TID 551) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:00,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 825.0, whose tasks have all completed, from pool 
2019-06-11 09:33:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 825 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 275 finished: print at Transform.scala:36, took 0.025868 s
2019-06-11 09:33:00,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:00,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 275 is 160 bytes
2019-06-11 09:33:00,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 274 is 83 bytes
2019-06-11 09:33:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 276 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 828 (print at Transform.scala:36)
2019-06-11 09:33:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 826, ShuffleMapStage 827)
2019-06-11 09:33:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 828 (MapPartitionsRDD[967] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_414 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_414_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:00,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_414_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:00,040  INFO [org.apache.spark.SparkContext] - Created broadcast 414 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 828 (MapPartitionsRDD[967] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 828.0 with 1 tasks
2019-06-11 09:33:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 828.0 (TID 552, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:00,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 828.0 (TID 552)
2019-06-11 09:33:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:00,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 828.0 (TID 552). 966 bytes result sent to driver
2019-06-11 09:33:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 828.0 (TID 552) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:00,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 828.0, whose tasks have all completed, from pool 
2019-06-11 09:33:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 828 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 276 finished: print at Transform.scala:36, took 0.004949 s
2019-06-11 09:33:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216780000 ms.0 from job set of time 1560216780000 ms
2019-06-11 09:33:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216780000 ms (execution: 0.035 s)
2019-06-11 09:33:00,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 960 from persistence list
2019-06-11 09:33:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 960
2019-06-11 09:33:00,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 955 from persistence list
2019-06-11 09:33:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 955
2019-06-11 09:33:00,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 954 from persistence list
2019-06-11 09:33:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 954
2019-06-11 09:33:00,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[954] at socketTextStream at Transform.scala:18 of time 1560216780000 ms
2019-06-11 09:33:00,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216770000 ms
2019-06-11 09:33:00,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216770000 ms
2019-06-11 09:33:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216785000 ms
2019-06-11 09:33:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216785000 ms.0 from job set of time 1560216785000 ms
2019-06-11 09:33:05,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 969 (map at Transform.scala:20)
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 277 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 831 (print at Transform.scala:36)
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 829, ShuffleMapStage 830)
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 830)
2019-06-11 09:33:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 830 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_415 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_415_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_415_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 415 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 830 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 830.0 with 2 tasks
2019-06-11 09:33:05,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 830.0 (TID 553, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 830.0 (TID 553)
2019-06-11 09:33:05,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 830.0 (TID 553). 810 bytes result sent to driver
2019-06-11 09:33:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 830.0 (TID 554, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 830.0 (TID 554)
2019-06-11 09:33:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 830.0 (TID 553) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:05,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 830.0 (TID 554). 767 bytes result sent to driver
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 830.0 (TID 554) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 830.0, whose tasks have all completed, from pool 
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 830 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 831)
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 831 (MapPartitionsRDD[974] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:05,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_416 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_416_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:05,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_416_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:05,029  INFO [org.apache.spark.SparkContext] - Created broadcast 416 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 831 (MapPartitionsRDD[974] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:05,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 831.0 with 1 tasks
2019-06-11 09:33:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 831.0 (TID 555, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:05,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 831.0 (TID 555)
2019-06-11 09:33:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:05,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 831.0 (TID 555). 966 bytes result sent to driver
2019-06-11 09:33:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 831.0 (TID 555) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:05,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 831.0, whose tasks have all completed, from pool 
2019-06-11 09:33:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 831 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 277 finished: print at Transform.scala:36, took 0.023705 s
2019-06-11 09:33:05,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:05,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 276 is 83 bytes
2019-06-11 09:33:05,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 277 is 160 bytes
2019-06-11 09:33:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 278 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 834 (print at Transform.scala:36)
2019-06-11 09:33:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 832, ShuffleMapStage 833)
2019-06-11 09:33:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 834 (MapPartitionsRDD[974] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:05,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_417 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_417_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:05,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_417_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:05,035  INFO [org.apache.spark.SparkContext] - Created broadcast 417 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 834 (MapPartitionsRDD[974] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 834.0 with 1 tasks
2019-06-11 09:33:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 834.0 (TID 556, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:05,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 834.0 (TID 556)
2019-06-11 09:33:05,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:05,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:05,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 834.0 (TID 556). 1009 bytes result sent to driver
2019-06-11 09:33:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 834.0 (TID 556) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 834.0, whose tasks have all completed, from pool 
2019-06-11 09:33:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 834 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 278 finished: print at Transform.scala:36, took 0.005982 s
2019-06-11 09:33:05,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216785000 ms.0 from job set of time 1560216785000 ms
2019-06-11 09:33:05,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216785000 ms (execution: 0.034 s)
2019-06-11 09:33:05,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 967 from persistence list
2019-06-11 09:33:05,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 967
2019-06-11 09:33:05,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 962 from persistence list
2019-06-11 09:33:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 962
2019-06-11 09:33:05,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 961 from persistence list
2019-06-11 09:33:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 961
2019-06-11 09:33:05,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[961] at socketTextStream at Transform.scala:18 of time 1560216785000 ms
2019-06-11 09:33:05,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216775000 ms
2019-06-11 09:33:05,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216775000 ms
2019-06-11 09:33:10,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216790000 ms
2019-06-11 09:33:10,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216790000 ms.0 from job set of time 1560216790000 ms
2019-06-11 09:33:10,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 976 (map at Transform.scala:20)
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 279 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 837 (print at Transform.scala:36)
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 836, ShuffleMapStage 835)
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 835)
2019-06-11 09:33:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 835 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:10,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_418 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:10,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_418_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:10,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_418_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:10,014  INFO [org.apache.spark.SparkContext] - Created broadcast 418 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 835 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:10,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 835.0 with 2 tasks
2019-06-11 09:33:10,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 835.0 (TID 557, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:10,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 835.0 (TID 557)
2019-06-11 09:33:10,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 835.0 (TID 557). 810 bytes result sent to driver
2019-06-11 09:33:10,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 835.0 (TID 558, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:10,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 835.0 (TID 558)
2019-06-11 09:33:10,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 835.0 (TID 557) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:10,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 835.0 (TID 558). 810 bytes result sent to driver
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 835.0 (TID 558) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 835.0, whose tasks have all completed, from pool 
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 835 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 837)
2019-06-11 09:33:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 837 (MapPartitionsRDD[981] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:10,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_419 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_419_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:10,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_419_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:10,033  INFO [org.apache.spark.SparkContext] - Created broadcast 419 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 837 (MapPartitionsRDD[981] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 837.0 with 1 tasks
2019-06-11 09:33:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 837.0 (TID 559, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:10,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 837.0 (TID 559)
2019-06-11 09:33:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:10,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 837.0 (TID 559). 966 bytes result sent to driver
2019-06-11 09:33:10,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 837.0 (TID 559) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 837.0, whose tasks have all completed, from pool 
2019-06-11 09:33:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 837 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 279 finished: print at Transform.scala:36, took 0.023509 s
2019-06-11 09:33:10,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:10,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 279 is 160 bytes
2019-06-11 09:33:10,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 278 is 83 bytes
2019-06-11 09:33:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 280 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 840 (print at Transform.scala:36)
2019-06-11 09:33:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 838, ShuffleMapStage 839)
2019-06-11 09:33:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 840 (MapPartitionsRDD[981] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:10,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_420 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:10,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_420_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:10,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_420_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:10,040  INFO [org.apache.spark.SparkContext] - Created broadcast 420 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 840 (MapPartitionsRDD[981] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 840.0 with 1 tasks
2019-06-11 09:33:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 840.0 (TID 560, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:10,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 840.0 (TID 560)
2019-06-11 09:33:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:10,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:10,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 840.0 (TID 560). 966 bytes result sent to driver
2019-06-11 09:33:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 840.0 (TID 560) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:10,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 840.0, whose tasks have all completed, from pool 
2019-06-11 09:33:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 840 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 280 finished: print at Transform.scala:36, took 0.005674 s
2019-06-11 09:33:10,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216790000 ms.0 from job set of time 1560216790000 ms
2019-06-11 09:33:10,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216790000 ms (execution: 0.033 s)
2019-06-11 09:33:10,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 974 from persistence list
2019-06-11 09:33:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 974
2019-06-11 09:33:10,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 969 from persistence list
2019-06-11 09:33:10,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 969
2019-06-11 09:33:10,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 968 from persistence list
2019-06-11 09:33:10,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 968
2019-06-11 09:33:10,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[968] at socketTextStream at Transform.scala:18 of time 1560216790000 ms
2019-06-11 09:33:10,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216780000 ms
2019-06-11 09:33:10,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216780000 ms
2019-06-11 09:33:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216795000 ms
2019-06-11 09:33:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216795000 ms.0 from job set of time 1560216795000 ms
2019-06-11 09:33:15,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 983 (map at Transform.scala:20)
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 281 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 843 (print at Transform.scala:36)
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 841, ShuffleMapStage 842)
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 842)
2019-06-11 09:33:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 842 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_421 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_421_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:15,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_421_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 421 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 842 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 842.0 with 2 tasks
2019-06-11 09:33:15,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 842.0 (TID 561, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:15,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 842.0 (TID 561)
2019-06-11 09:33:15,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 842.0 (TID 561). 853 bytes result sent to driver
2019-06-11 09:33:15,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 842.0 (TID 562, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:15,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 842.0 (TID 562)
2019-06-11 09:33:15,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 842.0 (TID 561) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:15,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 842.0 (TID 562). 767 bytes result sent to driver
2019-06-11 09:33:15,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 842.0 (TID 562) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 842.0, whose tasks have all completed, from pool 
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 842 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 843)
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 843 (MapPartitionsRDD[988] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:15,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_422 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:15,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_422_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:15,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_422_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:15,029  INFO [org.apache.spark.SparkContext] - Created broadcast 422 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 843 (MapPartitionsRDD[988] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:15,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 843.0 with 1 tasks
2019-06-11 09:33:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 843.0 (TID 563, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:15,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 843.0 (TID 563)
2019-06-11 09:33:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:15,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 843.0 (TID 563). 1009 bytes result sent to driver
2019-06-11 09:33:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 843.0 (TID 563) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:15,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 843.0, whose tasks have all completed, from pool 
2019-06-11 09:33:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 843 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:33:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 281 finished: print at Transform.scala:36, took 0.024120 s
2019-06-11 09:33:15,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:15,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 280 is 83 bytes
2019-06-11 09:33:15,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 281 is 160 bytes
2019-06-11 09:33:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 282 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 846 (print at Transform.scala:36)
2019-06-11 09:33:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 844, ShuffleMapStage 845)
2019-06-11 09:33:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 846 (MapPartitionsRDD[988] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_423 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_423_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:15,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_423_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:15,036  INFO [org.apache.spark.SparkContext] - Created broadcast 423 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 846 (MapPartitionsRDD[988] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:15,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 846.0 with 1 tasks
2019-06-11 09:33:15,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 846.0 (TID 564, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:15,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 846.0 (TID 564)
2019-06-11 09:33:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:15,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 846.0 (TID 564). 966 bytes result sent to driver
2019-06-11 09:33:15,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 846.0 (TID 564) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:15,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 846.0, whose tasks have all completed, from pool 
2019-06-11 09:33:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 846 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 282 finished: print at Transform.scala:36, took 0.005272 s
2019-06-11 09:33:15,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216795000 ms.0 from job set of time 1560216795000 ms
2019-06-11 09:33:15,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216795000 ms (execution: 0.034 s)
2019-06-11 09:33:15,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 981 from persistence list
2019-06-11 09:33:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 981
2019-06-11 09:33:15,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 976 from persistence list
2019-06-11 09:33:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 976
2019-06-11 09:33:15,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 975 from persistence list
2019-06-11 09:33:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 975
2019-06-11 09:33:15,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[975] at socketTextStream at Transform.scala:18 of time 1560216795000 ms
2019-06-11 09:33:15,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216785000 ms
2019-06-11 09:33:15,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216785000 ms
2019-06-11 09:33:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216800000 ms
2019-06-11 09:33:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216800000 ms.0 from job set of time 1560216800000 ms
2019-06-11 09:33:20,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 990 (map at Transform.scala:20)
2019-06-11 09:33:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 283 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 849 (print at Transform.scala:36)
2019-06-11 09:33:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 847, ShuffleMapStage 848)
2019-06-11 09:33:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 847)
2019-06-11 09:33:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 847 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_424 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_424_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:20,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_424_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:20,010  INFO [org.apache.spark.SparkContext] - Created broadcast 424 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 847 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 847.0 with 2 tasks
2019-06-11 09:33:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 847.0 (TID 565, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 847.0 (TID 565)
2019-06-11 09:33:20,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 847.0 (TID 565). 853 bytes result sent to driver
2019-06-11 09:33:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 847.0 (TID 566, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 847.0 (TID 566)
2019-06-11 09:33:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 847.0 (TID 565) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:20,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 847.0 (TID 566). 810 bytes result sent to driver
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 847.0 (TID 566) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 847.0, whose tasks have all completed, from pool 
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 847 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 849)
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 849 (MapPartitionsRDD[995] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_425 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_425_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:20,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_425_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:20,030  INFO [org.apache.spark.SparkContext] - Created broadcast 425 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 849 (MapPartitionsRDD[995] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 849.0 with 1 tasks
2019-06-11 09:33:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 849.0 (TID 567, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 849.0 (TID 567)
2019-06-11 09:33:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 849.0 (TID 567). 1009 bytes result sent to driver
2019-06-11 09:33:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 849.0 (TID 567) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 849.0, whose tasks have all completed, from pool 
2019-06-11 09:33:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 849 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 283 finished: print at Transform.scala:36, took 0.024630 s
2019-06-11 09:33:20,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 283 is 160 bytes
2019-06-11 09:33:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 282 is 83 bytes
2019-06-11 09:33:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 284 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 852 (print at Transform.scala:36)
2019-06-11 09:33:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 850, ShuffleMapStage 851)
2019-06-11 09:33:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 852 (MapPartitionsRDD[995] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:20,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_426 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_426_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:20,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_426_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:20,037  INFO [org.apache.spark.SparkContext] - Created broadcast 426 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 852 (MapPartitionsRDD[995] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 852.0 with 1 tasks
2019-06-11 09:33:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 852.0 (TID 568, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:20,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 852.0 (TID 568)
2019-06-11 09:33:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:20,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 852.0 (TID 568). 1009 bytes result sent to driver
2019-06-11 09:33:20,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 852.0 (TID 568) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 852.0, whose tasks have all completed, from pool 
2019-06-11 09:33:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 852 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 284 finished: print at Transform.scala:36, took 0.005809 s
2019-06-11 09:33:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216800000 ms.0 from job set of time 1560216800000 ms
2019-06-11 09:33:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216800000 ms (execution: 0.035 s)
2019-06-11 09:33:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 988 from persistence list
2019-06-11 09:33:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 988
2019-06-11 09:33:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 983 from persistence list
2019-06-11 09:33:20,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 983
2019-06-11 09:33:20,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 982 from persistence list
2019-06-11 09:33:20,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 982
2019-06-11 09:33:20,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[982] at socketTextStream at Transform.scala:18 of time 1560216800000 ms
2019-06-11 09:33:20,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216790000 ms
2019-06-11 09:33:20,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216790000 ms
2019-06-11 09:33:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216805000 ms
2019-06-11 09:33:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216805000 ms.0 from job set of time 1560216805000 ms
2019-06-11 09:33:25,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 997 (map at Transform.scala:20)
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 285 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 855 (print at Transform.scala:36)
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 854, ShuffleMapStage 853)
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 853)
2019-06-11 09:33:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 853 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:25,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_427 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:25,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_427_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:25,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_421_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_427_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,021  INFO [org.apache.spark.SparkContext] - Created broadcast 427 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:25,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_413_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 853 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:25,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 853.0 with 2 tasks
2019-06-11 09:33:25,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 853.0 (TID 569, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:25,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 273
2019-06-11 09:33:25,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 853.0 (TID 569)
2019-06-11 09:33:25,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_420_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 281
2019-06-11 09:33:25,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 271
2019-06-11 09:33:25,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_425_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_411_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 270
2019-06-11 09:33:25,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 274
2019-06-11 09:33:25,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 272
2019-06-11 09:33:25,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_417_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 276
2019-06-11 09:33:25,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_415_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 280
2019-06-11 09:33:25,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_423_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_412_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_419_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_426_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_422_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_418_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 275
2019-06-11 09:33:25,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 278
2019-06-11 09:33:25,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_414_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 853.0 (TID 569). 853 bytes result sent to driver
2019-06-11 09:33:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 853.0 (TID 570, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:25,033  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 853.0 (TID 570)
2019-06-11 09:33:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 853.0 (TID 569) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:25,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_416_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_424_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:25,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 279
2019-06-11 09:33:25,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 277
2019-06-11 09:33:25,043  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 853.0 (TID 570). 767 bytes result sent to driver
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 853.0 (TID 570) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 853.0, whose tasks have all completed, from pool 
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 853 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 855)
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 855 (MapPartitionsRDD[1002] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:25,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_428 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:25,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_428_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:25,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_428_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,046  INFO [org.apache.spark.SparkContext] - Created broadcast 428 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 855 (MapPartitionsRDD[1002] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:25,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 855.0 with 1 tasks
2019-06-11 09:33:25,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 855.0 (TID 571, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:25,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 855.0 (TID 571)
2019-06-11 09:33:25,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:25,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:25,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:25,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:25,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 855.0 (TID 571). 1009 bytes result sent to driver
2019-06-11 09:33:25,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 855.0 (TID 571) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:25,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 855.0, whose tasks have all completed, from pool 
2019-06-11 09:33:25,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 855 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:25,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 285 finished: print at Transform.scala:36, took 0.042216 s
2019-06-11 09:33:25,051  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:25,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 285 is 160 bytes
2019-06-11 09:33:25,051  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 284 is 83 bytes
2019-06-11 09:33:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 286 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 858 (print at Transform.scala:36)
2019-06-11 09:33:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 856, ShuffleMapStage 857)
2019-06-11 09:33:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:25,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 858 (MapPartitionsRDD[1002] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:25,052  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_429 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:25,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_429_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:25,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_429_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:25,053  INFO [org.apache.spark.SparkContext] - Created broadcast 429 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:25,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 858 (MapPartitionsRDD[1002] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:25,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 858.0 with 1 tasks
2019-06-11 09:33:25,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 858.0 (TID 572, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:25,054  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 858.0 (TID 572)
2019-06-11 09:33:25,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:25,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:25,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:25,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:25,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 858.0 (TID 572). 966 bytes result sent to driver
2019-06-11 09:33:25,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 858.0 (TID 572) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:25,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 858.0, whose tasks have all completed, from pool 
2019-06-11 09:33:25,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 858 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:25,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 286 finished: print at Transform.scala:36, took 0.004317 s
2019-06-11 09:33:25,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216805000 ms.0 from job set of time 1560216805000 ms
2019-06-11 09:33:25,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.056 s for time 1560216805000 ms (execution: 0.051 s)
2019-06-11 09:33:25,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 995 from persistence list
2019-06-11 09:33:25,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 995
2019-06-11 09:33:25,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 990 from persistence list
2019-06-11 09:33:25,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 990
2019-06-11 09:33:25,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 989 from persistence list
2019-06-11 09:33:25,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 989
2019-06-11 09:33:25,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[989] at socketTextStream at Transform.scala:18 of time 1560216805000 ms
2019-06-11 09:33:25,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216795000 ms
2019-06-11 09:33:25,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216795000 ms
2019-06-11 09:33:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216810000 ms
2019-06-11 09:33:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216810000 ms.0 from job set of time 1560216810000 ms
2019-06-11 09:33:30,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1004 (map at Transform.scala:20)
2019-06-11 09:33:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 287 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 861 (print at Transform.scala:36)
2019-06-11 09:33:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 859, ShuffleMapStage 860)
2019-06-11 09:33:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 860)
2019-06-11 09:33:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 860 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:30,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_430 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_430_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:30,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_430_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:30,009  INFO [org.apache.spark.SparkContext] - Created broadcast 430 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 860 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:30,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 860.0 with 2 tasks
2019-06-11 09:33:30,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 860.0 (TID 573, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:30,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 860.0 (TID 573)
2019-06-11 09:33:30,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 860.0 (TID 573). 810 bytes result sent to driver
2019-06-11 09:33:30,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 860.0 (TID 574, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:30,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 860.0 (TID 574)
2019-06-11 09:33:30,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 860.0 (TID 573) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:30,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 860.0 (TID 574). 767 bytes result sent to driver
2019-06-11 09:33:30,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 860.0 (TID 574) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:30,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 860.0, whose tasks have all completed, from pool 
2019-06-11 09:33:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 860 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 861)
2019-06-11 09:33:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 861 (MapPartitionsRDD[1009] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:30,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_431 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:30,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_431_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:30,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_431_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:30,029  INFO [org.apache.spark.SparkContext] - Created broadcast 431 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 861 (MapPartitionsRDD[1009] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:30,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 861.0 with 1 tasks
2019-06-11 09:33:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 861.0 (TID 575, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:30,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 861.0 (TID 575)
2019-06-11 09:33:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:30,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 861.0 (TID 575). 1009 bytes result sent to driver
2019-06-11 09:33:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 861.0 (TID 575) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 861.0, whose tasks have all completed, from pool 
2019-06-11 09:33:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 861 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:30,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 287 finished: print at Transform.scala:36, took 0.024095 s
2019-06-11 09:33:30,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:30,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 286 is 83 bytes
2019-06-11 09:33:30,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 287 is 160 bytes
2019-06-11 09:33:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 288 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 864 (print at Transform.scala:36)
2019-06-11 09:33:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 862, ShuffleMapStage 863)
2019-06-11 09:33:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 864 (MapPartitionsRDD[1009] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:30,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_432 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:30,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_432_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:30,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_432_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:30,037  INFO [org.apache.spark.SparkContext] - Created broadcast 432 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 864 (MapPartitionsRDD[1009] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:30,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 864.0 with 1 tasks
2019-06-11 09:33:30,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 864.0 (TID 576, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:30,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 864.0 (TID 576)
2019-06-11 09:33:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:30,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:33:30,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 864.0 (TID 576). 966 bytes result sent to driver
2019-06-11 09:33:30,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 864.0 (TID 576) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:30,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 864.0, whose tasks have all completed, from pool 
2019-06-11 09:33:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 864 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 288 finished: print at Transform.scala:36, took 0.006009 s
2019-06-11 09:33:30,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216810000 ms.0 from job set of time 1560216810000 ms
2019-06-11 09:33:30,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216810000 ms (execution: 0.034 s)
2019-06-11 09:33:30,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1002 from persistence list
2019-06-11 09:33:30,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1002
2019-06-11 09:33:30,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 997 from persistence list
2019-06-11 09:33:30,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 997
2019-06-11 09:33:30,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 996 from persistence list
2019-06-11 09:33:30,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 996
2019-06-11 09:33:30,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[996] at socketTextStream at Transform.scala:18 of time 1560216810000 ms
2019-06-11 09:33:30,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216800000 ms
2019-06-11 09:33:30,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216800000 ms
2019-06-11 09:33:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216815000 ms
2019-06-11 09:33:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216815000 ms.0 from job set of time 1560216815000 ms
2019-06-11 09:33:35,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1011 (map at Transform.scala:20)
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 289 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 867 (print at Transform.scala:36)
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 865, ShuffleMapStage 866)
2019-06-11 09:33:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 865)
2019-06-11 09:33:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 865 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:35,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_433 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_433_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:35,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_433_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 433 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 865 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 865.0 with 2 tasks
2019-06-11 09:33:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 865.0 (TID 577, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 865.0 (TID 577)
2019-06-11 09:33:35,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 865.0 (TID 577). 853 bytes result sent to driver
2019-06-11 09:33:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 865.0 (TID 578, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:35,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 865.0 (TID 578)
2019-06-11 09:33:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 865.0 (TID 577) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:35,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 865.0 (TID 578). 767 bytes result sent to driver
2019-06-11 09:33:35,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 865.0 (TID 578) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:35,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 865.0, whose tasks have all completed, from pool 
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 865 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 867)
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 867 (MapPartitionsRDD[1016] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:35,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_434 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:35,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_434_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:35,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_434_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:35,029  INFO [org.apache.spark.SparkContext] - Created broadcast 434 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 867 (MapPartitionsRDD[1016] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:35,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 867.0 with 1 tasks
2019-06-11 09:33:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 867.0 (TID 579, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:35,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 867.0 (TID 579)
2019-06-11 09:33:35,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:35,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:33:35,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 867.0 (TID 579). 1009 bytes result sent to driver
2019-06-11 09:33:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 867.0 (TID 579) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 867.0, whose tasks have all completed, from pool 
2019-06-11 09:33:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 867 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 289 finished: print at Transform.scala:36, took 0.024506 s
2019-06-11 09:33:35,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:35,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 289 is 160 bytes
2019-06-11 09:33:35,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 288 is 83 bytes
2019-06-11 09:33:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 290 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 870 (print at Transform.scala:36)
2019-06-11 09:33:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 868, ShuffleMapStage 869)
2019-06-11 09:33:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 870 (MapPartitionsRDD[1016] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:35,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_435 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_435_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:35,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_435_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:35,036  INFO [org.apache.spark.SparkContext] - Created broadcast 435 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 870 (MapPartitionsRDD[1016] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 870.0 with 1 tasks
2019-06-11 09:33:35,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 870.0 (TID 580, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:35,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 870.0 (TID 580)
2019-06-11 09:33:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:35,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 870.0 (TID 580). 1009 bytes result sent to driver
2019-06-11 09:33:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 870.0 (TID 580) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 870.0, whose tasks have all completed, from pool 
2019-06-11 09:33:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 870 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 290 finished: print at Transform.scala:36, took 0.006312 s
2019-06-11 09:33:35,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216815000 ms.0 from job set of time 1560216815000 ms
2019-06-11 09:33:35,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216815000 ms (execution: 0.035 s)
2019-06-11 09:33:35,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1009 from persistence list
2019-06-11 09:33:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1009
2019-06-11 09:33:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1004 from persistence list
2019-06-11 09:33:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1004
2019-06-11 09:33:35,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1003 from persistence list
2019-06-11 09:33:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1003
2019-06-11 09:33:35,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1003] at socketTextStream at Transform.scala:18 of time 1560216815000 ms
2019-06-11 09:33:35,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216805000 ms
2019-06-11 09:33:35,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216805000 ms
2019-06-11 09:33:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216820000 ms
2019-06-11 09:33:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216820000 ms.0 from job set of time 1560216820000 ms
2019-06-11 09:33:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1018 (map at Transform.scala:20)
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 291 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 873 (print at Transform.scala:36)
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 871, ShuffleMapStage 872)
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 872)
2019-06-11 09:33:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 872 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_436 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_436_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_436_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 436 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 872 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 872.0 with 2 tasks
2019-06-11 09:33:40,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 872.0 (TID 581, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 872.0 (TID 581)
2019-06-11 09:33:40,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 872.0 (TID 581). 810 bytes result sent to driver
2019-06-11 09:33:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 872.0 (TID 582, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:40,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 872.0 (TID 582)
2019-06-11 09:33:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 872.0 (TID 581) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:40,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 872.0 (TID 582). 810 bytes result sent to driver
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 872.0 (TID 582) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 872.0, whose tasks have all completed, from pool 
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 872 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 873)
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 873 (MapPartitionsRDD[1023] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:40,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_437 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:40,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_437_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:40,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_437_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:40,032  INFO [org.apache.spark.SparkContext] - Created broadcast 437 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 873 (MapPartitionsRDD[1023] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 873.0 with 1 tasks
2019-06-11 09:33:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 873.0 (TID 583, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:40,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 873.0 (TID 583)
2019-06-11 09:33:40,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:40,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:40,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:40,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:40,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 873.0 (TID 583). 1009 bytes result sent to driver
2019-06-11 09:33:40,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 873.0 (TID 583) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:40,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 873.0, whose tasks have all completed, from pool 
2019-06-11 09:33:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 873 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 291 finished: print at Transform.scala:36, took 0.026754 s
2019-06-11 09:33:40,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:40,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 290 is 83 bytes
2019-06-11 09:33:40,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 291 is 160 bytes
2019-06-11 09:33:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 292 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 876 (print at Transform.scala:36)
2019-06-11 09:33:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 874, ShuffleMapStage 875)
2019-06-11 09:33:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 876 (MapPartitionsRDD[1023] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:40,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_438 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:40,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_438_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:40,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_438_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:40,040  INFO [org.apache.spark.SparkContext] - Created broadcast 438 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 876 (MapPartitionsRDD[1023] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 876.0 with 1 tasks
2019-06-11 09:33:40,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 876.0 (TID 584, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:40,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 876.0 (TID 584)
2019-06-11 09:33:40,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:40,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:40,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:40,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:40,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 876.0 (TID 584). 966 bytes result sent to driver
2019-06-11 09:33:40,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 876.0 (TID 584) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:40,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 876.0, whose tasks have all completed, from pool 
2019-06-11 09:33:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 876 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:40,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 292 finished: print at Transform.scala:36, took 0.005082 s
2019-06-11 09:33:40,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216820000 ms.0 from job set of time 1560216820000 ms
2019-06-11 09:33:40,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216820000 ms (execution: 0.037 s)
2019-06-11 09:33:40,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1016 from persistence list
2019-06-11 09:33:40,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1016
2019-06-11 09:33:40,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1011 from persistence list
2019-06-11 09:33:40,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1011
2019-06-11 09:33:40,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1010 from persistence list
2019-06-11 09:33:40,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1010
2019-06-11 09:33:40,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1010] at socketTextStream at Transform.scala:18 of time 1560216820000 ms
2019-06-11 09:33:40,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216810000 ms
2019-06-11 09:33:40,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216810000 ms
2019-06-11 09:33:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216825000 ms
2019-06-11 09:33:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216825000 ms.0 from job set of time 1560216825000 ms
2019-06-11 09:33:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1025 (map at Transform.scala:20)
2019-06-11 09:33:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 293 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 879 (print at Transform.scala:36)
2019-06-11 09:33:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 877, ShuffleMapStage 878)
2019-06-11 09:33:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 877)
2019-06-11 09:33:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 877 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_439 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_439_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_439_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:45,011  INFO [org.apache.spark.SparkContext] - Created broadcast 439 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 877 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:45,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 877.0 with 2 tasks
2019-06-11 09:33:45,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 877.0 (TID 585, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 877.0 (TID 585)
2019-06-11 09:33:45,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 877.0 (TID 585). 810 bytes result sent to driver
2019-06-11 09:33:45,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 877.0 (TID 586, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:45,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 877.0 (TID 586)
2019-06-11 09:33:45,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 877.0 (TID 585) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:45,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 877.0 (TID 586). 810 bytes result sent to driver
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 877.0 (TID 586) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 877.0, whose tasks have all completed, from pool 
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 877 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 879)
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 879 (MapPartitionsRDD[1030] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_440 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:45,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_440_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:45,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_440_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:45,033  INFO [org.apache.spark.SparkContext] - Created broadcast 440 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 879 (MapPartitionsRDD[1030] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:45,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 879.0 with 1 tasks
2019-06-11 09:33:45,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 879.0 (TID 587, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:45,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 879.0 (TID 587)
2019-06-11 09:33:45,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:45,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:45,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:45,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:45,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 879.0 (TID 587). 966 bytes result sent to driver
2019-06-11 09:33:45,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 879.0 (TID 587) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:45,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 879.0, whose tasks have all completed, from pool 
2019-06-11 09:33:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 879 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 293 finished: print at Transform.scala:36, took 0.027183 s
2019-06-11 09:33:45,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:45,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 293 is 160 bytes
2019-06-11 09:33:45,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 292 is 83 bytes
2019-06-11 09:33:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 294 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 882 (print at Transform.scala:36)
2019-06-11 09:33:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 880, ShuffleMapStage 881)
2019-06-11 09:33:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 882 (MapPartitionsRDD[1030] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_441 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:45,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_441_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:45,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_441_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:45,040  INFO [org.apache.spark.SparkContext] - Created broadcast 441 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 882 (MapPartitionsRDD[1030] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:45,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 882.0 with 1 tasks
2019-06-11 09:33:45,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 882.0 (TID 588, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:45,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 882.0 (TID 588)
2019-06-11 09:33:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:45,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:45,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 882.0 (TID 588). 1009 bytes result sent to driver
2019-06-11 09:33:45,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 882.0 (TID 588) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:45,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 882.0, whose tasks have all completed, from pool 
2019-06-11 09:33:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 882 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 294 finished: print at Transform.scala:36, took 0.005338 s
2019-06-11 09:33:45,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216825000 ms.0 from job set of time 1560216825000 ms
2019-06-11 09:33:45,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216825000 ms (execution: 0.037 s)
2019-06-11 09:33:45,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1023 from persistence list
2019-06-11 09:33:45,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1023
2019-06-11 09:33:45,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1018 from persistence list
2019-06-11 09:33:45,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1018
2019-06-11 09:33:45,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1017 from persistence list
2019-06-11 09:33:45,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1017
2019-06-11 09:33:45,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1017] at socketTextStream at Transform.scala:18 of time 1560216825000 ms
2019-06-11 09:33:45,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216815000 ms
2019-06-11 09:33:45,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216815000 ms
2019-06-11 09:33:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216830000 ms
2019-06-11 09:33:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216830000 ms.0 from job set of time 1560216830000 ms
2019-06-11 09:33:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1032 (map at Transform.scala:20)
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 295 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 885 (print at Transform.scala:36)
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 883, ShuffleMapStage 884)
2019-06-11 09:33:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 883)
2019-06-11 09:33:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 883 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_442 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_442_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:33:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_442_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,010  INFO [org.apache.spark.SparkContext] - Created broadcast 442 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 883 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:50,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 883.0 with 2 tasks
2019-06-11 09:33:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 883.0 (TID 589, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 883.0 (TID 589)
2019-06-11 09:33:50,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 883.0 (TID 589). 810 bytes result sent to driver
2019-06-11 09:33:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 883.0 (TID 590, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:50,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 883.0 (TID 590)
2019-06-11 09:33:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 883.0 (TID 589) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:50,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 883.0 (TID 590). 767 bytes result sent to driver
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 883.0 (TID 590) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 883.0, whose tasks have all completed, from pool 
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 883 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 885)
2019-06-11 09:33:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 885 (MapPartitionsRDD[1037] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:50,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_443 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:33:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_443_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:33:50,037  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 291
2019-06-11 09:33:50,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_443_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_438_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,042  INFO [org.apache.spark.SparkContext] - Created broadcast 443 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:50,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 885 (MapPartitionsRDD[1037] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:50,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 885.0 with 1 tasks
2019-06-11 09:33:50,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 885.0 (TID 591, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:50,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_435_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 885.0 (TID 591)
2019-06-11 09:33:50,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 286
2019-06-11 09:33:50,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 285
2019-06-11 09:33:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_434_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:50,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_427_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 885.0 (TID 591). 1009 bytes result sent to driver
2019-06-11 09:33:50,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_437_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 885.0 (TID 591) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:50,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 885.0, whose tasks have all completed, from pool 
2019-06-11 09:33:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 885 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 295 finished: print at Transform.scala:36, took 0.038193 s
2019-06-11 09:33:50,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_433_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_428_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_431_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_441_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_430_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,052  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_439_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 295 is 160 bytes
2019-06-11 09:33:50,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 294 is 83 bytes
2019-06-11 09:33:50,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 288
2019-06-11 09:33:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 296 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 888 (print at Transform.scala:36)
2019-06-11 09:33:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 887, ShuffleMapStage 886)
2019-06-11 09:33:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:50,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 888 (MapPartitionsRDD[1037] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:50,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_432_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_444 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:50,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 282
2019-06-11 09:33:50,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 284
2019-06-11 09:33:50,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 290
2019-06-11 09:33:50,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_444_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:50,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_429_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_444_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 287
2019-06-11 09:33:50,055  INFO [org.apache.spark.SparkContext] - Created broadcast 444 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:50,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 888 (MapPartitionsRDD[1037] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:50,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 888.0 with 1 tasks
2019-06-11 09:33:50,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 888.0 (TID 592, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:50,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_440_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:50,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 888.0 (TID 592)
2019-06-11 09:33:50,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_436_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:50,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 289
2019-06-11 09:33:50,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 283
2019-06-11 09:33:50,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:50,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:50,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:50,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:50,059  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 888.0 (TID 592). 1009 bytes result sent to driver
2019-06-11 09:33:50,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 888.0 (TID 592) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:50,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 888.0, whose tasks have all completed, from pool 
2019-06-11 09:33:50,060  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 888 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:33:50,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 296 finished: print at Transform.scala:36, took 0.008085 s
2019-06-11 09:33:50,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216830000 ms.0 from job set of time 1560216830000 ms
2019-06-11 09:33:50,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.060 s for time 1560216830000 ms (execution: 0.054 s)
2019-06-11 09:33:50,060  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1030 from persistence list
2019-06-11 09:33:50,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1030
2019-06-11 09:33:50,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1025 from persistence list
2019-06-11 09:33:50,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1025
2019-06-11 09:33:50,061  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1024 from persistence list
2019-06-11 09:33:50,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1024
2019-06-11 09:33:50,061  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1024] at socketTextStream at Transform.scala:18 of time 1560216830000 ms
2019-06-11 09:33:50,061  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216820000 ms
2019-06-11 09:33:50,061  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216820000 ms
2019-06-11 09:33:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216835000 ms
2019-06-11 09:33:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216835000 ms.0 from job set of time 1560216835000 ms
2019-06-11 09:33:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1039 (map at Transform.scala:20)
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 297 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 891 (print at Transform.scala:36)
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 889, ShuffleMapStage 890)
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 890)
2019-06-11 09:33:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 890 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:33:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_445 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_445_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:33:55,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_445_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:33:55,010  INFO [org.apache.spark.SparkContext] - Created broadcast 445 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 890 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:33:55,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 890.0 with 2 tasks
2019-06-11 09:33:55,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 890.0 (TID 593, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:55,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 890.0 (TID 593)
2019-06-11 09:33:55,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 890.0 (TID 593). 853 bytes result sent to driver
2019-06-11 09:33:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 890.0 (TID 594, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:33:55,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 890.0 (TID 594)
2019-06-11 09:33:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 890.0 (TID 593) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:33:55,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 890.0 (TID 594). 810 bytes result sent to driver
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 890.0 (TID 594) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 890.0, whose tasks have all completed, from pool 
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 890 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 891)
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:33:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 891 (MapPartitionsRDD[1044] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:55,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_446 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:55,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_446_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:55,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_446_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:55,032  INFO [org.apache.spark.SparkContext] - Created broadcast 446 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 891 (MapPartitionsRDD[1044] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:33:55,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 891.0 with 1 tasks
2019-06-11 09:33:55,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 891.0 (TID 595, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:55,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 891.0 (TID 595)
2019-06-11 09:33:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:55,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:55,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 891.0 (TID 595). 966 bytes result sent to driver
2019-06-11 09:33:55,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 891.0 (TID 595) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:55,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 891.0, whose tasks have all completed, from pool 
2019-06-11 09:33:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 891 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:33:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 297 finished: print at Transform.scala:36, took 0.026627 s
2019-06-11 09:33:55,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:33:55,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 296 is 83 bytes
2019-06-11 09:33:55,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 297 is 160 bytes
2019-06-11 09:33:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 298 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:33:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 894 (print at Transform.scala:36)
2019-06-11 09:33:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 892, ShuffleMapStage 893)
2019-06-11 09:33:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:33:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 894 (MapPartitionsRDD[1044] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:33:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_447 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:33:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_447_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:33:55,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_447_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:33:55,040  INFO [org.apache.spark.SparkContext] - Created broadcast 447 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:33:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 894 (MapPartitionsRDD[1044] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:33:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 894.0 with 1 tasks
2019-06-11 09:33:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 894.0 (TID 596, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:33:55,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 894.0 (TID 596)
2019-06-11 09:33:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:33:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:33:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:33:55,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 894.0 (TID 596). 1009 bytes result sent to driver
2019-06-11 09:33:55,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 894.0 (TID 596) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:33:55,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 894.0, whose tasks have all completed, from pool 
2019-06-11 09:33:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 894 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:33:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 298 finished: print at Transform.scala:36, took 0.005106 s
2019-06-11 09:33:55,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216835000 ms.0 from job set of time 1560216835000 ms
2019-06-11 09:33:55,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216835000 ms (execution: 0.037 s)
2019-06-11 09:33:55,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1037 from persistence list
2019-06-11 09:33:55,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1037
2019-06-11 09:33:55,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1032 from persistence list
2019-06-11 09:33:55,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1032
2019-06-11 09:33:55,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1031 from persistence list
2019-06-11 09:33:55,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1031
2019-06-11 09:33:55,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1031] at socketTextStream at Transform.scala:18 of time 1560216835000 ms
2019-06-11 09:33:55,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216825000 ms
2019-06-11 09:33:55,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216825000 ms
2019-06-11 09:34:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216840000 ms
2019-06-11 09:34:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216840000 ms.0 from job set of time 1560216840000 ms
2019-06-11 09:34:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1046 (map at Transform.scala:20)
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 299 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 897 (print at Transform.scala:36)
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 895, ShuffleMapStage 896)
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 896)
2019-06-11 09:34:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 896 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_448 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_448_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:00,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_448_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:00,013  INFO [org.apache.spark.SparkContext] - Created broadcast 448 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 896 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:00,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 896.0 with 2 tasks
2019-06-11 09:34:00,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 896.0 (TID 597, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:00,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 896.0 (TID 597)
2019-06-11 09:34:00,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 896.0 (TID 597). 810 bytes result sent to driver
2019-06-11 09:34:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 896.0 (TID 598, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:00,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 896.0 (TID 598)
2019-06-11 09:34:00,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 896.0 (TID 597) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 896.0 (TID 598). 767 bytes result sent to driver
2019-06-11 09:34:00,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 896.0 (TID 598) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:00,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 896.0, whose tasks have all completed, from pool 
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 896 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 897)
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 897 (MapPartitionsRDD[1051] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_449 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_449_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:00,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_449_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:00,032  INFO [org.apache.spark.SparkContext] - Created broadcast 449 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 897 (MapPartitionsRDD[1051] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 897.0 with 1 tasks
2019-06-11 09:34:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 897.0 (TID 599, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:00,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 897.0 (TID 599)
2019-06-11 09:34:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:00,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 897.0 (TID 599). 966 bytes result sent to driver
2019-06-11 09:34:00,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 897.0 (TID 599) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:00,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 897.0, whose tasks have all completed, from pool 
2019-06-11 09:34:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 897 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 299 finished: print at Transform.scala:36, took 0.024233 s
2019-06-11 09:34:00,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 298 is 83 bytes
2019-06-11 09:34:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 299 is 160 bytes
2019-06-11 09:34:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 300 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 900 (print at Transform.scala:36)
2019-06-11 09:34:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 898, ShuffleMapStage 899)
2019-06-11 09:34:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 900 (MapPartitionsRDD[1051] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_450 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_450_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:00,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_450_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:00,040  INFO [org.apache.spark.SparkContext] - Created broadcast 450 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 900 (MapPartitionsRDD[1051] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 900.0 with 1 tasks
2019-06-11 09:34:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 900.0 (TID 600, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:00,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 900.0 (TID 600)
2019-06-11 09:34:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:00,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 900.0 (TID 600). 1009 bytes result sent to driver
2019-06-11 09:34:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 900.0 (TID 600) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:00,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 900.0, whose tasks have all completed, from pool 
2019-06-11 09:34:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 900 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 300 finished: print at Transform.scala:36, took 0.006041 s
2019-06-11 09:34:00,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216840000 ms.0 from job set of time 1560216840000 ms
2019-06-11 09:34:00,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216840000 ms (execution: 0.035 s)
2019-06-11 09:34:00,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1044 from persistence list
2019-06-11 09:34:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1044
2019-06-11 09:34:00,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1039 from persistence list
2019-06-11 09:34:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1039
2019-06-11 09:34:00,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1038 from persistence list
2019-06-11 09:34:00,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1038
2019-06-11 09:34:00,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1038] at socketTextStream at Transform.scala:18 of time 1560216840000 ms
2019-06-11 09:34:00,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216830000 ms
2019-06-11 09:34:00,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216830000 ms
2019-06-11 09:34:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216845000 ms
2019-06-11 09:34:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216845000 ms.0 from job set of time 1560216845000 ms
2019-06-11 09:34:05,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1053 (map at Transform.scala:20)
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 301 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 903 (print at Transform.scala:36)
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 901, ShuffleMapStage 902)
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 902)
2019-06-11 09:34:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 902 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:05,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_451 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_451_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:34:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_451_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 451 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 902 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 902.0 with 2 tasks
2019-06-11 09:34:05,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 902.0 (TID 601, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:05,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 902.0 (TID 601)
2019-06-11 09:34:05,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 902.0 (TID 601). 853 bytes result sent to driver
2019-06-11 09:34:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 902.0 (TID 602, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 902.0 (TID 602)
2019-06-11 09:34:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 902.0 (TID 601) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:05,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 902.0 (TID 602). 810 bytes result sent to driver
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 902.0 (TID 602) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 902.0, whose tasks have all completed, from pool 
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 902 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 903)
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 903 (MapPartitionsRDD[1058] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_452 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_452_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_452_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:05,029  INFO [org.apache.spark.SparkContext] - Created broadcast 452 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 903 (MapPartitionsRDD[1058] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:05,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 903.0 with 1 tasks
2019-06-11 09:34:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 903.0 (TID 603, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:05,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 903.0 (TID 603)
2019-06-11 09:34:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 903.0 (TID 603). 1052 bytes result sent to driver
2019-06-11 09:34:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 903.0 (TID 603) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:05,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 903.0, whose tasks have all completed, from pool 
2019-06-11 09:34:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 903 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 301 finished: print at Transform.scala:36, took 0.025118 s
2019-06-11 09:34:05,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:05,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 300 is 83 bytes
2019-06-11 09:34:05,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 301 is 160 bytes
2019-06-11 09:34:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 302 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 906 (print at Transform.scala:36)
2019-06-11 09:34:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 905, ShuffleMapStage 904)
2019-06-11 09:34:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 906 (MapPartitionsRDD[1058] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:05,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_453 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_453_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:05,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_453_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:05,036  INFO [org.apache.spark.SparkContext] - Created broadcast 453 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 906 (MapPartitionsRDD[1058] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 906.0 with 1 tasks
2019-06-11 09:34:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 906.0 (TID 604, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:05,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 906.0 (TID 604)
2019-06-11 09:34:05,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:05,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:05,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 906.0 (TID 604). 966 bytes result sent to driver
2019-06-11 09:34:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 906.0 (TID 604) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 906.0, whose tasks have all completed, from pool 
2019-06-11 09:34:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 906 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 302 finished: print at Transform.scala:36, took 0.006138 s
2019-06-11 09:34:05,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216845000 ms.0 from job set of time 1560216845000 ms
2019-06-11 09:34:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216845000 ms (execution: 0.034 s)
2019-06-11 09:34:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1051 from persistence list
2019-06-11 09:34:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1051
2019-06-11 09:34:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1046 from persistence list
2019-06-11 09:34:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1046
2019-06-11 09:34:05,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1045 from persistence list
2019-06-11 09:34:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1045
2019-06-11 09:34:05,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1045] at socketTextStream at Transform.scala:18 of time 1560216845000 ms
2019-06-11 09:34:05,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216835000 ms
2019-06-11 09:34:05,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216835000 ms
2019-06-11 09:34:10,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216850000 ms
2019-06-11 09:34:10,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216850000 ms.0 from job set of time 1560216850000 ms
2019-06-11 09:34:10,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1060 (map at Transform.scala:20)
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 303 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 909 (print at Transform.scala:36)
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 907, ShuffleMapStage 908)
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 908)
2019-06-11 09:34:10,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 908 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:10,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_454 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:10,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_454_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:34:10,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_454_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:10,016  INFO [org.apache.spark.SparkContext] - Created broadcast 454 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:10,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 908 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:10,017  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 908.0 with 2 tasks
2019-06-11 09:34:10,017  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 908.0 (TID 605, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:10,017  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 908.0 (TID 605)
2019-06-11 09:34:10,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 908.0 (TID 605). 853 bytes result sent to driver
2019-06-11 09:34:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 908.0 (TID 606, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:10,031  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 908.0 (TID 606)
2019-06-11 09:34:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 908.0 (TID 605) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:10,041  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 908.0 (TID 606). 767 bytes result sent to driver
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 908.0 (TID 606) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 908.0, whose tasks have all completed, from pool 
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 908 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 909)
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 909 (MapPartitionsRDD[1065] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:10,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_455 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_455_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:10,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_455_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:10,043  INFO [org.apache.spark.SparkContext] - Created broadcast 455 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 909 (MapPartitionsRDD[1065] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:10,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 909.0 with 1 tasks
2019-06-11 09:34:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 909.0 (TID 607, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:10,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 909.0 (TID 607)
2019-06-11 09:34:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:10,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 909.0 (TID 607). 966 bytes result sent to driver
2019-06-11 09:34:10,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 909.0 (TID 607) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:10,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 909.0, whose tasks have all completed, from pool 
2019-06-11 09:34:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 909 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:10,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 303 finished: print at Transform.scala:36, took 0.031049 s
2019-06-11 09:34:10,049  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:10,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 302 is 83 bytes
2019-06-11 09:34:10,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 303 is 160 bytes
2019-06-11 09:34:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 304 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 912 (print at Transform.scala:36)
2019-06-11 09:34:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 910, ShuffleMapStage 911)
2019-06-11 09:34:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 912 (MapPartitionsRDD[1065] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:10,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_456 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:10,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_456_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:10,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_456_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:10,052  INFO [org.apache.spark.SparkContext] - Created broadcast 456 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:10,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 912 (MapPartitionsRDD[1065] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:10,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 912.0 with 1 tasks
2019-06-11 09:34:10,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 912.0 (TID 608, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:10,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 912.0 (TID 608)
2019-06-11 09:34:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:10,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 912.0 (TID 608). 966 bytes result sent to driver
2019-06-11 09:34:10,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 912.0 (TID 608) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:10,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 912.0, whose tasks have all completed, from pool 
2019-06-11 09:34:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 912 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 304 finished: print at Transform.scala:36, took 0.005581 s
2019-06-11 09:34:10,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216850000 ms.0 from job set of time 1560216850000 ms
2019-06-11 09:34:10,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560216850000 ms (execution: 0.043 s)
2019-06-11 09:34:10,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1058 from persistence list
2019-06-11 09:34:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1058
2019-06-11 09:34:10,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1053 from persistence list
2019-06-11 09:34:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1053
2019-06-11 09:34:10,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1052 from persistence list
2019-06-11 09:34:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1052
2019-06-11 09:34:10,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1052] at socketTextStream at Transform.scala:18 of time 1560216850000 ms
2019-06-11 09:34:10,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216840000 ms
2019-06-11 09:34:10,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216840000 ms
2019-06-11 09:34:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216855000 ms
2019-06-11 09:34:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216855000 ms.0 from job set of time 1560216855000 ms
2019-06-11 09:34:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1067 (map at Transform.scala:20)
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 305 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 915 (print at Transform.scala:36)
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 913, ShuffleMapStage 914)
2019-06-11 09:34:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 914)
2019-06-11 09:34:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 914 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_457 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_457_piece0 stored as bytes in memory (estimated size 1310.0 B, free 1989.3 MB)
2019-06-11 09:34:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_457_piece0 in memory on 192.168.91.1:63518 (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 457 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 914 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 914.0 with 2 tasks
2019-06-11 09:34:15,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 914.0 (TID 609, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 914.0 (TID 609)
2019-06-11 09:34:15,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 914.0 (TID 609). 810 bytes result sent to driver
2019-06-11 09:34:15,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 914.0 (TID 610, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:15,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 914.0 (TID 610)
2019-06-11 09:34:15,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 914.0 (TID 609) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:15,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 914.0 (TID 610). 767 bytes result sent to driver
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 914.0 (TID 610) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 914.0, whose tasks have all completed, from pool 
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 914 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 915)
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:15,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 915 (MapPartitionsRDD[1072] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:15,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_458 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:15,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_458_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:15,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_458_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,030  INFO [org.apache.spark.SparkContext] - Created broadcast 458 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 915 (MapPartitionsRDD[1072] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 915.0 with 1 tasks
2019-06-11 09:34:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 915.0 (TID 611, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:15,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 915.0 (TID 611)
2019-06-11 09:34:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:15,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 915.0 (TID 611). 1052 bytes result sent to driver
2019-06-11 09:34:15,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 915.0 (TID 611) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:15,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 915.0, whose tasks have all completed, from pool 
2019-06-11 09:34:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 915 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 305 finished: print at Transform.scala:36, took 0.023944 s
2019-06-11 09:34:15,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:15,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 304 is 83 bytes
2019-06-11 09:34:15,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 305 is 160 bytes
2019-06-11 09:34:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 306 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 918 (print at Transform.scala:36)
2019-06-11 09:34:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 916, ShuffleMapStage 917)
2019-06-11 09:34:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 918 (MapPartitionsRDD[1072] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_459 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:15,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_459_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:15,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_451_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_459_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,048  INFO [org.apache.spark.SparkContext] - Created broadcast 459 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:15,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 292
2019-06-11 09:34:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 918 (MapPartitionsRDD[1072] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:15,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 918.0 with 1 tasks
2019-06-11 09:34:15,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_443_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 918.0 (TID 612, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:15,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 918.0 (TID 612)
2019-06-11 09:34:15,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_449_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:15,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:34:15,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_446_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_444_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 918.0 (TID 612). 966 bytes result sent to driver
2019-06-11 09:34:15,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 918.0 (TID 612) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:15,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 918.0, whose tasks have all completed, from pool 
2019-06-11 09:34:15,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_452_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 918 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:15,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 306 finished: print at Transform.scala:36, took 0.017249 s
2019-06-11 09:34:15,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216855000 ms.0 from job set of time 1560216855000 ms
2019-06-11 09:34:15,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560216855000 ms (execution: 0.046 s)
2019-06-11 09:34:15,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1065 from persistence list
2019-06-11 09:34:15,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 299
2019-06-11 09:34:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1065
2019-06-11 09:34:15,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 297
2019-06-11 09:34:15,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1060 from persistence list
2019-06-11 09:34:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1060
2019-06-11 09:34:15,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1059 from persistence list
2019-06-11 09:34:15,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1059
2019-06-11 09:34:15,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1059] at socketTextStream at Transform.scala:18 of time 1560216855000 ms
2019-06-11 09:34:15,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216845000 ms
2019-06-11 09:34:15,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_450_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216845000 ms
2019-06-11 09:34:15,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_458_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 296
2019-06-11 09:34:15,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_448_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_445_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_455_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_442_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 300
2019-06-11 09:34:15,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 293
2019-06-11 09:34:15,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 301
2019-06-11 09:34:15,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_454_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_456_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_457_piece0 on 192.168.91.1:63518 in memory (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:34:15,059  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 295
2019-06-11 09:34:15,059  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 298
2019-06-11 09:34:15,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_447_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:15,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 294
2019-06-11 09:34:15,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_453_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216860000 ms
2019-06-11 09:34:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216860000 ms.0 from job set of time 1560216860000 ms
2019-06-11 09:34:20,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1074 (map at Transform.scala:20)
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 307 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 921 (print at Transform.scala:36)
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 919, ShuffleMapStage 920)
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 919)
2019-06-11 09:34:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 919 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_460 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_460_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:20,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_460_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:20,010  INFO [org.apache.spark.SparkContext] - Created broadcast 460 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 919 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 919.0 with 2 tasks
2019-06-11 09:34:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 919.0 (TID 613, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 919.0 (TID 613)
2019-06-11 09:34:20,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 919.0 (TID 613). 853 bytes result sent to driver
2019-06-11 09:34:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 919.0 (TID 614, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 919.0 (TID 614)
2019-06-11 09:34:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 919.0 (TID 613) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:20,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 919.0 (TID 614). 767 bytes result sent to driver
2019-06-11 09:34:20,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 919.0 (TID 614) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:20,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 919.0, whose tasks have all completed, from pool 
2019-06-11 09:34:20,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 919 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:34:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 921)
2019-06-11 09:34:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 921 (MapPartitionsRDD[1079] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_461 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_461_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:20,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_461_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:20,029  INFO [org.apache.spark.SparkContext] - Created broadcast 461 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 921 (MapPartitionsRDD[1079] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:20,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 921.0 with 1 tasks
2019-06-11 09:34:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 921.0 (TID 615, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 921.0 (TID 615)
2019-06-11 09:34:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 921.0 (TID 615). 1009 bytes result sent to driver
2019-06-11 09:34:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 921.0 (TID 615) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 921.0, whose tasks have all completed, from pool 
2019-06-11 09:34:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 921 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:34:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 307 finished: print at Transform.scala:36, took 0.023936 s
2019-06-11 09:34:20,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 307 is 160 bytes
2019-06-11 09:34:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 306 is 83 bytes
2019-06-11 09:34:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 308 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 924 (print at Transform.scala:36)
2019-06-11 09:34:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 922, ShuffleMapStage 923)
2019-06-11 09:34:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 924 (MapPartitionsRDD[1079] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:20,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_462 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_462_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:20,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_462_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:20,037  INFO [org.apache.spark.SparkContext] - Created broadcast 462 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 924 (MapPartitionsRDD[1079] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 924.0 with 1 tasks
2019-06-11 09:34:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 924.0 (TID 616, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:20,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 924.0 (TID 616)
2019-06-11 09:34:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:20,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 924.0 (TID 616). 966 bytes result sent to driver
2019-06-11 09:34:20,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 924.0 (TID 616) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 924.0, whose tasks have all completed, from pool 
2019-06-11 09:34:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 924 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 308 finished: print at Transform.scala:36, took 0.004665 s
2019-06-11 09:34:20,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216860000 ms.0 from job set of time 1560216860000 ms
2019-06-11 09:34:20,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216860000 ms (execution: 0.034 s)
2019-06-11 09:34:20,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1072 from persistence list
2019-06-11 09:34:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1072
2019-06-11 09:34:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1067 from persistence list
2019-06-11 09:34:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1067
2019-06-11 09:34:20,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1066 from persistence list
2019-06-11 09:34:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1066
2019-06-11 09:34:20,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1066] at socketTextStream at Transform.scala:18 of time 1560216860000 ms
2019-06-11 09:34:20,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216850000 ms
2019-06-11 09:34:20,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216850000 ms
2019-06-11 09:34:25,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216865000 ms
2019-06-11 09:34:25,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216865000 ms.0 from job set of time 1560216865000 ms
2019-06-11 09:34:25,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1081 (map at Transform.scala:20)
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 309 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 927 (print at Transform.scala:36)
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 925, ShuffleMapStage 926)
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 925)
2019-06-11 09:34:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 925 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:25,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_463 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:25,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_463_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:25,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_463_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:25,014  INFO [org.apache.spark.SparkContext] - Created broadcast 463 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:25,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 925 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:25,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 925.0 with 2 tasks
2019-06-11 09:34:25,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 925.0 (TID 617, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:25,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 925.0 (TID 617)
2019-06-11 09:34:25,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 925.0 (TID 617). 810 bytes result sent to driver
2019-06-11 09:34:25,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 925.0 (TID 618, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:25,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 925.0 (TID 618)
2019-06-11 09:34:25,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 925.0 (TID 617) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 925.0 (TID 618). 853 bytes result sent to driver
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 925.0 (TID 618) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 925.0, whose tasks have all completed, from pool 
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 925 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 927)
2019-06-11 09:34:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 927 (MapPartitionsRDD[1086] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:25,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_464 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:25,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_464_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:25,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_464_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:25,034  INFO [org.apache.spark.SparkContext] - Created broadcast 464 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 927 (MapPartitionsRDD[1086] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:25,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 927.0 with 1 tasks
2019-06-11 09:34:25,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 927.0 (TID 619, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:25,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 927.0 (TID 619)
2019-06-11 09:34:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:25,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 927.0 (TID 619). 966 bytes result sent to driver
2019-06-11 09:34:25,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 927.0 (TID 619) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:25,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 927.0, whose tasks have all completed, from pool 
2019-06-11 09:34:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 927 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 309 finished: print at Transform.scala:36, took 0.025102 s
2019-06-11 09:34:25,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 309 is 160 bytes
2019-06-11 09:34:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 308 is 83 bytes
2019-06-11 09:34:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 310 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 930 (print at Transform.scala:36)
2019-06-11 09:34:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 928, ShuffleMapStage 929)
2019-06-11 09:34:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 930 (MapPartitionsRDD[1086] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:25,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_465 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:25,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_465_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:25,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_465_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:25,041  INFO [org.apache.spark.SparkContext] - Created broadcast 465 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 930 (MapPartitionsRDD[1086] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 930.0 with 1 tasks
2019-06-11 09:34:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 930.0 (TID 620, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:25,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 930.0 (TID 620)
2019-06-11 09:34:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:25,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 930.0 (TID 620). 966 bytes result sent to driver
2019-06-11 09:34:25,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 930.0 (TID 620) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:25,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 930.0, whose tasks have all completed, from pool 
2019-06-11 09:34:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 930 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 310 finished: print at Transform.scala:36, took 0.004776 s
2019-06-11 09:34:25,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216865000 ms.0 from job set of time 1560216865000 ms
2019-06-11 09:34:25,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216865000 ms (execution: 0.034 s)
2019-06-11 09:34:25,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1079 from persistence list
2019-06-11 09:34:25,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1079
2019-06-11 09:34:25,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1074 from persistence list
2019-06-11 09:34:25,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1074
2019-06-11 09:34:25,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1073 from persistence list
2019-06-11 09:34:25,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1073
2019-06-11 09:34:25,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1073] at socketTextStream at Transform.scala:18 of time 1560216865000 ms
2019-06-11 09:34:25,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216855000 ms
2019-06-11 09:34:25,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216855000 ms
2019-06-11 09:34:30,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216870000 ms
2019-06-11 09:34:30,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216870000 ms.0 from job set of time 1560216870000 ms
2019-06-11 09:34:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1088 (map at Transform.scala:20)
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 311 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 933 (print at Transform.scala:36)
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 931, ShuffleMapStage 932)
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 931)
2019-06-11 09:34:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 931 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:30,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_466 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_466_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:30,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_466_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:30,010  INFO [org.apache.spark.SparkContext] - Created broadcast 466 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 931 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:30,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 931.0 with 2 tasks
2019-06-11 09:34:30,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 931.0 (TID 621, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:30,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 931.0 (TID 621)
2019-06-11 09:34:30,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 931.0 (TID 621). 853 bytes result sent to driver
2019-06-11 09:34:30,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 931.0 (TID 622, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:30,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 931.0 (TID 622)
2019-06-11 09:34:30,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 931.0 (TID 621) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:30,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 931.0 (TID 622). 767 bytes result sent to driver
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 931.0 (TID 622) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 931.0, whose tasks have all completed, from pool 
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 931 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 933)
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:30,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 933 (MapPartitionsRDD[1093] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:30,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_467 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:30,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_467_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:30,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_467_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:30,029  INFO [org.apache.spark.SparkContext] - Created broadcast 467 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 933 (MapPartitionsRDD[1093] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:30,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 933.0 with 1 tasks
2019-06-11 09:34:30,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 933.0 (TID 623, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:30,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 933.0 (TID 623)
2019-06-11 09:34:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:30,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:30,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 933.0 (TID 623). 1009 bytes result sent to driver
2019-06-11 09:34:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 933.0 (TID 623) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 933.0, whose tasks have all completed, from pool 
2019-06-11 09:34:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 933 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 311 finished: print at Transform.scala:36, took 0.023357 s
2019-06-11 09:34:30,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:30,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 311 is 160 bytes
2019-06-11 09:34:30,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 310 is 83 bytes
2019-06-11 09:34:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 312 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 936 (print at Transform.scala:36)
2019-06-11 09:34:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 934, ShuffleMapStage 935)
2019-06-11 09:34:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 936 (MapPartitionsRDD[1093] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:30,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_468 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:30,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_468_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:30,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_468_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:30,035  INFO [org.apache.spark.SparkContext] - Created broadcast 468 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 936 (MapPartitionsRDD[1093] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:30,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 936.0 with 1 tasks
2019-06-11 09:34:30,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 936.0 (TID 624, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:30,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 936.0 (TID 624)
2019-06-11 09:34:30,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:30,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:30,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:30,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:30,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 936.0 (TID 624). 966 bytes result sent to driver
2019-06-11 09:34:30,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 936.0 (TID 624) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:30,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 936.0, whose tasks have all completed, from pool 
2019-06-11 09:34:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 936 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 312 finished: print at Transform.scala:36, took 0.004853 s
2019-06-11 09:34:30,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216870000 ms.0 from job set of time 1560216870000 ms
2019-06-11 09:34:30,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560216870000 ms (execution: 0.033 s)
2019-06-11 09:34:30,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1086 from persistence list
2019-06-11 09:34:30,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1086
2019-06-11 09:34:30,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1081 from persistence list
2019-06-11 09:34:30,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1081
2019-06-11 09:34:30,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1080 from persistence list
2019-06-11 09:34:30,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1080
2019-06-11 09:34:30,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1080] at socketTextStream at Transform.scala:18 of time 1560216870000 ms
2019-06-11 09:34:30,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216860000 ms
2019-06-11 09:34:30,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216860000 ms
2019-06-11 09:34:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216875000 ms
2019-06-11 09:34:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216875000 ms.0 from job set of time 1560216875000 ms
2019-06-11 09:34:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1095 (map at Transform.scala:20)
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 313 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 939 (print at Transform.scala:36)
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 938, ShuffleMapStage 937)
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 937)
2019-06-11 09:34:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 937 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_469 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_469_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:34:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_469_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 469 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 937 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:35,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 937.0 with 2 tasks
2019-06-11 09:34:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 937.0 (TID 625, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:35,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 937.0 (TID 625)
2019-06-11 09:34:35,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 937.0 (TID 625). 853 bytes result sent to driver
2019-06-11 09:34:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 937.0 (TID 626, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:35,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 937.0 (TID 626)
2019-06-11 09:34:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 937.0 (TID 625) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:35,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 937.0 (TID 626). 810 bytes result sent to driver
2019-06-11 09:34:35,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 937.0 (TID 626) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:35,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 937.0, whose tasks have all completed, from pool 
2019-06-11 09:34:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 937 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:34:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 939)
2019-06-11 09:34:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 939 (MapPartitionsRDD[1100] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:35,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_470 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:35,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_470_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:35,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_470_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:35,030  INFO [org.apache.spark.SparkContext] - Created broadcast 470 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 939 (MapPartitionsRDD[1100] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:35,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 939.0 with 1 tasks
2019-06-11 09:34:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 939.0 (TID 627, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:35,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 939.0 (TID 627)
2019-06-11 09:34:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:35,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 939.0 (TID 627). 966 bytes result sent to driver
2019-06-11 09:34:35,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 939.0 (TID 627) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:35,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 939.0, whose tasks have all completed, from pool 
2019-06-11 09:34:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 939 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 313 finished: print at Transform.scala:36, took 0.024361 s
2019-06-11 09:34:35,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:35,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 313 is 160 bytes
2019-06-11 09:34:35,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 312 is 83 bytes
2019-06-11 09:34:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 314 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 942 (print at Transform.scala:36)
2019-06-11 09:34:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 940, ShuffleMapStage 941)
2019-06-11 09:34:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 942 (MapPartitionsRDD[1100] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_471 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_471_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_471_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:35,037  INFO [org.apache.spark.SparkContext] - Created broadcast 471 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 942 (MapPartitionsRDD[1100] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 942.0 with 1 tasks
2019-06-11 09:34:35,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 942.0 (TID 628, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:35,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 942.0 (TID 628)
2019-06-11 09:34:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:35,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 942.0 (TID 628). 1009 bytes result sent to driver
2019-06-11 09:34:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 942.0 (TID 628) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 942.0, whose tasks have all completed, from pool 
2019-06-11 09:34:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 942 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 314 finished: print at Transform.scala:36, took 0.005423 s
2019-06-11 09:34:35,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216875000 ms.0 from job set of time 1560216875000 ms
2019-06-11 09:34:35,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216875000 ms (execution: 0.034 s)
2019-06-11 09:34:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1093 from persistence list
2019-06-11 09:34:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1093
2019-06-11 09:34:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1088 from persistence list
2019-06-11 09:34:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1088
2019-06-11 09:34:35,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1087 from persistence list
2019-06-11 09:34:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1087
2019-06-11 09:34:35,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1087] at socketTextStream at Transform.scala:18 of time 1560216875000 ms
2019-06-11 09:34:35,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216865000 ms
2019-06-11 09:34:35,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216865000 ms
2019-06-11 09:34:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216880000 ms
2019-06-11 09:34:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216880000 ms.0 from job set of time 1560216880000 ms
2019-06-11 09:34:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1102 (map at Transform.scala:20)
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 315 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 945 (print at Transform.scala:36)
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 943, ShuffleMapStage 944)
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 943)
2019-06-11 09:34:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 943 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_472 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_472_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:34:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_472_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 472 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 943 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 943.0 with 2 tasks
2019-06-11 09:34:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 943.0 (TID 629, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 943.0 (TID 629)
2019-06-11 09:34:40,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 943.0 (TID 629). 810 bytes result sent to driver
2019-06-11 09:34:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 943.0 (TID 630, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 943.0 (TID 630)
2019-06-11 09:34:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 943.0 (TID 629) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:40,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 943.0 (TID 630). 810 bytes result sent to driver
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 943.0 (TID 630) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 943.0, whose tasks have all completed, from pool 
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 943 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 945)
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 945 (MapPartitionsRDD[1107] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_473 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_473_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:40,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_473_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:40,030  INFO [org.apache.spark.SparkContext] - Created broadcast 473 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 945 (MapPartitionsRDD[1107] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 945.0 with 1 tasks
2019-06-11 09:34:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 945.0 (TID 631, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:40,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 945.0 (TID 631)
2019-06-11 09:34:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 945.0 (TID 631). 966 bytes result sent to driver
2019-06-11 09:34:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 945.0 (TID 631) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 945.0, whose tasks have all completed, from pool 
2019-06-11 09:34:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 945 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 315 finished: print at Transform.scala:36, took 0.024030 s
2019-06-11 09:34:40,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 315 is 160 bytes
2019-06-11 09:34:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 314 is 83 bytes
2019-06-11 09:34:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 316 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 948 (print at Transform.scala:36)
2019-06-11 09:34:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 946, ShuffleMapStage 947)
2019-06-11 09:34:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 948 (MapPartitionsRDD[1107] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_474 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:34:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_474_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:34:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_474_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 474 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 948 (MapPartitionsRDD[1107] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 948.0 with 1 tasks
2019-06-11 09:34:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 948.0 (TID 632, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 948.0 (TID 632)
2019-06-11 09:34:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:40,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 948.0 (TID 632). 1009 bytes result sent to driver
2019-06-11 09:34:40,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 948.0 (TID 632) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 948.0, whose tasks have all completed, from pool 
2019-06-11 09:34:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 948 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 316 finished: print at Transform.scala:36, took 0.006206 s
2019-06-11 09:34:40,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216880000 ms.0 from job set of time 1560216880000 ms
2019-06-11 09:34:40,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216880000 ms (execution: 0.036 s)
2019-06-11 09:34:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1100 from persistence list
2019-06-11 09:34:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1100
2019-06-11 09:34:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1095 from persistence list
2019-06-11 09:34:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1095
2019-06-11 09:34:40,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1094 from persistence list
2019-06-11 09:34:40,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1094
2019-06-11 09:34:40,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1094] at socketTextStream at Transform.scala:18 of time 1560216880000 ms
2019-06-11 09:34:40,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216870000 ms
2019-06-11 09:34:40,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216870000 ms
2019-06-11 09:34:45,009  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 306
2019-06-11 09:34:45,012  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 307
2019-06-11 09:34:45,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_472_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_474_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_464_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,018  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216885000 ms
2019-06-11 09:34:45,018  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216885000 ms.0 from job set of time 1560216885000 ms
2019-06-11 09:34:45,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_463_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 303
2019-06-11 09:34:45,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_470_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_473_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_460_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_467_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,022  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:45,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_461_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1109 (map at Transform.scala:20)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 317 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 951 (print at Transform.scala:36)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 949, ShuffleMapStage 950)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 950)
2019-06-11 09:34:45,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_465_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 950 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:45,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 304
2019-06-11 09:34:45,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 309
2019-06-11 09:34:45,024  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_475 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:45,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 310
2019-06-11 09:34:45,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_459_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,026  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_475_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:45,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_475_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_466_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,026  INFO [org.apache.spark.SparkContext] - Created broadcast 475 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 950 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:45,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 950.0 with 2 tasks
2019-06-11 09:34:45,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_469_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:45,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 950.0 (TID 633, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:45,027  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 950.0 (TID 633)
2019-06-11 09:34:45,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_471_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 313
2019-06-11 09:34:45,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 305
2019-06-11 09:34:45,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_468_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 311
2019-06-11 09:34:45,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 308
2019-06-11 09:34:45,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_462_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 312
2019-06-11 09:34:45,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 302
2019-06-11 09:34:45,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 950.0 (TID 633). 810 bytes result sent to driver
2019-06-11 09:34:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 950.0 (TID 634, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:45,039  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 950.0 (TID 634)
2019-06-11 09:34:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 950.0 (TID 633) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:45,049  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 950.0 (TID 634). 853 bytes result sent to driver
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 950.0 (TID 634) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 950.0, whose tasks have all completed, from pool 
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 950 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 951)
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:45,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 951 (MapPartitionsRDD[1114] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:45,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_476 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:45,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_476_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:45,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_476_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,052  INFO [org.apache.spark.SparkContext] - Created broadcast 476 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 951 (MapPartitionsRDD[1114] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:45,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 951.0 with 1 tasks
2019-06-11 09:34:45,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 951.0 (TID 635, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:45,053  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 951.0 (TID 635)
2019-06-11 09:34:45,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:45,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:45,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:45,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:45,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 951.0 (TID 635). 966 bytes result sent to driver
2019-06-11 09:34:45,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 951.0 (TID 635) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:45,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 951.0, whose tasks have all completed, from pool 
2019-06-11 09:34:45,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 951 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:45,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 317 finished: print at Transform.scala:36, took 0.032279 s
2019-06-11 09:34:45,057  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:45,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 316 is 83 bytes
2019-06-11 09:34:45,057  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 317 is 160 bytes
2019-06-11 09:34:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 318 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 954 (print at Transform.scala:36)
2019-06-11 09:34:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 952, ShuffleMapStage 953)
2019-06-11 09:34:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 954 (MapPartitionsRDD[1114] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:45,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_477 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:45,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_477_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:45,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_477_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:45,058  INFO [org.apache.spark.SparkContext] - Created broadcast 477 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:45,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 954 (MapPartitionsRDD[1114] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:45,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 954.0 with 1 tasks
2019-06-11 09:34:45,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 954.0 (TID 636, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:45,060  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 954.0 (TID 636)
2019-06-11 09:34:45,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:45,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:45,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:45,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:45,061  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 954.0 (TID 636). 923 bytes result sent to driver
2019-06-11 09:34:45,061  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 954.0 (TID 636) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:45,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 954.0, whose tasks have all completed, from pool 
2019-06-11 09:34:45,061  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 954 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:45,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 318 finished: print at Transform.scala:36, took 0.004805 s
2019-06-11 09:34:45,061  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216885000 ms.0 from job set of time 1560216885000 ms
2019-06-11 09:34:45,061  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.061 s for time 1560216885000 ms (execution: 0.043 s)
2019-06-11 09:34:45,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1107 from persistence list
2019-06-11 09:34:45,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1107
2019-06-11 09:34:45,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1102 from persistence list
2019-06-11 09:34:45,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1102
2019-06-11 09:34:45,062  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1101 from persistence list
2019-06-11 09:34:45,062  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1101] at socketTextStream at Transform.scala:18 of time 1560216885000 ms
2019-06-11 09:34:45,062  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216875000 ms
2019-06-11 09:34:45,062  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216875000 ms
2019-06-11 09:34:45,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1101
2019-06-11 09:34:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216890000 ms
2019-06-11 09:34:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216890000 ms.0 from job set of time 1560216890000 ms
2019-06-11 09:34:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1116 (map at Transform.scala:20)
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 319 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 957 (print at Transform.scala:36)
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 956, ShuffleMapStage 955)
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 955)
2019-06-11 09:34:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 955 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_478 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_478_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_478_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:50,011  INFO [org.apache.spark.SparkContext] - Created broadcast 478 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 955 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:50,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 955.0 with 2 tasks
2019-06-11 09:34:50,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 955.0 (TID 637, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:50,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 955.0 (TID 637)
2019-06-11 09:34:50,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 955.0 (TID 637). 853 bytes result sent to driver
2019-06-11 09:34:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 955.0 (TID 638, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:50,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 955.0 (TID 638)
2019-06-11 09:34:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 955.0 (TID 637) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:50,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 955.0 (TID 638). 767 bytes result sent to driver
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 955.0 (TID 638) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 955.0, whose tasks have all completed, from pool 
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 955 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 957)
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 957 (MapPartitionsRDD[1121] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:50,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_479 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_479_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:50,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_479_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:50,030  INFO [org.apache.spark.SparkContext] - Created broadcast 479 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 957 (MapPartitionsRDD[1121] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 957.0 with 1 tasks
2019-06-11 09:34:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 957.0 (TID 639, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:50,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 957.0 (TID 639)
2019-06-11 09:34:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:50,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 957.0 (TID 639). 1009 bytes result sent to driver
2019-06-11 09:34:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 957.0 (TID 639) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:50,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 957.0, whose tasks have all completed, from pool 
2019-06-11 09:34:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 957 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 319 finished: print at Transform.scala:36, took 0.024078 s
2019-06-11 09:34:50,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:50,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 319 is 160 bytes
2019-06-11 09:34:50,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 318 is 83 bytes
2019-06-11 09:34:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 320 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 960 (print at Transform.scala:36)
2019-06-11 09:34:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 958, ShuffleMapStage 959)
2019-06-11 09:34:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 960 (MapPartitionsRDD[1121] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:50,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_480 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:50,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_480_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:50,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_480_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:50,037  INFO [org.apache.spark.SparkContext] - Created broadcast 480 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 960 (MapPartitionsRDD[1121] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 960.0 with 1 tasks
2019-06-11 09:34:50,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 960.0 (TID 640, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:50,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 960.0 (TID 640)
2019-06-11 09:34:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:50,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:50,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 960.0 (TID 640). 966 bytes result sent to driver
2019-06-11 09:34:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 960.0 (TID 640) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:50,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 960.0, whose tasks have all completed, from pool 
2019-06-11 09:34:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 960 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:50,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 320 finished: print at Transform.scala:36, took 0.006370 s
2019-06-11 09:34:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216890000 ms.0 from job set of time 1560216890000 ms
2019-06-11 09:34:50,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216890000 ms (execution: 0.034 s)
2019-06-11 09:34:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1114 from persistence list
2019-06-11 09:34:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1114
2019-06-11 09:34:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1109 from persistence list
2019-06-11 09:34:50,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1109
2019-06-11 09:34:50,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1108 from persistence list
2019-06-11 09:34:50,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1108
2019-06-11 09:34:50,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1108] at socketTextStream at Transform.scala:18 of time 1560216890000 ms
2019-06-11 09:34:50,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216880000 ms
2019-06-11 09:34:50,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216880000 ms
2019-06-11 09:34:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216895000 ms
2019-06-11 09:34:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216895000 ms.0 from job set of time 1560216895000 ms
2019-06-11 09:34:55,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1123 (map at Transform.scala:20)
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 321 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 963 (print at Transform.scala:36)
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 961, ShuffleMapStage 962)
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 961)
2019-06-11 09:34:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 961 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:34:55,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_481 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_481_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:34:55,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_481_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:34:55,009  INFO [org.apache.spark.SparkContext] - Created broadcast 481 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 961 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:34:55,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 961.0 with 2 tasks
2019-06-11 09:34:55,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 961.0 (TID 641, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 961.0 (TID 641)
2019-06-11 09:34:55,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 961.0 (TID 641). 810 bytes result sent to driver
2019-06-11 09:34:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 961.0 (TID 642, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:34:55,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 961.0 (TID 642)
2019-06-11 09:34:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 961.0 (TID 641) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:34:55,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 961.0 (TID 642). 810 bytes result sent to driver
2019-06-11 09:34:55,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 961.0 (TID 642) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:34:55,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 961.0, whose tasks have all completed, from pool 
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 961 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 963)
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:34:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 963 (MapPartitionsRDD[1128] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:55,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_482 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:55,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_482_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:55,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_482_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:55,029  INFO [org.apache.spark.SparkContext] - Created broadcast 482 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 963 (MapPartitionsRDD[1128] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:34:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 963.0 with 1 tasks
2019-06-11 09:34:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 963.0 (TID 643, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:55,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 963.0 (TID 643)
2019-06-11 09:34:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:55,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 963.0 (TID 643). 1009 bytes result sent to driver
2019-06-11 09:34:55,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 963.0 (TID 643) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:55,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 963.0, whose tasks have all completed, from pool 
2019-06-11 09:34:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 963 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:34:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 321 finished: print at Transform.scala:36, took 0.024590 s
2019-06-11 09:34:55,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:34:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 321 is 160 bytes
2019-06-11 09:34:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 320 is 83 bytes
2019-06-11 09:34:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 322 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:34:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 966 (print at Transform.scala:36)
2019-06-11 09:34:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 964, ShuffleMapStage 965)
2019-06-11 09:34:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:34:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 966 (MapPartitionsRDD[1128] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:34:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_483 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:34:55,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_483_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:34:55,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_483_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:34:55,036  INFO [org.apache.spark.SparkContext] - Created broadcast 483 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:34:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 966 (MapPartitionsRDD[1128] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:34:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 966.0 with 1 tasks
2019-06-11 09:34:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 966.0 (TID 644, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:34:55,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 966.0 (TID 644)
2019-06-11 09:34:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:34:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:34:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:34:55,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 966.0 (TID 644). 966 bytes result sent to driver
2019-06-11 09:34:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 966.0 (TID 644) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:34:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 966.0, whose tasks have all completed, from pool 
2019-06-11 09:34:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 966 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:34:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 322 finished: print at Transform.scala:36, took 0.005016 s
2019-06-11 09:34:55,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216895000 ms.0 from job set of time 1560216895000 ms
2019-06-11 09:34:55,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216895000 ms (execution: 0.034 s)
2019-06-11 09:34:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1121 from persistence list
2019-06-11 09:34:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1121
2019-06-11 09:34:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1116 from persistence list
2019-06-11 09:34:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1116
2019-06-11 09:34:55,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1115 from persistence list
2019-06-11 09:34:55,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1115
2019-06-11 09:34:55,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1115] at socketTextStream at Transform.scala:18 of time 1560216895000 ms
2019-06-11 09:34:55,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216885000 ms
2019-06-11 09:34:55,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216885000 ms
2019-06-11 09:35:00,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216900000 ms
2019-06-11 09:35:00,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216900000 ms.0 from job set of time 1560216900000 ms
2019-06-11 09:35:00,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:00,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1130 (map at Transform.scala:20)
2019-06-11 09:35:00,113  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 323 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:00,113  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 969 (print at Transform.scala:36)
2019-06-11 09:35:00,113  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 967, ShuffleMapStage 968)
2019-06-11 09:35:00,113  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 967)
2019-06-11 09:35:00,113  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 967 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:00,113  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_484 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:00,114  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_484_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:00,114  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_484_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:00,115  INFO [org.apache.spark.SparkContext] - Created broadcast 484 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:00,115  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 967 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:00,115  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 967.0 with 2 tasks
2019-06-11 09:35:00,115  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 967.0 (TID 645, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:00,115  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 967.0 (TID 645)
2019-06-11 09:35:00,123  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 967.0 (TID 645). 810 bytes result sent to driver
2019-06-11 09:35:00,124  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 967.0 (TID 646, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:00,124  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 967.0 (TID 646)
2019-06-11 09:35:00,124  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 967.0 (TID 645) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:00,133  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 967.0 (TID 646). 767 bytes result sent to driver
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 967.0 (TID 646) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 967.0, whose tasks have all completed, from pool 
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 967 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 969)
2019-06-11 09:35:00,133  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:00,134  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 969 (MapPartitionsRDD[1135] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:00,134  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_485 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:00,135  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_485_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:00,135  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_485_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:00,135  INFO [org.apache.spark.SparkContext] - Created broadcast 485 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:00,135  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 969 (MapPartitionsRDD[1135] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:00,135  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 969.0 with 1 tasks
2019-06-11 09:35:00,136  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 969.0 (TID 647, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:00,136  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 969.0 (TID 647)
2019-06-11 09:35:00,137  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:00,137  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:35:00,137  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:00,137  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:00,137  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 969.0 (TID 647). 966 bytes result sent to driver
2019-06-11 09:35:00,138  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 969.0 (TID 647) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:00,138  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 969.0, whose tasks have all completed, from pool 
2019-06-11 09:35:00,138  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 969 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:00,138  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 323 finished: print at Transform.scala:36, took 0.124457 s
2019-06-11 09:35:00,142  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:00,142  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 323 is 160 bytes
2019-06-11 09:35:00,142  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 322 is 83 bytes
2019-06-11 09:35:00,142  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 324 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:00,142  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 972 (print at Transform.scala:36)
2019-06-11 09:35:00,142  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 970, ShuffleMapStage 971)
2019-06-11 09:35:00,142  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:00,143  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 972 (MapPartitionsRDD[1135] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:00,143  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_486 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:00,144  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_486_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:00,144  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_486_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:00,144  INFO [org.apache.spark.SparkContext] - Created broadcast 486 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:00,145  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 972 (MapPartitionsRDD[1135] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:00,145  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 972.0 with 1 tasks
2019-06-11 09:35:00,145  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 972.0 (TID 648, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:00,145  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 972.0 (TID 648)
2019-06-11 09:35:00,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:00,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:00,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:00,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:00,146  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 972.0 (TID 648). 966 bytes result sent to driver
2019-06-11 09:35:00,147  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 972.0 (TID 648) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:00,147  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 972.0, whose tasks have all completed, from pool 
2019-06-11 09:35:00,147  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 972 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:00,147  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 324 finished: print at Transform.scala:36, took 0.005216 s
2019-06-11 09:35:00,147  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216900000 ms.0 from job set of time 1560216900000 ms
2019-06-11 09:35:00,147  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.147 s for time 1560216900000 ms (execution: 0.135 s)
2019-06-11 09:35:00,147  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1128 from persistence list
2019-06-11 09:35:00,147  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1128
2019-06-11 09:35:00,147  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1123 from persistence list
2019-06-11 09:35:00,148  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1123
2019-06-11 09:35:00,148  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1122 from persistence list
2019-06-11 09:35:00,148  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1122
2019-06-11 09:35:00,148  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1122] at socketTextStream at Transform.scala:18 of time 1560216900000 ms
2019-06-11 09:35:00,148  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216890000 ms
2019-06-11 09:35:00,148  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216890000 ms
2019-06-11 09:35:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216905000 ms
2019-06-11 09:35:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216905000 ms.0 from job set of time 1560216905000 ms
2019-06-11 09:35:05,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1137 (map at Transform.scala:20)
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 325 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 975 (print at Transform.scala:36)
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 974, ShuffleMapStage 973)
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 974)
2019-06-11 09:35:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 974 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_487 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_487_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_487_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 487 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 974 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 974.0 with 2 tasks
2019-06-11 09:35:05,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 974.0 (TID 649, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:05,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 974.0 (TID 649)
2019-06-11 09:35:05,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 974.0 (TID 649). 853 bytes result sent to driver
2019-06-11 09:35:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 974.0 (TID 650, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 974.0 (TID 650)
2019-06-11 09:35:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 974.0 (TID 649) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:05,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 974.0 (TID 650). 767 bytes result sent to driver
2019-06-11 09:35:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 974.0 (TID 650) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:05,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 974.0, whose tasks have all completed, from pool 
2019-06-11 09:35:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 974 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 975)
2019-06-11 09:35:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 975 (MapPartitionsRDD[1142] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_488 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_488_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_488_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:05,029  INFO [org.apache.spark.SparkContext] - Created broadcast 488 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 975 (MapPartitionsRDD[1142] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:05,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 975.0 with 1 tasks
2019-06-11 09:35:05,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 975.0 (TID 651, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:05,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 975.0 (TID 651)
2019-06-11 09:35:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 975.0 (TID 651). 1009 bytes result sent to driver
2019-06-11 09:35:05,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 975.0 (TID 651) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:05,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 975.0, whose tasks have all completed, from pool 
2019-06-11 09:35:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 975 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 325 finished: print at Transform.scala:36, took 0.024720 s
2019-06-11 09:35:05,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:05,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 324 is 83 bytes
2019-06-11 09:35:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 325 is 160 bytes
2019-06-11 09:35:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 326 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 978 (print at Transform.scala:36)
2019-06-11 09:35:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 976, ShuffleMapStage 977)
2019-06-11 09:35:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 978 (MapPartitionsRDD[1142] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_489 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_489_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_489_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:05,036  INFO [org.apache.spark.SparkContext] - Created broadcast 489 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 978 (MapPartitionsRDD[1142] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 978.0 with 1 tasks
2019-06-11 09:35:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 978.0 (TID 652, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 978.0 (TID 652)
2019-06-11 09:35:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:05,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:35:05,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 978.0 (TID 652). 1009 bytes result sent to driver
2019-06-11 09:35:05,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 978.0 (TID 652) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:05,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 978.0, whose tasks have all completed, from pool 
2019-06-11 09:35:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 978 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 326 finished: print at Transform.scala:36, took 0.005860 s
2019-06-11 09:35:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216905000 ms.0 from job set of time 1560216905000 ms
2019-06-11 09:35:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216905000 ms (execution: 0.035 s)
2019-06-11 09:35:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1135 from persistence list
2019-06-11 09:35:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1135
2019-06-11 09:35:05,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1130 from persistence list
2019-06-11 09:35:05,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1130
2019-06-11 09:35:05,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1129 from persistence list
2019-06-11 09:35:05,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1129
2019-06-11 09:35:05,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1129] at socketTextStream at Transform.scala:18 of time 1560216905000 ms
2019-06-11 09:35:05,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216895000 ms
2019-06-11 09:35:05,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216895000 ms
2019-06-11 09:35:10,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216910000 ms
2019-06-11 09:35:10,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216910000 ms.0 from job set of time 1560216910000 ms
2019-06-11 09:35:10,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1144 (map at Transform.scala:20)
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 327 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 981 (print at Transform.scala:36)
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 979, ShuffleMapStage 980)
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 979)
2019-06-11 09:35:10,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 979 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:10,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_490 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:10,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_490_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:10,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_490_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_477_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,021  INFO [org.apache.spark.SparkContext] - Created broadcast 490 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:10,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 979 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:10,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_488_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,024  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 979.0 with 2 tasks
2019-06-11 09:35:10,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 979.0 (TID 653, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:10,025  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 979.0 (TID 653)
2019-06-11 09:35:10,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_484_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 317
2019-06-11 09:35:10,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 318
2019-06-11 09:35:10,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_487_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_479_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 314
2019-06-11 09:35:10,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_480_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 322
2019-06-11 09:35:10,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_478_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 319
2019-06-11 09:35:10,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 316
2019-06-11 09:35:10,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 320
2019-06-11 09:35:10,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_485_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_486_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 321
2019-06-11 09:35:10,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 323
2019-06-11 09:35:10,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_481_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 315
2019-06-11 09:35:10,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_475_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:10,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_489_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_483_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_482_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 979.0 (TID 653). 810 bytes result sent to driver
2019-06-11 09:35:10,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_476_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 979.0 (TID 654, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:10,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 979.0 (TID 653) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:10,038  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 979.0 (TID 654)
2019-06-11 09:35:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 979.0 (TID 654). 810 bytes result sent to driver
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 979.0 (TID 654) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 979.0, whose tasks have all completed, from pool 
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 979 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 981)
2019-06-11 09:35:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:10,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 981 (MapPartitionsRDD[1149] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:10,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_491 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:10,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_491_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:10,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_491_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,049  INFO [org.apache.spark.SparkContext] - Created broadcast 491 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 981 (MapPartitionsRDD[1149] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:10,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 981.0 with 1 tasks
2019-06-11 09:35:10,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 981.0 (TID 655, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:10,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 981.0 (TID 655)
2019-06-11 09:35:10,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:10,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:35:10,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 981.0 (TID 655). 966 bytes result sent to driver
2019-06-11 09:35:10,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 981.0 (TID 655) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:10,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 981.0, whose tasks have all completed, from pool 
2019-06-11 09:35:10,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 981 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:10,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 327 finished: print at Transform.scala:36, took 0.039485 s
2019-06-11 09:35:10,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:10,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 327 is 160 bytes
2019-06-11 09:35:10,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 326 is 83 bytes
2019-06-11 09:35:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 328 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 984 (print at Transform.scala:36)
2019-06-11 09:35:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 982, ShuffleMapStage 983)
2019-06-11 09:35:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 984 (MapPartitionsRDD[1149] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:10,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_492 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:10,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_492_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:10,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_492_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:10,056  INFO [org.apache.spark.SparkContext] - Created broadcast 492 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:10,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 984 (MapPartitionsRDD[1149] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:10,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 984.0 with 1 tasks
2019-06-11 09:35:10,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 984.0 (TID 656, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:10,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 984.0 (TID 656)
2019-06-11 09:35:10,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:10,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:10,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:10,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:10,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 984.0 (TID 656). 966 bytes result sent to driver
2019-06-11 09:35:10,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 984.0 (TID 656) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:10,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 984.0, whose tasks have all completed, from pool 
2019-06-11 09:35:10,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 984 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:10,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 328 finished: print at Transform.scala:36, took 0.004189 s
2019-06-11 09:35:10,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216910000 ms.0 from job set of time 1560216910000 ms
2019-06-11 09:35:10,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560216910000 ms (execution: 0.048 s)
2019-06-11 09:35:10,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1142 from persistence list
2019-06-11 09:35:10,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1142
2019-06-11 09:35:10,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1137 from persistence list
2019-06-11 09:35:10,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1137
2019-06-11 09:35:10,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1136 from persistence list
2019-06-11 09:35:10,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1136
2019-06-11 09:35:10,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1136] at socketTextStream at Transform.scala:18 of time 1560216910000 ms
2019-06-11 09:35:10,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216900000 ms
2019-06-11 09:35:10,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216900000 ms
2019-06-11 09:35:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216915000 ms
2019-06-11 09:35:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216915000 ms.0 from job set of time 1560216915000 ms
2019-06-11 09:35:15,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1151 (map at Transform.scala:20)
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 329 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 987 (print at Transform.scala:36)
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 985, ShuffleMapStage 986)
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 986)
2019-06-11 09:35:15,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 986 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_493 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_493_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:35:15,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_493_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:15,009  INFO [org.apache.spark.SparkContext] - Created broadcast 493 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 986 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:15,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 986.0 with 2 tasks
2019-06-11 09:35:15,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 986.0 (TID 657, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:15,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 986.0 (TID 657)
2019-06-11 09:35:15,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 986.0 (TID 657). 810 bytes result sent to driver
2019-06-11 09:35:15,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 986.0 (TID 658, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:15,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 986.0 (TID 658)
2019-06-11 09:35:15,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 986.0 (TID 657) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:15,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 986.0 (TID 658). 810 bytes result sent to driver
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 986.0 (TID 658) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 986.0, whose tasks have all completed, from pool 
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 986 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 987)
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 987 (MapPartitionsRDD[1156] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:15,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_494 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:15,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_494_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:15,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_494_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:15,029  INFO [org.apache.spark.SparkContext] - Created broadcast 494 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 987 (MapPartitionsRDD[1156] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:15,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 987.0 with 1 tasks
2019-06-11 09:35:15,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 987.0 (TID 659, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:15,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 987.0 (TID 659)
2019-06-11 09:35:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:15,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 987.0 (TID 659). 1009 bytes result sent to driver
2019-06-11 09:35:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 987.0 (TID 659) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:15,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 987.0, whose tasks have all completed, from pool 
2019-06-11 09:35:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 987 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 329 finished: print at Transform.scala:36, took 0.024235 s
2019-06-11 09:35:15,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:15,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 328 is 83 bytes
2019-06-11 09:35:15,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 329 is 160 bytes
2019-06-11 09:35:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 330 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 990 (print at Transform.scala:36)
2019-06-11 09:35:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 988, ShuffleMapStage 989)
2019-06-11 09:35:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 990 (MapPartitionsRDD[1156] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_495 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_495_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:15,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_495_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:15,037  INFO [org.apache.spark.SparkContext] - Created broadcast 495 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 990 (MapPartitionsRDD[1156] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 990.0 with 1 tasks
2019-06-11 09:35:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 990.0 (TID 660, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:15,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 990.0 (TID 660)
2019-06-11 09:35:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:15,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:15,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 990.0 (TID 660). 1009 bytes result sent to driver
2019-06-11 09:35:15,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 990.0 (TID 660) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:15,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 990.0, whose tasks have all completed, from pool 
2019-06-11 09:35:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 990 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:15,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 330 finished: print at Transform.scala:36, took 0.004801 s
2019-06-11 09:35:15,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216915000 ms.0 from job set of time 1560216915000 ms
2019-06-11 09:35:15,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560216915000 ms (execution: 0.034 s)
2019-06-11 09:35:15,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1149 from persistence list
2019-06-11 09:35:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1149
2019-06-11 09:35:15,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1144 from persistence list
2019-06-11 09:35:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1144
2019-06-11 09:35:15,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1143 from persistence list
2019-06-11 09:35:15,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1143
2019-06-11 09:35:15,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1143] at socketTextStream at Transform.scala:18 of time 1560216915000 ms
2019-06-11 09:35:15,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216905000 ms
2019-06-11 09:35:15,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216905000 ms
2019-06-11 09:35:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216920000 ms
2019-06-11 09:35:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216920000 ms.0 from job set of time 1560216920000 ms
2019-06-11 09:35:20,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1158 (map at Transform.scala:20)
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 331 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 993 (print at Transform.scala:36)
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 991, ShuffleMapStage 992)
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 991)
2019-06-11 09:35:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 991 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_496 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_496_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:35:20,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_496_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:20,009  INFO [org.apache.spark.SparkContext] - Created broadcast 496 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 991 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:20,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 991.0 with 2 tasks
2019-06-11 09:35:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 991.0 (TID 661, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 991.0 (TID 661)
2019-06-11 09:35:20,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 991.0 (TID 661). 810 bytes result sent to driver
2019-06-11 09:35:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 991.0 (TID 662, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 991.0 (TID 662)
2019-06-11 09:35:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 991.0 (TID 661) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:20,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 991.0 (TID 662). 767 bytes result sent to driver
2019-06-11 09:35:20,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 991.0 (TID 662) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:20,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 991.0, whose tasks have all completed, from pool 
2019-06-11 09:35:20,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 991 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 993)
2019-06-11 09:35:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 993 (MapPartitionsRDD[1163] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_497 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_497_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:20,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_497_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:20,029  INFO [org.apache.spark.SparkContext] - Created broadcast 497 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 993 (MapPartitionsRDD[1163] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:20,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 993.0 with 1 tasks
2019-06-11 09:35:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 993.0 (TID 663, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 993.0 (TID 663)
2019-06-11 09:35:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:20,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
