2019-06-11 09:42:10,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217320000 ms
2019-06-11 09:42:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217335000 ms
2019-06-11 09:42:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217335000 ms.0 from job set of time 1560217335000 ms
2019-06-11 09:42:15,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1739 (map at Transform.scala:20)
2019-06-11 09:42:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 497 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1491 (print at Transform.scala:36)
2019-06-11 09:42:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1489, ShuffleMapStage 1490)
2019-06-11 09:42:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1489)
2019-06-11 09:42:15,020  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1489 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:15,021  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_745 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:15,022  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_745_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:15,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_745_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:15,022  INFO [org.apache.spark.SparkContext] - Created broadcast 745 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:15,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1489 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:15,022  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1489.0 with 2 tasks
2019-06-11 09:42:15,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1489.0 (TID 993, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:15,023  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1489.0 (TID 993)
2019-06-11 09:42:15,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1489.0 (TID 993). 810 bytes result sent to driver
2019-06-11 09:42:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1489.0 (TID 994, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:15,031  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1489.0 (TID 994)
2019-06-11 09:42:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1489.0 (TID 993) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1489.0 (TID 994). 767 bytes result sent to driver
2019-06-11 09:42:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1489.0 (TID 994) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1489.0, whose tasks have all completed, from pool 
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1489 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1491)
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1491 (MapPartitionsRDD[1744] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_746 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:15,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_746_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_746_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 746 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1491 (MapPartitionsRDD[1744] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:15,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1491.0 with 1 tasks
2019-06-11 09:42:15,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1491.0 (TID 995, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:15,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1491.0 (TID 995)
2019-06-11 09:42:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:15,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1491.0 (TID 995). 966 bytes result sent to driver
2019-06-11 09:42:15,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1491.0 (TID 995) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:15,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1491.0, whose tasks have all completed, from pool 
2019-06-11 09:42:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1491 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 497 finished: print at Transform.scala:36, took 0.035525 s
2019-06-11 09:42:15,046  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:15,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 497 is 160 bytes
2019-06-11 09:42:15,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 496 is 83 bytes
2019-06-11 09:42:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 498 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1494 (print at Transform.scala:36)
2019-06-11 09:42:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1493, ShuffleMapStage 1492)
2019-06-11 09:42:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:15,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1494 (MapPartitionsRDD[1744] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:15,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_747 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:15,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_747_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:15,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_747_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:15,050  INFO [org.apache.spark.SparkContext] - Created broadcast 747 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1494 (MapPartitionsRDD[1744] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:15,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1494.0 with 1 tasks
2019-06-11 09:42:15,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1494.0 (TID 996, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:15,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1494.0 (TID 996)
2019-06-11 09:42:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:15,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:15,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1494.0 (TID 996). 1009 bytes result sent to driver
2019-06-11 09:42:15,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1494.0 (TID 996) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:15,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1494.0, whose tasks have all completed, from pool 
2019-06-11 09:42:15,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1494 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:15,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 498 finished: print at Transform.scala:36, took 0.006320 s
2019-06-11 09:42:15,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217335000 ms.0 from job set of time 1560217335000 ms
2019-06-11 09:42:15,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.053 s for time 1560217335000 ms (execution: 0.047 s)
2019-06-11 09:42:15,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1737 from persistence list
2019-06-11 09:42:15,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1737
2019-06-11 09:42:15,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1732 from persistence list
2019-06-11 09:42:15,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1732
2019-06-11 09:42:15,053  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1731 from persistence list
2019-06-11 09:42:15,053  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1731
2019-06-11 09:42:15,053  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1731] at socketTextStream at Transform.scala:18 of time 1560217335000 ms
2019-06-11 09:42:15,053  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217325000 ms
2019-06-11 09:42:15,053  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217325000 ms
2019-06-11 09:42:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217340000 ms
2019-06-11 09:42:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217340000 ms.0 from job set of time 1560217340000 ms
2019-06-11 09:42:20,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1746 (map at Transform.scala:20)
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 499 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1497 (print at Transform.scala:36)
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1496, ShuffleMapStage 1495)
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1496)
2019-06-11 09:42:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1496 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_748 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_748_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:20,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_748_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:20,010  INFO [org.apache.spark.SparkContext] - Created broadcast 748 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1496 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1496.0 with 2 tasks
2019-06-11 09:42:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1496.0 (TID 997, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1496.0 (TID 997)
2019-06-11 09:42:20,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1496.0 (TID 997). 810 bytes result sent to driver
2019-06-11 09:42:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1496.0 (TID 998, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:20,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1496.0 (TID 998)
2019-06-11 09:42:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1496.0 (TID 997) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1496.0 (TID 998). 810 bytes result sent to driver
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1496.0 (TID 998) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1496.0, whose tasks have all completed, from pool 
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1496 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1497)
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1497 (MapPartitionsRDD[1751] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:20,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_749 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:20,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_749_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:20,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_749_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:20,034  INFO [org.apache.spark.SparkContext] - Created broadcast 749 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1497 (MapPartitionsRDD[1751] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:20,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1497.0 with 1 tasks
2019-06-11 09:42:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1497.0 (TID 999, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:20,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1497.0 (TID 999)
2019-06-11 09:42:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:20,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1497.0 (TID 999). 966 bytes result sent to driver
2019-06-11 09:42:20,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1497.0 (TID 999) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:20,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1497.0, whose tasks have all completed, from pool 
2019-06-11 09:42:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1497 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 499 finished: print at Transform.scala:36, took 0.028688 s
2019-06-11 09:42:20,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 498 is 83 bytes
2019-06-11 09:42:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 499 is 160 bytes
2019-06-11 09:42:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 500 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1500 (print at Transform.scala:36)
2019-06-11 09:42:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1498, ShuffleMapStage 1499)
2019-06-11 09:42:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1500 (MapPartitionsRDD[1751] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:20,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_750 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_750_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:20,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_750_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:20,041  INFO [org.apache.spark.SparkContext] - Created broadcast 750 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1500 (MapPartitionsRDD[1751] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:20,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1500.0 with 1 tasks
2019-06-11 09:42:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1500.0 (TID 1000, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:20,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1500.0 (TID 1000)
2019-06-11 09:42:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:20,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:20,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1500.0 (TID 1000). 1009 bytes result sent to driver
2019-06-11 09:42:20,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1500.0 (TID 1000) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:20,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1500.0, whose tasks have all completed, from pool 
2019-06-11 09:42:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1500 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 500 finished: print at Transform.scala:36, took 0.005598 s
2019-06-11 09:42:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217340000 ms.0 from job set of time 1560217340000 ms
2019-06-11 09:42:20,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560217340000 ms (execution: 0.040 s)
2019-06-11 09:42:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1744 from persistence list
2019-06-11 09:42:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1744
2019-06-11 09:42:20,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1739 from persistence list
2019-06-11 09:42:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1739
2019-06-11 09:42:20,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1738 from persistence list
2019-06-11 09:42:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1738
2019-06-11 09:42:20,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1738] at socketTextStream at Transform.scala:18 of time 1560217340000 ms
2019-06-11 09:42:20,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217330000 ms
2019-06-11 09:42:20,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217330000 ms
2019-06-11 09:42:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217345000 ms
2019-06-11 09:42:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217345000 ms.0 from job set of time 1560217345000 ms
2019-06-11 09:42:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1753 (map at Transform.scala:20)
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 501 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1503 (print at Transform.scala:36)
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1501, ShuffleMapStage 1502)
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1501)
2019-06-11 09:42:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1501 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:25,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_751 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_751_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:25,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_751_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 751 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1501 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1501.0 with 2 tasks
2019-06-11 09:42:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1501.0 (TID 1001, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:25,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1501.0 (TID 1001)
2019-06-11 09:42:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1501.0 (TID 1001). 853 bytes result sent to driver
2019-06-11 09:42:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1501.0 (TID 1002, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1501.0 (TID 1002)
2019-06-11 09:42:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1501.0 (TID 1001) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1501.0 (TID 1002). 767 bytes result sent to driver
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1501.0 (TID 1002) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1501.0, whose tasks have all completed, from pool 
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1501 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1503)
2019-06-11 09:42:25,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1503 (MapPartitionsRDD[1758] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_752 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_752_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_752_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:25,030  INFO [org.apache.spark.SparkContext] - Created broadcast 752 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1503 (MapPartitionsRDD[1758] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1503.0 with 1 tasks
2019-06-11 09:42:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1503.0 (TID 1003, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1503.0 (TID 1003)
2019-06-11 09:42:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1503.0 (TID 1003). 966 bytes result sent to driver
2019-06-11 09:42:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1503.0 (TID 1003) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1503.0, whose tasks have all completed, from pool 
2019-06-11 09:42:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1503 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 501 finished: print at Transform.scala:36, took 0.024399 s
2019-06-11 09:42:25,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:25,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 501 is 160 bytes
2019-06-11 09:42:25,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 500 is 83 bytes
2019-06-11 09:42:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 502 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1506 (print at Transform.scala:36)
2019-06-11 09:42:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1504, ShuffleMapStage 1505)
2019-06-11 09:42:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1506 (MapPartitionsRDD[1758] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:25,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_753 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_753_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:25,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_753_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:25,036  INFO [org.apache.spark.SparkContext] - Created broadcast 753 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1506 (MapPartitionsRDD[1758] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:25,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1506.0 with 1 tasks
2019-06-11 09:42:25,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1506.0 (TID 1004, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:25,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1506.0 (TID 1004)
2019-06-11 09:42:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:25,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1506.0 (TID 1004). 1009 bytes result sent to driver
2019-06-11 09:42:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1506.0 (TID 1004) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1506.0, whose tasks have all completed, from pool 
2019-06-11 09:42:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1506 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 502 finished: print at Transform.scala:36, took 0.005678 s
2019-06-11 09:42:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217345000 ms.0 from job set of time 1560217345000 ms
2019-06-11 09:42:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217345000 ms (execution: 0.034 s)
2019-06-11 09:42:25,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1751 from persistence list
2019-06-11 09:42:25,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1751
2019-06-11 09:42:25,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1746 from persistence list
2019-06-11 09:42:25,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1746
2019-06-11 09:42:25,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1745 from persistence list
2019-06-11 09:42:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1745
2019-06-11 09:42:25,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1745] at socketTextStream at Transform.scala:18 of time 1560217345000 ms
2019-06-11 09:42:25,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217335000 ms
2019-06-11 09:42:25,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217335000 ms
2019-06-11 09:42:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217350000 ms
2019-06-11 09:42:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217350000 ms.0 from job set of time 1560217350000 ms
2019-06-11 09:42:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1760 (map at Transform.scala:20)
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 503 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1509 (print at Transform.scala:36)
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1507, ShuffleMapStage 1508)
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1508)
2019-06-11 09:42:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1508 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_754 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:30,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_754_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:42:30,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_754_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:30,012  INFO [org.apache.spark.SparkContext] - Created broadcast 754 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:30,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1508 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:30,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1508.0 with 2 tasks
2019-06-11 09:42:30,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1508.0 (TID 1005, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:30,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1508.0 (TID 1005)
2019-06-11 09:42:30,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1508.0 (TID 1005). 810 bytes result sent to driver
2019-06-11 09:42:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1508.0 (TID 1006, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:30,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1508.0 (TID 1006)
2019-06-11 09:42:30,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1508.0 (TID 1005) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:30,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1508.0 (TID 1006). 853 bytes result sent to driver
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1508.0 (TID 1006) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1508.0, whose tasks have all completed, from pool 
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1508 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1509)
2019-06-11 09:42:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1509 (MapPartitionsRDD[1765] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:30,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_755 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:30,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_755_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_755_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_745_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:30,042  INFO [org.apache.spark.SparkContext] - Created broadcast 755 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1509 (MapPartitionsRDD[1765] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:30,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1509.0 with 1 tasks
2019-06-11 09:42:30,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_746_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1509.0 (TID 1007, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:30,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1509.0 (TID 1007)
2019-06-11 09:42:30,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 497
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_750_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:30,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_748_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:30,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1509.0 (TID 1007). 1052 bytes result sent to driver
2019-06-11 09:42:30,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1509.0 (TID 1007) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:30,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1509.0, whose tasks have all completed, from pool 
2019-06-11 09:42:30,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_753_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1509 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:30,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 503 finished: print at Transform.scala:36, took 0.037296 s
2019-06-11 09:42:30,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 494
2019-06-11 09:42:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 495
2019-06-11 09:42:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 498
2019-06-11 09:42:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 492
2019-06-11 09:42:30,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 496
2019-06-11 09:42:30,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_744_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 499
2019-06-11 09:42:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_751_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:30,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_752_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 493
2019-06-11 09:42:30,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:30,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 502 is 83 bytes
2019-06-11 09:42:30,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_747_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 503 is 160 bytes
2019-06-11 09:42:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 504 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1512 (print at Transform.scala:36)
2019-06-11 09:42:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1511, ShuffleMapStage 1510)
2019-06-11 09:42:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:30,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1512 (MapPartitionsRDD[1765] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:30,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_756 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:30,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_749_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_756_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:30,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_756_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:30,058  INFO [org.apache.spark.SparkContext] - Created broadcast 756 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:30,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1512 (MapPartitionsRDD[1765] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:30,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1512.0 with 1 tasks
2019-06-11 09:42:30,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1512.0 (TID 1008, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:30,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1512.0 (TID 1008)
2019-06-11 09:42:30,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:30,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:30,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:30,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:30,061  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1512.0 (TID 1008). 1009 bytes result sent to driver
2019-06-11 09:42:30,061  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1512.0 (TID 1008) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:30,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1512.0, whose tasks have all completed, from pool 
2019-06-11 09:42:30,061  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1512 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:30,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 504 finished: print at Transform.scala:36, took 0.007195 s
2019-06-11 09:42:30,062  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217350000 ms.0 from job set of time 1560217350000 ms
2019-06-11 09:42:30,062  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.062 s for time 1560217350000 ms (execution: 0.055 s)
2019-06-11 09:42:30,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1758 from persistence list
2019-06-11 09:42:30,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1758
2019-06-11 09:42:30,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1753 from persistence list
2019-06-11 09:42:30,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1753
2019-06-11 09:42:30,062  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1752 from persistence list
2019-06-11 09:42:30,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1752
2019-06-11 09:42:30,063  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1752] at socketTextStream at Transform.scala:18 of time 1560217350000 ms
2019-06-11 09:42:30,063  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217340000 ms
2019-06-11 09:42:30,063  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217340000 ms
2019-06-11 09:42:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217355000 ms
2019-06-11 09:42:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217355000 ms.0 from job set of time 1560217355000 ms
2019-06-11 09:42:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1767 (map at Transform.scala:20)
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 505 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1515 (print at Transform.scala:36)
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1513, ShuffleMapStage 1514)
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1513)
2019-06-11 09:42:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1513 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_757 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_757_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_757_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 757 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1513 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1513.0 with 2 tasks
2019-06-11 09:42:35,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1513.0 (TID 1009, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:35,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1513.0 (TID 1009)
2019-06-11 09:42:35,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1513.0 (TID 1009). 810 bytes result sent to driver
2019-06-11 09:42:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1513.0 (TID 1010, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:35,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1513.0 (TID 1010)
2019-06-11 09:42:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1513.0 (TID 1009) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:35,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1513.0 (TID 1010). 767 bytes result sent to driver
2019-06-11 09:42:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1513.0 (TID 1010) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:35,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1513.0, whose tasks have all completed, from pool 
2019-06-11 09:42:35,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1513 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:42:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1515)
2019-06-11 09:42:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1515 (MapPartitionsRDD[1772] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:35,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_758 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_758_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:35,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_758_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:35,031  INFO [org.apache.spark.SparkContext] - Created broadcast 758 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1515 (MapPartitionsRDD[1772] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:35,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1515.0 with 1 tasks
2019-06-11 09:42:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1515.0 (TID 1011, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:35,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1515.0 (TID 1011)
2019-06-11 09:42:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:35,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1515.0 (TID 1011). 966 bytes result sent to driver
2019-06-11 09:42:35,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1515.0 (TID 1011) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:35,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1515.0, whose tasks have all completed, from pool 
2019-06-11 09:42:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1515 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:42:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 505 finished: print at Transform.scala:36, took 0.025166 s
2019-06-11 09:42:35,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:35,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 505 is 160 bytes
2019-06-11 09:42:35,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 504 is 83 bytes
2019-06-11 09:42:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 506 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1518 (print at Transform.scala:36)
2019-06-11 09:42:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1516, ShuffleMapStage 1517)
2019-06-11 09:42:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1518 (MapPartitionsRDD[1772] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_759 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_759_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_759_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:35,037  INFO [org.apache.spark.SparkContext] - Created broadcast 759 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1518 (MapPartitionsRDD[1772] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:35,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1518.0 with 1 tasks
2019-06-11 09:42:35,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1518.0 (TID 1012, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:35,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1518.0 (TID 1012)
2019-06-11 09:42:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:35,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1518.0 (TID 1012). 966 bytes result sent to driver
2019-06-11 09:42:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1518.0 (TID 1012) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1518.0, whose tasks have all completed, from pool 
2019-06-11 09:42:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1518 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 506 finished: print at Transform.scala:36, took 0.004635 s
2019-06-11 09:42:35,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217355000 ms.0 from job set of time 1560217355000 ms
2019-06-11 09:42:35,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217355000 ms (execution: 0.034 s)
2019-06-11 09:42:35,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1765 from persistence list
2019-06-11 09:42:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1765
2019-06-11 09:42:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1760 from persistence list
2019-06-11 09:42:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1760
2019-06-11 09:42:35,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1759 from persistence list
2019-06-11 09:42:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1759
2019-06-11 09:42:35,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1759] at socketTextStream at Transform.scala:18 of time 1560217355000 ms
2019-06-11 09:42:35,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217345000 ms
2019-06-11 09:42:35,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217345000 ms
2019-06-11 09:42:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217360000 ms
2019-06-11 09:42:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217360000 ms.0 from job set of time 1560217360000 ms
2019-06-11 09:42:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1774 (map at Transform.scala:20)
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 507 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1521 (print at Transform.scala:36)
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1519, ShuffleMapStage 1520)
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1520)
2019-06-11 09:42:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1520 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_760 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_760_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_760_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 760 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1520 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1520.0 with 2 tasks
2019-06-11 09:42:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1520.0 (TID 1013, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1520.0 (TID 1013)
2019-06-11 09:42:40,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1520.0 (TID 1013). 810 bytes result sent to driver
2019-06-11 09:42:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1520.0 (TID 1014, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:40,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1520.0 (TID 1014)
2019-06-11 09:42:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1520.0 (TID 1013) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:40,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1520.0 (TID 1014). 810 bytes result sent to driver
2019-06-11 09:42:40,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1520.0 (TID 1014) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:40,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1520.0, whose tasks have all completed, from pool 
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1520 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1521)
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1521 (MapPartitionsRDD[1779] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_761 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_761_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:40,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_761_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:40,029  INFO [org.apache.spark.SparkContext] - Created broadcast 761 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1521 (MapPartitionsRDD[1779] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:40,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1521.0 with 1 tasks
2019-06-11 09:42:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1521.0 (TID 1015, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:40,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1521.0 (TID 1015)
2019-06-11 09:42:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1521.0 (TID 1015). 966 bytes result sent to driver
2019-06-11 09:42:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1521.0 (TID 1015) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1521.0, whose tasks have all completed, from pool 
2019-06-11 09:42:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1521 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 507 finished: print at Transform.scala:36, took 0.024358 s
2019-06-11 09:42:40,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:40,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 506 is 83 bytes
2019-06-11 09:42:40,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 507 is 160 bytes
2019-06-11 09:42:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 508 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1524 (print at Transform.scala:36)
2019-06-11 09:42:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1522, ShuffleMapStage 1523)
2019-06-11 09:42:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1524 (MapPartitionsRDD[1779] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_762 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_762_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:40,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_762_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:40,038  INFO [org.apache.spark.SparkContext] - Created broadcast 762 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1524 (MapPartitionsRDD[1779] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1524.0 with 1 tasks
2019-06-11 09:42:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1524.0 (TID 1016, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1524.0 (TID 1016)
2019-06-11 09:42:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:40,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1524.0 (TID 1016). 966 bytes result sent to driver
2019-06-11 09:42:40,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1524.0 (TID 1016) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1524.0, whose tasks have all completed, from pool 
2019-06-11 09:42:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1524 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 508 finished: print at Transform.scala:36, took 0.004230 s
2019-06-11 09:42:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217360000 ms.0 from job set of time 1560217360000 ms
2019-06-11 09:42:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217360000 ms (execution: 0.034 s)
2019-06-11 09:42:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1772 from persistence list
2019-06-11 09:42:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1772
2019-06-11 09:42:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1767 from persistence list
2019-06-11 09:42:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1767
2019-06-11 09:42:40,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1766 from persistence list
2019-06-11 09:42:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1766
2019-06-11 09:42:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1766] at socketTextStream at Transform.scala:18 of time 1560217360000 ms
2019-06-11 09:42:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217350000 ms
2019-06-11 09:42:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217350000 ms
2019-06-11 09:42:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217365000 ms
2019-06-11 09:42:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217365000 ms.0 from job set of time 1560217365000 ms
2019-06-11 09:42:45,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1781 (map at Transform.scala:20)
2019-06-11 09:42:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 509 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1527 (print at Transform.scala:36)
2019-06-11 09:42:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1525, ShuffleMapStage 1526)
2019-06-11 09:42:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1526)
2019-06-11 09:42:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1526 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:45,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_763 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_763_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:42:45,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_763_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:45,009  INFO [org.apache.spark.SparkContext] - Created broadcast 763 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1526 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:45,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1526.0 with 2 tasks
2019-06-11 09:42:45,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1526.0 (TID 1017, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:45,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1526.0 (TID 1017)
2019-06-11 09:42:45,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1526.0 (TID 1017). 810 bytes result sent to driver
2019-06-11 09:42:45,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1526.0 (TID 1018, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:45,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1526.0 (TID 1018)
2019-06-11 09:42:45,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1526.0 (TID 1017) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:45,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1526.0 (TID 1018). 767 bytes result sent to driver
2019-06-11 09:42:45,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1526.0 (TID 1018) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:45,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1526.0, whose tasks have all completed, from pool 
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1526 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1527)
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:45,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1527 (MapPartitionsRDD[1786] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:45,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_764 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:45,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_764_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:45,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_764_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:45,028  INFO [org.apache.spark.SparkContext] - Created broadcast 764 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1527 (MapPartitionsRDD[1786] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:45,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1527.0 with 1 tasks
2019-06-11 09:42:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1527.0 (TID 1019, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:45,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1527.0 (TID 1019)
2019-06-11 09:42:45,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:45,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:45,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:45,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:45,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1527.0 (TID 1019). 966 bytes result sent to driver
2019-06-11 09:42:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1527.0 (TID 1019) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:45,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1527.0, whose tasks have all completed, from pool 
2019-06-11 09:42:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1527 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:42:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 509 finished: print at Transform.scala:36, took 0.023254 s
2019-06-11 09:42:45,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:45,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 508 is 83 bytes
2019-06-11 09:42:45,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 509 is 160 bytes
2019-06-11 09:42:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 510 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1530 (print at Transform.scala:36)
2019-06-11 09:42:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1529, ShuffleMapStage 1528)
2019-06-11 09:42:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1530 (MapPartitionsRDD[1786] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:45,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_765 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_765_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:45,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_765_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:45,035  INFO [org.apache.spark.SparkContext] - Created broadcast 765 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1530 (MapPartitionsRDD[1786] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:45,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1530.0 with 1 tasks
2019-06-11 09:42:45,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1530.0 (TID 1020, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:45,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1530.0 (TID 1020)
2019-06-11 09:42:45,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:45,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:45,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:45,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:45,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1530.0 (TID 1020). 1009 bytes result sent to driver
2019-06-11 09:42:45,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1530.0 (TID 1020) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:45,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1530.0, whose tasks have all completed, from pool 
2019-06-11 09:42:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1530 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 510 finished: print at Transform.scala:36, took 0.004728 s
2019-06-11 09:42:45,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217365000 ms.0 from job set of time 1560217365000 ms
2019-06-11 09:42:45,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217365000 ms (execution: 0.033 s)
2019-06-11 09:42:45,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1779 from persistence list
2019-06-11 09:42:45,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1779
2019-06-11 09:42:45,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1774 from persistence list
2019-06-11 09:42:45,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1774
2019-06-11 09:42:45,038  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1773 from persistence list
2019-06-11 09:42:45,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1773
2019-06-11 09:42:45,038  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1773] at socketTextStream at Transform.scala:18 of time 1560217365000 ms
2019-06-11 09:42:45,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217355000 ms
2019-06-11 09:42:45,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217355000 ms
2019-06-11 09:42:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217370000 ms
2019-06-11 09:42:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217370000 ms.0 from job set of time 1560217370000 ms
2019-06-11 09:42:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1788 (map at Transform.scala:20)
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 511 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1533 (print at Transform.scala:36)
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1531, ShuffleMapStage 1532)
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1532)
2019-06-11 09:42:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1532 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_766 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:50,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_766_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:42:50,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_766_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:50,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_761_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,014  INFO [org.apache.spark.SparkContext] - Created broadcast 766 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:50,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1532 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:50,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1532.0 with 2 tasks
2019-06-11 09:42:50,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_763_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:50,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1532.0 (TID 1021, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:50,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1532.0 (TID 1021)
2019-06-11 09:42:50,016  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 506
2019-06-11 09:42:50,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_760_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:50,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_765_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_755_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 502
2019-06-11 09:42:50,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 504
2019-06-11 09:42:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_754_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:50,020  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 500
2019-06-11 09:42:50,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 505
2019-06-11 09:42:50,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_762_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 507
2019-06-11 09:42:50,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_758_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 501
2019-06-11 09:42:50,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_764_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_757_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:50,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_756_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_759_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 503
2019-06-11 09:42:50,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1532.0 (TID 1021). 853 bytes result sent to driver
2019-06-11 09:42:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1532.0 (TID 1022, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:50,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1532.0 (TID 1022)
2019-06-11 09:42:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1532.0 (TID 1021) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:50,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1532.0 (TID 1022). 810 bytes result sent to driver
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1532.0 (TID 1022) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1532.0, whose tasks have all completed, from pool 
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1532 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1533)
2019-06-11 09:42:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1533 (MapPartitionsRDD[1793] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_767 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:50,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_767_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:50,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_767_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,042  INFO [org.apache.spark.SparkContext] - Created broadcast 767 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1533 (MapPartitionsRDD[1793] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:50,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1533.0 with 1 tasks
2019-06-11 09:42:50,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1533.0 (TID 1023, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:50,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1533.0 (TID 1023)
2019-06-11 09:42:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:50,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1533.0 (TID 1023). 1009 bytes result sent to driver
2019-06-11 09:42:50,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1533.0 (TID 1023) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:50,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1533.0, whose tasks have all completed, from pool 
2019-06-11 09:42:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1533 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 511 finished: print at Transform.scala:36, took 0.037603 s
2019-06-11 09:42:50,048  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:50,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 510 is 83 bytes
2019-06-11 09:42:50,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 511 is 160 bytes
2019-06-11 09:42:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 512 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1536 (print at Transform.scala:36)
2019-06-11 09:42:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1534, ShuffleMapStage 1535)
2019-06-11 09:42:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1536 (MapPartitionsRDD[1793] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:50,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_768 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:50,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_768_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_768_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:50,052  INFO [org.apache.spark.SparkContext] - Created broadcast 768 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1536 (MapPartitionsRDD[1793] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:50,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1536.0 with 1 tasks
2019-06-11 09:42:50,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1536.0 (TID 1024, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:50,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1536.0 (TID 1024)
2019-06-11 09:42:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:50,054  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:42:50,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1536.0 (TID 1024). 1009 bytes result sent to driver
2019-06-11 09:42:50,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1536.0 (TID 1024) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:50,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1536.0, whose tasks have all completed, from pool 
2019-06-11 09:42:50,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1536 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:50,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 512 finished: print at Transform.scala:36, took 0.007125 s
2019-06-11 09:42:50,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217370000 ms.0 from job set of time 1560217370000 ms
2019-06-11 09:42:50,056  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.056 s for time 1560217370000 ms (execution: 0.050 s)
2019-06-11 09:42:50,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1786 from persistence list
2019-06-11 09:42:50,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1786
2019-06-11 09:42:50,056  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1781 from persistence list
2019-06-11 09:42:50,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1781
2019-06-11 09:42:50,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1780 from persistence list
2019-06-11 09:42:50,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1780
2019-06-11 09:42:50,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1780] at socketTextStream at Transform.scala:18 of time 1560217370000 ms
2019-06-11 09:42:50,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217360000 ms
2019-06-11 09:42:50,057  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217360000 ms
2019-06-11 09:42:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217375000 ms
2019-06-11 09:42:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217375000 ms.0 from job set of time 1560217375000 ms
2019-06-11 09:42:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1795 (map at Transform.scala:20)
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 513 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1539 (print at Transform.scala:36)
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1537, ShuffleMapStage 1538)
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1537)
2019-06-11 09:42:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1537 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_769 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_769_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:42:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_769_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:42:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 769 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1537 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:55,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1537.0 with 2 tasks
2019-06-11 09:42:55,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1537.0 (TID 1025, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:55,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1537.0 (TID 1025)
2019-06-11 09:42:55,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1537.0 (TID 1025). 810 bytes result sent to driver
2019-06-11 09:42:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1537.0 (TID 1026, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:55,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1537.0 (TID 1026)
2019-06-11 09:42:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1537.0 (TID 1025) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:55,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1537.0 (TID 1026). 767 bytes result sent to driver
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1537.0 (TID 1026) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1537.0, whose tasks have all completed, from pool 
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1537 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1539)
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1539 (MapPartitionsRDD[1800] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:55,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_770 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:55,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_770_piece0 stored as bytes in memory (estimated size 2040.0 B, free 1989.4 MB)
2019-06-11 09:42:55,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_770_piece0 in memory on 192.168.91.1:63518 (size: 2040.0 B, free: 1989.5 MB)
2019-06-11 09:42:55,029  INFO [org.apache.spark.SparkContext] - Created broadcast 770 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1539 (MapPartitionsRDD[1800] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1539.0 with 1 tasks
2019-06-11 09:42:55,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1539.0 (TID 1027, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:55,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1539.0 (TID 1027)
2019-06-11 09:42:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:55,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:55,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:55,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1539.0 (TID 1027). 1052 bytes result sent to driver
2019-06-11 09:42:55,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1539.0 (TID 1027) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:55,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1539.0, whose tasks have all completed, from pool 
2019-06-11 09:42:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1539 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 513 finished: print at Transform.scala:36, took 0.023392 s
2019-06-11 09:42:55,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 513 is 160 bytes
2019-06-11 09:42:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 512 is 83 bytes
2019-06-11 09:42:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 514 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1542 (print at Transform.scala:36)
2019-06-11 09:42:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1540, ShuffleMapStage 1541)
2019-06-11 09:42:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1542 (MapPartitionsRDD[1800] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:55,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_771 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_771_piece0 stored as bytes in memory (estimated size 2040.0 B, free 1989.4 MB)
2019-06-11 09:42:55,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_771_piece0 in memory on 192.168.91.1:63518 (size: 2040.0 B, free: 1989.5 MB)
2019-06-11 09:42:55,036  INFO [org.apache.spark.SparkContext] - Created broadcast 771 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1542 (MapPartitionsRDD[1800] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1542.0 with 1 tasks
2019-06-11 09:42:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1542.0 (TID 1028, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:55,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1542.0 (TID 1028)
2019-06-11 09:42:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:55,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1542.0 (TID 1028). 966 bytes result sent to driver
2019-06-11 09:42:55,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1542.0 (TID 1028) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1542.0, whose tasks have all completed, from pool 
2019-06-11 09:42:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1542 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 514 finished: print at Transform.scala:36, took 0.004319 s
2019-06-11 09:42:55,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217375000 ms.0 from job set of time 1560217375000 ms
2019-06-11 09:42:55,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217375000 ms (execution: 0.032 s)
2019-06-11 09:42:55,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1793 from persistence list
2019-06-11 09:42:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1793
2019-06-11 09:42:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1788 from persistence list
2019-06-11 09:42:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1788
2019-06-11 09:42:55,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1787 from persistence list
2019-06-11 09:42:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1787
2019-06-11 09:42:55,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1787] at socketTextStream at Transform.scala:18 of time 1560217375000 ms
2019-06-11 09:42:55,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217365000 ms
2019-06-11 09:42:55,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217365000 ms
2019-06-11 09:43:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217380000 ms
2019-06-11 09:43:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217380000 ms.0 from job set of time 1560217380000 ms
2019-06-11 09:43:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1802 (map at Transform.scala:20)
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 515 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1545 (print at Transform.scala:36)
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1543, ShuffleMapStage 1544)
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1543)
2019-06-11 09:43:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1543 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:00,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_772 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_772_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:00,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_772_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:00,012  INFO [org.apache.spark.SparkContext] - Created broadcast 772 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1543 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:00,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1543.0 with 2 tasks
2019-06-11 09:43:00,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1543.0 (TID 1029, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:00,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1543.0 (TID 1029)
2019-06-11 09:43:00,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1543.0 (TID 1029). 853 bytes result sent to driver
2019-06-11 09:43:00,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1543.0 (TID 1030, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:00,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1543.0 (TID 1030)
2019-06-11 09:43:00,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1543.0 (TID 1029) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:00,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1543.0 (TID 1030). 810 bytes result sent to driver
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1543.0 (TID 1030) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1543.0, whose tasks have all completed, from pool 
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1543 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1545)
2019-06-11 09:43:00,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1545 (MapPartitionsRDD[1807] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:00,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_773 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_773_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:00,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_773_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:00,031  INFO [org.apache.spark.SparkContext] - Created broadcast 773 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1545 (MapPartitionsRDD[1807] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:00,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1545.0 with 1 tasks
2019-06-11 09:43:00,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1545.0 (TID 1031, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:00,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1545.0 (TID 1031)
2019-06-11 09:43:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:00,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1545.0 (TID 1031). 1009 bytes result sent to driver
2019-06-11 09:43:00,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1545.0 (TID 1031) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:00,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1545.0, whose tasks have all completed, from pool 
2019-06-11 09:43:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1545 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 515 finished: print at Transform.scala:36, took 0.024984 s
2019-06-11 09:43:00,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 515 is 160 bytes
2019-06-11 09:43:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 514 is 83 bytes
2019-06-11 09:43:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 516 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1548 (print at Transform.scala:36)
2019-06-11 09:43:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1547, ShuffleMapStage 1546)
2019-06-11 09:43:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1548 (MapPartitionsRDD[1807] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:00,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_774 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_774_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:00,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_774_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:00,038  INFO [org.apache.spark.SparkContext] - Created broadcast 774 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1548 (MapPartitionsRDD[1807] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:00,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1548.0 with 1 tasks
2019-06-11 09:43:00,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1548.0 (TID 1032, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:00,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1548.0 (TID 1032)
2019-06-11 09:43:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:00,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1548.0 (TID 1032). 966 bytes result sent to driver
2019-06-11 09:43:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1548.0 (TID 1032) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1548.0, whose tasks have all completed, from pool 
2019-06-11 09:43:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1548 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 516 finished: print at Transform.scala:36, took 0.004125 s
2019-06-11 09:43:00,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217380000 ms.0 from job set of time 1560217380000 ms
2019-06-11 09:43:00,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217380000 ms (execution: 0.034 s)
2019-06-11 09:43:00,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1800 from persistence list
2019-06-11 09:43:00,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1800
2019-06-11 09:43:00,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1795 from persistence list
2019-06-11 09:43:00,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1795
2019-06-11 09:43:00,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1794 from persistence list
2019-06-11 09:43:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1794
2019-06-11 09:43:00,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1794] at socketTextStream at Transform.scala:18 of time 1560217380000 ms
2019-06-11 09:43:00,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217370000 ms
2019-06-11 09:43:00,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217370000 ms
2019-06-11 09:43:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217385000 ms
2019-06-11 09:43:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217385000 ms.0 from job set of time 1560217385000 ms
2019-06-11 09:43:05,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1809 (map at Transform.scala:20)
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 517 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1551 (print at Transform.scala:36)
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1549, ShuffleMapStage 1550)
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1549)
2019-06-11 09:43:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1549 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_775 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_775_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.3 MB)
2019-06-11 09:43:05,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_775_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,010  INFO [org.apache.spark.SparkContext] - Created broadcast 775 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1549 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:05,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1549.0 with 2 tasks
2019-06-11 09:43:05,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1549.0 (TID 1033, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1549.0 (TID 1033)
2019-06-11 09:43:05,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1549.0 (TID 1033). 810 bytes result sent to driver
2019-06-11 09:43:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1549.0 (TID 1034, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1549.0 (TID 1034)
2019-06-11 09:43:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1549.0 (TID 1033) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:05,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1549.0 (TID 1034). 767 bytes result sent to driver
2019-06-11 09:43:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1549.0 (TID 1034) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:05,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1549.0, whose tasks have all completed, from pool 
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1549 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1551)
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1551 (MapPartitionsRDD[1814] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_776 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_776_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_776_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,029  INFO [org.apache.spark.SparkContext] - Created broadcast 776 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1551 (MapPartitionsRDD[1814] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:05,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1551.0 with 1 tasks
2019-06-11 09:43:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1551.0 (TID 1035, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:05,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1551.0 (TID 1035)
2019-06-11 09:43:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:05,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1551.0 (TID 1035). 1009 bytes result sent to driver
2019-06-11 09:43:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1551.0 (TID 1035) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:05,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1551.0, whose tasks have all completed, from pool 
2019-06-11 09:43:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1551 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 517 finished: print at Transform.scala:36, took 0.023738 s
2019-06-11 09:43:05,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 517 is 160 bytes
2019-06-11 09:43:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 516 is 83 bytes
2019-06-11 09:43:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 518 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1554 (print at Transform.scala:36)
2019-06-11 09:43:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1552, ShuffleMapStage 1553)
2019-06-11 09:43:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1554 (MapPartitionsRDD[1814] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_777 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_777_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_777_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,037  INFO [org.apache.spark.SparkContext] - Created broadcast 777 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:05,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1554 (MapPartitionsRDD[1814] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1554.0 with 1 tasks
2019-06-11 09:43:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1554.0 (TID 1036, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1554.0 (TID 1036)
2019-06-11 09:43:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:05,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_768_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1554.0 (TID 1036). 1052 bytes result sent to driver
2019-06-11 09:43:05,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1554.0 (TID 1036) in 6 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:05,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1554.0, whose tasks have all completed, from pool 
2019-06-11 09:43:05,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_770_piece0 on 192.168.91.1:63518 in memory (size: 2040.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1554 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:43:05,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 518 finished: print at Transform.scala:36, took 0.008816 s
2019-06-11 09:43:05,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217385000 ms.0 from job set of time 1560217385000 ms
2019-06-11 09:43:05,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560217385000 ms (execution: 0.038 s)
2019-06-11 09:43:05,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1807 from persistence list
2019-06-11 09:43:05,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1802 from persistence list
2019-06-11 09:43:05,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_769_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1807
2019-06-11 09:43:05,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1801 from persistence list
2019-06-11 09:43:05,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1802
2019-06-11 09:43:05,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1801
2019-06-11 09:43:05,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1801] at socketTextStream at Transform.scala:18 of time 1560217385000 ms
2019-06-11 09:43:05,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217375000 ms
2019-06-11 09:43:05,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217375000 ms
2019-06-11 09:43:05,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_772_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_771_piece0 on 192.168.91.1:63518 in memory (size: 2040.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 511
2019-06-11 09:43:05,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_767_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 510
2019-06-11 09:43:05,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 509
2019-06-11 09:43:05,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_766_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_776_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_773_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_774_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_775_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:05,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 512
2019-06-11 09:43:05,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 508
2019-06-11 09:43:05,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 513
2019-06-11 09:43:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217390000 ms
2019-06-11 09:43:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217390000 ms.0 from job set of time 1560217390000 ms
2019-06-11 09:43:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1816 (map at Transform.scala:20)
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 519 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1557 (print at Transform.scala:36)
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1555, ShuffleMapStage 1556)
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1555)
2019-06-11 09:43:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1555 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_778 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_778_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_778_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:10,010  INFO [org.apache.spark.SparkContext] - Created broadcast 778 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1555 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1555.0 with 2 tasks
2019-06-11 09:43:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1555.0 (TID 1037, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1555.0 (TID 1037)
2019-06-11 09:43:10,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1555.0 (TID 1037). 810 bytes result sent to driver
2019-06-11 09:43:10,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1555.0 (TID 1038, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:10,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1555.0 (TID 1038)
2019-06-11 09:43:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1555.0 (TID 1037) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:10,042  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1555.0 (TID 1038). 853 bytes result sent to driver
2019-06-11 09:43:10,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1555.0 (TID 1038) in 22 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1555.0, whose tasks have all completed, from pool 
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1555 (parallelize at Transform.scala:16) finished in 0.032 s
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1557)
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1557 (MapPartitionsRDD[1821] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_779 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:10,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_779_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_779_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:10,044  INFO [org.apache.spark.SparkContext] - Created broadcast 779 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:10,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1557 (MapPartitionsRDD[1821] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1557.0 with 1 tasks
2019-06-11 09:43:10,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1557.0 (TID 1039, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:10,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1557.0 (TID 1039)
2019-06-11 09:43:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:10,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:10,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1557.0 (TID 1039). 1009 bytes result sent to driver
2019-06-11 09:43:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1557.0 (TID 1039) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1557.0, whose tasks have all completed, from pool 
2019-06-11 09:43:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1557 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 519 finished: print at Transform.scala:36, took 0.038030 s
2019-06-11 09:43:10,050  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:10,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 519 is 160 bytes
2019-06-11 09:43:10,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 518 is 83 bytes
2019-06-11 09:43:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 520 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1560 (print at Transform.scala:36)
2019-06-11 09:43:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1558, ShuffleMapStage 1559)
2019-06-11 09:43:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:10,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1560 (MapPartitionsRDD[1821] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:10,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_780 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:10,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_780_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:10,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_780_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:10,052  INFO [org.apache.spark.SparkContext] - Created broadcast 780 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:10,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1560 (MapPartitionsRDD[1821] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:10,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1560.0 with 1 tasks
2019-06-11 09:43:10,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1560.0 (TID 1040, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:10,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1560.0 (TID 1040)
2019-06-11 09:43:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:10,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:10,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1560.0 (TID 1040). 1009 bytes result sent to driver
2019-06-11 09:43:10,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1560.0 (TID 1040) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:10,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1560.0, whose tasks have all completed, from pool 
2019-06-11 09:43:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1560 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:10,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 520 finished: print at Transform.scala:36, took 0.004384 s
2019-06-11 09:43:10,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217390000 ms.0 from job set of time 1560217390000 ms
2019-06-11 09:43:10,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560217390000 ms (execution: 0.048 s)
2019-06-11 09:43:10,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1814 from persistence list
2019-06-11 09:43:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1814
2019-06-11 09:43:10,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1809 from persistence list
2019-06-11 09:43:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1809
2019-06-11 09:43:10,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1808 from persistence list
2019-06-11 09:43:10,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1808
2019-06-11 09:43:10,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1808] at socketTextStream at Transform.scala:18 of time 1560217390000 ms
2019-06-11 09:43:10,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217380000 ms
2019-06-11 09:43:10,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217380000 ms
2019-06-11 09:43:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217395000 ms
2019-06-11 09:43:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217395000 ms.0 from job set of time 1560217395000 ms
2019-06-11 09:43:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1823 (map at Transform.scala:20)
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 521 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1563 (print at Transform.scala:36)
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1561, ShuffleMapStage 1562)
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1562)
2019-06-11 09:43:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1562 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_781 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_781_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:15,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_781_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 781 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1562 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1562.0 with 2 tasks
2019-06-11 09:43:15,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1562.0 (TID 1041, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:15,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1562.0 (TID 1041)
2019-06-11 09:43:15,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1562.0 (TID 1041). 853 bytes result sent to driver
2019-06-11 09:43:15,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1562.0 (TID 1042, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:15,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1562.0 (TID 1042)
2019-06-11 09:43:15,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1562.0 (TID 1041) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:15,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1562.0 (TID 1042). 810 bytes result sent to driver
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1562.0 (TID 1042) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1562.0, whose tasks have all completed, from pool 
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1562 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1563)
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1563 (MapPartitionsRDD[1828] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:15,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_782 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:15,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_782_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:15,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_782_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:15,034  INFO [org.apache.spark.SparkContext] - Created broadcast 782 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1563 (MapPartitionsRDD[1828] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:15,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1563.0 with 1 tasks
2019-06-11 09:43:15,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1563.0 (TID 1043, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:15,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1563.0 (TID 1043)
2019-06-11 09:43:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:43:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:15,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1563.0 (TID 1043). 966 bytes result sent to driver
2019-06-11 09:43:15,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1563.0 (TID 1043) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:15,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1563.0, whose tasks have all completed, from pool 
2019-06-11 09:43:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1563 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 521 finished: print at Transform.scala:36, took 0.028826 s
2019-06-11 09:43:15,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 520 is 83 bytes
2019-06-11 09:43:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 521 is 160 bytes
2019-06-11 09:43:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 522 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1566 (print at Transform.scala:36)
2019-06-11 09:43:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1565, ShuffleMapStage 1564)
2019-06-11 09:43:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1566 (MapPartitionsRDD[1828] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:15,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_783 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_783_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:15,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_783_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 783 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1566 (MapPartitionsRDD[1828] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1566.0 with 1 tasks
2019-06-11 09:43:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1566.0 (TID 1044, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:15,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1566.0 (TID 1044)
2019-06-11 09:43:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:15,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1566.0 (TID 1044). 966 bytes result sent to driver
2019-06-11 09:43:15,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1566.0 (TID 1044) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:15,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1566.0, whose tasks have all completed, from pool 
2019-06-11 09:43:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1566 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 522 finished: print at Transform.scala:36, took 0.004290 s
2019-06-11 09:43:15,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217395000 ms.0 from job set of time 1560217395000 ms
2019-06-11 09:43:15,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560217395000 ms (execution: 0.038 s)
2019-06-11 09:43:15,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1821 from persistence list
2019-06-11 09:43:15,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1821
2019-06-11 09:43:15,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1816 from persistence list
2019-06-11 09:43:15,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1816
2019-06-11 09:43:15,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1815 from persistence list
2019-06-11 09:43:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1815
2019-06-11 09:43:15,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1815] at socketTextStream at Transform.scala:18 of time 1560217395000 ms
2019-06-11 09:43:15,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217385000 ms
2019-06-11 09:43:15,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217385000 ms
2019-06-11 09:43:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217400000 ms
2019-06-11 09:43:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217400000 ms.0 from job set of time 1560217400000 ms
2019-06-11 09:43:20,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1830 (map at Transform.scala:20)
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 523 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1569 (print at Transform.scala:36)
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1567, ShuffleMapStage 1568)
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1568)
2019-06-11 09:43:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1568 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_784 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:20,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_784_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:20,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_784_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:20,012  INFO [org.apache.spark.SparkContext] - Created broadcast 784 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1568 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:20,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1568.0 with 2 tasks
2019-06-11 09:43:20,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1568.0 (TID 1045, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:20,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1568.0 (TID 1045)
2019-06-11 09:43:20,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1568.0 (TID 1045). 853 bytes result sent to driver
2019-06-11 09:43:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1568.0 (TID 1046, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:20,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1568.0 (TID 1045) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:20,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1568.0 (TID 1046)
2019-06-11 09:43:20,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1568.0 (TID 1046). 767 bytes result sent to driver
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1568.0 (TID 1046) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1568.0, whose tasks have all completed, from pool 
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1568 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1569)
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1569 (MapPartitionsRDD[1835] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_785 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:20,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_785_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:20,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_785_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:20,032  INFO [org.apache.spark.SparkContext] - Created broadcast 785 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1569 (MapPartitionsRDD[1835] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1569.0 with 1 tasks
2019-06-11 09:43:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1569.0 (TID 1047, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:20,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1569.0 (TID 1047)
2019-06-11 09:43:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:20,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:20,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1569.0 (TID 1047). 966 bytes result sent to driver
2019-06-11 09:43:20,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1569.0 (TID 1047) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:20,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1569.0, whose tasks have all completed, from pool 
2019-06-11 09:43:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1569 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:43:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 523 finished: print at Transform.scala:36, took 0.023707 s
2019-06-11 09:43:20,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 522 is 83 bytes
2019-06-11 09:43:20,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 523 is 160 bytes
2019-06-11 09:43:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 524 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1572 (print at Transform.scala:36)
2019-06-11 09:43:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1570, ShuffleMapStage 1571)
2019-06-11 09:43:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1572 (MapPartitionsRDD[1835] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_786 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:20,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_786_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:20,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_786_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:20,038  INFO [org.apache.spark.SparkContext] - Created broadcast 786 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1572 (MapPartitionsRDD[1835] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1572.0 with 1 tasks
2019-06-11 09:43:20,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1572.0 (TID 1048, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:20,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1572.0 (TID 1048)
2019-06-11 09:43:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:20,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:20,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1572.0 (TID 1048). 966 bytes result sent to driver
2019-06-11 09:43:20,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1572.0 (TID 1048) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:20,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1572.0, whose tasks have all completed, from pool 
2019-06-11 09:43:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1572 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 524 finished: print at Transform.scala:36, took 0.005408 s
2019-06-11 09:43:20,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217400000 ms.0 from job set of time 1560217400000 ms
2019-06-11 09:43:20,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217400000 ms (execution: 0.034 s)
2019-06-11 09:43:20,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1828 from persistence list
2019-06-11 09:43:20,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1828
2019-06-11 09:43:20,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1823 from persistence list
2019-06-11 09:43:20,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1823
2019-06-11 09:43:20,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1822 from persistence list
2019-06-11 09:43:20,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1822
2019-06-11 09:43:20,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1822] at socketTextStream at Transform.scala:18 of time 1560217400000 ms
2019-06-11 09:43:20,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217390000 ms
2019-06-11 09:43:20,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217390000 ms
2019-06-11 09:43:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217405000 ms
2019-06-11 09:43:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217405000 ms.0 from job set of time 1560217405000 ms
2019-06-11 09:43:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1837 (map at Transform.scala:20)
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 525 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1575 (print at Transform.scala:36)
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1573, ShuffleMapStage 1574)
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1574)
2019-06-11 09:43:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1574 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_787 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_787_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.3 MB)
2019-06-11 09:43:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_787_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 787 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1574 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1574.0 with 2 tasks
2019-06-11 09:43:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1574.0 (TID 1049, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:25,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1574.0 (TID 1049)
2019-06-11 09:43:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1574.0 (TID 1049). 853 bytes result sent to driver
2019-06-11 09:43:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1574.0 (TID 1050, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1574.0 (TID 1050)
2019-06-11 09:43:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1574.0 (TID 1049) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:25,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1574.0 (TID 1050). 853 bytes result sent to driver
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1574.0 (TID 1050) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1574.0, whose tasks have all completed, from pool 
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1574 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1575)
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1575 (MapPartitionsRDD[1842] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:25,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_788 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:25,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_788_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:25,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_788_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,035  INFO [org.apache.spark.SparkContext] - Created broadcast 788 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1575 (MapPartitionsRDD[1842] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:25,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1575.0 with 1 tasks
2019-06-11 09:43:25,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1575.0 (TID 1051, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:25,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1575.0 (TID 1051)
2019-06-11 09:43:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:25,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:25,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1575.0 (TID 1051). 1009 bytes result sent to driver
2019-06-11 09:43:25,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1575.0 (TID 1051) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:25,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1575.0, whose tasks have all completed, from pool 
2019-06-11 09:43:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1575 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 525 finished: print at Transform.scala:36, took 0.029913 s
2019-06-11 09:43:25,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 524 is 83 bytes
2019-06-11 09:43:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 525 is 160 bytes
2019-06-11 09:43:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 526 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1578 (print at Transform.scala:36)
2019-06-11 09:43:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1576, ShuffleMapStage 1577)
2019-06-11 09:43:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1578 (MapPartitionsRDD[1842] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:25,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_789 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:25,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 514
2019-06-11 09:43:25,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_789_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:25,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_789_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_788_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,046  INFO [org.apache.spark.SparkContext] - Created broadcast 789 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1578 (MapPartitionsRDD[1842] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:25,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1578.0 with 1 tasks
2019-06-11 09:43:25,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1578.0 (TID 1052, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:25,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_786_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1578.0 (TID 1052)
2019-06-11 09:43:25,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_784_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:25,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:25,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:43:25,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_779_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1578.0 (TID 1052). 966 bytes result sent to driver
2019-06-11 09:43:25,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_787_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:25,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1578.0 (TID 1052) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:25,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1578.0, whose tasks have all completed, from pool 
2019-06-11 09:43:25,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1578 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:43:25,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 526 finished: print at Transform.scala:36, took 0.010224 s
2019-06-11 09:43:25,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217405000 ms.0 from job set of time 1560217405000 ms
2019-06-11 09:43:25,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560217405000 ms (execution: 0.044 s)
2019-06-11 09:43:25,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1835 from persistence list
2019-06-11 09:43:25,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1835
2019-06-11 09:43:25,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1830 from persistence list
2019-06-11 09:43:25,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_778_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:25,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1830
2019-06-11 09:43:25,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1829 from persistence list
2019-06-11 09:43:25,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1829
2019-06-11 09:43:25,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1829] at socketTextStream at Transform.scala:18 of time 1560217405000 ms
2019-06-11 09:43:25,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217395000 ms
2019-06-11 09:43:25,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217395000 ms
2019-06-11 09:43:25,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_777_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_782_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_781_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:25,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 520
2019-06-11 09:43:25,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 516
2019-06-11 09:43:25,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_783_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_780_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 515
2019-06-11 09:43:25,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 517
2019-06-11 09:43:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_785_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:25,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 521
2019-06-11 09:43:25,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 519
2019-06-11 09:43:25,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 518
2019-06-11 09:43:30,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217410000 ms
2019-06-11 09:43:30,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217410000 ms.0 from job set of time 1560217410000 ms
2019-06-11 09:43:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1844 (map at Transform.scala:20)
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 527 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1581 (print at Transform.scala:36)
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1579, ShuffleMapStage 1580)
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1579)
2019-06-11 09:43:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1579 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_790 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_790_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:30,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_790_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 790 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1579 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1579.0 with 2 tasks
2019-06-11 09:43:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1579.0 (TID 1053, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1579.0 (TID 1053)
2019-06-11 09:43:30,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1579.0 (TID 1053). 853 bytes result sent to driver
2019-06-11 09:43:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1579.0 (TID 1054, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:30,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1579.0 (TID 1054)
2019-06-11 09:43:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1579.0 (TID 1053) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:30,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1579.0 (TID 1054). 810 bytes result sent to driver
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1579.0 (TID 1054) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1579.0, whose tasks have all completed, from pool 
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1579 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1581)
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1581 (MapPartitionsRDD[1849] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:30,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_791 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_791_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:30,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_791_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:30,030  INFO [org.apache.spark.SparkContext] - Created broadcast 791 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1581 (MapPartitionsRDD[1849] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1581.0 with 1 tasks
2019-06-11 09:43:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1581.0 (TID 1055, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:30,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1581.0 (TID 1055)
2019-06-11 09:43:30,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:30,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:30,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:30,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1581.0 (TID 1055). 966 bytes result sent to driver
2019-06-11 09:43:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1581.0 (TID 1055) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1581.0, whose tasks have all completed, from pool 
2019-06-11 09:43:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1581 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 527 finished: print at Transform.scala:36, took 0.024383 s
2019-06-11 09:43:30,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:30,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 527 is 160 bytes
2019-06-11 09:43:30,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 526 is 83 bytes
2019-06-11 09:43:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 528 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1584 (print at Transform.scala:36)
2019-06-11 09:43:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1582, ShuffleMapStage 1583)
2019-06-11 09:43:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1584 (MapPartitionsRDD[1849] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:30,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_792 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:30,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_792_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:30,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_792_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:30,038  INFO [org.apache.spark.SparkContext] - Created broadcast 792 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1584 (MapPartitionsRDD[1849] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:30,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1584.0 with 1 tasks
2019-06-11 09:43:30,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1584.0 (TID 1056, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:30,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1584.0 (TID 1056)
2019-06-11 09:43:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:30,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:30,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1584.0 (TID 1056). 1009 bytes result sent to driver
2019-06-11 09:43:30,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1584.0 (TID 1056) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1584.0, whose tasks have all completed, from pool 
2019-06-11 09:43:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1584 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:43:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 528 finished: print at Transform.scala:36, took 0.005879 s
2019-06-11 09:43:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217410000 ms.0 from job set of time 1560217410000 ms
2019-06-11 09:43:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217410000 ms (execution: 0.033 s)
2019-06-11 09:43:30,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1842 from persistence list
2019-06-11 09:43:30,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1842
2019-06-11 09:43:30,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1837 from persistence list
2019-06-11 09:43:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1837
2019-06-11 09:43:30,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1836 from persistence list
2019-06-11 09:43:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1836
2019-06-11 09:43:30,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1836] at socketTextStream at Transform.scala:18 of time 1560217410000 ms
2019-06-11 09:43:30,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217400000 ms
2019-06-11 09:43:30,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217400000 ms
2019-06-11 09:43:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217415000 ms
2019-06-11 09:43:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217415000 ms.0 from job set of time 1560217415000 ms
2019-06-11 09:43:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1851 (map at Transform.scala:20)
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 529 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1587 (print at Transform.scala:36)
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1585, ShuffleMapStage 1586)
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1585)
2019-06-11 09:43:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1585 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_793 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_793_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:35,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_793_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 793 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1585 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1585.0 with 2 tasks
2019-06-11 09:43:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1585.0 (TID 1057, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1585.0 (TID 1057)
2019-06-11 09:43:35,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1585.0 (TID 1057). 853 bytes result sent to driver
2019-06-11 09:43:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1585.0 (TID 1058, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:35,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1585.0 (TID 1058)
2019-06-11 09:43:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1585.0 (TID 1057) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:35,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1585.0 (TID 1058). 767 bytes result sent to driver
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1585.0 (TID 1058) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1585.0, whose tasks have all completed, from pool 
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1585 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1587)
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1587 (MapPartitionsRDD[1856] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:35,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_794 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:35,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_794_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:35,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_794_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:35,030  INFO [org.apache.spark.SparkContext] - Created broadcast 794 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1587 (MapPartitionsRDD[1856] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:35,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1587.0 with 1 tasks
2019-06-11 09:43:35,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1587.0 (TID 1059, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:35,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1587.0 (TID 1059)
2019-06-11 09:43:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:35,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:43:35,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1587.0 (TID 1059). 1009 bytes result sent to driver
2019-06-11 09:43:35,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1587.0 (TID 1059) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:35,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1587.0, whose tasks have all completed, from pool 
2019-06-11 09:43:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1587 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:43:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 529 finished: print at Transform.scala:36, took 0.024930 s
2019-06-11 09:43:35,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:35,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 529 is 160 bytes
2019-06-11 09:43:35,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 528 is 83 bytes
2019-06-11 09:43:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 530 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1590 (print at Transform.scala:36)
2019-06-11 09:43:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1588, ShuffleMapStage 1589)
2019-06-11 09:43:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1590 (MapPartitionsRDD[1856] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_795 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_795_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_795_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:35,037  INFO [org.apache.spark.SparkContext] - Created broadcast 795 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:35,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1590 (MapPartitionsRDD[1856] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1590.0 with 1 tasks
2019-06-11 09:43:35,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1590.0 (TID 1060, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:35,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1590.0 (TID 1060)
2019-06-11 09:43:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:35,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:35,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1590.0 (TID 1060). 966 bytes result sent to driver
2019-06-11 09:43:35,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1590.0 (TID 1060) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:35,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1590.0, whose tasks have all completed, from pool 
2019-06-11 09:43:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1590 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 530 finished: print at Transform.scala:36, took 0.004015 s
2019-06-11 09:43:35,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217415000 ms.0 from job set of time 1560217415000 ms
2019-06-11 09:43:35,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217415000 ms (execution: 0.033 s)
2019-06-11 09:43:35,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1849 from persistence list
2019-06-11 09:43:35,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1849
2019-06-11 09:43:35,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1844 from persistence list
2019-06-11 09:43:35,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1844
2019-06-11 09:43:35,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1843 from persistence list
2019-06-11 09:43:35,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1843
2019-06-11 09:43:35,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1843] at socketTextStream at Transform.scala:18 of time 1560217415000 ms
2019-06-11 09:43:35,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217405000 ms
2019-06-11 09:43:35,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217405000 ms
2019-06-11 09:43:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217420000 ms
2019-06-11 09:43:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217420000 ms.0 from job set of time 1560217420000 ms
2019-06-11 09:43:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1858 (map at Transform.scala:20)
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 531 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1593 (print at Transform.scala:36)
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1591, ShuffleMapStage 1592)
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1591)
2019-06-11 09:43:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1591 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_796 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_796_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_796_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 796 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1591 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1591.0 with 2 tasks
2019-06-11 09:43:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1591.0 (TID 1061, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:40,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1591.0 (TID 1061)
2019-06-11 09:43:40,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1591.0 (TID 1061). 853 bytes result sent to driver
2019-06-11 09:43:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1591.0 (TID 1062, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:40,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1591.0 (TID 1062)
2019-06-11 09:43:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1591.0 (TID 1061) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:40,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1591.0 (TID 1062). 767 bytes result sent to driver
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1591.0 (TID 1062) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1591.0, whose tasks have all completed, from pool 
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1591 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1593)
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1593 (MapPartitionsRDD[1863] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:40,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_797 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_797_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:40,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_797_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:40,028  INFO [org.apache.spark.SparkContext] - Created broadcast 797 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1593 (MapPartitionsRDD[1863] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:40,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1593.0 with 1 tasks
2019-06-11 09:43:40,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1593.0 (TID 1063, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:40,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1593.0 (TID 1063)
2019-06-11 09:43:40,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:43:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:40,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1593.0 (TID 1063). 966 bytes result sent to driver
2019-06-11 09:43:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1593.0 (TID 1063) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1593.0, whose tasks have all completed, from pool 
2019-06-11 09:43:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1593 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:43:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 531 finished: print at Transform.scala:36, took 0.023101 s
2019-06-11 09:43:40,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 531 is 160 bytes
2019-06-11 09:43:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 530 is 83 bytes
2019-06-11 09:43:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 532 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1596 (print at Transform.scala:36)
2019-06-11 09:43:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1594, ShuffleMapStage 1595)
2019-06-11 09:43:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:40,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1596 (MapPartitionsRDD[1863] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_798 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_798_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:40,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_798_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:40,036  INFO [org.apache.spark.SparkContext] - Created broadcast 798 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1596 (MapPartitionsRDD[1863] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1596.0 with 1 tasks
2019-06-11 09:43:40,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1596.0 (TID 1064, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:40,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1596.0 (TID 1064)
2019-06-11 09:43:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:40,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1596.0 (TID 1064). 966 bytes result sent to driver
2019-06-11 09:43:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1596.0 (TID 1064) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1596.0, whose tasks have all completed, from pool 
2019-06-11 09:43:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1596 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 532 finished: print at Transform.scala:36, took 0.004557 s
2019-06-11 09:43:40,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217420000 ms.0 from job set of time 1560217420000 ms
2019-06-11 09:43:40,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217420000 ms (execution: 0.032 s)
2019-06-11 09:43:40,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1856 from persistence list
2019-06-11 09:43:40,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1856
2019-06-11 09:43:40,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1851 from persistence list
2019-06-11 09:43:40,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1851
2019-06-11 09:43:40,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1850 from persistence list
2019-06-11 09:43:40,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1850
2019-06-11 09:43:40,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1850] at socketTextStream at Transform.scala:18 of time 1560217420000 ms
2019-06-11 09:43:40,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217410000 ms
2019-06-11 09:43:40,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217410000 ms
2019-06-11 09:43:45,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217425000 ms
2019-06-11 09:43:45,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217425000 ms.0 from job set of time 1560217425000 ms
2019-06-11 09:43:45,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1865 (map at Transform.scala:20)
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 533 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1599 (print at Transform.scala:36)
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1598, ShuffleMapStage 1597)
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1597)
2019-06-11 09:43:45,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1597 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:45,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_799 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:45,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_799_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.3 MB)
2019-06-11 09:43:45,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_799_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:45,017  INFO [org.apache.spark.SparkContext] - Created broadcast 799 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:45,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1597 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:45,017  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1597.0 with 2 tasks
2019-06-11 09:43:45,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1597.0 (TID 1065, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:45,018  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1597.0 (TID 1065)
2019-06-11 09:43:45,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1597.0 (TID 1065). 767 bytes result sent to driver
2019-06-11 09:43:45,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1597.0 (TID 1066, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:45,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1597.0 (TID 1066)
2019-06-11 09:43:45,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1597.0 (TID 1065) in 8 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:45,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1597.0 (TID 1066). 853 bytes result sent to driver
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1597.0 (TID 1066) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1597.0, whose tasks have all completed, from pool 
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1597 (parallelize at Transform.scala:16) finished in 0.016 s
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1599)
2019-06-11 09:43:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1599 (MapPartitionsRDD[1870] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_800 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:43:45,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_800_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:43:45,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_800_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_795_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,041  INFO [org.apache.spark.SparkContext] - Created broadcast 800 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1599 (MapPartitionsRDD[1870] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1599.0 with 1 tasks
2019-06-11 09:43:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1599.0 (TID 1067, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:45,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1599.0 (TID 1067)
2019-06-11 09:43:45,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_789_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 528
2019-06-11 09:43:45,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 526
2019-06-11 09:43:45,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 523
2019-06-11 09:43:45,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:45,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:45,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_793_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:45,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 525
2019-06-11 09:43:45,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1599.0 (TID 1067). 1009 bytes result sent to driver
2019-06-11 09:43:45,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_794_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1599.0 (TID 1067) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:45,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1599.0, whose tasks have all completed, from pool 
2019-06-11 09:43:45,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 527
2019-06-11 09:43:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1599 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:43:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 533 finished: print at Transform.scala:36, took 0.029869 s
2019-06-11 09:43:45,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_798_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_792_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_790_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:45,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 524
2019-06-11 09:43:45,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 529
2019-06-11 09:43:45,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 522
2019-06-11 09:43:45,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_791_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_797_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_796_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:45,051  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:45,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 533 is 160 bytes
2019-06-11 09:43:45,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 532 is 83 bytes
2019-06-11 09:43:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 534 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1602 (print at Transform.scala:36)
2019-06-11 09:43:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1600, ShuffleMapStage 1601)
2019-06-11 09:43:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1602 (MapPartitionsRDD[1870] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:45,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_801 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:45,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_801_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:45,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_801_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:45,054  INFO [org.apache.spark.SparkContext] - Created broadcast 801 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:45,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1602 (MapPartitionsRDD[1870] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:45,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1602.0 with 1 tasks
2019-06-11 09:43:45,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1602.0 (TID 1068, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:45,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1602.0 (TID 1068)
2019-06-11 09:43:45,055  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:45,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:43:45,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:45,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:45,056  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1602.0 (TID 1068). 966 bytes result sent to driver
2019-06-11 09:43:45,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1602.0 (TID 1068) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:45,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1602.0, whose tasks have all completed, from pool 
2019-06-11 09:43:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1602 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:45,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 534 finished: print at Transform.scala:36, took 0.005608 s
2019-06-11 09:43:45,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217425000 ms.0 from job set of time 1560217425000 ms
2019-06-11 09:43:45,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.057 s for time 1560217425000 ms (execution: 0.045 s)
2019-06-11 09:43:45,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1863 from persistence list
2019-06-11 09:43:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1863
2019-06-11 09:43:45,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1858 from persistence list
2019-06-11 09:43:45,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1858
2019-06-11 09:43:45,058  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1857 from persistence list
2019-06-11 09:43:45,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1857
2019-06-11 09:43:45,058  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1857] at socketTextStream at Transform.scala:18 of time 1560217425000 ms
2019-06-11 09:43:45,058  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217415000 ms
2019-06-11 09:43:45,058  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217415000 ms
2019-06-11 09:43:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217430000 ms
2019-06-11 09:43:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217430000 ms.0 from job set of time 1560217430000 ms
2019-06-11 09:43:50,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1872 (map at Transform.scala:20)
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 535 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1605 (print at Transform.scala:36)
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1603, ShuffleMapStage 1604)
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1604)
2019-06-11 09:43:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1604 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_802 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:50,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_802_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_802_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:50,011  INFO [org.apache.spark.SparkContext] - Created broadcast 802 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:50,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1604 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:50,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1604.0 with 2 tasks
2019-06-11 09:43:50,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1604.0 (TID 1069, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:50,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1604.0 (TID 1069)
2019-06-11 09:43:50,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1604.0 (TID 1069). 810 bytes result sent to driver
2019-06-11 09:43:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1604.0 (TID 1070, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:50,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1604.0 (TID 1070)
2019-06-11 09:43:50,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1604.0 (TID 1069) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:50,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1604.0 (TID 1070). 767 bytes result sent to driver
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1604.0 (TID 1070) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1604.0, whose tasks have all completed, from pool 
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1604 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1605)
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1605 (MapPartitionsRDD[1877] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:50,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_803 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:50,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_803_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:50,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_803_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:50,033  INFO [org.apache.spark.SparkContext] - Created broadcast 803 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1605 (MapPartitionsRDD[1877] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:50,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1605.0 with 1 tasks
2019-06-11 09:43:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1605.0 (TID 1071, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:50,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1605.0 (TID 1071)
2019-06-11 09:43:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:50,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1605.0 (TID 1071). 1009 bytes result sent to driver
2019-06-11 09:43:50,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1605.0 (TID 1071) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:50,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1605.0, whose tasks have all completed, from pool 
2019-06-11 09:43:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1605 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 535 finished: print at Transform.scala:36, took 0.027279 s
2019-06-11 09:43:50,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:50,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 534 is 83 bytes
2019-06-11 09:43:50,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 535 is 160 bytes
2019-06-11 09:43:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 536 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1608 (print at Transform.scala:36)
2019-06-11 09:43:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1606, ShuffleMapStage 1607)
2019-06-11 09:43:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1608 (MapPartitionsRDD[1877] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:50,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_804 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:50,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_804_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:50,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_804_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:50,042  INFO [org.apache.spark.SparkContext] - Created broadcast 804 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:50,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1608 (MapPartitionsRDD[1877] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:50,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1608.0 with 1 tasks
2019-06-11 09:43:50,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1608.0 (TID 1072, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:50,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1608.0 (TID 1072)
2019-06-11 09:43:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:50,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:50,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1608.0 (TID 1072). 1009 bytes result sent to driver
2019-06-11 09:43:50,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1608.0 (TID 1072) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:50,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1608.0, whose tasks have all completed, from pool 
2019-06-11 09:43:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1608 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 536 finished: print at Transform.scala:36, took 0.006799 s
2019-06-11 09:43:50,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217430000 ms.0 from job set of time 1560217430000 ms
2019-06-11 09:43:50,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560217430000 ms (execution: 0.039 s)
2019-06-11 09:43:50,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1870 from persistence list
2019-06-11 09:43:50,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1870
2019-06-11 09:43:50,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1865 from persistence list
2019-06-11 09:43:50,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1865
2019-06-11 09:43:50,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1864 from persistence list
2019-06-11 09:43:50,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1864
2019-06-11 09:43:50,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1864] at socketTextStream at Transform.scala:18 of time 1560217430000 ms
2019-06-11 09:43:50,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217420000 ms
2019-06-11 09:43:50,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217420000 ms
2019-06-11 09:43:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217435000 ms
2019-06-11 09:43:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217435000 ms.0 from job set of time 1560217435000 ms
2019-06-11 09:43:55,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1879 (map at Transform.scala:20)
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 537 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1611 (print at Transform.scala:36)
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1609, ShuffleMapStage 1610)
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1609)
2019-06-11 09:43:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1609 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:43:55,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_805 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:55,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_805_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:43:55,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_805_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:43:55,009  INFO [org.apache.spark.SparkContext] - Created broadcast 805 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1609 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:43:55,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1609.0 with 2 tasks
2019-06-11 09:43:55,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1609.0 (TID 1073, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:55,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1609.0 (TID 1073)
2019-06-11 09:43:55,017  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1609.0 (TID 1073). 853 bytes result sent to driver
2019-06-11 09:43:55,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1609.0 (TID 1074, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:43:55,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1609.0 (TID 1074)
2019-06-11 09:43:55,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1609.0 (TID 1073) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:43:55,025  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1609.0 (TID 1074). 767 bytes result sent to driver
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1609.0 (TID 1074) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1609.0, whose tasks have all completed, from pool 
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1609 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1611)
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:43:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1611 (MapPartitionsRDD[1884] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:55,026  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_806 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:55,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_806_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:55,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_806_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:55,028  INFO [org.apache.spark.SparkContext] - Created broadcast 806 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1611 (MapPartitionsRDD[1884] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:43:55,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1611.0 with 1 tasks
2019-06-11 09:43:55,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1611.0 (TID 1075, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:55,028  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1611.0 (TID 1075)
2019-06-11 09:43:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:55,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1611.0 (TID 1075). 966 bytes result sent to driver
2019-06-11 09:43:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1611.0 (TID 1075) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1611.0, whose tasks have all completed, from pool 
2019-06-11 09:43:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1611 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 537 finished: print at Transform.scala:36, took 0.023515 s
2019-06-11 09:43:55,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:43:55,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 537 is 160 bytes
2019-06-11 09:43:55,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 536 is 83 bytes
2019-06-11 09:43:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 538 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:43:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1614 (print at Transform.scala:36)
2019-06-11 09:43:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1612, ShuffleMapStage 1613)
2019-06-11 09:43:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:43:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1614 (MapPartitionsRDD[1884] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:43:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_807 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:43:55,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_807_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:43:55,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_807_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:43:55,036  INFO [org.apache.spark.SparkContext] - Created broadcast 807 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:43:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1614 (MapPartitionsRDD[1884] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:43:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1614.0 with 1 tasks
2019-06-11 09:43:55,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1614.0 (TID 1076, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:43:55,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1614.0 (TID 1076)
2019-06-11 09:43:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:43:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:43:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:43:55,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1614.0 (TID 1076). 966 bytes result sent to driver
2019-06-11 09:43:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1614.0 (TID 1076) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:43:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1614.0, whose tasks have all completed, from pool 
2019-06-11 09:43:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1614 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:43:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 538 finished: print at Transform.scala:36, took 0.005649 s
2019-06-11 09:43:55,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217435000 ms.0 from job set of time 1560217435000 ms
2019-06-11 09:43:55,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217435000 ms (execution: 0.034 s)
2019-06-11 09:43:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1877 from persistence list
2019-06-11 09:43:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1872 from persistence list
2019-06-11 09:43:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1877
2019-06-11 09:43:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1872
2019-06-11 09:43:55,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1871 from persistence list
2019-06-11 09:43:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1871
2019-06-11 09:43:55,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1871] at socketTextStream at Transform.scala:18 of time 1560217435000 ms
2019-06-11 09:43:55,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217425000 ms
2019-06-11 09:43:55,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217425000 ms
2019-06-11 09:44:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217440000 ms
2019-06-11 09:44:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217440000 ms.0 from job set of time 1560217440000 ms
2019-06-11 09:44:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:44:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1886 (map at Transform.scala:20)
2019-06-11 09:44:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:44:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 539 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:44:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1617 (print at Transform.scala:36)
2019-06-11 09:44:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1616, ShuffleMapStage 1615)
2019-06-11 09:44:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1616)
2019-06-11 09:44:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1616 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:44:00,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_808 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:44:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_808_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.3 MB)
2019-06-11 09:44:00,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_808_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:00,011  INFO [org.apache.spark.SparkContext] - Created broadcast 808 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1616 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:44:00,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1616.0 with 2 tasks
2019-06-11 09:44:00,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1616.0 (TID 1077, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:44:00,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1616.0 (TID 1077)
2019-06-11 09:44:00,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1616.0 (TID 1077). 810 bytes result sent to driver
2019-06-11 09:44:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1616.0 (TID 1078, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:44:00,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1616.0 (TID 1078)
2019-06-11 09:44:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1616.0 (TID 1077) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:44:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1616.0 (TID 1078). 853 bytes result sent to driver
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1616.0 (TID 1078) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1616.0, whose tasks have all completed, from pool 
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1616 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1617)
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:44:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1617 (MapPartitionsRDD[1891] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:44:00,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_809 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:44:00,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_809_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:44:00,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_809_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:00,036  INFO [org.apache.spark.SparkContext] - Created broadcast 809 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1617 (MapPartitionsRDD[1891] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:44:00,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1617.0 with 1 tasks
2019-06-11 09:44:00,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1617.0 (TID 1079, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:44:00,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1617.0 (TID 1079)
2019-06-11 09:44:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:44:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:44:00,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:00,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1617.0 (TID 1079). 1009 bytes result sent to driver
2019-06-11 09:44:00,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1617.0 (TID 1079) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:44:00,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1617.0, whose tasks have all completed, from pool 
2019-06-11 09:44:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1617 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:44:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 539 finished: print at Transform.scala:36, took 0.030051 s
2019-06-11 09:44:00,042  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:44:00,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 538 is 83 bytes
2019-06-11 09:44:00,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 539 is 160 bytes
2019-06-11 09:44:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 540 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:44:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1620 (print at Transform.scala:36)
2019-06-11 09:44:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1618, ShuffleMapStage 1619)
2019-06-11 09:44:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:44:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1620 (MapPartitionsRDD[1891] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:44:00,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_810 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:44:00,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_810_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:44:00,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_810_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:00,045  INFO [org.apache.spark.SparkContext] - Created broadcast 810 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1620 (MapPartitionsRDD[1891] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:44:00,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1620.0 with 1 tasks
2019-06-11 09:44:00,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1620.0 (TID 1080, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:44:00,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1620.0 (TID 1080)
2019-06-11 09:44:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:44:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:44:00,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:00,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1620.0 (TID 1080). 1052 bytes result sent to driver
2019-06-11 09:44:00,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1620.0 (TID 1080) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:44:00,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1620.0, whose tasks have all completed, from pool 
2019-06-11 09:44:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1620 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:44:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 540 finished: print at Transform.scala:36, took 0.006583 s
2019-06-11 09:44:00,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217440000 ms.0 from job set of time 1560217440000 ms
2019-06-11 09:44:00,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560217440000 ms (execution: 0.042 s)
2019-06-11 09:44:00,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1884 from persistence list
2019-06-11 09:44:00,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1879 from persistence list
2019-06-11 09:44:00,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1884
2019-06-11 09:44:00,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1879
2019-06-11 09:44:00,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1878 from persistence list
2019-06-11 09:44:00,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1878
2019-06-11 09:44:00,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1878] at socketTextStream at Transform.scala:18 of time 1560217440000 ms
2019-06-11 09:44:00,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217430000 ms
2019-06-11 09:44:00,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217430000 ms
2019-06-11 09:44:05,017  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217445000 ms
2019-06-11 09:44:05,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 530
2019-06-11 09:44:05,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 533
2019-06-11 09:44:05,017  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217445000 ms.0 from job set of time 1560217445000 ms
2019-06-11 09:44:05,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 531
2019-06-11 09:44:05,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 536
2019-06-11 09:44:05,018  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 537
2019-06-11 09:44:05,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_808_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:05,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 532
2019-06-11 09:44:05,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_805_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:05,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_802_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:05,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_801_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,023  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:44:05,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 534
2019-06-11 09:44:05,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 535
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1893 (map at Transform.scala:20)
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 541 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1623 (print at Transform.scala:36)
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1621, ShuffleMapStage 1622)
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1621)
2019-06-11 09:44:05,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1621 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:44:05,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_809_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,024  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_811 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:44:05,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_803_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,025  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_811_piece0 stored as bytes in memory (estimated size 1307.0 B, free 1989.4 MB)
2019-06-11 09:44:05,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_811_piece0 in memory on 192.168.91.1:63518 (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:05,026  INFO [org.apache.spark.SparkContext] - Created broadcast 811 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:05,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_799_piece0 on 192.168.91.1:63518 in memory (size: 1307.0 B, free: 1989.5 MB)
2019-06-11 09:44:05,026  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1621 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:44:05,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1621.0 with 2 tasks
2019-06-11 09:44:05,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_806_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1621.0 (TID 1081, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:44:05,026  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1621.0 (TID 1081)
2019-06-11 09:44:05,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_810_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_800_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_807_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_804_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1621.0 (TID 1081). 810 bytes result sent to driver
2019-06-11 09:44:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1621.0 (TID 1082, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:44:05,037  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1621.0 (TID 1082)
2019-06-11 09:44:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1621.0 (TID 1081) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:44:05,045  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1621.0 (TID 1082). 810 bytes result sent to driver
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1621.0 (TID 1082) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1621.0, whose tasks have all completed, from pool 
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1621 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1623)
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:44:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1623 (MapPartitionsRDD[1898] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:44:05,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_812 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:44:05,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_812_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:44:05,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_812_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,048  INFO [org.apache.spark.SparkContext] - Created broadcast 812 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:05,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1623 (MapPartitionsRDD[1898] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:44:05,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1623.0 with 1 tasks
2019-06-11 09:44:05,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1623.0 (TID 1083, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:44:05,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1623.0 (TID 1083)
2019-06-11 09:44:05,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:44:05,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:05,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:44:05,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:05,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1623.0 (TID 1083). 966 bytes result sent to driver
2019-06-11 09:44:05,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1623.0 (TID 1083) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:44:05,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1623.0, whose tasks have all completed, from pool 
2019-06-11 09:44:05,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1623 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:44:05,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 541 finished: print at Transform.scala:36, took 0.027799 s
2019-06-11 09:44:05,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:44:05,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 541 is 160 bytes
2019-06-11 09:44:05,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 540 is 83 bytes
2019-06-11 09:44:05,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 542 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:44:05,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1626 (print at Transform.scala:36)
2019-06-11 09:44:05,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1624, ShuffleMapStage 1625)
2019-06-11 09:44:05,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:44:05,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1626 (MapPartitionsRDD[1898] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:44:05,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_813 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:44:05,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_813_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:44:05,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_813_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:44:05,056  INFO [org.apache.spark.SparkContext] - Created broadcast 813 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:44:05,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1626 (MapPartitionsRDD[1898] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:44:05,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1626.0 with 1 tasks
2019-06-11 09:44:05,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1626.0 (TID 1084, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:44:05,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1626.0 (TID 1084)
2019-06-11 09:44:05,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:44:05,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:05,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:44:05,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:44:05,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1626.0 (TID 1084). 966 bytes result sent to driver
2019-06-11 09:44:05,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1626.0 (TID 1084) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:44:05,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1626.0, whose tasks have all completed, from pool 
2019-06-11 09:44:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1626 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:44:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 542 finished: print at Transform.scala:36, took 0.004143 s
2019-06-11 09:44:05,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217445000 ms.0 from job set of time 1560217445000 ms
2019-06-11 09:44:05,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560217445000 ms (execution: 0.041 s)
2019-06-11 09:44:05,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1891 from persistence list
2019-06-11 09:44:05,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1891
2019-06-11 09:44:05,059  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1886 from persistence list
2019-06-11 09:44:05,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1886
2019-06-11 09:44:05,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1885 from persistence list
2019-06-11 09:44:05,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1885
2019-06-11 09:44:05,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1885] at socketTextStream at Transform.scala:18 of time 1560217445000 ms
2019-06-11 09:44:05,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217435000 ms
2019-06-11 09:44:05,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217435000 ms
2019-06-11 09:44:10,019 ERROR [org.apache.spark.streaming.scheduler.JobScheduler] - Error generating jobs for time 1560217450000 ms
java.io.IOException: Class not found
	at org.apache.xbean.asm5.ClassReader.a(Unknown Source)
	at org.apache.xbean.asm5.ClassReader.<init>(Unknown Source)
	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:42)
	at org.apache.spark.util.ClosureCleaner$.getInnerClosureClasses(ClosureCleaner.scala:83)
	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:173)
	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:108)
	at org.apache.spark.SparkContext.clean(SparkContext.scala:2287)
	at org.apache.spark.rdd.RDD$$anonfun$filter$1.apply(RDD.scala:387)
	at org.apache.spark.rdd.RDD$$anonfun$filter$1.apply(RDD.scala:386)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)
	at org.apache.spark.rdd.RDD.filter(RDD.scala:386)
	at StreamDemo.Transform$$anonfun$2.apply(Transform.scala:27)
	at StreamDemo.Transform$$anonfun$2.apply(Transform.scala:26)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$transform$1$$anonfun$apply$21.apply(DStream.scala:667)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$transform$1$$anonfun$apply$21.apply(DStream.scala:667)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$transform$2$$anonfun$5.apply(DStream.scala:681)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$transform$2$$anonfun$5.apply(DStream.scala:679)
	at org.apache.spark.streaming.dstream.TransformedDStream.compute(TransformedDStream.scala:46)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1$$anonfun$apply$7.apply(DStream.scala:342)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1$$anonfun$1.apply(DStream.scala:341)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:416)
	at org.apache.spark.streaming.dstream.TransformedDStream.createRDDWithLocalProperties(TransformedDStream.scala:65)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:336)
	at org.apache.spark.streaming.dstream.DStream$$anonfun$getOrCompute$1.apply(DStream.scala:334)
	at scala.Option.orElse(Option.scala:289)
	at org.apache.spark.streaming.dstream.DStream.getOrCompute(DStream.scala:331)
	at org.apache.spark.streaming.dstream.ForEachDStream.generateJob(ForEachDStream.scala:48)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:122)
	at org.apache.spark.streaming.DStreamGraph$$anonfun$1.apply(DStreamGraph.scala:121)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104)
	at org.apache.spark.streaming.DStreamGraph.generateJobs(DStreamGraph.scala:121)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:249)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anonfun$3.apply(JobGenerator.scala:247)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.JobGenerator.generateJobs(JobGenerator.scala:247)
	at org.apache.spark.streaming.scheduler.JobGenerator.org$apache$spark$streaming$scheduler$JobGenerator$$processEvent(JobGenerator.scala:183)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:89)
	at org.apache.spark.streaming.scheduler.JobGenerator$$anon$1.onReceive(JobGenerator.scala:88)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
2019-06-11 09:44:10,123  INFO [org.apache.spark.streaming.StreamingContext] - Invoking stop(stopGracefully=false) from shutdown hook
2019-06-11 09:44:10,129  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - Sent stop signal to all 1 receivers
2019-06-11 09:44:10,151  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Received stop signal
2019-06-11 09:44:10,155  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Stopping receiver with message: Stopped by driver: 
2019-06-11 09:44:10,156  INFO [org.apache.spark.streaming.dstream.SocketReceiver] - Closed socket to hadoop01:8989
2019-06-11 09:44:10,171  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Called receiver onStop
2019-06-11 09:44:10,171  WARN [org.apache.spark.streaming.dstream.SocketReceiver] - Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:72)
2019-06-11 09:44:10,190  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Deregistering receiver 0
2019-06-11 09:44:10,192  WARN [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Restarting receiver with delay 2000 ms: Error receiving data
java.net.SocketException: Socket closed
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:121)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$1.getNext(SocketInputDStream.scala:119)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at org.apache.spark.streaming.dstream.SocketReceiver.receive(SocketInputDStream.scala:91)
	at org.apache.spark.streaming.dstream.SocketReceiver$$anon$2.run(SocketInputDStream.scala:72)
2019-06-11 09:44:10,193 ERROR [org.apache.spark.streaming.scheduler.ReceiverTracker] - Deregistered receiver for stream 0: Stopped by driver
2019-06-11 09:44:10,195  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Stopped receiver 0
2019-06-11 09:44:10,195  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Stopping receiver with message: Restarting receiver with delay 2000ms: Error receiving data: java.net.SocketException: Socket closed
2019-06-11 09:44:10,196  WARN [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Receiver has been stopped
2019-06-11 09:44:10,200  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Stopping BlockGenerator
2019-06-11 09:44:10,402  INFO [org.apache.spark.streaming.util.RecurringTimer] - Stopped timer for BlockGenerator after time 1560217450400
2019-06-11 09:44:10,402  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Waiting for block pushing thread to terminate
2019-06-11 09:44:10,408  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Pushing out the last 0 blocks
2019-06-11 09:44:10,409  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Stopped block pushing thread
2019-06-11 09:44:10,410  INFO [org.apache.spark.streaming.receiver.BlockGenerator] - Stopped BlockGenerator
2019-06-11 09:44:10,411  INFO [org.apache.spark.streaming.receiver.ReceiverSupervisorImpl] - Stopped receiver without error
2019-06-11 09:44:10,412  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 0.0 (TID 0). 751 bytes result sent to driver
2019-06-11 09:44:10,413  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 0.0 (TID 0) in 1356302 ms on localhost (executor driver) (1/1)
2019-06-11 09:44:10,413  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-06-11 09:44:10,413  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 0 (start at Transform.scala:37) finished in 1356.312 s
2019-06-11 09:44:10,563  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - All of the receivers have deregistered successfully
2019-06-11 09:44:10,564  INFO [org.apache.spark.streaming.scheduler.ReceiverTracker] - ReceiverTracker stopped
2019-06-11 09:44:10,565  INFO [org.apache.spark.streaming.scheduler.JobGenerator] - Stopping JobGenerator immediately
2019-06-11 09:44:10,565  INFO [org.apache.spark.streaming.util.RecurringTimer] - Stopped timer for JobGenerator after time 1560217450000
2019-06-11 09:44:10,566  INFO [org.apache.spark.streaming.scheduler.JobGenerator] - Stopped JobGenerator
2019-06-11 09:44:10,568  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Stopped JobScheduler
2019-06-11 09:44:10,573  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Stopped o.s.j.s.ServletContextHandler@5cd61783{/streaming,null,UNAVAILABLE,@Spark}
2019-06-11 09:44:10,574  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Stopped o.s.j.s.ServletContextHandler@769d513{/streaming/batch,null,UNAVAILABLE,@Spark}
2019-06-11 09:44:10,575  INFO [org.spark_project.jetty.server.handler.ContextHandler] - Stopped o.s.j.s.ServletContextHandler@6be25526{/static/streaming,null,UNAVAILABLE,@Spark}
2019-06-11 09:44:10,576  INFO [org.apache.spark.streaming.StreamingContext] - StreamingContext stopped successfully
2019-06-11 09:44:10,577  INFO [org.apache.spark.SparkContext] - Invoking stop() from shutdown hook
2019-06-11 09:44:10,630  INFO [org.spark_project.jetty.server.AbstractConnector] - Stopped Spark@58e6d4b8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-06-11 09:44:10,632  INFO [org.apache.spark.ui.SparkUI] - Stopped Spark web UI at http://192.168.91.1:4040
2019-06-11 09:44:10,642  INFO [org.apache.spark.MapOutputTrackerMasterEndpoint] - MapOutputTrackerMasterEndpoint stopped!
2019-06-11 09:44:11,047  INFO [org.apache.spark.storage.memory.MemoryStore] - MemoryStore cleared
2019-06-11 09:44:11,049  INFO [org.apache.spark.storage.BlockManager] - BlockManager stopped
2019-06-11 09:44:11,051  INFO [org.apache.spark.storage.BlockManagerMaster] - BlockManagerMaster stopped
2019-06-11 09:44:11,062  INFO [org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint] - OutputCommitCoordinator stopped!
2019-06-11 09:44:11,067  INFO [org.apache.spark.SparkContext] - Successfully stopped SparkContext
2019-06-11 09:44:11,068  INFO [org.apache.spark.util.ShutdownHookManager] - Shutdown hook called
2019-06-11 09:44:11,068  INFO [org.apache.spark.util.ShutdownHookManager] - Deleting directory C:\Users\于羊\AppData\Local\Temp\spark-ff6fc0ad-cc9e-44ee-90d7-991d56a45fa6
