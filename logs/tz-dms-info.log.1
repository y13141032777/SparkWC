2019-06-11 09:35:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 3 ms
2019-06-11 09:35:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 993.0 (TID 663). 1009 bytes result sent to driver
2019-06-11 09:35:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 993.0 (TID 663) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 993.0, whose tasks have all completed, from pool 
2019-06-11 09:35:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 993 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:35:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 331 finished: print at Transform.scala:36, took 0.028520 s
2019-06-11 09:35:20,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 331 is 160 bytes
2019-06-11 09:35:20,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 330 is 83 bytes
2019-06-11 09:35:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 332 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 996 (print at Transform.scala:36)
2019-06-11 09:35:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 994, ShuffleMapStage 995)
2019-06-11 09:35:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 996 (MapPartitionsRDD[1163] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:20,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_498 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:20,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_498_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:20,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_498_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:20,040  INFO [org.apache.spark.SparkContext] - Created broadcast 498 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 996 (MapPartitionsRDD[1163] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 996.0 with 1 tasks
2019-06-11 09:35:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 996.0 (TID 664, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:20,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 996.0 (TID 664)
2019-06-11 09:35:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:20,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:20,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 996.0 (TID 664). 966 bytes result sent to driver
2019-06-11 09:35:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 996.0 (TID 664) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:20,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 996.0, whose tasks have all completed, from pool 
2019-06-11 09:35:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 996 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:20,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 332 finished: print at Transform.scala:36, took 0.005019 s
2019-06-11 09:35:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216920000 ms.0 from job set of time 1560216920000 ms
2019-06-11 09:35:20,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216920000 ms (execution: 0.038 s)
2019-06-11 09:35:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1156 from persistence list
2019-06-11 09:35:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1156
2019-06-11 09:35:20,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1151 from persistence list
2019-06-11 09:35:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1151
2019-06-11 09:35:20,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1150 from persistence list
2019-06-11 09:35:20,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1150
2019-06-11 09:35:20,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1150] at socketTextStream at Transform.scala:18 of time 1560216920000 ms
2019-06-11 09:35:20,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216910000 ms
2019-06-11 09:35:20,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216910000 ms
2019-06-11 09:35:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216925000 ms
2019-06-11 09:35:25,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216925000 ms.0 from job set of time 1560216925000 ms
2019-06-11 09:35:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1165 (map at Transform.scala:20)
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 333 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 999 (print at Transform.scala:36)
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 997, ShuffleMapStage 998)
2019-06-11 09:35:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 997)
2019-06-11 09:35:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 997 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_499 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_499_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_499_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 499 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 997 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 997.0 with 2 tasks
2019-06-11 09:35:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 997.0 (TID 665, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 997.0 (TID 665)
2019-06-11 09:35:25,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 997.0 (TID 665). 810 bytes result sent to driver
2019-06-11 09:35:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 997.0 (TID 666, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 997.0 (TID 666)
2019-06-11 09:35:25,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 997.0 (TID 665) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:25,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 997.0 (TID 666). 810 bytes result sent to driver
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 997.0 (TID 666) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 997.0, whose tasks have all completed, from pool 
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 997 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 999)
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 999 (MapPartitionsRDD[1170] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:25,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_500 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:25,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_500_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:25,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_500_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:25,033  INFO [org.apache.spark.SparkContext] - Created broadcast 500 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 999 (MapPartitionsRDD[1170] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:25,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 999.0 with 1 tasks
2019-06-11 09:35:25,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 999.0 (TID 667, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:25,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 999.0 (TID 667)
2019-06-11 09:35:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:25,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:25,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 999.0 (TID 667). 1009 bytes result sent to driver
2019-06-11 09:35:25,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 999.0 (TID 667) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:25,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 999.0, whose tasks have all completed, from pool 
2019-06-11 09:35:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 999 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:25,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 333 finished: print at Transform.scala:36, took 0.029049 s
2019-06-11 09:35:25,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 333 is 160 bytes
2019-06-11 09:35:25,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 332 is 83 bytes
2019-06-11 09:35:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 334 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1002 (print at Transform.scala:36)
2019-06-11 09:35:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1000, ShuffleMapStage 1001)
2019-06-11 09:35:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1002 (MapPartitionsRDD[1170] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:25,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_501 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:25,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_501_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:25,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_501_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:25,042  INFO [org.apache.spark.SparkContext] - Created broadcast 501 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:25,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1002 (MapPartitionsRDD[1170] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:25,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1002.0 with 1 tasks
2019-06-11 09:35:25,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1002.0 (TID 668, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:25,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1002.0 (TID 668)
2019-06-11 09:35:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:25,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:25,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1002.0 (TID 668). 1009 bytes result sent to driver
2019-06-11 09:35:25,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1002.0 (TID 668) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:25,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1002.0, whose tasks have all completed, from pool 
2019-06-11 09:35:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1002 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:25,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 334 finished: print at Transform.scala:36, took 0.006045 s
2019-06-11 09:35:25,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216925000 ms.0 from job set of time 1560216925000 ms
2019-06-11 09:35:25,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216925000 ms (execution: 0.041 s)
2019-06-11 09:35:25,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1163 from persistence list
2019-06-11 09:35:25,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1163
2019-06-11 09:35:25,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1158 from persistence list
2019-06-11 09:35:25,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1158
2019-06-11 09:35:25,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1157 from persistence list
2019-06-11 09:35:25,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1157
2019-06-11 09:35:25,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1157] at socketTextStream at Transform.scala:18 of time 1560216925000 ms
2019-06-11 09:35:25,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216915000 ms
2019-06-11 09:35:25,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216915000 ms
2019-06-11 09:35:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216930000 ms
2019-06-11 09:35:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216930000 ms.0 from job set of time 1560216930000 ms
2019-06-11 09:35:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1172 (map at Transform.scala:20)
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 335 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1005 (print at Transform.scala:36)
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1003, ShuffleMapStage 1004)
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1003)
2019-06-11 09:35:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1003 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_502 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_502_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_502_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 502 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1003 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1003.0 with 2 tasks
2019-06-11 09:35:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1003.0 (TID 669, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1003.0 (TID 669)
2019-06-11 09:35:30,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1003.0 (TID 669). 853 bytes result sent to driver
2019-06-11 09:35:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1003.0 (TID 670, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:30,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1003.0 (TID 670)
2019-06-11 09:35:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1003.0 (TID 669) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:30,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1003.0 (TID 670). 767 bytes result sent to driver
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1003.0 (TID 670) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1003.0, whose tasks have all completed, from pool 
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1003 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1005)
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:30,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1005 (MapPartitionsRDD[1177] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_503 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_503_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:30,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_503_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:30,031  INFO [org.apache.spark.SparkContext] - Created broadcast 503 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1005 (MapPartitionsRDD[1177] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1005.0 with 1 tasks
2019-06-11 09:35:30,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1005.0 (TID 671, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:30,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1005.0 (TID 671)
2019-06-11 09:35:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:30,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1005.0 (TID 671). 966 bytes result sent to driver
2019-06-11 09:35:30,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1005.0 (TID 671) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:30,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1005.0, whose tasks have all completed, from pool 
2019-06-11 09:35:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1005 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 335 finished: print at Transform.scala:36, took 0.025833 s
2019-06-11 09:35:30,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:30,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 335 is 160 bytes
2019-06-11 09:35:30,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 334 is 83 bytes
2019-06-11 09:35:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 336 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1008 (print at Transform.scala:36)
2019-06-11 09:35:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1007, ShuffleMapStage 1006)
2019-06-11 09:35:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1008 (MapPartitionsRDD[1177] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:30,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_504 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_504_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:30,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_504_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:30,038  INFO [org.apache.spark.SparkContext] - Created broadcast 504 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1008 (MapPartitionsRDD[1177] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:30,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1008.0 with 1 tasks
2019-06-11 09:35:30,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1008.0 (TID 672, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:30,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1008.0 (TID 672)
2019-06-11 09:35:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:30,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1008.0 (TID 672). 966 bytes result sent to driver
2019-06-11 09:35:30,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1008.0 (TID 672) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1008.0, whose tasks have all completed, from pool 
2019-06-11 09:35:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1008 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 336 finished: print at Transform.scala:36, took 0.004750 s
2019-06-11 09:35:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216930000 ms.0 from job set of time 1560216930000 ms
2019-06-11 09:35:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560216930000 ms (execution: 0.034 s)
2019-06-11 09:35:30,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1170 from persistence list
2019-06-11 09:35:30,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1170
2019-06-11 09:35:30,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1165 from persistence list
2019-06-11 09:35:30,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1164 from persistence list
2019-06-11 09:35:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1165
2019-06-11 09:35:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1164
2019-06-11 09:35:30,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1164] at socketTextStream at Transform.scala:18 of time 1560216930000 ms
2019-06-11 09:35:30,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216920000 ms
2019-06-11 09:35:30,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216920000 ms
2019-06-11 09:35:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216935000 ms
2019-06-11 09:35:35,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216935000 ms.0 from job set of time 1560216935000 ms
2019-06-11 09:35:35,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1179 (map at Transform.scala:20)
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 337 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1011 (print at Transform.scala:36)
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1009, ShuffleMapStage 1010)
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1009)
2019-06-11 09:35:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1009 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_505 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:35,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 330
2019-06-11 09:35:35,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_505_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:35,018  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 333
2019-06-11 09:35:35,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_505_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 329
2019-06-11 09:35:35,022  INFO [org.apache.spark.SparkContext] - Created broadcast 505 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:35,022  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1009 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:35,022  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1009.0 with 2 tasks
2019-06-11 09:35:35,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1009.0 (TID 673, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:35,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_496_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,023  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1009.0 (TID 673)
2019-06-11 09:35:35,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_490_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 327
2019-06-11 09:35:35,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 326
2019-06-11 09:35:35,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 332
2019-06-11 09:35:35,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_504_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_502_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_503_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_491_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_494_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_500_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_501_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_497_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,032  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 331
2019-06-11 09:35:35,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_492_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_493_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 324
2019-06-11 09:35:35,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_499_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:35,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 328
2019-06-11 09:35:35,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_498_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,036  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 325
2019-06-11 09:35:35,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1009.0 (TID 673). 853 bytes result sent to driver
2019-06-11 09:35:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1009.0 (TID 674, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1009.0 (TID 673) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:35,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_495_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,037  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1009.0 (TID 674)
2019-06-11 09:35:35,045  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1009.0 (TID 674). 767 bytes result sent to driver
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1009.0 (TID 674) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1009.0, whose tasks have all completed, from pool 
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1009 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1011)
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:35,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1011 (MapPartitionsRDD[1184] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:35,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_506 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:35,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_506_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:35,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_506_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,048  INFO [org.apache.spark.SparkContext] - Created broadcast 506 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:35,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1011 (MapPartitionsRDD[1184] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:35,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1011.0 with 1 tasks
2019-06-11 09:35:35,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1011.0 (TID 675, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:35,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1011.0 (TID 675)
2019-06-11 09:35:35,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:35,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:35,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:35,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:35,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1011.0 (TID 675). 966 bytes result sent to driver
2019-06-11 09:35:35,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1011.0 (TID 675) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:35,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1011.0, whose tasks have all completed, from pool 
2019-06-11 09:35:35,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1011 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:35,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 337 finished: print at Transform.scala:36, took 0.043167 s
2019-06-11 09:35:35,053  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:35,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 337 is 160 bytes
2019-06-11 09:35:35,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 336 is 83 bytes
2019-06-11 09:35:35,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 338 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:35,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1014 (print at Transform.scala:36)
2019-06-11 09:35:35,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1012, ShuffleMapStage 1013)
2019-06-11 09:35:35,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:35,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1014 (MapPartitionsRDD[1184] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:35,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_507 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:35,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_507_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:35,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_507_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:35,055  INFO [org.apache.spark.SparkContext] - Created broadcast 507 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:35,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1014 (MapPartitionsRDD[1184] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:35,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1014.0 with 1 tasks
2019-06-11 09:35:35,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1014.0 (TID 676, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:35,056  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1014.0 (TID 676)
2019-06-11 09:35:35,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:35,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:35,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:35,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:35,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1014.0 (TID 676). 966 bytes result sent to driver
2019-06-11 09:35:35,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1014.0 (TID 676) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:35,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1014.0, whose tasks have all completed, from pool 
2019-06-11 09:35:35,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1014 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:35,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 338 finished: print at Transform.scala:36, took 0.004849 s
2019-06-11 09:35:35,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216935000 ms.0 from job set of time 1560216935000 ms
2019-06-11 09:35:35,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560216935000 ms (execution: 0.052 s)
2019-06-11 09:35:35,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1177 from persistence list
2019-06-11 09:35:35,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1177
2019-06-11 09:35:35,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1172 from persistence list
2019-06-11 09:35:35,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1172
2019-06-11 09:35:35,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1171 from persistence list
2019-06-11 09:35:35,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1171
2019-06-11 09:35:35,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1171] at socketTextStream at Transform.scala:18 of time 1560216935000 ms
2019-06-11 09:35:35,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216925000 ms
2019-06-11 09:35:35,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216925000 ms
2019-06-11 09:35:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216940000 ms
2019-06-11 09:35:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216940000 ms.0 from job set of time 1560216940000 ms
2019-06-11 09:35:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1186 (map at Transform.scala:20)
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 339 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1017 (print at Transform.scala:36)
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1015, ShuffleMapStage 1016)
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1015)
2019-06-11 09:35:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1015 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_508 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_508_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:35:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_508_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:40,011  INFO [org.apache.spark.SparkContext] - Created broadcast 508 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1015 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:40,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1015.0 with 2 tasks
2019-06-11 09:35:40,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1015.0 (TID 677, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1015.0 (TID 677)
2019-06-11 09:35:40,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1015.0 (TID 677). 853 bytes result sent to driver
2019-06-11 09:35:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1015.0 (TID 678, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1015.0 (TID 678)
2019-06-11 09:35:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1015.0 (TID 677) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:40,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1015.0 (TID 678). 810 bytes result sent to driver
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1015.0 (TID 678) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1015.0, whose tasks have all completed, from pool 
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1015 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1017)
2019-06-11 09:35:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1017 (MapPartitionsRDD[1191] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_509 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_509_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:40,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_509_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:40,036  INFO [org.apache.spark.SparkContext] - Created broadcast 509 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1017 (MapPartitionsRDD[1191] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1017.0 with 1 tasks
2019-06-11 09:35:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1017.0 (TID 679, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:40,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1017.0 (TID 679)
2019-06-11 09:35:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:40,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:40,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1017.0 (TID 679). 966 bytes result sent to driver
2019-06-11 09:35:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1017.0 (TID 679) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1017.0, whose tasks have all completed, from pool 
2019-06-11 09:35:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1017 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 339 finished: print at Transform.scala:36, took 0.030663 s
2019-06-11 09:35:40,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:40,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 339 is 160 bytes
2019-06-11 09:35:40,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 338 is 83 bytes
2019-06-11 09:35:40,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 340 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1020 (print at Transform.scala:36)
2019-06-11 09:35:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1018, ShuffleMapStage 1019)
2019-06-11 09:35:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1020 (MapPartitionsRDD[1191] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:40,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_510 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:40,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_510_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:40,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_510_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:40,043  INFO [org.apache.spark.SparkContext] - Created broadcast 510 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:40,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1020 (MapPartitionsRDD[1191] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:40,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1020.0 with 1 tasks
2019-06-11 09:35:40,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1020.0 (TID 680, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:40,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1020.0 (TID 680)
2019-06-11 09:35:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:40,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1020.0 (TID 680). 966 bytes result sent to driver
2019-06-11 09:35:40,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1020.0 (TID 680) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:40,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1020.0, whose tasks have all completed, from pool 
2019-06-11 09:35:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1020 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:40,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 340 finished: print at Transform.scala:36, took 0.004985 s
2019-06-11 09:35:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216940000 ms.0 from job set of time 1560216940000 ms
2019-06-11 09:35:40,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216940000 ms (execution: 0.040 s)
2019-06-11 09:35:40,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1184 from persistence list
2019-06-11 09:35:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1184
2019-06-11 09:35:40,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1179 from persistence list
2019-06-11 09:35:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1179
2019-06-11 09:35:40,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1178 from persistence list
2019-06-11 09:35:40,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1178
2019-06-11 09:35:40,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1178] at socketTextStream at Transform.scala:18 of time 1560216940000 ms
2019-06-11 09:35:40,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216930000 ms
2019-06-11 09:35:40,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216930000 ms
2019-06-11 09:35:45,017  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216945000 ms
2019-06-11 09:35:45,024  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216945000 ms.0 from job set of time 1560216945000 ms
2019-06-11 09:35:45,027  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1193 (map at Transform.scala:20)
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 341 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1023 (print at Transform.scala:36)
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1021, ShuffleMapStage 1022)
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1022)
2019-06-11 09:35:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1022 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_511 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:45,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_511_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:35:45,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_511_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:45,044  INFO [org.apache.spark.SparkContext] - Created broadcast 511 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1022 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:45,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1022.0 with 2 tasks
2019-06-11 09:35:45,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1022.0 (TID 681, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:45,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1022.0 (TID 681)
2019-06-11 09:35:45,081  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1022.0 (TID 681). 896 bytes result sent to driver
2019-06-11 09:35:45,081  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1022.0 (TID 682, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:45,081  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1022.0 (TID 682)
2019-06-11 09:35:45,082  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1022.0 (TID 681) in 37 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:45,118  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1022.0 (TID 682). 810 bytes result sent to driver
2019-06-11 09:35:45,120  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1022.0 (TID 682) in 39 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:45,120  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1022.0, whose tasks have all completed, from pool 
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1022 (parallelize at Transform.scala:16) finished in 0.080 s
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1023)
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:45,126  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1023 (MapPartitionsRDD[1198] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:45,138  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_512 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:45,140  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_512_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:45,141  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_512_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:45,142  INFO [org.apache.spark.SparkContext] - Created broadcast 512 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:45,144  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1023 (MapPartitionsRDD[1198] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:45,144  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1023.0 with 1 tasks
2019-06-11 09:35:45,145  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1023.0 (TID 683, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:45,145  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1023.0 (TID 683)
2019-06-11 09:35:45,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:45,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:45,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:45,146  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:45,149  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1023.0 (TID 683). 1009 bytes result sent to driver
2019-06-11 09:35:45,149  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1023.0 (TID 683) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:45,150  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1023.0, whose tasks have all completed, from pool 
2019-06-11 09:35:45,150  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1023 (print at Transform.scala:36) finished in 0.006 s
2019-06-11 09:35:45,150  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 341 finished: print at Transform.scala:36, took 0.122539 s
2019-06-11 09:35:45,156  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:45,157  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 340 is 83 bytes
2019-06-11 09:35:45,157  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 341 is 160 bytes
2019-06-11 09:35:45,157  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 342 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:45,157  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1026 (print at Transform.scala:36)
2019-06-11 09:35:45,158  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1025, ShuffleMapStage 1024)
2019-06-11 09:35:45,158  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:45,158  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1026 (MapPartitionsRDD[1198] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:45,159  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_513 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:35:45,160  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_513_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:35:45,161  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_513_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:45,161  INFO [org.apache.spark.SparkContext] - Created broadcast 513 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:45,162  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1026 (MapPartitionsRDD[1198] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:45,162  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1026.0 with 1 tasks
2019-06-11 09:35:45,162  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1026.0 (TID 684, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:45,162  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1026.0 (TID 684)
2019-06-11 09:35:45,164  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:45,164  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:45,164  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:45,164  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:45,165  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1026.0 (TID 684). 1009 bytes result sent to driver
2019-06-11 09:35:45,166  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1026.0 (TID 684) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:45,166  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1026.0, whose tasks have all completed, from pool 
2019-06-11 09:35:45,166  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1026 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:35:45,166  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 342 finished: print at Transform.scala:36, took 0.009927 s
2019-06-11 09:35:45,166  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216945000 ms.0 from job set of time 1560216945000 ms
2019-06-11 09:35:45,166  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.166 s for time 1560216945000 ms (execution: 0.142 s)
2019-06-11 09:35:45,166  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1191 from persistence list
2019-06-11 09:35:45,168  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1186 from persistence list
2019-06-11 09:35:45,168  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1191
2019-06-11 09:35:45,170  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1186
2019-06-11 09:35:45,171  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1185 from persistence list
2019-06-11 09:35:45,172  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1185] at socketTextStream at Transform.scala:18 of time 1560216945000 ms
2019-06-11 09:35:45,172  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1185
2019-06-11 09:35:45,172  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216935000 ms
2019-06-11 09:35:45,172  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216935000 ms
2019-06-11 09:35:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216950000 ms
2019-06-11 09:35:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216950000 ms.0 from job set of time 1560216950000 ms
2019-06-11 09:35:50,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1200 (map at Transform.scala:20)
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 343 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1029 (print at Transform.scala:36)
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1027, ShuffleMapStage 1028)
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1028)
2019-06-11 09:35:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1028 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:50,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_514 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_514_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:50,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_514_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:50,010  INFO [org.apache.spark.SparkContext] - Created broadcast 514 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1028 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:50,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1028.0 with 2 tasks
2019-06-11 09:35:50,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1028.0 (TID 685, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:50,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1028.0 (TID 685)
2019-06-11 09:35:50,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1028.0 (TID 685). 853 bytes result sent to driver
2019-06-11 09:35:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1028.0 (TID 686, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:50,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1028.0 (TID 686)
2019-06-11 09:35:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1028.0 (TID 685) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:50,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1028.0 (TID 686). 810 bytes result sent to driver
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1028.0 (TID 686) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1028.0, whose tasks have all completed, from pool 
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1028 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1029)
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1029 (MapPartitionsRDD[1205] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_515 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_515_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:50,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_515_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:50,030  INFO [org.apache.spark.SparkContext] - Created broadcast 515 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1029 (MapPartitionsRDD[1205] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1029.0 with 1 tasks
2019-06-11 09:35:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1029.0 (TID 687, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:50,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1029.0 (TID 687)
2019-06-11 09:35:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:50,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:50,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1029.0 (TID 687). 1009 bytes result sent to driver
2019-06-11 09:35:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1029.0 (TID 687) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:50,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1029.0, whose tasks have all completed, from pool 
2019-06-11 09:35:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1029 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 343 finished: print at Transform.scala:36, took 0.024301 s
2019-06-11 09:35:50,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:50,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 342 is 83 bytes
2019-06-11 09:35:50,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 343 is 160 bytes
2019-06-11 09:35:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 344 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1032 (print at Transform.scala:36)
2019-06-11 09:35:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1030, ShuffleMapStage 1031)
2019-06-11 09:35:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1032 (MapPartitionsRDD[1205] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:50,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_516 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_516_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:50,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_516_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:50,036  INFO [org.apache.spark.SparkContext] - Created broadcast 516 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1032 (MapPartitionsRDD[1205] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1032.0 with 1 tasks
2019-06-11 09:35:50,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1032.0 (TID 688, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:50,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1032.0 (TID 688)
2019-06-11 09:35:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:50,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1032.0 (TID 688). 966 bytes result sent to driver
2019-06-11 09:35:50,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1032.0 (TID 688) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:50,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1032.0, whose tasks have all completed, from pool 
2019-06-11 09:35:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1032 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 344 finished: print at Transform.scala:36, took 0.005954 s
2019-06-11 09:35:50,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216950000 ms.0 from job set of time 1560216950000 ms
2019-06-11 09:35:50,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560216950000 ms (execution: 0.034 s)
2019-06-11 09:35:50,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1198 from persistence list
2019-06-11 09:35:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1198
2019-06-11 09:35:50,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1193 from persistence list
2019-06-11 09:35:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1193
2019-06-11 09:35:50,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1192 from persistence list
2019-06-11 09:35:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1192
2019-06-11 09:35:50,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1192] at socketTextStream at Transform.scala:18 of time 1560216950000 ms
2019-06-11 09:35:50,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216940000 ms
2019-06-11 09:35:50,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216940000 ms
2019-06-11 09:35:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216955000 ms
2019-06-11 09:35:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216955000 ms.0 from job set of time 1560216955000 ms
2019-06-11 09:35:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1207 (map at Transform.scala:20)
2019-06-11 09:35:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:35:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 345 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1035 (print at Transform.scala:36)
2019-06-11 09:35:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1033, ShuffleMapStage 1034)
2019-06-11 09:35:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1034)
2019-06-11 09:35:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1034 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:35:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_517 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:55,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_517_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:35:55,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_517_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:35:55,012  INFO [org.apache.spark.SparkContext] - Created broadcast 517 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:55,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1034 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:35:55,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1034.0 with 2 tasks
2019-06-11 09:35:55,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1034.0 (TID 689, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1034.0 (TID 689)
2019-06-11 09:35:55,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1034.0 (TID 689). 810 bytes result sent to driver
2019-06-11 09:35:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1034.0 (TID 690, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:35:55,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1034.0 (TID 690)
2019-06-11 09:35:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1034.0 (TID 689) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:35:55,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1034.0 (TID 690). 853 bytes result sent to driver
2019-06-11 09:35:55,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1034.0 (TID 690) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:35:55,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1034.0, whose tasks have all completed, from pool 
2019-06-11 09:35:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1034 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:35:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:35:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:35:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1035)
2019-06-11 09:35:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:35:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1035 (MapPartitionsRDD[1212] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:55,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_518 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_518_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:55,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_518_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:55,035  INFO [org.apache.spark.SparkContext] - Created broadcast 518 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1035 (MapPartitionsRDD[1212] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:35:55,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1035.0 with 1 tasks
2019-06-11 09:35:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1035.0 (TID 691, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:55,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1035.0 (TID 691)
2019-06-11 09:35:55,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:55,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:55,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:55,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:55,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1035.0 (TID 691). 966 bytes result sent to driver
2019-06-11 09:35:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1035.0 (TID 691) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1035.0, whose tasks have all completed, from pool 
2019-06-11 09:35:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1035 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:35:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 345 finished: print at Transform.scala:36, took 0.028632 s
2019-06-11 09:35:55,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:35:55,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 344 is 83 bytes
2019-06-11 09:35:55,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 345 is 160 bytes
2019-06-11 09:35:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 346 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:35:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1038 (print at Transform.scala:36)
2019-06-11 09:35:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1036, ShuffleMapStage 1037)
2019-06-11 09:35:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:35:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1038 (MapPartitionsRDD[1212] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:35:55,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_519 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:35:55,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_519_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:35:55,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_519_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:35:55,043  INFO [org.apache.spark.SparkContext] - Created broadcast 519 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:35:55,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1038 (MapPartitionsRDD[1212] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:35:55,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1038.0 with 1 tasks
2019-06-11 09:35:55,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1038.0 (TID 692, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:35:55,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1038.0 (TID 692)
2019-06-11 09:35:55,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:35:55,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:55,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:35:55,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:35:55,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1038.0 (TID 692). 1009 bytes result sent to driver
2019-06-11 09:35:55,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1038.0 (TID 692) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:35:55,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1038.0, whose tasks have all completed, from pool 
2019-06-11 09:35:55,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1038 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:35:55,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 346 finished: print at Transform.scala:36, took 0.005051 s
2019-06-11 09:35:55,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216955000 ms.0 from job set of time 1560216955000 ms
2019-06-11 09:35:55,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560216955000 ms (execution: 0.039 s)
2019-06-11 09:35:55,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1205 from persistence list
2019-06-11 09:35:55,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1205
2019-06-11 09:35:55,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1200 from persistence list
2019-06-11 09:35:55,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1200
2019-06-11 09:35:55,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1199 from persistence list
2019-06-11 09:35:55,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1199
2019-06-11 09:35:55,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1199] at socketTextStream at Transform.scala:18 of time 1560216955000 ms
2019-06-11 09:35:55,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216945000 ms
2019-06-11 09:35:55,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216945000 ms
2019-06-11 09:36:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216960000 ms
2019-06-11 09:36:00,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216960000 ms.0 from job set of time 1560216960000 ms
2019-06-11 09:36:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1214 (map at Transform.scala:20)
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 347 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1041 (print at Transform.scala:36)
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1039, ShuffleMapStage 1040)
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1039)
2019-06-11 09:36:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1039 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_520 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:00,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_520_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:36:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_520_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_512_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,019  INFO [org.apache.spark.SparkContext] - Created broadcast 520 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:00,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1039 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:00,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1039.0 with 2 tasks
2019-06-11 09:36:00,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1039.0 (TID 693, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:00,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1039.0 (TID 693)
2019-06-11 09:36:00,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_511_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 337
2019-06-11 09:36:00,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 341
2019-06-11 09:36:00,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_505_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_508_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_510_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_507_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 343
2019-06-11 09:36:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_516_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_506_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_514_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 339
2019-06-11 09:36:00,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 340
2019-06-11 09:36:00,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_518_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_509_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,029  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 338
2019-06-11 09:36:00,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 335
2019-06-11 09:36:00,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 334
2019-06-11 09:36:00,030  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 336
2019-06-11 09:36:00,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_515_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 342
2019-06-11 09:36:00,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_519_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_513_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_517_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:00,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1039.0 (TID 693). 853 bytes result sent to driver
2019-06-11 09:36:00,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1039.0 (TID 694, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:00,038  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1039.0 (TID 694)
2019-06-11 09:36:00,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1039.0 (TID 693) in 18 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:00,046  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1039.0 (TID 694). 810 bytes result sent to driver
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1039.0 (TID 694) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1039.0, whose tasks have all completed, from pool 
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1039 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1041)
2019-06-11 09:36:00,047  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1041 (MapPartitionsRDD[1219] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:00,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_521 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:00,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_521_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:00,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_521_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,050  INFO [org.apache.spark.SparkContext] - Created broadcast 521 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1041 (MapPartitionsRDD[1219] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:00,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1041.0 with 1 tasks
2019-06-11 09:36:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1041.0 (TID 695, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:00,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1041.0 (TID 695)
2019-06-11 09:36:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:00,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:00,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1041.0 (TID 695). 966 bytes result sent to driver
2019-06-11 09:36:00,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1041.0 (TID 695) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:00,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1041.0, whose tasks have all completed, from pool 
2019-06-11 09:36:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1041 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:00,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 347 finished: print at Transform.scala:36, took 0.042692 s
2019-06-11 09:36:00,055  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:00,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 347 is 160 bytes
2019-06-11 09:36:00,055  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 346 is 83 bytes
2019-06-11 09:36:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 348 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1044 (print at Transform.scala:36)
2019-06-11 09:36:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1042, ShuffleMapStage 1043)
2019-06-11 09:36:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1044 (MapPartitionsRDD[1219] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:00,056  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_522 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:00,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_522_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:00,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_522_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:00,057  INFO [org.apache.spark.SparkContext] - Created broadcast 522 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:00,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1044 (MapPartitionsRDD[1219] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:00,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1044.0 with 1 tasks
2019-06-11 09:36:00,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1044.0 (TID 696, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:00,058  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1044.0 (TID 696)
2019-06-11 09:36:00,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:00,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:00,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:00,059  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:00,059  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1044.0 (TID 696). 966 bytes result sent to driver
2019-06-11 09:36:00,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1044.0 (TID 696) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:00,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1044.0, whose tasks have all completed, from pool 
2019-06-11 09:36:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1044 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:00,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 348 finished: print at Transform.scala:36, took 0.004767 s
2019-06-11 09:36:00,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216960000 ms.0 from job set of time 1560216960000 ms
2019-06-11 09:36:00,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.060 s for time 1560216960000 ms (execution: 0.051 s)
2019-06-11 09:36:00,060  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1212 from persistence list
2019-06-11 09:36:00,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1212
2019-06-11 09:36:00,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1207 from persistence list
2019-06-11 09:36:00,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1207
2019-06-11 09:36:00,061  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1206 from persistence list
2019-06-11 09:36:00,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1206
2019-06-11 09:36:00,061  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1206] at socketTextStream at Transform.scala:18 of time 1560216960000 ms
2019-06-11 09:36:00,061  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216950000 ms
2019-06-11 09:36:00,061  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216950000 ms
2019-06-11 09:36:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216965000 ms
2019-06-11 09:36:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216965000 ms.0 from job set of time 1560216965000 ms
2019-06-11 09:36:05,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1221 (map at Transform.scala:20)
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 349 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1047 (print at Transform.scala:36)
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1045, ShuffleMapStage 1046)
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1046)
2019-06-11 09:36:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1046 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:05,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_523 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:05,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_523_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:36:05,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_523_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:05,011  INFO [org.apache.spark.SparkContext] - Created broadcast 523 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:05,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1046 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:05,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1046.0 with 2 tasks
2019-06-11 09:36:05,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1046.0 (TID 697, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:05,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1046.0 (TID 697)
2019-06-11 09:36:05,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1046.0 (TID 697). 853 bytes result sent to driver
2019-06-11 09:36:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1046.0 (TID 698, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:05,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1046.0 (TID 698)
2019-06-11 09:36:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1046.0 (TID 697) in 17 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:05,038  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1046.0 (TID 698). 810 bytes result sent to driver
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1046.0 (TID 698) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1046.0, whose tasks have all completed, from pool 
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1046 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1047)
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1047 (MapPartitionsRDD[1226] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:05,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_524 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:05,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_524_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:05,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_524_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:05,041  INFO [org.apache.spark.SparkContext] - Created broadcast 524 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:05,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1047 (MapPartitionsRDD[1226] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:05,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1047.0 with 1 tasks
2019-06-11 09:36:05,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1047.0 (TID 699, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:05,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1047.0 (TID 699)
2019-06-11 09:36:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:05,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1047.0 (TID 699). 966 bytes result sent to driver
2019-06-11 09:36:05,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1047.0 (TID 699) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:05,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1047.0, whose tasks have all completed, from pool 
2019-06-11 09:36:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1047 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 349 finished: print at Transform.scala:36, took 0.034265 s
2019-06-11 09:36:05,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:05,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 348 is 83 bytes
2019-06-11 09:36:05,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 349 is 160 bytes
2019-06-11 09:36:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 350 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1050 (print at Transform.scala:36)
2019-06-11 09:36:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1048, ShuffleMapStage 1049)
2019-06-11 09:36:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:05,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1050 (MapPartitionsRDD[1226] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:05,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_525 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:05,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_525_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:05,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_525_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:05,047  INFO [org.apache.spark.SparkContext] - Created broadcast 525 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:05,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1050 (MapPartitionsRDD[1226] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:05,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1050.0 with 1 tasks
2019-06-11 09:36:05,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1050.0 (TID 700, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:05,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1050.0 (TID 700)
2019-06-11 09:36:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:05,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:36:05,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:05,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:05,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1050.0 (TID 700). 1009 bytes result sent to driver
2019-06-11 09:36:05,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1050.0 (TID 700) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:05,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1050.0, whose tasks have all completed, from pool 
2019-06-11 09:36:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1050 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:36:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 350 finished: print at Transform.scala:36, took 0.005565 s
2019-06-11 09:36:05,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216965000 ms.0 from job set of time 1560216965000 ms
2019-06-11 09:36:05,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560216965000 ms (execution: 0.044 s)
2019-06-11 09:36:05,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1219 from persistence list
2019-06-11 09:36:05,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1219
2019-06-11 09:36:05,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1214 from persistence list
2019-06-11 09:36:05,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1214
2019-06-11 09:36:05,051  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1213 from persistence list
2019-06-11 09:36:05,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1213
2019-06-11 09:36:05,051  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1213] at socketTextStream at Transform.scala:18 of time 1560216965000 ms
2019-06-11 09:36:05,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216955000 ms
2019-06-11 09:36:05,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216955000 ms
2019-06-11 09:36:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216970000 ms
2019-06-11 09:36:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216970000 ms.0 from job set of time 1560216970000 ms
2019-06-11 09:36:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1228 (map at Transform.scala:20)
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 351 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1053 (print at Transform.scala:36)
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1051, ShuffleMapStage 1052)
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1051)
2019-06-11 09:36:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1051 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_526 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_526_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:36:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_526_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 526 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1051 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1051.0 with 2 tasks
2019-06-11 09:36:10,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1051.0 (TID 701, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:10,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1051.0 (TID 701)
2019-06-11 09:36:10,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1051.0 (TID 701). 810 bytes result sent to driver
2019-06-11 09:36:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1051.0 (TID 702, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:10,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1051.0 (TID 702)
2019-06-11 09:36:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1051.0 (TID 701) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:10,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1051.0 (TID 702). 767 bytes result sent to driver
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1051.0 (TID 702) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1051.0, whose tasks have all completed, from pool 
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1051 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1053)
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1053 (MapPartitionsRDD[1233] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:10,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_527 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:10,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_527_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:10,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_527_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:10,032  INFO [org.apache.spark.SparkContext] - Created broadcast 527 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1053 (MapPartitionsRDD[1233] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1053.0 with 1 tasks
2019-06-11 09:36:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1053.0 (TID 703, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:10,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1053.0 (TID 703)
2019-06-11 09:36:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:10,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:10,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:10,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1053.0 (TID 703). 966 bytes result sent to driver
2019-06-11 09:36:10,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1053.0 (TID 703) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1053.0, whose tasks have all completed, from pool 
2019-06-11 09:36:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1053 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 351 finished: print at Transform.scala:36, took 0.026662 s
2019-06-11 09:36:10,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:10,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 351 is 160 bytes
2019-06-11 09:36:10,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 350 is 83 bytes
2019-06-11 09:36:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 352 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1056 (print at Transform.scala:36)
2019-06-11 09:36:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1054, ShuffleMapStage 1055)
2019-06-11 09:36:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1056 (MapPartitionsRDD[1233] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_528 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:10,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_528_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:10,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_528_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:10,039  INFO [org.apache.spark.SparkContext] - Created broadcast 528 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1056 (MapPartitionsRDD[1233] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:10,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1056.0 with 1 tasks
2019-06-11 09:36:10,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1056.0 (TID 704, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:10,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1056.0 (TID 704)
2019-06-11 09:36:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:10,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:10,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1056.0 (TID 704). 966 bytes result sent to driver
2019-06-11 09:36:10,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1056.0 (TID 704) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:10,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1056.0, whose tasks have all completed, from pool 
2019-06-11 09:36:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1056 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 352 finished: print at Transform.scala:36, took 0.004904 s
2019-06-11 09:36:10,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216970000 ms.0 from job set of time 1560216970000 ms
2019-06-11 09:36:10,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560216970000 ms (execution: 0.035 s)
2019-06-11 09:36:10,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1226 from persistence list
2019-06-11 09:36:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1226
2019-06-11 09:36:10,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1221 from persistence list
2019-06-11 09:36:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1221
2019-06-11 09:36:10,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1220 from persistence list
2019-06-11 09:36:10,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1220
2019-06-11 09:36:10,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1220] at socketTextStream at Transform.scala:18 of time 1560216970000 ms
2019-06-11 09:36:10,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216960000 ms
2019-06-11 09:36:10,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216960000 ms
2019-06-11 09:36:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216975000 ms
2019-06-11 09:36:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216975000 ms.0 from job set of time 1560216975000 ms
2019-06-11 09:36:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1235 (map at Transform.scala:20)
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 353 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1059 (print at Transform.scala:36)
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1058, ShuffleMapStage 1057)
2019-06-11 09:36:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1058)
2019-06-11 09:36:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1058 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_529 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_529_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:36:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_529_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 529 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1058 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:15,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1058.0 with 2 tasks
2019-06-11 09:36:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1058.0 (TID 705, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1058.0 (TID 705)
2019-06-11 09:36:15,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1058.0 (TID 705). 810 bytes result sent to driver
2019-06-11 09:36:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1058.0 (TID 706, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:15,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1058.0 (TID 706)
2019-06-11 09:36:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1058.0 (TID 705) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:15,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1058.0 (TID 706). 810 bytes result sent to driver
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1058.0 (TID 706) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1058.0, whose tasks have all completed, from pool 
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1058 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1059)
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1059 (MapPartitionsRDD[1240] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:15,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_530 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:15,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_530_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:15,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_530_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:15,032  INFO [org.apache.spark.SparkContext] - Created broadcast 530 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:15,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1059 (MapPartitionsRDD[1240] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:15,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1059.0 with 1 tasks
2019-06-11 09:36:15,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1059.0 (TID 707, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:15,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1059.0 (TID 707)
2019-06-11 09:36:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:15,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:15,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1059.0 (TID 707). 966 bytes result sent to driver
2019-06-11 09:36:15,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1059.0 (TID 707) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:15,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1059.0, whose tasks have all completed, from pool 
2019-06-11 09:36:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1059 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 353 finished: print at Transform.scala:36, took 0.026496 s
2019-06-11 09:36:15,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:15,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 352 is 83 bytes
2019-06-11 09:36:15,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 353 is 160 bytes
2019-06-11 09:36:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 354 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1062 (print at Transform.scala:36)
2019-06-11 09:36:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1060, ShuffleMapStage 1061)
2019-06-11 09:36:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1062 (MapPartitionsRDD[1240] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:15,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_531 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:15,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_531_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:15,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_531_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:15,040  INFO [org.apache.spark.SparkContext] - Created broadcast 531 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1062 (MapPartitionsRDD[1240] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1062.0 with 1 tasks
2019-06-11 09:36:15,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1062.0 (TID 708, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:15,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1062.0 (TID 708)
2019-06-11 09:36:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:15,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:15,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1062.0 (TID 708). 966 bytes result sent to driver
2019-06-11 09:36:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1062.0 (TID 708) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1062.0, whose tasks have all completed, from pool 
2019-06-11 09:36:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1062 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:36:15,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 354 finished: print at Transform.scala:36, took 0.005939 s
2019-06-11 09:36:15,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216975000 ms.0 from job set of time 1560216975000 ms
2019-06-11 09:36:15,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560216975000 ms (execution: 0.037 s)
2019-06-11 09:36:15,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1233 from persistence list
2019-06-11 09:36:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1233
2019-06-11 09:36:15,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1228 from persistence list
2019-06-11 09:36:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1228
2019-06-11 09:36:15,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1227 from persistence list
2019-06-11 09:36:15,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1227
2019-06-11 09:36:15,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1227] at socketTextStream at Transform.scala:18 of time 1560216975000 ms
2019-06-11 09:36:15,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216965000 ms
2019-06-11 09:36:15,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216965000 ms
2019-06-11 09:36:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216980000 ms
2019-06-11 09:36:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216980000 ms.0 from job set of time 1560216980000 ms
2019-06-11 09:36:20,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1242 (map at Transform.scala:20)
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 355 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1065 (print at Transform.scala:36)
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1063, ShuffleMapStage 1064)
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1064)
2019-06-11 09:36:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1064 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_532 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_532_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:36:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_532_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 532 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:20,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1064 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:20,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1064.0 with 2 tasks
2019-06-11 09:36:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1064.0 (TID 709, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1064.0 (TID 709)
2019-06-11 09:36:20,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1064.0 (TID 709). 853 bytes result sent to driver
2019-06-11 09:36:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1064.0 (TID 710, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:20,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1064.0 (TID 710)
2019-06-11 09:36:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1064.0 (TID 709) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1064.0 (TID 710). 810 bytes result sent to driver
2019-06-11 09:36:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1064.0 (TID 710) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:20,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1064.0, whose tasks have all completed, from pool 
2019-06-11 09:36:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1064 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:36:20,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1065)
2019-06-11 09:36:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1065 (MapPartitionsRDD[1247] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:20,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_533 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:20,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_533_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:20,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_533_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:20,033  INFO [org.apache.spark.SparkContext] - Created broadcast 533 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:20,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1065 (MapPartitionsRDD[1247] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:20,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1065.0 with 1 tasks
2019-06-11 09:36:20,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1065.0 (TID 711, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:20,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1065.0 (TID 711)
2019-06-11 09:36:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:20,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1065.0 (TID 711). 966 bytes result sent to driver
2019-06-11 09:36:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1065.0 (TID 711) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1065.0, whose tasks have all completed, from pool 
2019-06-11 09:36:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1065 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:36:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 355 finished: print at Transform.scala:36, took 0.026865 s
2019-06-11 09:36:20,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 354 is 83 bytes
2019-06-11 09:36:20,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 355 is 160 bytes
2019-06-11 09:36:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 356 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1068 (print at Transform.scala:36)
2019-06-11 09:36:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1066, ShuffleMapStage 1067)
2019-06-11 09:36:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1068 (MapPartitionsRDD[1247] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:20,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_534 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:20,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_534_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:20,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_534_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:20,041  INFO [org.apache.spark.SparkContext] - Created broadcast 534 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1068 (MapPartitionsRDD[1247] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:20,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1068.0 with 1 tasks
2019-06-11 09:36:20,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1068.0 (TID 712, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:20,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1068.0 (TID 712)
2019-06-11 09:36:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:20,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:20,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1068.0 (TID 712). 966 bytes result sent to driver
2019-06-11 09:36:20,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1068.0 (TID 712) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:20,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1068.0, whose tasks have all completed, from pool 
2019-06-11 09:36:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1068 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:36:20,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 356 finished: print at Transform.scala:36, took 0.004827 s
2019-06-11 09:36:20,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216980000 ms.0 from job set of time 1560216980000 ms
2019-06-11 09:36:20,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216980000 ms (execution: 0.037 s)
2019-06-11 09:36:20,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1240 from persistence list
2019-06-11 09:36:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1240
2019-06-11 09:36:20,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1235 from persistence list
2019-06-11 09:36:20,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1235
2019-06-11 09:36:20,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1234 from persistence list
2019-06-11 09:36:20,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1234
2019-06-11 09:36:20,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1234] at socketTextStream at Transform.scala:18 of time 1560216980000 ms
2019-06-11 09:36:20,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216970000 ms
2019-06-11 09:36:20,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216970000 ms
2019-06-11 09:36:25,021  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216985000 ms
2019-06-11 09:36:25,021  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216985000 ms.0 from job set of time 1560216985000 ms
2019-06-11 09:36:25,024  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1249 (map at Transform.scala:20)
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 357 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1071 (print at Transform.scala:36)
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1069, ShuffleMapStage 1070)
2019-06-11 09:36:25,024  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1069)
2019-06-11 09:36:25,025  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1069 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:25,025  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_535 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:25,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_535_piece0 stored as bytes in memory (estimated size 1310.0 B, free 1989.3 MB)
2019-06-11 09:36:25,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_525_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_535_piece0 in memory on 192.168.91.1:63518 (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,033  INFO [org.apache.spark.SparkContext] - Created broadcast 535 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1069 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:25,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1069.0 with 2 tasks
2019-06-11 09:36:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1069.0 (TID 713, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:25,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_528_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1069.0 (TID 713)
2019-06-11 09:36:25,034  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 351
2019-06-11 09:36:25,035  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 353
2019-06-11 09:36:25,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_520_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,036  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 350
2019-06-11 09:36:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_529_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_522_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_527_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_534_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 349
2019-06-11 09:36:25,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_533_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 352
2019-06-11 09:36:25,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_521_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 348
2019-06-11 09:36:25,043  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 347
2019-06-11 09:36:25,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_531_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_532_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 345
2019-06-11 09:36:25,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_523_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_526_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:25,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 344
2019-06-11 09:36:25,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_530_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1069.0 (TID 713). 853 bytes result sent to driver
2019-06-11 09:36:25,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1069.0 (TID 714, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:25,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1069.0 (TID 713) in 17 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:25,050  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1069.0 (TID 714)
2019-06-11 09:36:25,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_524_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 346
2019-06-11 09:36:25,059  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1069.0 (TID 714). 767 bytes result sent to driver
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1069.0 (TID 714) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1069.0, whose tasks have all completed, from pool 
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1069 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1071)
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:25,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1071 (MapPartitionsRDD[1254] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:25,060  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_536 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:25,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_536_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:25,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_536_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,061  INFO [org.apache.spark.SparkContext] - Created broadcast 536 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:25,061  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1071 (MapPartitionsRDD[1254] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:25,061  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1071.0 with 1 tasks
2019-06-11 09:36:25,062  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1071.0 (TID 715, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:25,062  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1071.0 (TID 715)
2019-06-11 09:36:25,062  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:25,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:36:25,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:25,063  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:25,063  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1071.0 (TID 715). 966 bytes result sent to driver
2019-06-11 09:36:25,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1071.0 (TID 715) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:25,064  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1071.0, whose tasks have all completed, from pool 
2019-06-11 09:36:25,064  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1071 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:25,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 357 finished: print at Transform.scala:36, took 0.040225 s
2019-06-11 09:36:25,066  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:25,066  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 357 is 160 bytes
2019-06-11 09:36:25,067  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 356 is 83 bytes
2019-06-11 09:36:25,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 358 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:25,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1074 (print at Transform.scala:36)
2019-06-11 09:36:25,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1072, ShuffleMapStage 1073)
2019-06-11 09:36:25,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:25,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1074 (MapPartitionsRDD[1254] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:25,067  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_537 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:25,069  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_537_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:25,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_537_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:25,069  INFO [org.apache.spark.SparkContext] - Created broadcast 537 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:25,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1074 (MapPartitionsRDD[1254] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:25,070  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1074.0 with 1 tasks
2019-06-11 09:36:25,070  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1074.0 (TID 716, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:25,070  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1074.0 (TID 716)
2019-06-11 09:36:25,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:25,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:25,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:25,071  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:25,072  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1074.0 (TID 716). 966 bytes result sent to driver
2019-06-11 09:36:25,072  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1074.0 (TID 716) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:25,072  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1074.0, whose tasks have all completed, from pool 
2019-06-11 09:36:25,073  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1074 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:25,073  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 358 finished: print at Transform.scala:36, took 0.006578 s
2019-06-11 09:36:25,073  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216985000 ms.0 from job set of time 1560216985000 ms
2019-06-11 09:36:25,073  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.073 s for time 1560216985000 ms (execution: 0.052 s)
2019-06-11 09:36:25,073  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1247 from persistence list
2019-06-11 09:36:25,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1247
2019-06-11 09:36:25,073  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1242 from persistence list
2019-06-11 09:36:25,073  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1242
2019-06-11 09:36:25,073  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1241 from persistence list
2019-06-11 09:36:25,074  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1241
2019-06-11 09:36:25,074  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1241] at socketTextStream at Transform.scala:18 of time 1560216985000 ms
2019-06-11 09:36:25,074  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216975000 ms
2019-06-11 09:36:25,074  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216975000 ms
2019-06-11 09:36:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216990000 ms
2019-06-11 09:36:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216990000 ms.0 from job set of time 1560216990000 ms
2019-06-11 09:36:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1256 (map at Transform.scala:20)
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 359 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1077 (print at Transform.scala:36)
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1076, ShuffleMapStage 1075)
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1075)
2019-06-11 09:36:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1075 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_538 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:30,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_538_piece0 stored as bytes in memory (estimated size 1310.0 B, free 1989.4 MB)
2019-06-11 09:36:30,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_538_piece0 in memory on 192.168.91.1:63518 (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:36:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 538 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1075 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1075.0 with 2 tasks
2019-06-11 09:36:30,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1075.0 (TID 717, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:30,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1075.0 (TID 717)
2019-06-11 09:36:30,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1075.0 (TID 717). 810 bytes result sent to driver
2019-06-11 09:36:30,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1075.0 (TID 718, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:30,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1075.0 (TID 718)
2019-06-11 09:36:30,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1075.0 (TID 717) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:30,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1075.0 (TID 718). 853 bytes result sent to driver
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1075.0 (TID 718) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1075.0, whose tasks have all completed, from pool 
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1075 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1077)
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1077 (MapPartitionsRDD[1261] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:30,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_539 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:30,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_539_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:30,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_539_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:30,034  INFO [org.apache.spark.SparkContext] - Created broadcast 539 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1077 (MapPartitionsRDD[1261] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:30,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1077.0 with 1 tasks
2019-06-11 09:36:30,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1077.0 (TID 719, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:30,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1077.0 (TID 719)
2019-06-11 09:36:30,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:30,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:30,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:30,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:30,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1077.0 (TID 719). 966 bytes result sent to driver
2019-06-11 09:36:30,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1077.0 (TID 719) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:30,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1077.0, whose tasks have all completed, from pool 
2019-06-11 09:36:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1077 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 359 finished: print at Transform.scala:36, took 0.027774 s
2019-06-11 09:36:30,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:30,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 359 is 160 bytes
2019-06-11 09:36:30,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 358 is 83 bytes
2019-06-11 09:36:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 360 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1080 (print at Transform.scala:36)
2019-06-11 09:36:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1078, ShuffleMapStage 1079)
2019-06-11 09:36:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1080 (MapPartitionsRDD[1261] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_540 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:30,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_540_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_540_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:30,041  INFO [org.apache.spark.SparkContext] - Created broadcast 540 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:30,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1080 (MapPartitionsRDD[1261] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:30,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1080.0 with 1 tasks
2019-06-11 09:36:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1080.0 (TID 720, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:30,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1080.0 (TID 720)
2019-06-11 09:36:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:30,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:30,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1080.0 (TID 720). 966 bytes result sent to driver
2019-06-11 09:36:30,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1080.0 (TID 720) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:30,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1080.0, whose tasks have all completed, from pool 
2019-06-11 09:36:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1080 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 360 finished: print at Transform.scala:36, took 0.005404 s
2019-06-11 09:36:30,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216990000 ms.0 from job set of time 1560216990000 ms
2019-06-11 09:36:30,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216990000 ms (execution: 0.037 s)
2019-06-11 09:36:30,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1254 from persistence list
2019-06-11 09:36:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1254
2019-06-11 09:36:30,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1249 from persistence list
2019-06-11 09:36:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1249
2019-06-11 09:36:30,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1248 from persistence list
2019-06-11 09:36:30,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1248
2019-06-11 09:36:30,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1248] at socketTextStream at Transform.scala:18 of time 1560216990000 ms
2019-06-11 09:36:30,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216980000 ms
2019-06-11 09:36:30,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216980000 ms
2019-06-11 09:36:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560216995000 ms
2019-06-11 09:36:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560216995000 ms.0 from job set of time 1560216995000 ms
2019-06-11 09:36:35,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1263 (map at Transform.scala:20)
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 361 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1083 (print at Transform.scala:36)
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1081, ShuffleMapStage 1082)
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1082)
2019-06-11 09:36:35,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1082 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:35,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_541 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_541_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:36:35,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_541_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 541 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1082 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1082.0 with 2 tasks
2019-06-11 09:36:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1082.0 (TID 721, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1082.0 (TID 721)
2019-06-11 09:36:35,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1082.0 (TID 721). 810 bytes result sent to driver
2019-06-11 09:36:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1082.0 (TID 722, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:35,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1082.0 (TID 722)
2019-06-11 09:36:35,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1082.0 (TID 721) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:35,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1082.0 (TID 722). 767 bytes result sent to driver
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1082.0 (TID 722) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1082.0, whose tasks have all completed, from pool 
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1082 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1083)
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:35,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1083 (MapPartitionsRDD[1268] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:35,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_542 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:35,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_542_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:35,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_542_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:35,033  INFO [org.apache.spark.SparkContext] - Created broadcast 542 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1083 (MapPartitionsRDD[1268] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:35,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1083.0 with 1 tasks
2019-06-11 09:36:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1083.0 (TID 723, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:35,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1083.0 (TID 723)
2019-06-11 09:36:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:35,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1083.0 (TID 723). 1009 bytes result sent to driver
2019-06-11 09:36:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1083.0 (TID 723) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:35,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1083.0, whose tasks have all completed, from pool 
2019-06-11 09:36:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1083 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 361 finished: print at Transform.scala:36, took 0.028818 s
2019-06-11 09:36:35,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:35,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 360 is 83 bytes
2019-06-11 09:36:35,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 361 is 160 bytes
2019-06-11 09:36:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 362 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1086 (print at Transform.scala:36)
2019-06-11 09:36:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1084, ShuffleMapStage 1085)
2019-06-11 09:36:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1086 (MapPartitionsRDD[1268] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:35,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_543 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_543_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:35,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_543_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:35,041  INFO [org.apache.spark.SparkContext] - Created broadcast 543 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1086 (MapPartitionsRDD[1268] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:35,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1086.0 with 1 tasks
2019-06-11 09:36:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1086.0 (TID 724, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:35,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1086.0 (TID 724)
2019-06-11 09:36:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:35,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:35,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1086.0 (TID 724). 966 bytes result sent to driver
2019-06-11 09:36:35,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1086.0 (TID 724) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:35,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1086.0, whose tasks have all completed, from pool 
2019-06-11 09:36:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1086 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 362 finished: print at Transform.scala:36, took 0.004644 s
2019-06-11 09:36:35,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560216995000 ms.0 from job set of time 1560216995000 ms
2019-06-11 09:36:35,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560216995000 ms (execution: 0.039 s)
2019-06-11 09:36:35,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1261 from persistence list
2019-06-11 09:36:35,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1261
2019-06-11 09:36:35,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1256 from persistence list
2019-06-11 09:36:35,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1256
2019-06-11 09:36:35,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1255 from persistence list
2019-06-11 09:36:35,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1255
2019-06-11 09:36:35,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1255] at socketTextStream at Transform.scala:18 of time 1560216995000 ms
2019-06-11 09:36:35,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216985000 ms
2019-06-11 09:36:35,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216985000 ms
2019-06-11 09:36:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217000000 ms
2019-06-11 09:36:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217000000 ms.0 from job set of time 1560217000000 ms
2019-06-11 09:36:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1270 (map at Transform.scala:20)
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 363 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1089 (print at Transform.scala:36)
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1087, ShuffleMapStage 1088)
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1088)
2019-06-11 09:36:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1088 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_544 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_544_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:36:40,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_544_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:40,009  INFO [org.apache.spark.SparkContext] - Created broadcast 544 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1088 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:40,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1088.0 with 2 tasks
2019-06-11 09:36:40,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1088.0 (TID 725, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:40,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1088.0 (TID 725)
2019-06-11 09:36:40,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1088.0 (TID 725). 810 bytes result sent to driver
2019-06-11 09:36:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1088.0 (TID 726, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:40,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1088.0 (TID 726)
2019-06-11 09:36:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1088.0 (TID 725) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:40,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1088.0 (TID 726). 767 bytes result sent to driver
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1088.0 (TID 726) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1088.0, whose tasks have all completed, from pool 
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1088 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1089)
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:40,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1089 (MapPartitionsRDD[1275] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:40,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_545 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_545_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:40,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_545_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:40,029  INFO [org.apache.spark.SparkContext] - Created broadcast 545 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1089 (MapPartitionsRDD[1275] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:40,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1089.0 with 1 tasks
2019-06-11 09:36:40,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1089.0 (TID 727, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:40,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1089.0 (TID 727)
2019-06-11 09:36:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:40,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1089.0 (TID 727). 966 bytes result sent to driver
2019-06-11 09:36:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1089.0 (TID 727) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1089.0, whose tasks have all completed, from pool 
2019-06-11 09:36:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1089 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:40,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 363 finished: print at Transform.scala:36, took 0.023256 s
2019-06-11 09:36:40,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:40,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 362 is 83 bytes
2019-06-11 09:36:40,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 363 is 160 bytes
2019-06-11 09:36:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 364 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1092 (print at Transform.scala:36)
2019-06-11 09:36:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1090, ShuffleMapStage 1091)
2019-06-11 09:36:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1092 (MapPartitionsRDD[1275] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_546 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_546_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:40,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_546_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:40,035  INFO [org.apache.spark.SparkContext] - Created broadcast 546 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1092 (MapPartitionsRDD[1275] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:40,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1092.0 with 1 tasks
2019-06-11 09:36:40,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1092.0 (TID 728, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:40,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1092.0 (TID 728)
2019-06-11 09:36:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:40,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:40,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1092.0 (TID 728). 966 bytes result sent to driver
2019-06-11 09:36:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1092.0 (TID 728) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1092.0, whose tasks have all completed, from pool 
2019-06-11 09:36:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1092 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 364 finished: print at Transform.scala:36, took 0.005209 s
2019-06-11 09:36:40,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217000000 ms.0 from job set of time 1560217000000 ms
2019-06-11 09:36:40,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217000000 ms (execution: 0.033 s)
2019-06-11 09:36:40,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1268 from persistence list
2019-06-11 09:36:40,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1268
2019-06-11 09:36:40,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1263 from persistence list
2019-06-11 09:36:40,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1263
2019-06-11 09:36:40,038  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1262 from persistence list
2019-06-11 09:36:40,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1262
2019-06-11 09:36:40,038  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1262] at socketTextStream at Transform.scala:18 of time 1560217000000 ms
2019-06-11 09:36:40,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216990000 ms
2019-06-11 09:36:40,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216990000 ms
2019-06-11 09:36:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217005000 ms
2019-06-11 09:36:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217005000 ms.0 from job set of time 1560217005000 ms
2019-06-11 09:36:45,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1277 (map at Transform.scala:20)
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 365 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1095 (print at Transform.scala:36)
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1094, ShuffleMapStage 1093)
2019-06-11 09:36:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1093)
2019-06-11 09:36:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1093 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:45,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_547 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_547_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:36:45,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_547_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:45,009  INFO [org.apache.spark.SparkContext] - Created broadcast 547 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1093 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:45,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1093.0 with 2 tasks
2019-06-11 09:36:45,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1093.0 (TID 729, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:45,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1093.0 (TID 729)
2019-06-11 09:36:45,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1093.0 (TID 729). 810 bytes result sent to driver
2019-06-11 09:36:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1093.0 (TID 730, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:45,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1093.0 (TID 730)
2019-06-11 09:36:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1093.0 (TID 729) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:45,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1093.0 (TID 730). 767 bytes result sent to driver
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1093.0 (TID 730) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1093.0, whose tasks have all completed, from pool 
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1093 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1095)
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:45,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1095 (MapPartitionsRDD[1282] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:45,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_548 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:45,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_548_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:45,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_548_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:45,029  INFO [org.apache.spark.SparkContext] - Created broadcast 548 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1095 (MapPartitionsRDD[1282] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:45,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1095.0 with 1 tasks
2019-06-11 09:36:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1095.0 (TID 731, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:45,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1095.0 (TID 731)
2019-06-11 09:36:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:45,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:45,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1095.0 (TID 731). 966 bytes result sent to driver
2019-06-11 09:36:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1095.0 (TID 731) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:45,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1095.0, whose tasks have all completed, from pool 
2019-06-11 09:36:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1095 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 365 finished: print at Transform.scala:36, took 0.025342 s
2019-06-11 09:36:45,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:45,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 365 is 160 bytes
2019-06-11 09:36:45,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 364 is 83 bytes
2019-06-11 09:36:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 366 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1098 (print at Transform.scala:36)
2019-06-11 09:36:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1096, ShuffleMapStage 1097)
2019-06-11 09:36:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:45,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1098 (MapPartitionsRDD[1282] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_549 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:36:45,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_549_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:36:45,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_549_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:45,036  INFO [org.apache.spark.SparkContext] - Created broadcast 549 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1098 (MapPartitionsRDD[1282] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:45,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1098.0 with 1 tasks
2019-06-11 09:36:45,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1098.0 (TID 732, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:45,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1098.0 (TID 732)
2019-06-11 09:36:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:45,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:45,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:36:45,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1098.0 (TID 732). 966 bytes result sent to driver
2019-06-11 09:36:45,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1098.0 (TID 732) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:45,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1098.0, whose tasks have all completed, from pool 
2019-06-11 09:36:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1098 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:36:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 366 finished: print at Transform.scala:36, took 0.006083 s
2019-06-11 09:36:45,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217005000 ms.0 from job set of time 1560217005000 ms
2019-06-11 09:36:45,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217005000 ms (execution: 0.036 s)
2019-06-11 09:36:45,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1275 from persistence list
2019-06-11 09:36:45,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1275
2019-06-11 09:36:45,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1270 from persistence list
2019-06-11 09:36:45,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1270
2019-06-11 09:36:45,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1269 from persistence list
2019-06-11 09:36:45,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1269
2019-06-11 09:36:45,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1269] at socketTextStream at Transform.scala:18 of time 1560217005000 ms
2019-06-11 09:36:45,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560216995000 ms
2019-06-11 09:36:45,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560216995000 ms
2019-06-11 09:36:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_541_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217010000 ms
2019-06-11 09:36:50,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_548_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217010000 ms.0 from job set of time 1560217010000 ms
2019-06-11 09:36:50,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_543_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,013  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 363
2019-06-11 09:36:50,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_540_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,014  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 355
2019-06-11 09:36:50,014  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 361
2019-06-11 09:36:50,014  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 354
2019-06-11 09:36:50,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_549_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_538_piece0 on 192.168.91.1:63518 in memory (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,016  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:50,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:50,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1284 (map at Transform.scala:20)
2019-06-11 09:36:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 367 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1101 (print at Transform.scala:36)
2019-06-11 09:36:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1099, ShuffleMapStage 1100)
2019-06-11 09:36:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1099)
2019-06-11 09:36:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1099 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:50,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_535_piece0 on 192.168.91.1:63518 in memory (size: 1310.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_550 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:50,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_550_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:36:50,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_550_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,019  INFO [org.apache.spark.SparkContext] - Created broadcast 550 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:50,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1099 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:50,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_536_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1099.0 with 2 tasks
2019-06-11 09:36:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1099.0 (TID 733, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:50,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1099.0 (TID 733)
2019-06-11 09:36:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_537_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 356
2019-06-11 09:36:50,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_545_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_542_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 359
2019-06-11 09:36:50,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 357
2019-06-11 09:36:50,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 360
2019-06-11 09:36:50,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_544_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 362
2019-06-11 09:36:50,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_547_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:50,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 358
2019-06-11 09:36:50,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_539_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_546_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1099.0 (TID 733). 853 bytes result sent to driver
2019-06-11 09:36:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1099.0 (TID 734, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:50,032  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1099.0 (TID 734)
2019-06-11 09:36:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1099.0 (TID 733) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:50,041  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1099.0 (TID 734). 767 bytes result sent to driver
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1099.0 (TID 734) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1099.0, whose tasks have all completed, from pool 
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1099 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1101)
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:50,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1101 (MapPartitionsRDD[1289] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:50,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_551 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:50,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_551_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_551_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,044  INFO [org.apache.spark.SparkContext] - Created broadcast 551 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:50,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1101 (MapPartitionsRDD[1289] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1101.0 with 1 tasks
2019-06-11 09:36:50,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1101.0 (TID 735, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:50,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1101.0 (TID 735)
2019-06-11 09:36:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:50,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:50,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1101.0 (TID 735). 1009 bytes result sent to driver
2019-06-11 09:36:50,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1101.0 (TID 735) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:50,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1101.0, whose tasks have all completed, from pool 
2019-06-11 09:36:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1101 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 367 finished: print at Transform.scala:36, took 0.029948 s
2019-06-11 09:36:50,050  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:50,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 367 is 160 bytes
2019-06-11 09:36:50,050  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 366 is 83 bytes
2019-06-11 09:36:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 368 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1104 (print at Transform.scala:36)
2019-06-11 09:36:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1102, ShuffleMapStage 1103)
2019-06-11 09:36:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:50,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1104 (MapPartitionsRDD[1289] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:50,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_552 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:50,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_552_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_552_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:50,052  INFO [org.apache.spark.SparkContext] - Created broadcast 552 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:50,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1104 (MapPartitionsRDD[1289] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:50,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1104.0 with 1 tasks
2019-06-11 09:36:50,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1104.0 (TID 736, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:50,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1104.0 (TID 736)
2019-06-11 09:36:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:50,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:50,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1104.0 (TID 736). 966 bytes result sent to driver
2019-06-11 09:36:50,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1104.0 (TID 736) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:50,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1104.0, whose tasks have all completed, from pool 
2019-06-11 09:36:50,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1104 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:50,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 368 finished: print at Transform.scala:36, took 0.004255 s
2019-06-11 09:36:50,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217010000 ms.0 from job set of time 1560217010000 ms
2019-06-11 09:36:50,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560217010000 ms (execution: 0.043 s)
2019-06-11 09:36:50,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1282 from persistence list
2019-06-11 09:36:50,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1282
2019-06-11 09:36:50,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1277 from persistence list
2019-06-11 09:36:50,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1277
2019-06-11 09:36:50,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1276 from persistence list
2019-06-11 09:36:50,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1276
2019-06-11 09:36:50,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1276] at socketTextStream at Transform.scala:18 of time 1560217010000 ms
2019-06-11 09:36:50,055  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217000000 ms
2019-06-11 09:36:50,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217000000 ms
2019-06-11 09:36:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217015000 ms
2019-06-11 09:36:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217015000 ms.0 from job set of time 1560217015000 ms
2019-06-11 09:36:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1291 (map at Transform.scala:20)
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 369 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1107 (print at Transform.scala:36)
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1105, ShuffleMapStage 1106)
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1105)
2019-06-11 09:36:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1105 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:36:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_553 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_553_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:36:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_553_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:36:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 553 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:55,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1105 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:36:55,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1105.0 with 2 tasks
2019-06-11 09:36:55,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1105.0 (TID 737, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1105.0 (TID 737)
2019-06-11 09:36:55,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1105.0 (TID 737). 810 bytes result sent to driver
2019-06-11 09:36:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1105.0 (TID 738, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:36:55,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1105.0 (TID 738)
2019-06-11 09:36:55,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1105.0 (TID 737) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:36:55,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1105.0 (TID 738). 767 bytes result sent to driver
2019-06-11 09:36:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1105.0 (TID 738) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:36:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1105.0, whose tasks have all completed, from pool 
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1105 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1107)
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:36:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1107 (MapPartitionsRDD[1296] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:55,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_554 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:55,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_554_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:55,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_554_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:55,034  INFO [org.apache.spark.SparkContext] - Created broadcast 554 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1107 (MapPartitionsRDD[1296] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:36:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1107.0 with 1 tasks
2019-06-11 09:36:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1107.0 (TID 739, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:55,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1107.0 (TID 739)
2019-06-11 09:36:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:55,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:55,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1107.0 (TID 739). 966 bytes result sent to driver
2019-06-11 09:36:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1107.0 (TID 739) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1107.0, whose tasks have all completed, from pool 
2019-06-11 09:36:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1107 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 369 finished: print at Transform.scala:36, took 0.027466 s
2019-06-11 09:36:55,038  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:36:55,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 369 is 160 bytes
2019-06-11 09:36:55,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 368 is 83 bytes
2019-06-11 09:36:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 370 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:36:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1110 (print at Transform.scala:36)
2019-06-11 09:36:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1108, ShuffleMapStage 1109)
2019-06-11 09:36:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:36:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1110 (MapPartitionsRDD[1296] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:36:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_555 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:36:55,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_555_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:36:55,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_555_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:36:55,040  INFO [org.apache.spark.SparkContext] - Created broadcast 555 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:36:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1110 (MapPartitionsRDD[1296] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:36:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1110.0 with 1 tasks
2019-06-11 09:36:55,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1110.0 (TID 740, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:36:55,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1110.0 (TID 740)
2019-06-11 09:36:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:36:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:36:55,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:36:55,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1110.0 (TID 740). 966 bytes result sent to driver
2019-06-11 09:36:55,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1110.0 (TID 740) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:36:55,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1110.0, whose tasks have all completed, from pool 
2019-06-11 09:36:55,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1110 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:36:55,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 370 finished: print at Transform.scala:36, took 0.004226 s
2019-06-11 09:36:55,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217015000 ms.0 from job set of time 1560217015000 ms
2019-06-11 09:36:55,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560217015000 ms (execution: 0.036 s)
2019-06-11 09:36:55,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1289 from persistence list
2019-06-11 09:36:55,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1289
2019-06-11 09:36:55,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1284 from persistence list
2019-06-11 09:36:55,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1284
2019-06-11 09:36:55,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1283 from persistence list
2019-06-11 09:36:55,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1283
2019-06-11 09:36:55,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1283] at socketTextStream at Transform.scala:18 of time 1560217015000 ms
2019-06-11 09:36:55,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217005000 ms
2019-06-11 09:36:55,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217005000 ms
2019-06-11 09:37:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217020000 ms
2019-06-11 09:37:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217020000 ms.0 from job set of time 1560217020000 ms
2019-06-11 09:37:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1298 (map at Transform.scala:20)
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 371 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1113 (print at Transform.scala:36)
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1112, ShuffleMapStage 1111)
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1111)
2019-06-11 09:37:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1111 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:00,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_556 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_556_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:37:00,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_556_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:00,015  INFO [org.apache.spark.SparkContext] - Created broadcast 556 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:00,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1111 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:00,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1111.0 with 2 tasks
2019-06-11 09:37:00,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1111.0 (TID 741, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:00,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1111.0 (TID 741)
2019-06-11 09:37:00,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1111.0 (TID 741). 767 bytes result sent to driver
2019-06-11 09:37:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1111.0 (TID 742, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:00,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1111.0 (TID 742)
2019-06-11 09:37:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1111.0 (TID 741) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:00,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1111.0 (TID 742). 810 bytes result sent to driver
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1111.0 (TID 742) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1111.0, whose tasks have all completed, from pool 
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1111 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1113)
2019-06-11 09:37:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1113 (MapPartitionsRDD[1303] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:00,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_557 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_557_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:00,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_557_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:00,038  INFO [org.apache.spark.SparkContext] - Created broadcast 557 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1113 (MapPartitionsRDD[1303] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:00,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1113.0 with 1 tasks
2019-06-11 09:37:00,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1113.0 (TID 743, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:00,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1113.0 (TID 743)
2019-06-11 09:37:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:00,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1113.0 (TID 743). 966 bytes result sent to driver
2019-06-11 09:37:00,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1113.0 (TID 743) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:00,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1113.0, whose tasks have all completed, from pool 
2019-06-11 09:37:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1113 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 371 finished: print at Transform.scala:36, took 0.029949 s
2019-06-11 09:37:00,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:00,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 371 is 160 bytes
2019-06-11 09:37:00,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 370 is 83 bytes
2019-06-11 09:37:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 372 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1116 (print at Transform.scala:36)
2019-06-11 09:37:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1114, ShuffleMapStage 1115)
2019-06-11 09:37:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:00,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1116 (MapPartitionsRDD[1303] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:00,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_558 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:00,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_558_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:00,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_558_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:00,045  INFO [org.apache.spark.SparkContext] - Created broadcast 558 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1116 (MapPartitionsRDD[1303] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:00,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1116.0 with 1 tasks
2019-06-11 09:37:00,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1116.0 (TID 744, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:00,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1116.0 (TID 744)
2019-06-11 09:37:00,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:00,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:00,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:00,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:00,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1116.0 (TID 744). 1052 bytes result sent to driver
2019-06-11 09:37:00,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1116.0 (TID 744) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:00,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1116.0, whose tasks have all completed, from pool 
2019-06-11 09:37:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1116 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 372 finished: print at Transform.scala:36, took 0.004739 s
2019-06-11 09:37:00,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217020000 ms.0 from job set of time 1560217020000 ms
2019-06-11 09:37:00,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560217020000 ms (execution: 0.040 s)
2019-06-11 09:37:00,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1296 from persistence list
2019-06-11 09:37:00,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1296
2019-06-11 09:37:00,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1291 from persistence list
2019-06-11 09:37:00,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1291
2019-06-11 09:37:00,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1290 from persistence list
2019-06-11 09:37:00,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1290
2019-06-11 09:37:00,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1290] at socketTextStream at Transform.scala:18 of time 1560217020000 ms
2019-06-11 09:37:00,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217010000 ms
2019-06-11 09:37:00,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217010000 ms
2019-06-11 09:37:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217025000 ms
2019-06-11 09:37:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217025000 ms.0 from job set of time 1560217025000 ms
2019-06-11 09:37:05,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:05,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:05,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1305 (map at Transform.scala:20)
2019-06-11 09:37:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 373 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1119 (print at Transform.scala:36)
2019-06-11 09:37:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1117, ShuffleMapStage 1118)
2019-06-11 09:37:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1117)
2019-06-11 09:37:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1117 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:05,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_559 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_559_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_559_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 559 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1117 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1117.0 with 2 tasks
2019-06-11 09:37:05,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1117.0 (TID 745, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1117.0 (TID 745)
2019-06-11 09:37:05,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1117.0 (TID 745). 767 bytes result sent to driver
2019-06-11 09:37:05,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1117.0 (TID 746, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:05,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1117.0 (TID 746)
2019-06-11 09:37:05,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1117.0 (TID 745) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1117.0 (TID 746). 853 bytes result sent to driver
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1117.0 (TID 746) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1117.0, whose tasks have all completed, from pool 
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1117 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1119)
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:05,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1119 (MapPartitionsRDD[1310] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:05,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_560 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:05,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_560_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:05,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_560_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:05,033  INFO [org.apache.spark.SparkContext] - Created broadcast 560 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1119 (MapPartitionsRDD[1310] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:05,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1119.0 with 1 tasks
2019-06-11 09:37:05,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1119.0 (TID 747, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:05,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1119.0 (TID 747)
2019-06-11 09:37:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:05,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1119.0 (TID 747). 1009 bytes result sent to driver
2019-06-11 09:37:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1119.0 (TID 747) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:05,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1119.0, whose tasks have all completed, from pool 
2019-06-11 09:37:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1119 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 373 finished: print at Transform.scala:36, took 0.029411 s
2019-06-11 09:37:05,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:05,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 373 is 160 bytes
2019-06-11 09:37:05,039  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 372 is 83 bytes
2019-06-11 09:37:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 374 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1122 (print at Transform.scala:36)
2019-06-11 09:37:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1120, ShuffleMapStage 1121)
2019-06-11 09:37:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:05,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1122 (MapPartitionsRDD[1310] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:05,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_561 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:05,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_561_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:05,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_561_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:05,041  INFO [org.apache.spark.SparkContext] - Created broadcast 561 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:05,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1122 (MapPartitionsRDD[1310] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:05,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1122.0 with 1 tasks
2019-06-11 09:37:05,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1122.0 (TID 748, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:05,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1122.0 (TID 748)
2019-06-11 09:37:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:05,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:05,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1122.0 (TID 748). 1009 bytes result sent to driver
2019-06-11 09:37:05,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1122.0 (TID 748) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:05,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1122.0, whose tasks have all completed, from pool 
2019-06-11 09:37:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1122 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:05,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 374 finished: print at Transform.scala:36, took 0.004325 s
2019-06-11 09:37:05,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217025000 ms.0 from job set of time 1560217025000 ms
2019-06-11 09:37:05,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560217025000 ms (execution: 0.038 s)
2019-06-11 09:37:05,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1303 from persistence list
2019-06-11 09:37:05,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1298 from persistence list
2019-06-11 09:37:05,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1303
2019-06-11 09:37:05,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1298
2019-06-11 09:37:05,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1297 from persistence list
2019-06-11 09:37:05,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1297
2019-06-11 09:37:05,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1297] at socketTextStream at Transform.scala:18 of time 1560217025000 ms
2019-06-11 09:37:05,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217015000 ms
2019-06-11 09:37:05,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217015000 ms
2019-06-11 09:37:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217030000 ms
2019-06-11 09:37:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217030000 ms.0 from job set of time 1560217030000 ms
2019-06-11 09:37:10,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1312 (map at Transform.scala:20)
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 375 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1125 (print at Transform.scala:36)
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1123, ShuffleMapStage 1124)
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1124)
2019-06-11 09:37:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1124 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:10,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_562 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_562_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:10,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_562_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,010  INFO [org.apache.spark.SparkContext] - Created broadcast 562 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1124 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:10,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1124.0 with 2 tasks
2019-06-11 09:37:10,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1124.0 (TID 749, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:10,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1124.0 (TID 749)
2019-06-11 09:37:10,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1124.0 (TID 749). 853 bytes result sent to driver
2019-06-11 09:37:10,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1124.0 (TID 750, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:10,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1124.0 (TID 750)
2019-06-11 09:37:10,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1124.0 (TID 749) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:10,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1124.0 (TID 750). 810 bytes result sent to driver
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1124.0 (TID 750) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1124.0, whose tasks have all completed, from pool 
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1124 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1125)
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1125 (MapPartitionsRDD[1317] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:10,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_563 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:10,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_563_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:10,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_563_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,029  INFO [org.apache.spark.SparkContext] - Created broadcast 563 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1125 (MapPartitionsRDD[1317] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:10,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1125.0 with 1 tasks
2019-06-11 09:37:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1125.0 (TID 751, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:10,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1125.0 (TID 751)
2019-06-11 09:37:10,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:10,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:10,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:10,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:10,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1125.0 (TID 751). 1009 bytes result sent to driver
2019-06-11 09:37:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1125.0 (TID 751) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:10,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1125.0, whose tasks have all completed, from pool 
2019-06-11 09:37:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1125 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:10,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 375 finished: print at Transform.scala:36, took 0.024581 s
2019-06-11 09:37:10,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:10,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 374 is 83 bytes
2019-06-11 09:37:10,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 375 is 160 bytes
2019-06-11 09:37:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 376 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1128 (print at Transform.scala:36)
2019-06-11 09:37:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1127, ShuffleMapStage 1126)
2019-06-11 09:37:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1128 (MapPartitionsRDD[1317] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:10,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_564 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:10,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_564_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:10,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_564_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_554_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,042  INFO [org.apache.spark.SparkContext] - Created broadcast 564 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:10,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1128 (MapPartitionsRDD[1317] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:10,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1128.0 with 1 tasks
2019-06-11 09:37:10,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1128.0 (TID 752, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:10,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1128.0 (TID 752)
2019-06-11 09:37:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_555_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_551_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:10,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 366
2019-06-11 09:37:10,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 369
2019-06-11 09:37:10,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_563_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1128.0 (TID 752). 1009 bytes result sent to driver
2019-06-11 09:37:10,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 367
2019-06-11 09:37:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1128.0 (TID 752) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1128.0, whose tasks have all completed, from pool 
2019-06-11 09:37:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1128 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 376 finished: print at Transform.scala:36, took 0.011579 s
2019-06-11 09:37:10,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217030000 ms.0 from job set of time 1560217030000 ms
2019-06-11 09:37:10,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.046 s for time 1560217030000 ms (execution: 0.041 s)
2019-06-11 09:37:10,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_557_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1310 from persistence list
2019-06-11 09:37:10,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1305 from persistence list
2019-06-11 09:37:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1310
2019-06-11 09:37:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1305
2019-06-11 09:37:10,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1304 from persistence list
2019-06-11 09:37:10,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1304
2019-06-11 09:37:10,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1304] at socketTextStream at Transform.scala:18 of time 1560217030000 ms
2019-06-11 09:37:10,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_550_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,047  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217020000 ms
2019-06-11 09:37:10,047  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217020000 ms
2019-06-11 09:37:10,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_559_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_561_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_562_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_560_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_558_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_556_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 370
2019-06-11 09:37:10,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_552_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:10,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 364
2019-06-11 09:37:10,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_553_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:10,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 368
2019-06-11 09:37:10,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 371
2019-06-11 09:37:10,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 365
2019-06-11 09:37:15,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217035000 ms
2019-06-11 09:37:15,012  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217035000 ms.0 from job set of time 1560217035000 ms
2019-06-11 09:37:15,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1319 (map at Transform.scala:20)
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 377 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1131 (print at Transform.scala:36)
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1130, ShuffleMapStage 1129)
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1130)
2019-06-11 09:37:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1130 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:15,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_565 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:15,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_565_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:37:15,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_565_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:15,015  INFO [org.apache.spark.SparkContext] - Created broadcast 565 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:15,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1130 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:15,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1130.0 with 2 tasks
2019-06-11 09:37:15,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1130.0 (TID 753, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:15,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1130.0 (TID 753)
2019-06-11 09:37:15,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1130.0 (TID 753). 810 bytes result sent to driver
2019-06-11 09:37:15,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1130.0 (TID 754, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:15,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1130.0 (TID 754)
2019-06-11 09:37:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1130.0 (TID 753) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:15,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1130.0 (TID 754). 810 bytes result sent to driver
2019-06-11 09:37:15,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1130.0 (TID 754) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:15,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1130.0, whose tasks have all completed, from pool 
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1130 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1131)
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1131 (MapPartitionsRDD[1324] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:15,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_566 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_566_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:15,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_566_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:15,035  INFO [org.apache.spark.SparkContext] - Created broadcast 566 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1131 (MapPartitionsRDD[1324] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:15,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1131.0 with 1 tasks
2019-06-11 09:37:15,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1131.0 (TID 755, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:15,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1131.0 (TID 755)
2019-06-11 09:37:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:15,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:15,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1131.0 (TID 755). 966 bytes result sent to driver
2019-06-11 09:37:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1131.0 (TID 755) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:15,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1131.0, whose tasks have all completed, from pool 
2019-06-11 09:37:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1131 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 377 finished: print at Transform.scala:36, took 0.024471 s
2019-06-11 09:37:15,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 376 is 83 bytes
2019-06-11 09:37:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 377 is 160 bytes
2019-06-11 09:37:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 378 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1134 (print at Transform.scala:36)
2019-06-11 09:37:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1132, ShuffleMapStage 1133)
2019-06-11 09:37:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1134 (MapPartitionsRDD[1324] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_567 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_567_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_567_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 567 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1134 (MapPartitionsRDD[1324] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1134.0 with 1 tasks
2019-06-11 09:37:15,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1134.0 (TID 756, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:15,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1134.0 (TID 756)
2019-06-11 09:37:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:15,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1134.0 (TID 756). 1009 bytes result sent to driver
2019-06-11 09:37:15,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1134.0 (TID 756) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:15,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1134.0, whose tasks have all completed, from pool 
2019-06-11 09:37:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1134 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 378 finished: print at Transform.scala:36, took 0.004501 s
2019-06-11 09:37:15,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217035000 ms.0 from job set of time 1560217035000 ms
2019-06-11 09:37:15,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560217035000 ms (execution: 0.032 s)
2019-06-11 09:37:15,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1317 from persistence list
2019-06-11 09:37:15,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1317
2019-06-11 09:37:15,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1312 from persistence list
2019-06-11 09:37:15,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1312
2019-06-11 09:37:15,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1311 from persistence list
2019-06-11 09:37:15,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1311] at socketTextStream at Transform.scala:18 of time 1560217035000 ms
2019-06-11 09:37:15,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217025000 ms
2019-06-11 09:37:15,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217025000 ms
2019-06-11 09:37:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1311
2019-06-11 09:37:20,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217040000 ms
2019-06-11 09:37:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217040000 ms.0 from job set of time 1560217040000 ms
2019-06-11 09:37:20,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1326 (map at Transform.scala:20)
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 379 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1137 (print at Transform.scala:36)
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1135, ShuffleMapStage 1136)
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1135)
2019-06-11 09:37:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1135 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_568 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_568_piece0 stored as bytes in memory (estimated size 1314.0 B, free 1989.4 MB)
2019-06-11 09:37:20,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_568_piece0 in memory on 192.168.91.1:63518 (size: 1314.0 B, free: 1989.5 MB)
2019-06-11 09:37:20,009  INFO [org.apache.spark.SparkContext] - Created broadcast 568 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1135 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1135.0 with 2 tasks
2019-06-11 09:37:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1135.0 (TID 757, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1135.0 (TID 757)
2019-06-11 09:37:20,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1135.0 (TID 757). 853 bytes result sent to driver
2019-06-11 09:37:20,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1135.0 (TID 758, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:20,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1135.0 (TID 758)
2019-06-11 09:37:20,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1135.0 (TID 757) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:20,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1135.0 (TID 758). 767 bytes result sent to driver
2019-06-11 09:37:20,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1135.0 (TID 758) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:20,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1135.0, whose tasks have all completed, from pool 
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1135 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1137)
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:20,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1137 (MapPartitionsRDD[1331] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_569 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:20,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_569_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:20,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_569_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:20,030  INFO [org.apache.spark.SparkContext] - Created broadcast 569 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1137 (MapPartitionsRDD[1331] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1137.0 with 1 tasks
2019-06-11 09:37:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1137.0 (TID 759, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:20,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1137.0 (TID 759)
2019-06-11 09:37:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:20,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1137.0 (TID 759). 966 bytes result sent to driver
2019-06-11 09:37:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1137.0 (TID 759) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1137.0, whose tasks have all completed, from pool 
2019-06-11 09:37:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1137 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:37:20,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 379 finished: print at Transform.scala:36, took 0.025389 s
2019-06-11 09:37:20,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 379 is 160 bytes
2019-06-11 09:37:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 378 is 83 bytes
2019-06-11 09:37:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 380 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1140 (print at Transform.scala:36)
2019-06-11 09:37:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1138, ShuffleMapStage 1139)
2019-06-11 09:37:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1140 (MapPartitionsRDD[1331] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:20,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_570 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_570_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:20,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_570_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:20,037  INFO [org.apache.spark.SparkContext] - Created broadcast 570 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1140 (MapPartitionsRDD[1331] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1140.0 with 1 tasks
2019-06-11 09:37:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1140.0 (TID 760, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:20,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1140.0 (TID 760)
2019-06-11 09:37:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:20,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:37:20,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1140.0 (TID 760). 1009 bytes result sent to driver
2019-06-11 09:37:20,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1140.0 (TID 760) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:20,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1140.0, whose tasks have all completed, from pool 
2019-06-11 09:37:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1140 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 380 finished: print at Transform.scala:36, took 0.005383 s
2019-06-11 09:37:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217040000 ms.0 from job set of time 1560217040000 ms
2019-06-11 09:37:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217040000 ms (execution: 0.035 s)
2019-06-11 09:37:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1324 from persistence list
2019-06-11 09:37:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1324
2019-06-11 09:37:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1319 from persistence list
2019-06-11 09:37:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1319
2019-06-11 09:37:20,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1318 from persistence list
2019-06-11 09:37:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1318
2019-06-11 09:37:20,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1318] at socketTextStream at Transform.scala:18 of time 1560217040000 ms
2019-06-11 09:37:20,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217030000 ms
2019-06-11 09:37:20,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217030000 ms
2019-06-11 09:37:25,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217045000 ms
2019-06-11 09:37:25,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217045000 ms.0 from job set of time 1560217045000 ms
2019-06-11 09:37:25,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1333 (map at Transform.scala:20)
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 381 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1143 (print at Transform.scala:36)
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1141, ShuffleMapStage 1142)
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1141)
2019-06-11 09:37:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1141 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:25,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_571 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_571_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:37:25,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_571_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:25,009  INFO [org.apache.spark.SparkContext] - Created broadcast 571 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1141 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1141.0 with 2 tasks
2019-06-11 09:37:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1141.0 (TID 761, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:25,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1141.0 (TID 761)
2019-06-11 09:37:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1141.0 (TID 761). 810 bytes result sent to driver
2019-06-11 09:37:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1141.0 (TID 762, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:25,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1141.0 (TID 762)
2019-06-11 09:37:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1141.0 (TID 761) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1141.0 (TID 762). 810 bytes result sent to driver
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1141.0 (TID 762) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1141.0, whose tasks have all completed, from pool 
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1141 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1143)
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1143 (MapPartitionsRDD[1338] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_572 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_572_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:25,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_572_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:25,031  INFO [org.apache.spark.SparkContext] - Created broadcast 572 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:25,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1143 (MapPartitionsRDD[1338] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:25,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1143.0 with 1 tasks
2019-06-11 09:37:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1143.0 (TID 763, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1143.0 (TID 763)
2019-06-11 09:37:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:25,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:25,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1143.0 (TID 763). 1009 bytes result sent to driver
2019-06-11 09:37:25,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1143.0 (TID 763) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:25,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1143.0, whose tasks have all completed, from pool 
2019-06-11 09:37:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1143 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 381 finished: print at Transform.scala:36, took 0.027030 s
2019-06-11 09:37:25,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:25,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 381 is 160 bytes
2019-06-11 09:37:25,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 380 is 83 bytes
2019-06-11 09:37:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 382 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1146 (print at Transform.scala:36)
2019-06-11 09:37:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1145, ShuffleMapStage 1144)
2019-06-11 09:37:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1146 (MapPartitionsRDD[1338] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:25,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_573 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:25,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_573_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:25,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_573_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:25,040  INFO [org.apache.spark.SparkContext] - Created broadcast 573 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1146 (MapPartitionsRDD[1338] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1146.0 with 1 tasks
2019-06-11 09:37:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1146.0 (TID 764, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:25,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1146.0 (TID 764)
2019-06-11 09:37:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:25,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1146.0 (TID 764). 966 bytes result sent to driver
2019-06-11 09:37:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1146.0 (TID 764) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1146.0, whose tasks have all completed, from pool 
2019-06-11 09:37:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1146 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 382 finished: print at Transform.scala:36, took 0.004970 s
2019-06-11 09:37:25,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217045000 ms.0 from job set of time 1560217045000 ms
2019-06-11 09:37:25,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217045000 ms (execution: 0.038 s)
2019-06-11 09:37:25,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1331 from persistence list
2019-06-11 09:37:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1326 from persistence list
2019-06-11 09:37:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1331
2019-06-11 09:37:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1326
2019-06-11 09:37:25,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1325 from persistence list
2019-06-11 09:37:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1325
2019-06-11 09:37:25,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1325] at socketTextStream at Transform.scala:18 of time 1560217045000 ms
2019-06-11 09:37:25,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217035000 ms
2019-06-11 09:37:25,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217035000 ms
2019-06-11 09:37:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217050000 ms
2019-06-11 09:37:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217050000 ms.0 from job set of time 1560217050000 ms
2019-06-11 09:37:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1340 (map at Transform.scala:20)
2019-06-11 09:37:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 383 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1149 (print at Transform.scala:36)
2019-06-11 09:37:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1148, ShuffleMapStage 1147)
2019-06-11 09:37:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1148)
2019-06-11 09:37:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1148 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_574 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_574_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:30,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_574_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:30,010  INFO [org.apache.spark.SparkContext] - Created broadcast 574 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1148 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1148.0 with 2 tasks
2019-06-11 09:37:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1148.0 (TID 765, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:30,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1148.0 (TID 765)
2019-06-11 09:37:30,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1148.0 (TID 765). 767 bytes result sent to driver
2019-06-11 09:37:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1148.0 (TID 766, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:30,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1148.0 (TID 766)
2019-06-11 09:37:30,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1148.0 (TID 765) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:30,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1148.0 (TID 766). 810 bytes result sent to driver
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1148.0 (TID 766) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1148.0, whose tasks have all completed, from pool 
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1148 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1149)
2019-06-11 09:37:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:30,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1149 (MapPartitionsRDD[1345] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:30,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_575 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:30,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_575_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:30,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_575_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:30,033  INFO [org.apache.spark.SparkContext] - Created broadcast 575 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1149 (MapPartitionsRDD[1345] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1149.0 with 1 tasks
2019-06-11 09:37:30,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1149.0 (TID 767, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:30,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1149.0 (TID 767)
2019-06-11 09:37:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:30,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:30,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1149.0 (TID 767). 966 bytes result sent to driver
2019-06-11 09:37:30,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1149.0 (TID 767) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:30,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1149.0, whose tasks have all completed, from pool 
2019-06-11 09:37:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1149 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:30,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 383 finished: print at Transform.scala:36, took 0.026878 s
2019-06-11 09:37:30,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:30,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 382 is 83 bytes
2019-06-11 09:37:30,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 383 is 160 bytes
2019-06-11 09:37:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 384 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1152 (print at Transform.scala:36)
2019-06-11 09:37:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1150, ShuffleMapStage 1151)
2019-06-11 09:37:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1152 (MapPartitionsRDD[1345] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_576 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_576_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:30,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_576_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:30,040  INFO [org.apache.spark.SparkContext] - Created broadcast 576 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:30,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1152 (MapPartitionsRDD[1345] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:30,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1152.0 with 1 tasks
2019-06-11 09:37:30,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1152.0 (TID 768, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:30,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1152.0 (TID 768)
2019-06-11 09:37:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:30,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:30,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1152.0 (TID 768). 966 bytes result sent to driver
2019-06-11 09:37:30,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1152.0 (TID 768) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:30,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1152.0, whose tasks have all completed, from pool 
2019-06-11 09:37:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1152 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 384 finished: print at Transform.scala:36, took 0.006133 s
2019-06-11 09:37:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217050000 ms.0 from job set of time 1560217050000 ms
2019-06-11 09:37:30,043  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.043 s for time 1560217050000 ms (execution: 0.037 s)
2019-06-11 09:37:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1338 from persistence list
2019-06-11 09:37:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1338
2019-06-11 09:37:30,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1333 from persistence list
2019-06-11 09:37:30,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1333
2019-06-11 09:37:30,044  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1332 from persistence list
2019-06-11 09:37:30,044  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1332
2019-06-11 09:37:30,044  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1332] at socketTextStream at Transform.scala:18 of time 1560217050000 ms
2019-06-11 09:37:30,044  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217040000 ms
2019-06-11 09:37:30,044  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217040000 ms
2019-06-11 09:37:35,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217055000 ms
2019-06-11 09:37:35,009  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217055000 ms.0 from job set of time 1560217055000 ms
2019-06-11 09:37:35,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1347 (map at Transform.scala:20)
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 385 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1155 (print at Transform.scala:36)
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1153, ShuffleMapStage 1154)
2019-06-11 09:37:35,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1154)
2019-06-11 09:37:35,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1154 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:35,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_577 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:35,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_577_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:35,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_577_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:35,015  INFO [org.apache.spark.SparkContext] - Created broadcast 577 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:35,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1154 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:35,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1154.0 with 2 tasks
2019-06-11 09:37:35,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1154.0 (TID 769, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:35,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1154.0 (TID 769)
2019-06-11 09:37:35,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1154.0 (TID 769). 767 bytes result sent to driver
2019-06-11 09:37:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1154.0 (TID 770, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:35,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1154.0 (TID 770)
2019-06-11 09:37:35,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1154.0 (TID 769) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:35,039  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1154.0 (TID 770). 810 bytes result sent to driver
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1154.0 (TID 770) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1154.0, whose tasks have all completed, from pool 
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1154 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1155)
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:35,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1155 (MapPartitionsRDD[1352] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:35,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_578 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:35,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 376
2019-06-11 09:37:35,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_578_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:35,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 380
2019-06-11 09:37:35,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 374
2019-06-11 09:37:35,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_578_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,051  INFO [org.apache.spark.SparkContext] - Created broadcast 578 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:35,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_564_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1155 (MapPartitionsRDD[1352] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:35,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1155.0 with 1 tasks
2019-06-11 09:37:35,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1155.0 (TID 771, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:35,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1155.0 (TID 771)
2019-06-11 09:37:35,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_570_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:35,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:35,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_567_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,055  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1155.0 (TID 771). 1009 bytes result sent to driver
2019-06-11 09:37:35,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_569_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1155.0 (TID 771) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:35,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1155.0, whose tasks have all completed, from pool 
2019-06-11 09:37:35,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1155 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:35,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_576_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 385 finished: print at Transform.scala:36, took 0.042052 s
2019-06-11 09:37:35,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 381
2019-06-11 09:37:35,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 377
2019-06-11 09:37:35,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_575_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,060  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 375
2019-06-11 09:37:35,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_565_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:35,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 372
2019-06-11 09:37:35,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 378
2019-06-11 09:37:35,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_568_piece0 on 192.168.91.1:63518 in memory (size: 1314.0 B, free: 1989.5 MB)
2019-06-11 09:37:35,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_566_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,065  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:35,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_574_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:35,066  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 384 is 83 bytes
2019-06-11 09:37:35,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_571_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:35,067  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 385 is 160 bytes
2019-06-11 09:37:35,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 386 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:35,067  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1158 (print at Transform.scala:36)
2019-06-11 09:37:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1156, ShuffleMapStage 1157)
2019-06-11 09:37:35,068  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 379
2019-06-11 09:37:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:35,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1158 (MapPartitionsRDD[1352] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:35,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_572_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,068  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_579 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:35,069  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 373
2019-06-11 09:37:35,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_573_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,070  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_579_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:35,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_579_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:35,070  INFO [org.apache.spark.SparkContext] - Created broadcast 579 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:35,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1158 (MapPartitionsRDD[1352] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:35,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1158.0 with 1 tasks
2019-06-11 09:37:35,071  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1158.0 (TID 772, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:35,071  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1158.0 (TID 772)
2019-06-11 09:37:35,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:35,072  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:35,073  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1158.0 (TID 772). 966 bytes result sent to driver
2019-06-11 09:37:35,074  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1158.0 (TID 772) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:35,074  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1158.0, whose tasks have all completed, from pool 
2019-06-11 09:37:35,074  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1158 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:35,074  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 386 finished: print at Transform.scala:36, took 0.009130 s
2019-06-11 09:37:35,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217055000 ms.0 from job set of time 1560217055000 ms
2019-06-11 09:37:35,075  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.075 s for time 1560217055000 ms (execution: 0.066 s)
2019-06-11 09:37:35,075  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1345 from persistence list
2019-06-11 09:37:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1345
2019-06-11 09:37:35,076  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1340 from persistence list
2019-06-11 09:37:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1340
2019-06-11 09:37:35,076  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1339 from persistence list
2019-06-11 09:37:35,076  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1339
2019-06-11 09:37:35,076  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1339] at socketTextStream at Transform.scala:18 of time 1560217055000 ms
2019-06-11 09:37:35,076  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217045000 ms
2019-06-11 09:37:35,076  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217045000 ms
2019-06-11 09:37:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217060000 ms
2019-06-11 09:37:40,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217060000 ms.0 from job set of time 1560217060000 ms
2019-06-11 09:37:40,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1354 (map at Transform.scala:20)
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 387 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1161 (print at Transform.scala:36)
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1159, ShuffleMapStage 1160)
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1159)
2019-06-11 09:37:40,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1159 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:40,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_580 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:40,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_580_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:37:40,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_580_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:40,009  INFO [org.apache.spark.SparkContext] - Created broadcast 580 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1159 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:40,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1159.0 with 2 tasks
2019-06-11 09:37:40,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1159.0 (TID 773, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:40,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1159.0 (TID 773)
2019-06-11 09:37:40,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1159.0 (TID 773). 810 bytes result sent to driver
2019-06-11 09:37:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1159.0 (TID 774, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:40,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1159.0 (TID 774)
2019-06-11 09:37:40,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1159.0 (TID 773) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:40,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1159.0 (TID 774). 767 bytes result sent to driver
2019-06-11 09:37:40,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1159.0 (TID 774) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1159.0, whose tasks have all completed, from pool 
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1159 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1161)
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1161 (MapPartitionsRDD[1359] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:40,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_581 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_581_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:40,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_581_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:40,029  INFO [org.apache.spark.SparkContext] - Created broadcast 581 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1161 (MapPartitionsRDD[1359] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1161.0 with 1 tasks
2019-06-11 09:37:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1161.0 (TID 775, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:40,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1161.0 (TID 775)
2019-06-11 09:37:40,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:37:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:40,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1161.0 (TID 775). 1009 bytes result sent to driver
2019-06-11 09:37:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1161.0 (TID 775) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:40,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1161.0, whose tasks have all completed, from pool 
2019-06-11 09:37:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1161 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 387 finished: print at Transform.scala:36, took 0.025316 s
2019-06-11 09:37:40,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 387 is 160 bytes
2019-06-11 09:37:40,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 386 is 83 bytes
2019-06-11 09:37:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 388 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1164 (print at Transform.scala:36)
2019-06-11 09:37:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1163, ShuffleMapStage 1162)
2019-06-11 09:37:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1164 (MapPartitionsRDD[1359] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_582 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_582_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:40,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_582_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 582 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:40,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1164 (MapPartitionsRDD[1359] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:40,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1164.0 with 1 tasks
2019-06-11 09:37:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1164.0 (TID 776, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:40,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1164.0 (TID 776)
2019-06-11 09:37:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1164.0 (TID 776). 966 bytes result sent to driver
2019-06-11 09:37:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1164.0 (TID 776) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1164.0, whose tasks have all completed, from pool 
2019-06-11 09:37:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1164 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 388 finished: print at Transform.scala:36, took 0.005307 s
2019-06-11 09:37:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217060000 ms.0 from job set of time 1560217060000 ms
2019-06-11 09:37:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217060000 ms (execution: 0.034 s)
2019-06-11 09:37:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1352 from persistence list
2019-06-11 09:37:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1352
2019-06-11 09:37:40,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1347 from persistence list
2019-06-11 09:37:40,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1347
2019-06-11 09:37:40,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1346 from persistence list
2019-06-11 09:37:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1346
2019-06-11 09:37:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1346] at socketTextStream at Transform.scala:18 of time 1560217060000 ms
2019-06-11 09:37:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217050000 ms
2019-06-11 09:37:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217050000 ms
2019-06-11 09:37:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217065000 ms
2019-06-11 09:37:45,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217065000 ms.0 from job set of time 1560217065000 ms
2019-06-11 09:37:45,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1361 (map at Transform.scala:20)
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 389 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1167 (print at Transform.scala:36)
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1166, ShuffleMapStage 1165)
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1165)
2019-06-11 09:37:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1165 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_583 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_583_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:37:45,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_583_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:45,010  INFO [org.apache.spark.SparkContext] - Created broadcast 583 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:45,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1165 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:45,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1165.0 with 2 tasks
2019-06-11 09:37:45,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1165.0 (TID 777, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:45,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1165.0 (TID 777)
2019-06-11 09:37:45,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1165.0 (TID 777). 853 bytes result sent to driver
2019-06-11 09:37:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1165.0 (TID 778, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:45,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1165.0 (TID 778)
2019-06-11 09:37:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1165.0 (TID 777) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:45,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1165.0 (TID 778). 810 bytes result sent to driver
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1165.0 (TID 778) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1165.0, whose tasks have all completed, from pool 
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1165 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1167)
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:45,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1167 (MapPartitionsRDD[1366] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_584 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:45,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_584_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:45,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_584_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:45,031  INFO [org.apache.spark.SparkContext] - Created broadcast 584 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:45,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1167 (MapPartitionsRDD[1366] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:45,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1167.0 with 1 tasks
2019-06-11 09:37:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1167.0 (TID 779, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:45,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1167.0 (TID 779)
2019-06-11 09:37:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:45,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:45,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1167.0 (TID 779). 966 bytes result sent to driver
2019-06-11 09:37:45,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1167.0 (TID 779) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:45,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1167.0, whose tasks have all completed, from pool 
2019-06-11 09:37:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1167 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 389 finished: print at Transform.scala:36, took 0.025265 s
2019-06-11 09:37:45,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 389 is 160 bytes
2019-06-11 09:37:45,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 388 is 83 bytes
2019-06-11 09:37:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 390 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1170 (print at Transform.scala:36)
2019-06-11 09:37:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1168, ShuffleMapStage 1169)
2019-06-11 09:37:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1170 (MapPartitionsRDD[1366] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:45,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_585 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:37:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_585_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:37:45,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_585_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:45,038  INFO [org.apache.spark.SparkContext] - Created broadcast 585 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1170 (MapPartitionsRDD[1366] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:45,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1170.0 with 1 tasks
2019-06-11 09:37:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1170.0 (TID 780, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:45,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1170.0 (TID 780)
2019-06-11 09:37:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:45,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1170.0 (TID 780). 1009 bytes result sent to driver
2019-06-11 09:37:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1170.0 (TID 780) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1170.0, whose tasks have all completed, from pool 
2019-06-11 09:37:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1170 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:37:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 390 finished: print at Transform.scala:36, took 0.005633 s
2019-06-11 09:37:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217065000 ms.0 from job set of time 1560217065000 ms
2019-06-11 09:37:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217065000 ms (execution: 0.036 s)
2019-06-11 09:37:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1359 from persistence list
2019-06-11 09:37:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1359
2019-06-11 09:37:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1354 from persistence list
2019-06-11 09:37:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1354
2019-06-11 09:37:45,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1353 from persistence list
2019-06-11 09:37:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1353
2019-06-11 09:37:45,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1353] at socketTextStream at Transform.scala:18 of time 1560217065000 ms
2019-06-11 09:37:45,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217055000 ms
2019-06-11 09:37:45,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217055000 ms
2019-06-11 09:37:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217070000 ms
2019-06-11 09:37:50,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217070000 ms.0 from job set of time 1560217070000 ms
2019-06-11 09:37:50,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1368 (map at Transform.scala:20)
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 391 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1173 (print at Transform.scala:36)
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1171, ShuffleMapStage 1172)
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1172)
2019-06-11 09:37:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1172 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_586 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:50,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_586_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_586_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:50,010  INFO [org.apache.spark.SparkContext] - Created broadcast 586 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1172 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:50,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1172.0 with 2 tasks
2019-06-11 09:37:50,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1172.0 (TID 781, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:50,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1172.0 (TID 781)
2019-06-11 09:37:50,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1172.0 (TID 781). 810 bytes result sent to driver
2019-06-11 09:37:50,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1172.0 (TID 782, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:50,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1172.0 (TID 782)
2019-06-11 09:37:50,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1172.0 (TID 781) in 8 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:50,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1172.0 (TID 782). 767 bytes result sent to driver
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1172.0 (TID 782) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1172.0, whose tasks have all completed, from pool 
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1172 (parallelize at Transform.scala:16) finished in 0.016 s
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1173)
2019-06-11 09:37:50,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1173 (MapPartitionsRDD[1373] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:50,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_587 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_587_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:50,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_587_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:50,029  INFO [org.apache.spark.SparkContext] - Created broadcast 587 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1173 (MapPartitionsRDD[1373] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:50,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1173.0 with 1 tasks
2019-06-11 09:37:50,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1173.0 (TID 783, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:50,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1173.0 (TID 783)
2019-06-11 09:37:50,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:50,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:50,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:50,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:50,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1173.0 (TID 783). 1052 bytes result sent to driver
2019-06-11 09:37:50,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1173.0 (TID 783) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:50,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1173.0, whose tasks have all completed, from pool 
2019-06-11 09:37:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1173 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 391 finished: print at Transform.scala:36, took 0.024140 s
2019-06-11 09:37:50,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:50,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 390 is 83 bytes
2019-06-11 09:37:50,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 391 is 160 bytes
2019-06-11 09:37:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 392 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1176 (print at Transform.scala:36)
2019-06-11 09:37:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1174, ShuffleMapStage 1175)
2019-06-11 09:37:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:50,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1176 (MapPartitionsRDD[1373] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:50,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_588 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_588_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:50,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_588_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:50,037  INFO [org.apache.spark.SparkContext] - Created broadcast 588 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:50,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1176 (MapPartitionsRDD[1373] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:50,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1176.0 with 1 tasks
2019-06-11 09:37:50,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1176.0 (TID 784, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:50,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1176.0 (TID 784)
2019-06-11 09:37:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:50,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:50,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1176.0 (TID 784). 1009 bytes result sent to driver
2019-06-11 09:37:50,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1176.0 (TID 784) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:50,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1176.0, whose tasks have all completed, from pool 
2019-06-11 09:37:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1176 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:50,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 392 finished: print at Transform.scala:36, took 0.005339 s
2019-06-11 09:37:50,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217070000 ms.0 from job set of time 1560217070000 ms
2019-06-11 09:37:50,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217070000 ms (execution: 0.035 s)
2019-06-11 09:37:50,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1366 from persistence list
2019-06-11 09:37:50,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1361 from persistence list
2019-06-11 09:37:50,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1366
2019-06-11 09:37:50,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1361
2019-06-11 09:37:50,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1360 from persistence list
2019-06-11 09:37:50,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1360
2019-06-11 09:37:50,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1360] at socketTextStream at Transform.scala:18 of time 1560217070000 ms
2019-06-11 09:37:50,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217060000 ms
2019-06-11 09:37:50,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217060000 ms
2019-06-11 09:37:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217075000 ms
2019-06-11 09:37:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217075000 ms.0 from job set of time 1560217075000 ms
2019-06-11 09:37:55,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1375 (map at Transform.scala:20)
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 393 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1179 (print at Transform.scala:36)
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1178, ShuffleMapStage 1177)
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1178)
2019-06-11 09:37:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1178 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:37:55,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_589 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_589_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:37:55,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_589_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:37:55,009  INFO [org.apache.spark.SparkContext] - Created broadcast 589 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1178 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:37:55,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1178.0 with 2 tasks
2019-06-11 09:37:55,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1178.0 (TID 785, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1178.0 (TID 785)
2019-06-11 09:37:55,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1178.0 (TID 785). 810 bytes result sent to driver
2019-06-11 09:37:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1178.0 (TID 786, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:37:55,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1178.0 (TID 786)
2019-06-11 09:37:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1178.0 (TID 785) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:37:55,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1178.0 (TID 786). 767 bytes result sent to driver
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1178.0 (TID 786) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1178.0, whose tasks have all completed, from pool 
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1178 (parallelize at Transform.scala:16) finished in 0.016 s
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1179)
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:37:55,026  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1179 (MapPartitionsRDD[1380] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:55,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_590 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:55,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_590_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:55,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_590_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:55,028  INFO [org.apache.spark.SparkContext] - Created broadcast 590 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:55,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1179 (MapPartitionsRDD[1380] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:37:55,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1179.0 with 1 tasks
2019-06-11 09:37:55,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1179.0 (TID 787, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:55,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1179.0 (TID 787)
2019-06-11 09:37:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:55,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:55,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1179.0 (TID 787). 966 bytes result sent to driver
2019-06-11 09:37:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1179.0 (TID 787) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1179.0, whose tasks have all completed, from pool 
2019-06-11 09:37:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1179 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:55,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 393 finished: print at Transform.scala:36, took 0.024334 s
2019-06-11 09:37:55,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:37:55,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 392 is 83 bytes
2019-06-11 09:37:55,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 393 is 160 bytes
2019-06-11 09:37:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 394 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:37:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1182 (print at Transform.scala:36)
2019-06-11 09:37:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1181, ShuffleMapStage 1180)
2019-06-11 09:37:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:37:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1182 (MapPartitionsRDD[1380] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:37:55,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_591 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:37:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_591_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:37:55,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_591_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:37:55,036  INFO [org.apache.spark.SparkContext] - Created broadcast 591 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:37:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1182 (MapPartitionsRDD[1380] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:37:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1182.0 with 1 tasks
2019-06-11 09:37:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1182.0 (TID 788, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:37:55,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1182.0 (TID 788)
2019-06-11 09:37:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:37:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:37:55,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:37:55,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1182.0 (TID 788). 1009 bytes result sent to driver
2019-06-11 09:37:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1182.0 (TID 788) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:37:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1182.0, whose tasks have all completed, from pool 
2019-06-11 09:37:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1182 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:37:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 394 finished: print at Transform.scala:36, took 0.005396 s
2019-06-11 09:37:55,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217075000 ms.0 from job set of time 1560217075000 ms
2019-06-11 09:37:55,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217075000 ms (execution: 0.033 s)
2019-06-11 09:37:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1373 from persistence list
2019-06-11 09:37:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1373
2019-06-11 09:37:55,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1368 from persistence list
2019-06-11 09:37:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1368
2019-06-11 09:37:55,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1367 from persistence list
2019-06-11 09:37:55,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1367
2019-06-11 09:37:55,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1367] at socketTextStream at Transform.scala:18 of time 1560217075000 ms
2019-06-11 09:37:55,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217065000 ms
2019-06-11 09:37:55,039  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217065000 ms
2019-06-11 09:38:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217080000 ms
2019-06-11 09:38:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217080000 ms.0 from job set of time 1560217080000 ms
2019-06-11 09:38:00,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_579_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_581_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,016  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1382 (map at Transform.scala:20)
2019-06-11 09:38:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 395 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1185 (print at Transform.scala:36)
2019-06-11 09:38:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1184, ShuffleMapStage 1183)
2019-06-11 09:38:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1183)
2019-06-11 09:38:00,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1183 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:00,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_588_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,017  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_592 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:00,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_583_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_592_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:38:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_587_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_592_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,019  INFO [org.apache.spark.SparkContext] - Created broadcast 592 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:00,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1183 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:00,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_590_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,019  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1183.0 with 2 tasks
2019-06-11 09:38:00,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1183.0 (TID 789, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:00,020  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1183.0 (TID 789)
2019-06-11 09:38:00,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_589_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_582_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 383
2019-06-11 09:38:00,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_591_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 388
2019-06-11 09:38:00,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 389
2019-06-11 09:38:00,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_577_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_578_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 387
2019-06-11 09:38:00,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_585_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 390
2019-06-11 09:38:00,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_580_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,025  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 385
2019-06-11 09:38:00,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 391
2019-06-11 09:38:00,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_586_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:00,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 382
2019-06-11 09:38:00,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 384
2019-06-11 09:38:00,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_584_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,033  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 386
2019-06-11 09:38:00,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1183.0 (TID 789). 810 bytes result sent to driver
2019-06-11 09:38:00,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1183.0 (TID 790, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:00,035  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1183.0 (TID 790)
2019-06-11 09:38:00,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1183.0 (TID 789) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:00,045  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1183.0 (TID 790). 767 bytes result sent to driver
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1183.0 (TID 790) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1183.0, whose tasks have all completed, from pool 
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1183 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1185)
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1185 (MapPartitionsRDD[1387] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:00,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_593 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:00,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_593_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:00,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_593_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,049  INFO [org.apache.spark.SparkContext] - Created broadcast 593 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:00,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1185 (MapPartitionsRDD[1387] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:00,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1185.0 with 1 tasks
2019-06-11 09:38:00,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1185.0 (TID 791, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:00,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1185.0 (TID 791)
2019-06-11 09:38:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:00,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1185.0 (TID 791). 1009 bytes result sent to driver
2019-06-11 09:38:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1185.0 (TID 791) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:00,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1185.0, whose tasks have all completed, from pool 
2019-06-11 09:38:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1185 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:00,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 395 finished: print at Transform.scala:36, took 0.035372 s
2019-06-11 09:38:00,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:00,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 395 is 160 bytes
2019-06-11 09:38:00,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 394 is 83 bytes
2019-06-11 09:38:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 396 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1188 (print at Transform.scala:36)
2019-06-11 09:38:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1186, ShuffleMapStage 1187)
2019-06-11 09:38:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:00,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1188 (MapPartitionsRDD[1387] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:00,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_594 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:00,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_594_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:00,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_594_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:00,056  INFO [org.apache.spark.SparkContext] - Created broadcast 594 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:00,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1188 (MapPartitionsRDD[1387] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:00,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1188.0 with 1 tasks
2019-06-11 09:38:00,057  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1188.0 (TID 792, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:00,057  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1188.0 (TID 792)
2019-06-11 09:38:00,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:00,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:00,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:00,057  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:00,058  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1188.0 (TID 792). 966 bytes result sent to driver
2019-06-11 09:38:00,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1188.0 (TID 792) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:00,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1188.0, whose tasks have all completed, from pool 
2019-06-11 09:38:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1188 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:00,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 396 finished: print at Transform.scala:36, took 0.004859 s
2019-06-11 09:38:00,059  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217080000 ms.0 from job set of time 1560217080000 ms
2019-06-11 09:38:00,059  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.059 s for time 1560217080000 ms (execution: 0.051 s)
2019-06-11 09:38:00,059  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1380 from persistence list
2019-06-11 09:38:00,059  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1375 from persistence list
2019-06-11 09:38:00,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1380
2019-06-11 09:38:00,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1375
2019-06-11 09:38:00,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1374 from persistence list
2019-06-11 09:38:00,060  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1374
2019-06-11 09:38:00,060  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1374] at socketTextStream at Transform.scala:18 of time 1560217080000 ms
2019-06-11 09:38:00,060  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217070000 ms
2019-06-11 09:38:00,060  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217070000 ms
2019-06-11 09:38:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217085000 ms
2019-06-11 09:38:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217085000 ms.0 from job set of time 1560217085000 ms
2019-06-11 09:38:05,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1389 (map at Transform.scala:20)
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 397 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1191 (print at Transform.scala:36)
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1189, ShuffleMapStage 1190)
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1190)
2019-06-11 09:38:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1190 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:05,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_595 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_595_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:05,008  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_595_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:05,008  INFO [org.apache.spark.SparkContext] - Created broadcast 595 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1190 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1190.0 with 2 tasks
2019-06-11 09:38:05,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1190.0 (TID 793, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1190.0 (TID 793)
2019-06-11 09:38:05,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1190.0 (TID 793). 810 bytes result sent to driver
2019-06-11 09:38:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1190.0 (TID 794, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1190.0 (TID 794)
2019-06-11 09:38:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1190.0 (TID 793) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:05,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1190.0 (TID 794). 810 bytes result sent to driver
2019-06-11 09:38:05,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1190.0 (TID 794) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:05,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1190.0, whose tasks have all completed, from pool 
2019-06-11 09:38:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1190 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:38:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1191)
2019-06-11 09:38:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1191 (MapPartitionsRDD[1394] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_596 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_596_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:05,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_596_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:05,029  INFO [org.apache.spark.SparkContext] - Created broadcast 596 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1191 (MapPartitionsRDD[1394] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:05,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1191.0 with 1 tasks
2019-06-11 09:38:05,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1191.0 (TID 795, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:05,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1191.0 (TID 795)
2019-06-11 09:38:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:05,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1191.0 (TID 795). 1009 bytes result sent to driver
2019-06-11 09:38:05,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1191.0 (TID 795) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:05,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1191.0, whose tasks have all completed, from pool 
2019-06-11 09:38:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1191 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 397 finished: print at Transform.scala:36, took 0.026313 s
2019-06-11 09:38:05,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 396 is 83 bytes
2019-06-11 09:38:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 397 is 160 bytes
2019-06-11 09:38:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 398 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1194 (print at Transform.scala:36)
2019-06-11 09:38:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1192, ShuffleMapStage 1193)
2019-06-11 09:38:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1194 (MapPartitionsRDD[1394] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_597 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:05,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_597_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:05,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_597_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:05,038  INFO [org.apache.spark.SparkContext] - Created broadcast 597 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:05,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1194 (MapPartitionsRDD[1394] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:05,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1194.0 with 1 tasks
2019-06-11 09:38:05,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1194.0 (TID 796, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:05,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1194.0 (TID 796)
2019-06-11 09:38:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:05,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:05,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1194.0 (TID 796). 1009 bytes result sent to driver
2019-06-11 09:38:05,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1194.0 (TID 796) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:05,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1194.0, whose tasks have all completed, from pool 
2019-06-11 09:38:05,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1194 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:05,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 398 finished: print at Transform.scala:36, took 0.006350 s
2019-06-11 09:38:05,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217085000 ms.0 from job set of time 1560217085000 ms
2019-06-11 09:38:05,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217085000 ms (execution: 0.036 s)
2019-06-11 09:38:05,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1387 from persistence list
2019-06-11 09:38:05,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1382 from persistence list
2019-06-11 09:38:05,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1387
2019-06-11 09:38:05,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1382
2019-06-11 09:38:05,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1381 from persistence list
2019-06-11 09:38:05,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1381
2019-06-11 09:38:05,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1381] at socketTextStream at Transform.scala:18 of time 1560217085000 ms
2019-06-11 09:38:05,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217075000 ms
2019-06-11 09:38:05,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217075000 ms
2019-06-11 09:38:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217090000 ms
2019-06-11 09:38:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217090000 ms.0 from job set of time 1560217090000 ms
2019-06-11 09:38:10,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1396 (map at Transform.scala:20)
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 399 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1197 (print at Transform.scala:36)
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1196, ShuffleMapStage 1195)
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1195)
2019-06-11 09:38:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1195 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_598 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_598_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_598_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:10,010  INFO [org.apache.spark.SparkContext] - Created broadcast 598 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:10,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1195 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:10,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1195.0 with 2 tasks
2019-06-11 09:38:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1195.0 (TID 797, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1195.0 (TID 797)
2019-06-11 09:38:10,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1195.0 (TID 797). 810 bytes result sent to driver
2019-06-11 09:38:10,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1195.0 (TID 798, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:10,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1195.0 (TID 798)
2019-06-11 09:38:10,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1195.0 (TID 797) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:10,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1195.0 (TID 798). 810 bytes result sent to driver
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1195.0 (TID 798) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1195.0, whose tasks have all completed, from pool 
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1195 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1197)
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:10,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1197 (MapPartitionsRDD[1401] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:10,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_599 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:10,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_599_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:10,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_599_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:10,031  INFO [org.apache.spark.SparkContext] - Created broadcast 599 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:10,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1197 (MapPartitionsRDD[1401] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:10,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1197.0 with 1 tasks
2019-06-11 09:38:10,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1197.0 (TID 799, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:10,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1197.0 (TID 799)
2019-06-11 09:38:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:10,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1197.0 (TID 799). 966 bytes result sent to driver
2019-06-11 09:38:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1197.0 (TID 799) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:10,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1197.0, whose tasks have all completed, from pool 
2019-06-11 09:38:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1197 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 399 finished: print at Transform.scala:36, took 0.025657 s
2019-06-11 09:38:10,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:10,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 399 is 160 bytes
2019-06-11 09:38:10,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 398 is 83 bytes
2019-06-11 09:38:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 400 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1200 (print at Transform.scala:36)
2019-06-11 09:38:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1199, ShuffleMapStage 1198)
2019-06-11 09:38:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1200 (MapPartitionsRDD[1401] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_600 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_600_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:10,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_600_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:10,039  INFO [org.apache.spark.SparkContext] - Created broadcast 600 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:10,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1200 (MapPartitionsRDD[1401] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:10,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1200.0 with 1 tasks
2019-06-11 09:38:10,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1200.0 (TID 800, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:10,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1200.0 (TID 800)
2019-06-11 09:38:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:10,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:10,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1200.0 (TID 800). 1009 bytes result sent to driver
2019-06-11 09:38:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1200.0 (TID 800) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1200.0, whose tasks have all completed, from pool 
2019-06-11 09:38:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1200 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 400 finished: print at Transform.scala:36, took 0.004904 s
2019-06-11 09:38:10,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217090000 ms.0 from job set of time 1560217090000 ms
2019-06-11 09:38:10,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217090000 ms (execution: 0.035 s)
2019-06-11 09:38:10,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1394 from persistence list
2019-06-11 09:38:10,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1394
2019-06-11 09:38:10,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1389 from persistence list
2019-06-11 09:38:10,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1389
2019-06-11 09:38:10,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1388 from persistence list
2019-06-11 09:38:10,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1388
2019-06-11 09:38:10,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1388] at socketTextStream at Transform.scala:18 of time 1560217090000 ms
2019-06-11 09:38:10,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217080000 ms
2019-06-11 09:38:10,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217080000 ms
2019-06-11 09:38:15,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217095000 ms
2019-06-11 09:38:15,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217095000 ms.0 from job set of time 1560217095000 ms
2019-06-11 09:38:15,012  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1403 (map at Transform.scala:20)
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 401 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1203 (print at Transform.scala:36)
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1202, ShuffleMapStage 1201)
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1201)
2019-06-11 09:38:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1201 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:15,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_601 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:15,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_601_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:38:15,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_601_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:15,016  INFO [org.apache.spark.SparkContext] - Created broadcast 601 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:15,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1201 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:15,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1201.0 with 2 tasks
2019-06-11 09:38:15,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1201.0 (TID 801, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:15,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1201.0 (TID 801)
2019-06-11 09:38:15,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1201.0 (TID 801). 767 bytes result sent to driver
2019-06-11 09:38:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1201.0 (TID 802, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:15,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1201.0 (TID 802)
2019-06-11 09:38:15,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1201.0 (TID 801) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:15,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1201.0 (TID 802). 810 bytes result sent to driver
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1201.0 (TID 802) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1201.0, whose tasks have all completed, from pool 
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1201 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1203)
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1203 (MapPartitionsRDD[1408] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:15,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_602 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:15,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_602_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:15,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_602_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:15,034  INFO [org.apache.spark.SparkContext] - Created broadcast 602 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:15,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1203 (MapPartitionsRDD[1408] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:15,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1203.0 with 1 tasks
2019-06-11 09:38:15,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1203.0 (TID 803, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:15,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1203.0 (TID 803)
2019-06-11 09:38:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:15,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:38:15,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1203.0 (TID 803). 966 bytes result sent to driver
2019-06-11 09:38:15,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1203.0 (TID 803) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:15,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1203.0, whose tasks have all completed, from pool 
2019-06-11 09:38:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1203 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:15,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 401 finished: print at Transform.scala:36, took 0.024677 s
2019-06-11 09:38:15,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 401 is 160 bytes
2019-06-11 09:38:15,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 400 is 83 bytes
2019-06-11 09:38:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 402 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1206 (print at Transform.scala:36)
2019-06-11 09:38:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1204, ShuffleMapStage 1205)
2019-06-11 09:38:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1206 (MapPartitionsRDD[1408] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_603 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:15,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_603_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_603_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 603 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1206 (MapPartitionsRDD[1408] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:15,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1206.0 with 1 tasks
2019-06-11 09:38:15,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1206.0 (TID 804, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:15,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1206.0 (TID 804)
2019-06-11 09:38:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:15,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:15,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1206.0 (TID 804). 966 bytes result sent to driver
2019-06-11 09:38:15,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1206.0 (TID 804) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:15,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1206.0, whose tasks have all completed, from pool 
2019-06-11 09:38:15,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1206 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:38:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 402 finished: print at Transform.scala:36, took 0.004916 s
2019-06-11 09:38:15,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217095000 ms.0 from job set of time 1560217095000 ms
2019-06-11 09:38:15,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560217095000 ms (execution: 0.034 s)
2019-06-11 09:38:15,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1401 from persistence list
2019-06-11 09:38:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1401
2019-06-11 09:38:15,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1396 from persistence list
2019-06-11 09:38:15,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1396
2019-06-11 09:38:15,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1395 from persistence list
2019-06-11 09:38:15,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1395
2019-06-11 09:38:15,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1395] at socketTextStream at Transform.scala:18 of time 1560217095000 ms
2019-06-11 09:38:15,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217085000 ms
2019-06-11 09:38:15,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217085000 ms
2019-06-11 09:38:20,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217100000 ms
2019-06-11 09:38:20,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217100000 ms.0 from job set of time 1560217100000 ms
2019-06-11 09:38:20,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1410 (map at Transform.scala:20)
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 403 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1209 (print at Transform.scala:36)
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1207, ShuffleMapStage 1208)
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1208)
2019-06-11 09:38:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1208 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:20,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_604 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_604_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:38:20,008  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_604_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,009  INFO [org.apache.spark.SparkContext] - Created broadcast 604 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1208 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:20,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1208.0 with 2 tasks
2019-06-11 09:38:20,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1208.0 (TID 805, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:20,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1208.0 (TID 805)
2019-06-11 09:38:20,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1208.0 (TID 805). 853 bytes result sent to driver
2019-06-11 09:38:20,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1208.0 (TID 806, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1208.0 (TID 806)
2019-06-11 09:38:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1208.0 (TID 805) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:20,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1208.0 (TID 806). 767 bytes result sent to driver
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1208.0 (TID 806) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1208.0, whose tasks have all completed, from pool 
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1208 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1209)
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1209 (MapPartitionsRDD[1415] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_605 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_605_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:20,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_605_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,030  INFO [org.apache.spark.SparkContext] - Created broadcast 605 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1209 (MapPartitionsRDD[1415] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1209.0 with 1 tasks
2019-06-11 09:38:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1209.0 (TID 807, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1209.0 (TID 807)
2019-06-11 09:38:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:20,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1209.0 (TID 807). 1009 bytes result sent to driver
2019-06-11 09:38:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1209.0 (TID 807) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1209.0, whose tasks have all completed, from pool 
2019-06-11 09:38:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1209 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 403 finished: print at Transform.scala:36, took 0.025520 s
2019-06-11 09:38:20,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_593_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:20,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 402 is 83 bytes
2019-06-11 09:38:20,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 403 is 160 bytes
2019-06-11 09:38:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 404 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1212 (print at Transform.scala:36)
2019-06-11 09:38:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1210, ShuffleMapStage 1211)
2019-06-11 09:38:20,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_595_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:20,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1212 (MapPartitionsRDD[1415] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:20,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_598_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_606 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:20,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_599_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_606_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:20,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_606_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_600_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,045  INFO [org.apache.spark.SparkContext] - Created broadcast 606 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1212 (MapPartitionsRDD[1415] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:20,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1212.0 with 1 tasks
2019-06-11 09:38:20,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1212.0 (TID 808, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:20,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1212.0 (TID 808)
2019-06-11 09:38:20,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_602_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 396
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_601_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:20,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_592_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1212.0 (TID 808). 1052 bytes result sent to driver
2019-06-11 09:38:20,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1212.0 (TID 808) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:20,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1212.0, whose tasks have all completed, from pool 
2019-06-11 09:38:20,047  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1212 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:20,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 404 finished: print at Transform.scala:36, took 0.006027 s
2019-06-11 09:38:20,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217100000 ms.0 from job set of time 1560217100000 ms
2019-06-11 09:38:20,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_605_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1408 from persistence list
2019-06-11 09:38:20,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560217100000 ms (execution: 0.043 s)
2019-06-11 09:38:20,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1408
2019-06-11 09:38:20,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1403 from persistence list
2019-06-11 09:38:20,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1403
2019-06-11 09:38:20,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1402 from persistence list
2019-06-11 09:38:20,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1402
2019-06-11 09:38:20,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1402] at socketTextStream at Transform.scala:18 of time 1560217100000 ms
2019-06-11 09:38:20,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_604_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:20,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217090000 ms
2019-06-11 09:38:20,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217090000 ms
2019-06-11 09:38:20,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 395
2019-06-11 09:38:20,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 397
2019-06-11 09:38:20,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_603_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_597_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_596_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 393
2019-06-11 09:38:20,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_594_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:20,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 399
2019-06-11 09:38:20,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 394
2019-06-11 09:38:20,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 398
2019-06-11 09:38:20,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 392
2019-06-11 09:38:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217105000 ms
2019-06-11 09:38:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217105000 ms.0 from job set of time 1560217105000 ms
2019-06-11 09:38:25,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1417 (map at Transform.scala:20)
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 405 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1215 (print at Transform.scala:36)
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1214, ShuffleMapStage 1213)
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1214)
2019-06-11 09:38:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1214 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_607 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_607_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:25,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_607_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:25,011  INFO [org.apache.spark.SparkContext] - Created broadcast 607 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1214 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:25,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1214.0 with 2 tasks
2019-06-11 09:38:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1214.0 (TID 809, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1214.0 (TID 809)
2019-06-11 09:38:25,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1214.0 (TID 809). 810 bytes result sent to driver
2019-06-11 09:38:25,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1214.0 (TID 810, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:25,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1214.0 (TID 810)
2019-06-11 09:38:25,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1214.0 (TID 809) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:25,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1214.0 (TID 810). 767 bytes result sent to driver
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1214.0 (TID 810) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1214.0, whose tasks have all completed, from pool 
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1214 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1215)
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1215 (MapPartitionsRDD[1422] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:25,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_608 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:25,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_608_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:25,032  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_608_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:25,033  INFO [org.apache.spark.SparkContext] - Created broadcast 608 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1215 (MapPartitionsRDD[1422] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:25,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1215.0 with 1 tasks
2019-06-11 09:38:25,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1215.0 (TID 811, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:25,033  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1215.0 (TID 811)
2019-06-11 09:38:25,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:25,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:25,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:25,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:25,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1215.0 (TID 811). 966 bytes result sent to driver
2019-06-11 09:38:25,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1215.0 (TID 811) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:25,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1215.0, whose tasks have all completed, from pool 
2019-06-11 09:38:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1215 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 405 finished: print at Transform.scala:36, took 0.026752 s
2019-06-11 09:38:25,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:25,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 404 is 83 bytes
2019-06-11 09:38:25,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 405 is 160 bytes
2019-06-11 09:38:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 406 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1218 (print at Transform.scala:36)
2019-06-11 09:38:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1217, ShuffleMapStage 1216)
2019-06-11 09:38:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1218 (MapPartitionsRDD[1422] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:25,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_609 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:25,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_609_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:25,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_609_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:25,040  INFO [org.apache.spark.SparkContext] - Created broadcast 609 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1218 (MapPartitionsRDD[1422] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1218.0 with 1 tasks
2019-06-11 09:38:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1218.0 (TID 812, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:25,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1218.0 (TID 812)
2019-06-11 09:38:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:25,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:25,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1218.0 (TID 812). 1009 bytes result sent to driver
2019-06-11 09:38:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1218.0 (TID 812) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1218.0, whose tasks have all completed, from pool 
2019-06-11 09:38:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1218 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:25,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 406 finished: print at Transform.scala:36, took 0.004800 s
2019-06-11 09:38:25,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217105000 ms.0 from job set of time 1560217105000 ms
2019-06-11 09:38:25,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217105000 ms (execution: 0.036 s)
2019-06-11 09:38:25,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1415 from persistence list
2019-06-11 09:38:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1415
2019-06-11 09:38:25,043  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1410 from persistence list
2019-06-11 09:38:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1410
2019-06-11 09:38:25,043  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1409 from persistence list
2019-06-11 09:38:25,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1409
2019-06-11 09:38:25,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1409] at socketTextStream at Transform.scala:18 of time 1560217105000 ms
2019-06-11 09:38:25,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217095000 ms
2019-06-11 09:38:25,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217095000 ms
2019-06-11 09:38:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217110000 ms
2019-06-11 09:38:30,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217110000 ms.0 from job set of time 1560217110000 ms
2019-06-11 09:38:30,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1424 (map at Transform.scala:20)
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 407 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1221 (print at Transform.scala:36)
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1220, ShuffleMapStage 1219)
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1220)
2019-06-11 09:38:30,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1220 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_610 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_610_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:30,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_610_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:30,010  INFO [org.apache.spark.SparkContext] - Created broadcast 610 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1220 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:30,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1220.0 with 2 tasks
2019-06-11 09:38:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1220.0 (TID 813, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1220.0 (TID 813)
2019-06-11 09:38:30,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1220.0 (TID 813). 810 bytes result sent to driver
2019-06-11 09:38:30,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1220.0 (TID 814, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:30,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1220.0 (TID 814)
2019-06-11 09:38:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1220.0 (TID 813) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:30,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1220.0 (TID 814). 810 bytes result sent to driver
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1220.0 (TID 814) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1220.0, whose tasks have all completed, from pool 
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1220 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1221)
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:30,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1221 (MapPartitionsRDD[1429] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:30,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_611 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:30,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_611_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:30,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_611_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:30,030  INFO [org.apache.spark.SparkContext] - Created broadcast 611 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1221 (MapPartitionsRDD[1429] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1221.0 with 1 tasks
2019-06-11 09:38:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1221.0 (TID 815, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:30,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1221.0 (TID 815)
2019-06-11 09:38:30,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:30,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:30,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:30,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:30,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1221.0 (TID 815). 1009 bytes result sent to driver
2019-06-11 09:38:30,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1221.0 (TID 815) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:30,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1221.0, whose tasks have all completed, from pool 
2019-06-11 09:38:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1221 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:30,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 407 finished: print at Transform.scala:36, took 0.025108 s
2019-06-11 09:38:30,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:30,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 406 is 83 bytes
2019-06-11 09:38:30,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 407 is 160 bytes
2019-06-11 09:38:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 408 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1224 (print at Transform.scala:36)
2019-06-11 09:38:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1222, ShuffleMapStage 1223)
2019-06-11 09:38:30,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:30,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1224 (MapPartitionsRDD[1429] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:30,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_612 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:30,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_612_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:30,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_612_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:30,038  INFO [org.apache.spark.SparkContext] - Created broadcast 612 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1224 (MapPartitionsRDD[1429] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:30,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1224.0 with 1 tasks
2019-06-11 09:38:30,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1224.0 (TID 816, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:30,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1224.0 (TID 816)
2019-06-11 09:38:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:30,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:30,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1224.0 (TID 816). 966 bytes result sent to driver
2019-06-11 09:38:30,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1224.0 (TID 816) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1224.0, whose tasks have all completed, from pool 
2019-06-11 09:38:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1224 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 408 finished: print at Transform.scala:36, took 0.005067 s
2019-06-11 09:38:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217110000 ms.0 from job set of time 1560217110000 ms
2019-06-11 09:38:30,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217110000 ms (execution: 0.035 s)
2019-06-11 09:38:30,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1422 from persistence list
2019-06-11 09:38:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1422
2019-06-11 09:38:30,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1417 from persistence list
2019-06-11 09:38:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1417
2019-06-11 09:38:30,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1416 from persistence list
2019-06-11 09:38:30,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1416
2019-06-11 09:38:30,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1416] at socketTextStream at Transform.scala:18 of time 1560217110000 ms
2019-06-11 09:38:30,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217100000 ms
2019-06-11 09:38:30,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217100000 ms
2019-06-11 09:38:35,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217115000 ms
2019-06-11 09:38:35,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217115000 ms.0 from job set of time 1560217115000 ms
2019-06-11 09:38:35,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1431 (map at Transform.scala:20)
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 409 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1227 (print at Transform.scala:36)
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1225, ShuffleMapStage 1226)
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1225)
2019-06-11 09:38:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1225 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_613 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_613_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:35,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_613_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 613 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:35,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1225 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:35,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1225.0 with 2 tasks
2019-06-11 09:38:35,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1225.0 (TID 817, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:35,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1225.0 (TID 817)
2019-06-11 09:38:35,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1225.0 (TID 817). 853 bytes result sent to driver
2019-06-11 09:38:35,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1225.0 (TID 818, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:35,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1225.0 (TID 818)
2019-06-11 09:38:35,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1225.0 (TID 817) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:35,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1225.0 (TID 818). 810 bytes result sent to driver
2019-06-11 09:38:35,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1225.0 (TID 818) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:35,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1225.0, whose tasks have all completed, from pool 
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1225 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1227)
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1227 (MapPartitionsRDD[1436] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:35,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_614 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:35,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_614_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:35,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_614_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:35,035  INFO [org.apache.spark.SparkContext] - Created broadcast 614 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:35,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1227 (MapPartitionsRDD[1436] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:35,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1227.0 with 1 tasks
2019-06-11 09:38:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1227.0 (TID 819, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:35,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1227.0 (TID 819)
2019-06-11 09:38:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:35,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:35,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1227.0 (TID 819). 966 bytes result sent to driver
2019-06-11 09:38:35,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1227.0 (TID 819) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:35,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1227.0, whose tasks have all completed, from pool 
2019-06-11 09:38:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1227 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 409 finished: print at Transform.scala:36, took 0.028451 s
2019-06-11 09:38:35,040  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 409 is 160 bytes
2019-06-11 09:38:35,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 408 is 83 bytes
2019-06-11 09:38:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 410 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1230 (print at Transform.scala:36)
2019-06-11 09:38:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1228, ShuffleMapStage 1229)
2019-06-11 09:38:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1230 (MapPartitionsRDD[1436] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_615 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:35,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_615_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:35,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_615_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:35,043  INFO [org.apache.spark.SparkContext] - Created broadcast 615 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:35,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1230 (MapPartitionsRDD[1436] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:35,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1230.0 with 1 tasks
2019-06-11 09:38:35,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1230.0 (TID 820, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:35,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1230.0 (TID 820)
2019-06-11 09:38:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:35,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:35,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1230.0 (TID 820). 966 bytes result sent to driver
2019-06-11 09:38:35,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1230.0 (TID 820) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:35,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1230.0, whose tasks have all completed, from pool 
2019-06-11 09:38:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1230 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:35,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 410 finished: print at Transform.scala:36, took 0.005434 s
2019-06-11 09:38:35,045  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217115000 ms.0 from job set of time 1560217115000 ms
2019-06-11 09:38:35,046  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.045 s for time 1560217115000 ms (execution: 0.038 s)
2019-06-11 09:38:35,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1429 from persistence list
2019-06-11 09:38:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1429
2019-06-11 09:38:35,046  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1424 from persistence list
2019-06-11 09:38:35,046  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1423 from persistence list
2019-06-11 09:38:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1424
2019-06-11 09:38:35,046  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1423
2019-06-11 09:38:35,046  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1423] at socketTextStream at Transform.scala:18 of time 1560217115000 ms
2019-06-11 09:38:35,046  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217105000 ms
2019-06-11 09:38:35,046  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217105000 ms
2019-06-11 09:38:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217120000 ms
2019-06-11 09:38:40,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217120000 ms.0 from job set of time 1560217120000 ms
2019-06-11 09:38:40,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1438 (map at Transform.scala:20)
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 411 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1233 (print at Transform.scala:36)
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1232, ShuffleMapStage 1231)
2019-06-11 09:38:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1232)
2019-06-11 09:38:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1232 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_616 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:40,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_616_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:38:40,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_616_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:40,011  INFO [org.apache.spark.SparkContext] - Created broadcast 616 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:40,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1232 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:40,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1232.0 with 2 tasks
2019-06-11 09:38:40,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1232.0 (TID 821, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:40,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1232.0 (TID 821)
2019-06-11 09:38:40,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1232.0 (TID 821). 810 bytes result sent to driver
2019-06-11 09:38:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1232.0 (TID 822, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:40,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1232.0 (TID 822)
2019-06-11 09:38:40,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1232.0 (TID 821) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1232.0 (TID 822). 853 bytes result sent to driver
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1232.0 (TID 822) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1232.0, whose tasks have all completed, from pool 
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1232 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1233)
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1233 (MapPartitionsRDD[1443] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:40,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_617 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:40,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_617_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:40,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_617_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:40,036  INFO [org.apache.spark.SparkContext] - Created broadcast 617 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1233 (MapPartitionsRDD[1443] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:40,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1233.0 with 1 tasks
2019-06-11 09:38:40,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1233.0 (TID 823, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:40,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1233.0 (TID 823)
2019-06-11 09:38:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:40,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:40,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1233.0 (TID 823). 966 bytes result sent to driver
2019-06-11 09:38:40,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1233.0 (TID 823) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:40,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1233.0, whose tasks have all completed, from pool 
2019-06-11 09:38:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1233 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:40,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 411 finished: print at Transform.scala:36, took 0.030277 s
2019-06-11 09:38:40,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:40,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 410 is 83 bytes
2019-06-11 09:38:40,042  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 411 is 160 bytes
2019-06-11 09:38:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 412 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1236 (print at Transform.scala:36)
2019-06-11 09:38:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1235, ShuffleMapStage 1234)
2019-06-11 09:38:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:40,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1236 (MapPartitionsRDD[1443] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:40,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_618 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:38:40,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_618_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:40,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_618_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:40,044  INFO [org.apache.spark.SparkContext] - Created broadcast 618 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:40,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1236 (MapPartitionsRDD[1443] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:40,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1236.0 with 1 tasks
2019-06-11 09:38:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1236.0 (TID 824, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:40,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1236.0 (TID 824)
2019-06-11 09:38:40,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:40,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:40,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:40,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:40,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1236.0 (TID 824). 1052 bytes result sent to driver
2019-06-11 09:38:40,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1236.0 (TID 824) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:40,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1236.0, whose tasks have all completed, from pool 
2019-06-11 09:38:40,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1236 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:40,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 412 finished: print at Transform.scala:36, took 0.006493 s
2019-06-11 09:38:40,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217120000 ms.0 from job set of time 1560217120000 ms
2019-06-11 09:38:40,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560217120000 ms (execution: 0.041 s)
2019-06-11 09:38:40,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1436 from persistence list
2019-06-11 09:38:40,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1436
2019-06-11 09:38:40,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1431 from persistence list
2019-06-11 09:38:40,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1431
2019-06-11 09:38:40,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1430 from persistence list
2019-06-11 09:38:40,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1430
2019-06-11 09:38:40,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1430] at socketTextStream at Transform.scala:18 of time 1560217120000 ms
2019-06-11 09:38:40,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217110000 ms
2019-06-11 09:38:40,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217110000 ms
2019-06-11 09:38:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217125000 ms
2019-06-11 09:38:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217125000 ms.0 from job set of time 1560217125000 ms
2019-06-11 09:38:45,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1445 (map at Transform.scala:20)
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 413 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1239 (print at Transform.scala:36)
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1238, ShuffleMapStage 1237)
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1238)
2019-06-11 09:38:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1238 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_619 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:38:45,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_619_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:38:45,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_619_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:45,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_606_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,017  INFO [org.apache.spark.SparkContext] - Created broadcast 619 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:45,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 403
2019-06-11 09:38:45,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1238 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:45,017  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1238.0 with 2 tasks
2019-06-11 09:38:45,017  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 407
2019-06-11 09:38:45,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1238.0 (TID 825, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:45,018  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1238.0 (TID 825)
2019-06-11 09:38:45,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_611_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,019  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 404
2019-06-11 09:38:45,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_618_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_617_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_612_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_609_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 400
2019-06-11 09:38:45,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_616_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:45,024  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 401
2019-06-11 09:38:45,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_610_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:45,026  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_614_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 406
2019-06-11 09:38:45,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 402
2019-06-11 09:38:45,027  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_607_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:45,027  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 405
2019-06-11 09:38:45,028  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 409
2019-06-11 09:38:45,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_615_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_613_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:45,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_608_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,031  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 408
2019-06-11 09:38:45,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1238.0 (TID 825). 810 bytes result sent to driver
2019-06-11 09:38:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1238.0 (TID 826, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:45,032  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1238.0 (TID 826)
2019-06-11 09:38:45,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1238.0 (TID 825) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:45,043  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1238.0 (TID 826). 810 bytes result sent to driver
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1238.0 (TID 826) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1238.0, whose tasks have all completed, from pool 
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1238 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1239)
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1239 (MapPartitionsRDD[1450] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:45,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_620 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:45,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_620_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:45,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_620_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,045  INFO [org.apache.spark.SparkContext] - Created broadcast 620 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1239 (MapPartitionsRDD[1450] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1239.0 with 1 tasks
2019-06-11 09:38:45,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1239.0 (TID 827, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:45,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1239.0 (TID 827)
2019-06-11 09:38:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:45,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:45,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:38:45,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1239.0 (TID 827). 1052 bytes result sent to driver
2019-06-11 09:38:45,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1239.0 (TID 827) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:45,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1239.0, whose tasks have all completed, from pool 
2019-06-11 09:38:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1239 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 413 finished: print at Transform.scala:36, took 0.040049 s
2019-06-11 09:38:45,051  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:45,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 412 is 83 bytes
2019-06-11 09:38:45,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 413 is 160 bytes
2019-06-11 09:38:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 414 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1242 (print at Transform.scala:36)
2019-06-11 09:38:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1240, ShuffleMapStage 1241)
2019-06-11 09:38:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:45,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1242 (MapPartitionsRDD[1450] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:45,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_621 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:45,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_621_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:45,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_621_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:45,054  INFO [org.apache.spark.SparkContext] - Created broadcast 621 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:45,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1242 (MapPartitionsRDD[1450] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:45,054  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1242.0 with 1 tasks
2019-06-11 09:38:45,054  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1242.0 (TID 828, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:45,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1242.0 (TID 828)
2019-06-11 09:38:45,055  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:45,055  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:45,055  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:45,055  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:45,056  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1242.0 (TID 828). 966 bytes result sent to driver
2019-06-11 09:38:45,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1242.0 (TID 828) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:45,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1242.0, whose tasks have all completed, from pool 
2019-06-11 09:38:45,056  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1242 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:45,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 414 finished: print at Transform.scala:36, took 0.005030 s
2019-06-11 09:38:45,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217125000 ms.0 from job set of time 1560217125000 ms
2019-06-11 09:38:45,057  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.057 s for time 1560217125000 ms (execution: 0.050 s)
2019-06-11 09:38:45,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1443 from persistence list
2019-06-11 09:38:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1443
2019-06-11 09:38:45,057  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1438 from persistence list
2019-06-11 09:38:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1438
2019-06-11 09:38:45,057  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1437 from persistence list
2019-06-11 09:38:45,057  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1437
2019-06-11 09:38:45,057  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1437] at socketTextStream at Transform.scala:18 of time 1560217125000 ms
2019-06-11 09:38:45,057  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217115000 ms
2019-06-11 09:38:45,058  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217115000 ms
2019-06-11 09:38:50,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217130000 ms
2019-06-11 09:38:50,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217130000 ms.0 from job set of time 1560217130000 ms
2019-06-11 09:38:50,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1452 (map at Transform.scala:20)
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 415 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1245 (print at Transform.scala:36)
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1243, ShuffleMapStage 1244)
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1243)
2019-06-11 09:38:50,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1243 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:50,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_622 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_622_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:50,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_622_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:50,009  INFO [org.apache.spark.SparkContext] - Created broadcast 622 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:50,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1243 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:50,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1243.0 with 2 tasks
2019-06-11 09:38:50,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1243.0 (TID 829, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:50,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1243.0 (TID 829)
2019-06-11 09:38:50,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1243.0 (TID 829). 810 bytes result sent to driver
2019-06-11 09:38:50,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1243.0 (TID 830, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:50,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1243.0 (TID 830)
2019-06-11 09:38:50,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1243.0 (TID 829) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:50,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1243.0 (TID 830). 767 bytes result sent to driver
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1243.0 (TID 830) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1243.0, whose tasks have all completed, from pool 
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1243 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1245)
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:50,026  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1245 (MapPartitionsRDD[1457] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:50,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_623 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:50,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_623_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:50,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_623_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:50,028  INFO [org.apache.spark.SparkContext] - Created broadcast 623 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:50,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1245 (MapPartitionsRDD[1457] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:50,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1245.0 with 1 tasks
2019-06-11 09:38:50,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1245.0 (TID 831, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:50,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1245.0 (TID 831)
2019-06-11 09:38:50,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:50,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:50,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:50,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:50,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1245.0 (TID 831). 966 bytes result sent to driver
2019-06-11 09:38:50,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1245.0 (TID 831) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:50,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1245.0, whose tasks have all completed, from pool 
2019-06-11 09:38:50,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1245 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:38:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 415 finished: print at Transform.scala:36, took 0.025104 s
2019-06-11 09:38:50,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:50,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 415 is 160 bytes
2019-06-11 09:38:50,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 414 is 83 bytes
2019-06-11 09:38:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 416 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1248 (print at Transform.scala:36)
2019-06-11 09:38:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1247, ShuffleMapStage 1246)
2019-06-11 09:38:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1248 (MapPartitionsRDD[1457] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:50,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_624 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:50,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_624_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:50,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_624_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:50,036  INFO [org.apache.spark.SparkContext] - Created broadcast 624 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1248 (MapPartitionsRDD[1457] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:50,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1248.0 with 1 tasks
2019-06-11 09:38:50,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1248.0 (TID 832, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:50,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1248.0 (TID 832)
2019-06-11 09:38:50,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:50,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:50,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:50,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:50,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1248.0 (TID 832). 1009 bytes result sent to driver
2019-06-11 09:38:50,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1248.0 (TID 832) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:50,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1248.0, whose tasks have all completed, from pool 
2019-06-11 09:38:50,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1248 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:38:50,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 416 finished: print at Transform.scala:36, took 0.005005 s
2019-06-11 09:38:50,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217130000 ms.0 from job set of time 1560217130000 ms
2019-06-11 09:38:50,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217130000 ms (execution: 0.035 s)
2019-06-11 09:38:50,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1450 from persistence list
2019-06-11 09:38:50,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1450
2019-06-11 09:38:50,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1445 from persistence list
2019-06-11 09:38:50,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1445
2019-06-11 09:38:50,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1444 from persistence list
2019-06-11 09:38:50,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1444
2019-06-11 09:38:50,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1444] at socketTextStream at Transform.scala:18 of time 1560217130000 ms
2019-06-11 09:38:50,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217120000 ms
2019-06-11 09:38:50,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217120000 ms
2019-06-11 09:38:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217135000 ms
2019-06-11 09:38:55,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217135000 ms.0 from job set of time 1560217135000 ms
2019-06-11 09:38:55,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1459 (map at Transform.scala:20)
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 417 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1251 (print at Transform.scala:36)
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1250, ShuffleMapStage 1249)
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1250)
2019-06-11 09:38:55,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1250 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:38:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_625 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_625_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:38:55,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_625_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:38:55,010  INFO [org.apache.spark.SparkContext] - Created broadcast 625 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1250 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:38:55,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1250.0 with 2 tasks
2019-06-11 09:38:55,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1250.0 (TID 833, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:55,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1250.0 (TID 833)
2019-06-11 09:38:55,025  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1250.0 (TID 833). 853 bytes result sent to driver
2019-06-11 09:38:55,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1250.0 (TID 834, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:38:55,025  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1250.0 (TID 834)
2019-06-11 09:38:55,025  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1250.0 (TID 833) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:38:55,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1250.0 (TID 834). 853 bytes result sent to driver
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1250.0 (TID 834) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1250.0, whose tasks have all completed, from pool 
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1250 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1251)
2019-06-11 09:38:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:38:55,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1251 (MapPartitionsRDD[1464] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:55,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_626 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:55,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_626_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:55,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_626_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:55,037  INFO [org.apache.spark.SparkContext] - Created broadcast 626 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1251 (MapPartitionsRDD[1464] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:38:55,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1251.0 with 1 tasks
2019-06-11 09:38:55,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1251.0 (TID 835, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:55,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1251.0 (TID 835)
2019-06-11 09:38:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:55,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:55,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1251.0 (TID 835). 966 bytes result sent to driver
2019-06-11 09:38:55,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1251.0 (TID 835) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:55,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1251.0, whose tasks have all completed, from pool 
2019-06-11 09:38:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1251 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:55,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 417 finished: print at Transform.scala:36, took 0.032254 s
2019-06-11 09:38:55,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:38:55,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 416 is 83 bytes
2019-06-11 09:38:55,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 417 is 160 bytes
2019-06-11 09:38:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 418 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:38:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1254 (print at Transform.scala:36)
2019-06-11 09:38:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1253, ShuffleMapStage 1252)
2019-06-11 09:38:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:38:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1254 (MapPartitionsRDD[1464] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:38:55,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_627 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:38:55,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_627_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:38:55,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_627_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:38:55,046  INFO [org.apache.spark.SparkContext] - Created broadcast 627 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:38:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1254 (MapPartitionsRDD[1464] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:38:55,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1254.0 with 1 tasks
2019-06-11 09:38:55,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1254.0 (TID 836, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:38:55,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1254.0 (TID 836)
2019-06-11 09:38:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:38:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:38:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:38:55,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1254.0 (TID 836). 1052 bytes result sent to driver
2019-06-11 09:38:55,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1254.0 (TID 836) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:38:55,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1254.0, whose tasks have all completed, from pool 
2019-06-11 09:38:55,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1254 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:38:55,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 418 finished: print at Transform.scala:36, took 0.006509 s
2019-06-11 09:38:55,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217135000 ms.0 from job set of time 1560217135000 ms
2019-06-11 09:38:55,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560217135000 ms (execution: 0.044 s)
2019-06-11 09:38:55,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1457 from persistence list
2019-06-11 09:38:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1457
2019-06-11 09:38:55,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1452 from persistence list
2019-06-11 09:38:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1452
2019-06-11 09:38:55,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1451 from persistence list
2019-06-11 09:38:55,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1451
2019-06-11 09:38:55,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1451] at socketTextStream at Transform.scala:18 of time 1560217135000 ms
2019-06-11 09:38:55,051  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217125000 ms
2019-06-11 09:38:55,051  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217125000 ms
2019-06-11 09:39:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217140000 ms
2019-06-11 09:39:00,010  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217140000 ms.0 from job set of time 1560217140000 ms
2019-06-11 09:39:00,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1466 (map at Transform.scala:20)
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 419 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1257 (print at Transform.scala:36)
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1256, ShuffleMapStage 1255)
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1255)
2019-06-11 09:39:00,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1255 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:00,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_628 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:00,015  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_628_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:39:00,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_628_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:00,015  INFO [org.apache.spark.SparkContext] - Created broadcast 628 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:00,016  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1255 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:00,016  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1255.0 with 2 tasks
2019-06-11 09:39:00,016  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1255.0 (TID 837, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:00,016  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1255.0 (TID 837)
2019-06-11 09:39:00,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1255.0 (TID 837). 767 bytes result sent to driver
2019-06-11 09:39:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1255.0 (TID 838, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:00,026  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1255.0 (TID 838)
2019-06-11 09:39:00,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1255.0 (TID 837) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:00,037  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1255.0 (TID 838). 810 bytes result sent to driver
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1255.0 (TID 838) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1255.0, whose tasks have all completed, from pool 
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1255 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1257)
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1257 (MapPartitionsRDD[1471] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_629 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_629_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:00,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_629_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:00,039  INFO [org.apache.spark.SparkContext] - Created broadcast 629 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1257 (MapPartitionsRDD[1471] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:00,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1257.0 with 1 tasks
2019-06-11 09:39:00,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1257.0 (TID 839, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:00,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1257.0 (TID 839)
2019-06-11 09:39:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:00,042  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1257.0 (TID 839). 966 bytes result sent to driver
2019-06-11 09:39:00,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1257.0 (TID 839) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:00,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1257.0, whose tasks have all completed, from pool 
2019-06-11 09:39:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1257 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 419 finished: print at Transform.scala:36, took 0.029003 s
2019-06-11 09:39:00,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:00,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 419 is 160 bytes
2019-06-11 09:39:00,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 418 is 83 bytes
2019-06-11 09:39:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 420 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1260 (print at Transform.scala:36)
2019-06-11 09:39:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1258, ShuffleMapStage 1259)
2019-06-11 09:39:00,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:00,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1260 (MapPartitionsRDD[1471] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:00,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_630 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:00,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_630_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:00,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_630_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:00,048  INFO [org.apache.spark.SparkContext] - Created broadcast 630 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:00,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1260 (MapPartitionsRDD[1471] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:00,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1260.0 with 1 tasks
2019-06-11 09:39:00,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1260.0 (TID 840, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:00,049  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1260.0 (TID 840)
2019-06-11 09:39:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:00,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:00,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1260.0 (TID 840). 1009 bytes result sent to driver
2019-06-11 09:39:00,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1260.0 (TID 840) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:00,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1260.0, whose tasks have all completed, from pool 
2019-06-11 09:39:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1260 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:39:00,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 420 finished: print at Transform.scala:36, took 0.007210 s
2019-06-11 09:39:00,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217140000 ms.0 from job set of time 1560217140000 ms
2019-06-11 09:39:00,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560217140000 ms (execution: 0.042 s)
2019-06-11 09:39:00,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1464 from persistence list
2019-06-11 09:39:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1464
2019-06-11 09:39:00,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1459 from persistence list
2019-06-11 09:39:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1459
2019-06-11 09:39:00,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1458 from persistence list
2019-06-11 09:39:00,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1458
2019-06-11 09:39:00,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1458] at socketTextStream at Transform.scala:18 of time 1560217140000 ms
2019-06-11 09:39:00,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217130000 ms
2019-06-11 09:39:00,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217130000 ms
2019-06-11 09:39:05,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217145000 ms
2019-06-11 09:39:05,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217145000 ms.0 from job set of time 1560217145000 ms
2019-06-11 09:39:05,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1473 (map at Transform.scala:20)
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 421 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1263 (print at Transform.scala:36)
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1261, ShuffleMapStage 1262)
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1261)
2019-06-11 09:39:05,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1261 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:05,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_631 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:05,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_631_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:39:05,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_631_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:05,013  INFO [org.apache.spark.SparkContext] - Created broadcast 631 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:05,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1261 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:05,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1261.0 with 2 tasks
2019-06-11 09:39:05,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1261.0 (TID 841, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:05,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1261.0 (TID 841)
2019-06-11 09:39:05,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1261.0 (TID 841). 853 bytes result sent to driver
2019-06-11 09:39:05,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1261.0 (TID 842, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:05,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1261.0 (TID 842)
2019-06-11 09:39:05,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1261.0 (TID 841) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:05,034  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1261.0 (TID 842). 853 bytes result sent to driver
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1261.0 (TID 842) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1261.0, whose tasks have all completed, from pool 
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1261 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1263)
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1263 (MapPartitionsRDD[1478] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_632 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:05,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_632_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:05,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_628_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:05,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_632_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,046  INFO [org.apache.spark.SparkContext] - Created broadcast 632 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:05,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1263 (MapPartitionsRDD[1478] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:05,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1263.0 with 1 tasks
2019-06-11 09:39:05,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_621_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1263.0 (TID 843, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:05,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1263.0 (TID 843)
2019-06-11 09:39:05,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 415
2019-06-11 09:39:05,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_630_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:05,048  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:05,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_627_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1263.0 (TID 843). 1009 bytes result sent to driver
2019-06-11 09:39:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_624_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1263.0 (TID 843) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:05,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1263.0, whose tasks have all completed, from pool 
2019-06-11 09:39:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1263 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:39:05,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_625_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:05,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 421 finished: print at Transform.scala:36, took 0.039596 s
2019-06-11 09:39:05,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_623_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 416
2019-06-11 09:39:05,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 413
2019-06-11 09:39:05,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_629_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_620_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 410
2019-06-11 09:39:05,055  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 414
2019-06-11 09:39:05,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_626_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,056  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 411
2019-06-11 09:39:05,057  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:05,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 417
2019-06-11 09:39:05,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 421 is 160 bytes
2019-06-11 09:39:05,058  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 420 is 83 bytes
2019-06-11 09:39:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 422 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:05,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_622_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1266 (print at Transform.scala:36)
2019-06-11 09:39:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1265, ShuffleMapStage 1264)
2019-06-11 09:39:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:05,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1266 (MapPartitionsRDD[1478] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:05,059  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_633 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:05,061  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_633_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:05,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_633_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:05,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 412
2019-06-11 09:39:05,064  INFO [org.apache.spark.SparkContext] - Created broadcast 633 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:05,065  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1266 (MapPartitionsRDD[1478] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:05,065  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1266.0 with 1 tasks
2019-06-11 09:39:05,065  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_619_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:05,065  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1266.0 (TID 844, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:05,066  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1266.0 (TID 844)
2019-06-11 09:39:05,067  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:05,067  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:05,067  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:05,067  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:05,069  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1266.0 (TID 844). 1009 bytes result sent to driver
2019-06-11 09:39:05,070  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1266.0 (TID 844) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:05,070  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1266.0, whose tasks have all completed, from pool 
2019-06-11 09:39:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1266 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:39:05,070  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 422 finished: print at Transform.scala:36, took 0.013559 s
2019-06-11 09:39:05,071  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217145000 ms.0 from job set of time 1560217145000 ms
2019-06-11 09:39:05,071  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.071 s for time 1560217145000 ms (execution: 0.063 s)
2019-06-11 09:39:05,071  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1471 from persistence list
2019-06-11 09:39:05,071  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1466 from persistence list
2019-06-11 09:39:05,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1471
2019-06-11 09:39:05,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1466
2019-06-11 09:39:05,071  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1465 from persistence list
2019-06-11 09:39:05,071  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1465
2019-06-11 09:39:05,071  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1465] at socketTextStream at Transform.scala:18 of time 1560217145000 ms
2019-06-11 09:39:05,071  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217135000 ms
2019-06-11 09:39:05,071  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217135000 ms
2019-06-11 09:39:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217150000 ms
2019-06-11 09:39:10,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217150000 ms.0 from job set of time 1560217150000 ms
2019-06-11 09:39:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1480 (map at Transform.scala:20)
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 423 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1269 (print at Transform.scala:36)
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1268, ShuffleMapStage 1267)
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1267)
2019-06-11 09:39:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1267 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_634 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:10,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_634_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:10,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_634_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 634 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1267 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1267.0 with 2 tasks
2019-06-11 09:39:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1267.0 (TID 845, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1267.0 (TID 845)
2019-06-11 09:39:10,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1267.0 (TID 845). 810 bytes result sent to driver
2019-06-11 09:39:10,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1267.0 (TID 846, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:10,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1267.0 (TID 846)
2019-06-11 09:39:10,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1267.0 (TID 845) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:10,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1267.0 (TID 846). 853 bytes result sent to driver
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1267.0 (TID 846) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1267.0, whose tasks have all completed, from pool 
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1267 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1269)
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:10,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1269 (MapPartitionsRDD[1485] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:10,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_635 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:10,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_635_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:10,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_635_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:10,036  INFO [org.apache.spark.SparkContext] - Created broadcast 635 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1269 (MapPartitionsRDD[1485] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:10,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1269.0 with 1 tasks
2019-06-11 09:39:10,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1269.0 (TID 847, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:10,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1269.0 (TID 847)
2019-06-11 09:39:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:10,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:10,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1269.0 (TID 847). 966 bytes result sent to driver
2019-06-11 09:39:10,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1269.0 (TID 847) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:10,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1269.0, whose tasks have all completed, from pool 
2019-06-11 09:39:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1269 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:10,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 423 finished: print at Transform.scala:36, took 0.031488 s
2019-06-11 09:39:10,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:10,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 423 is 160 bytes
2019-06-11 09:39:10,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 422 is 83 bytes
2019-06-11 09:39:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 424 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1272 (print at Transform.scala:36)
2019-06-11 09:39:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1271, ShuffleMapStage 1270)
2019-06-11 09:39:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:10,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1272 (MapPartitionsRDD[1485] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:10,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_636 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:10,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_636_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:10,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_636_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:10,046  INFO [org.apache.spark.SparkContext] - Created broadcast 636 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1272 (MapPartitionsRDD[1485] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1272.0 with 1 tasks
2019-06-11 09:39:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1272.0 (TID 848, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:10,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1272.0 (TID 848)
2019-06-11 09:39:10,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:10,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:10,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:10,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:10,049  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1272.0 (TID 848). 1009 bytes result sent to driver
2019-06-11 09:39:10,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1272.0 (TID 848) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:10,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1272.0, whose tasks have all completed, from pool 
2019-06-11 09:39:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1272 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 424 finished: print at Transform.scala:36, took 0.006661 s
2019-06-11 09:39:10,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217150000 ms.0 from job set of time 1560217150000 ms
2019-06-11 09:39:10,050  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.050 s for time 1560217150000 ms (execution: 0.044 s)
2019-06-11 09:39:10,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1478 from persistence list
2019-06-11 09:39:10,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1478
2019-06-11 09:39:10,050  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1473 from persistence list
2019-06-11 09:39:10,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1473
2019-06-11 09:39:10,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1472 from persistence list
2019-06-11 09:39:10,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1472
2019-06-11 09:39:10,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1472] at socketTextStream at Transform.scala:18 of time 1560217150000 ms
2019-06-11 09:39:10,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217140000 ms
2019-06-11 09:39:10,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217140000 ms
2019-06-11 09:39:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217155000 ms
2019-06-11 09:39:15,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217155000 ms.0 from job set of time 1560217155000 ms
2019-06-11 09:39:15,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1487 (map at Transform.scala:20)
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 425 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1275 (print at Transform.scala:36)
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1274, ShuffleMapStage 1273)
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1274)
2019-06-11 09:39:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1274 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:15,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_637 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:15,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_637_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:15,013  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_637_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:15,013  INFO [org.apache.spark.SparkContext] - Created broadcast 637 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:15,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1274 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:15,013  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1274.0 with 2 tasks
2019-06-11 09:39:15,014  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1274.0 (TID 849, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:15,014  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1274.0 (TID 849)
2019-06-11 09:39:15,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1274.0 (TID 849). 853 bytes result sent to driver
2019-06-11 09:39:15,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1274.0 (TID 850, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:15,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1274.0 (TID 850)
2019-06-11 09:39:15,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1274.0 (TID 849) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1274.0 (TID 850). 853 bytes result sent to driver
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1274.0 (TID 850) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1274.0, whose tasks have all completed, from pool 
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1274 (parallelize at Transform.scala:16) finished in 0.026 s
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1275)
2019-06-11 09:39:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:15,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1275 (MapPartitionsRDD[1492] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:15,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_638 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:15,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_638_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:15,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_638_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:15,042  INFO [org.apache.spark.SparkContext] - Created broadcast 638 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:15,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1275 (MapPartitionsRDD[1492] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:15,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1275.0 with 1 tasks
2019-06-11 09:39:15,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1275.0 (TID 851, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:15,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1275.0 (TID 851)
2019-06-11 09:39:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:15,044  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:15,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1275.0 (TID 851). 966 bytes result sent to driver
2019-06-11 09:39:15,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1275.0 (TID 851) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:15,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1275.0, whose tasks have all completed, from pool 
2019-06-11 09:39:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1275 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:39:15,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 425 finished: print at Transform.scala:36, took 0.035650 s
2019-06-11 09:39:15,049  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:15,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 424 is 83 bytes
2019-06-11 09:39:15,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 425 is 160 bytes
2019-06-11 09:39:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 426 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:15,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1278 (print at Transform.scala:36)
2019-06-11 09:39:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1276, ShuffleMapStage 1277)
2019-06-11 09:39:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:15,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1278 (MapPartitionsRDD[1492] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:15,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_639 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:15,051  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_639_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:15,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_639_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:15,052  INFO [org.apache.spark.SparkContext] - Created broadcast 639 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:15,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1278 (MapPartitionsRDD[1492] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:15,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1278.0 with 1 tasks
2019-06-11 09:39:15,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1278.0 (TID 852, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:15,052  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1278.0 (TID 852)
2019-06-11 09:39:15,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:15,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:15,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:15,053  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:15,054  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1278.0 (TID 852). 966 bytes result sent to driver
2019-06-11 09:39:15,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1278.0 (TID 852) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:15,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1278.0, whose tasks have all completed, from pool 
2019-06-11 09:39:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1278 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:15,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 426 finished: print at Transform.scala:36, took 0.005982 s
2019-06-11 09:39:15,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217155000 ms.0 from job set of time 1560217155000 ms
2019-06-11 09:39:15,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560217155000 ms (execution: 0.048 s)
2019-06-11 09:39:15,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1485 from persistence list
2019-06-11 09:39:15,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1485
2019-06-11 09:39:15,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1480 from persistence list
2019-06-11 09:39:15,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1480
2019-06-11 09:39:15,056  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1479 from persistence list
2019-06-11 09:39:15,056  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1479
2019-06-11 09:39:15,056  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1479] at socketTextStream at Transform.scala:18 of time 1560217155000 ms
2019-06-11 09:39:15,056  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217145000 ms
2019-06-11 09:39:15,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217145000 ms
2019-06-11 09:39:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217160000 ms
2019-06-11 09:39:20,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217160000 ms.0 from job set of time 1560217160000 ms
2019-06-11 09:39:20,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1494 (map at Transform.scala:20)
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 427 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1281 (print at Transform.scala:36)
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1279, ShuffleMapStage 1280)
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1280)
2019-06-11 09:39:20,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1280 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:20,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_640 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:20,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_640_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:39:20,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_640_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:20,011  INFO [org.apache.spark.SparkContext] - Created broadcast 640 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:20,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1280 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:20,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1280.0 with 2 tasks
2019-06-11 09:39:20,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1280.0 (TID 853, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:20,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1280.0 (TID 853)
2019-06-11 09:39:20,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1280.0 (TID 853). 810 bytes result sent to driver
2019-06-11 09:39:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1280.0 (TID 854, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:20,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1280.0 (TID 854)
2019-06-11 09:39:20,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1280.0 (TID 853) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:20,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1280.0 (TID 854). 810 bytes result sent to driver
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1280.0 (TID 854) in 12 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1280.0, whose tasks have all completed, from pool 
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1280 (parallelize at Transform.scala:16) finished in 0.023 s
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1281)
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1281 (MapPartitionsRDD[1499] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_641 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:20,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_641_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:20,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_641_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:20,038  INFO [org.apache.spark.SparkContext] - Created broadcast 641 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1281 (MapPartitionsRDD[1499] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:20,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1281.0 with 1 tasks
2019-06-11 09:39:20,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1281.0 (TID 855, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:20,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1281.0 (TID 855)
2019-06-11 09:39:20,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:20,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:20,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:20,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:20,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1281.0 (TID 855). 966 bytes result sent to driver
2019-06-11 09:39:20,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1281.0 (TID 855) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:20,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1281.0, whose tasks have all completed, from pool 
2019-06-11 09:39:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1281 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:20,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 427 finished: print at Transform.scala:36, took 0.032274 s
2019-06-11 09:39:20,044  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:20,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 426 is 83 bytes
2019-06-11 09:39:20,045  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 427 is 160 bytes
2019-06-11 09:39:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 428 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1284 (print at Transform.scala:36)
2019-06-11 09:39:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1283, ShuffleMapStage 1282)
2019-06-11 09:39:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:20,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1284 (MapPartitionsRDD[1499] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:20,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_642 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:20,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_642_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:20,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_642_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:20,048  INFO [org.apache.spark.SparkContext] - Created broadcast 642 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:20,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1284 (MapPartitionsRDD[1499] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:20,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1284.0 with 1 tasks
2019-06-11 09:39:20,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1284.0 (TID 856, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:20,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1284.0 (TID 856)
2019-06-11 09:39:20,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:20,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:20,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:20,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:39:20,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1284.0 (TID 856). 1009 bytes result sent to driver
2019-06-11 09:39:20,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1284.0 (TID 856) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:20,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1284.0, whose tasks have all completed, from pool 
2019-06-11 09:39:20,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1284 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:20,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 428 finished: print at Transform.scala:36, took 0.006466 s
2019-06-11 09:39:20,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217160000 ms.0 from job set of time 1560217160000 ms
2019-06-11 09:39:20,051  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.051 s for time 1560217160000 ms (execution: 0.044 s)
2019-06-11 09:39:20,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1492 from persistence list
2019-06-11 09:39:20,051  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1492
2019-06-11 09:39:20,051  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1487 from persistence list
2019-06-11 09:39:20,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1486 from persistence list
2019-06-11 09:39:20,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1487
2019-06-11 09:39:20,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1486
2019-06-11 09:39:20,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1486] at socketTextStream at Transform.scala:18 of time 1560217160000 ms
2019-06-11 09:39:20,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217150000 ms
2019-06-11 09:39:20,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217150000 ms
2019-06-11 09:39:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217165000 ms
2019-06-11 09:39:25,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217165000 ms.0 from job set of time 1560217165000 ms
2019-06-11 09:39:25,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:25,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1501 (map at Transform.scala:20)
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 429 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1287 (print at Transform.scala:36)
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1286, ShuffleMapStage 1285)
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1285)
2019-06-11 09:39:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1285 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_643 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:25,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_643_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:39:25,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_643_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:25,012  INFO [org.apache.spark.SparkContext] - Created broadcast 643 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:25,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1285 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:25,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1285.0 with 2 tasks
2019-06-11 09:39:25,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1285.0 (TID 857, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:25,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1285.0 (TID 857)
2019-06-11 09:39:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1285.0 (TID 857). 810 bytes result sent to driver
2019-06-11 09:39:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1285.0 (TID 858, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:25,028  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1285.0 (TID 858)
2019-06-11 09:39:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1285.0 (TID 857) in 16 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:25,038  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1285.0 (TID 858). 853 bytes result sent to driver
2019-06-11 09:39:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1285.0 (TID 858) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1285.0, whose tasks have all completed, from pool 
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1285 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1287)
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1287 (MapPartitionsRDD[1506] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:25,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_644 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:25,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_644_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:25,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_644_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,041  INFO [org.apache.spark.SparkContext] - Created broadcast 644 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:25,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1287 (MapPartitionsRDD[1506] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:25,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1287.0 with 1 tasks
2019-06-11 09:39:25,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1287.0 (TID 859, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:25,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1287.0 (TID 859)
2019-06-11 09:39:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:25,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:25,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1287.0 (TID 859). 1009 bytes result sent to driver
2019-06-11 09:39:25,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1287.0 (TID 859) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:25,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1287.0, whose tasks have all completed, from pool 
2019-06-11 09:39:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1287 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:39:25,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 429 finished: print at Transform.scala:36, took 0.035863 s
2019-06-11 09:39:25,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:25,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 429 is 160 bytes
2019-06-11 09:39:25,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 428 is 83 bytes
2019-06-11 09:39:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 430 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1290 (print at Transform.scala:36)
2019-06-11 09:39:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1289, ShuffleMapStage 1288)
2019-06-11 09:39:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:25,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1290 (MapPartitionsRDD[1506] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:25,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_645 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:25,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_645_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_633_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_645_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,056  INFO [org.apache.spark.SparkContext] - Created broadcast 645 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:25,056  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1290 (MapPartitionsRDD[1506] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:25,056  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1290.0 with 1 tasks
2019-06-11 09:39:25,056  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_643_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:25,056  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1290.0 (TID 860, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:25,057  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1290.0 (TID 860)
2019-06-11 09:39:25,057  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 418
2019-06-11 09:39:25,057  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_636_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:25,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_637_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:25,058  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:25,058  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 419
2019-06-11 09:39:25,059  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_642_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,060  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1290.0 (TID 860). 1009 bytes result sent to driver
2019-06-11 09:39:25,060  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1290.0 (TID 860) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:25,060  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1290.0, whose tasks have all completed, from pool 
2019-06-11 09:39:25,060  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1290 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:39:25,060  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 430 finished: print at Transform.scala:36, took 0.012502 s
2019-06-11 09:39:25,060  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_634_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:25,060  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217165000 ms.0 from job set of time 1560217165000 ms
2019-06-11 09:39:25,061  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.060 s for time 1560217165000 ms (execution: 0.053 s)
2019-06-11 09:39:25,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1499 from persistence list
2019-06-11 09:39:25,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1499
2019-06-11 09:39:25,061  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1494 from persistence list
2019-06-11 09:39:25,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1494
2019-06-11 09:39:25,061  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1493 from persistence list
2019-06-11 09:39:25,061  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_635_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,061  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1493
2019-06-11 09:39:25,061  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1493] at socketTextStream at Transform.scala:18 of time 1560217165000 ms
2019-06-11 09:39:25,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 421
2019-06-11 09:39:25,062  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217155000 ms
2019-06-11 09:39:25,062  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217155000 ms
2019-06-11 09:39:25,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 424
2019-06-11 09:39:25,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 422
2019-06-11 09:39:25,063  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_641_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,063  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 420
2019-06-11 09:39:25,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_632_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,065  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 425
2019-06-11 09:39:25,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_638_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_644_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,068  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 423
2019-06-11 09:39:25,069  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_639_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:25,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_631_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:25,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_640_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:30,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217170000 ms
2019-06-11 09:39:30,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217170000 ms.0 from job set of time 1560217170000 ms
2019-06-11 09:39:30,011  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1508 (map at Transform.scala:20)
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 431 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1293 (print at Transform.scala:36)
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1291, ShuffleMapStage 1292)
2019-06-11 09:39:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1291)
2019-06-11 09:39:30,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1291 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:30,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_646 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:30,013  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_646_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:30,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_646_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:30,014  INFO [org.apache.spark.SparkContext] - Created broadcast 646 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:30,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1291 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:30,014  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1291.0 with 2 tasks
2019-06-11 09:39:30,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1291.0 (TID 861, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:30,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1291.0 (TID 861)
2019-06-11 09:39:30,026  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1291.0 (TID 861). 853 bytes result sent to driver
2019-06-11 09:39:30,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1291.0 (TID 862, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:30,027  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1291.0 (TID 862)
2019-06-11 09:39:30,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1291.0 (TID 861) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:30,038  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1291.0 (TID 862). 853 bytes result sent to driver
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1291.0 (TID 862) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1291.0, whose tasks have all completed, from pool 
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1291 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1293)
2019-06-11 09:39:30,038  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:30,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1293 (MapPartitionsRDD[1513] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:30,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_647 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:30,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_647_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_647_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:30,041  INFO [org.apache.spark.SparkContext] - Created broadcast 647 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:30,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1293 (MapPartitionsRDD[1513] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:30,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1293.0 with 1 tasks
2019-06-11 09:39:30,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1293.0 (TID 863, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:30,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1293.0 (TID 863)
2019-06-11 09:39:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:30,042  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:30,043  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1293.0 (TID 863). 1009 bytes result sent to driver
2019-06-11 09:39:30,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1293.0 (TID 863) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:30,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1293.0, whose tasks have all completed, from pool 
2019-06-11 09:39:30,043  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1293 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:39:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 431 finished: print at Transform.scala:36, took 0.032785 s
2019-06-11 09:39:30,047  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:30,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 431 is 160 bytes
2019-06-11 09:39:30,047  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 430 is 83 bytes
2019-06-11 09:39:30,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 432 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1296 (print at Transform.scala:36)
2019-06-11 09:39:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1294, ShuffleMapStage 1295)
2019-06-11 09:39:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1296 (MapPartitionsRDD[1513] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:30,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_648 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:30,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_648_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_648_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:30,050  INFO [org.apache.spark.SparkContext] - Created broadcast 648 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:30,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1296 (MapPartitionsRDD[1513] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:30,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1296.0 with 1 tasks
2019-06-11 09:39:30,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1296.0 (TID 864, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:30,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1296.0 (TID 864)
2019-06-11 09:39:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:30,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:30,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1296.0 (TID 864). 966 bytes result sent to driver
2019-06-11 09:39:30,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1296.0 (TID 864) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:30,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1296.0, whose tasks have all completed, from pool 
2019-06-11 09:39:30,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1296 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:30,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 432 finished: print at Transform.scala:36, took 0.006317 s
2019-06-11 09:39:30,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217170000 ms.0 from job set of time 1560217170000 ms
2019-06-11 09:39:30,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.053 s for time 1560217170000 ms (execution: 0.045 s)
2019-06-11 09:39:30,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1506 from persistence list
2019-06-11 09:39:30,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1506
2019-06-11 09:39:30,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1501 from persistence list
2019-06-11 09:39:30,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1501
2019-06-11 09:39:30,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1500 from persistence list
2019-06-11 09:39:30,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1500
2019-06-11 09:39:30,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1500] at socketTextStream at Transform.scala:18 of time 1560217170000 ms
2019-06-11 09:39:30,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217160000 ms
2019-06-11 09:39:30,054  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217160000 ms
2019-06-11 09:39:35,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217175000 ms
2019-06-11 09:39:35,013  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217175000 ms.0 from job set of time 1560217175000 ms
2019-06-11 09:39:35,019  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1515 (map at Transform.scala:20)
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 433 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1299 (print at Transform.scala:36)
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1298, ShuffleMapStage 1297)
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1297)
2019-06-11 09:39:35,019  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1297 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:35,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_649 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:35,022  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_649_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:35,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_649_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:35,023  INFO [org.apache.spark.SparkContext] - Created broadcast 649 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:35,023  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1297 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:35,023  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1297.0 with 2 tasks
2019-06-11 09:39:35,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1297.0 (TID 865, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:35,023  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1297.0 (TID 865)
2019-06-11 09:39:35,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1297.0 (TID 865). 853 bytes result sent to driver
2019-06-11 09:39:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1297.0 (TID 866, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:35,042  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1297.0 (TID 866)
2019-06-11 09:39:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1297.0 (TID 865) in 19 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:35,063  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1297.0 (TID 866). 853 bytes result sent to driver
2019-06-11 09:39:35,063  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1297.0 (TID 866) in 22 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:35,063  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1297.0, whose tasks have all completed, from pool 
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1297 (parallelize at Transform.scala:16) finished in 0.040 s
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1299)
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:35,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1299 (MapPartitionsRDD[1520] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:35,065  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_650 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:35,067  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_650_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:35,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_650_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:35,070  INFO [org.apache.spark.SparkContext] - Created broadcast 650 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:35,071  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1299 (MapPartitionsRDD[1520] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:35,071  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1299.0 with 1 tasks
2019-06-11 09:39:35,071  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1299.0 (TID 867, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:35,071  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1299.0 (TID 867)
2019-06-11 09:39:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:35,073  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:35,074  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1299.0 (TID 867). 966 bytes result sent to driver
2019-06-11 09:39:35,075  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1299.0 (TID 867) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:35,075  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1299.0, whose tasks have all completed, from pool 
2019-06-11 09:39:35,076  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1299 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:39:35,084  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 433 finished: print at Transform.scala:36, took 0.064788 s
2019-06-11 09:39:35,091  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:35,091  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 433 is 160 bytes
2019-06-11 09:39:35,092  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 432 is 83 bytes
2019-06-11 09:39:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 434 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1302 (print at Transform.scala:36)
2019-06-11 09:39:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1301, ShuffleMapStage 1300)
2019-06-11 09:39:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:35,092  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1302 (MapPartitionsRDD[1520] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:35,093  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_651 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:35,096  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_651_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:35,097  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_651_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:35,097  INFO [org.apache.spark.SparkContext] - Created broadcast 651 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:35,098  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1302 (MapPartitionsRDD[1520] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:35,098  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1302.0 with 1 tasks
2019-06-11 09:39:35,099  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1302.0 (TID 868, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:35,099  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1302.0 (TID 868)
2019-06-11 09:39:35,100  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:35,100  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:35,101  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:35,101  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:35,102  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1302.0 (TID 868). 966 bytes result sent to driver
2019-06-11 09:39:35,102  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1302.0 (TID 868) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:35,102  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1302.0, whose tasks have all completed, from pool 
2019-06-11 09:39:35,102  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1302 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:35,102  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 434 finished: print at Transform.scala:36, took 0.012061 s
2019-06-11 09:39:35,103  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217175000 ms.0 from job set of time 1560217175000 ms
2019-06-11 09:39:35,103  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.103 s for time 1560217175000 ms (execution: 0.090 s)
2019-06-11 09:39:35,103  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1513 from persistence list
2019-06-11 09:39:35,103  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1513
2019-06-11 09:39:35,103  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1508 from persistence list
2019-06-11 09:39:35,103  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1508
2019-06-11 09:39:35,103  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1507 from persistence list
2019-06-11 09:39:35,103  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1507
2019-06-11 09:39:35,103  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1507] at socketTextStream at Transform.scala:18 of time 1560217175000 ms
2019-06-11 09:39:35,103  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217165000 ms
2019-06-11 09:39:35,103  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217165000 ms
2019-06-11 09:39:40,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217180000 ms
2019-06-11 09:39:40,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217180000 ms.0 from job set of time 1560217180000 ms
2019-06-11 09:39:40,014  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:40,014  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1522 (map at Transform.scala:20)
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 435 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1305 (print at Transform.scala:36)
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1304, ShuffleMapStage 1303)
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1303)
2019-06-11 09:39:40,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1303 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:40,016  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_652 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:40,019  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_652_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:40,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_652_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:40,021  INFO [org.apache.spark.SparkContext] - Created broadcast 652 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:40,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1303 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:40,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1303.0 with 2 tasks
2019-06-11 09:39:40,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1303.0 (TID 869, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:40,022  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1303.0 (TID 869)
2019-06-11 09:39:40,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1303.0 (TID 869). 810 bytes result sent to driver
2019-06-11 09:39:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1303.0 (TID 870, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:40,045  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1303.0 (TID 870)
2019-06-11 09:39:40,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1303.0 (TID 869) in 24 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:40,065  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1303.0 (TID 870). 896 bytes result sent to driver
2019-06-11 09:39:40,065  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1303.0 (TID 870) in 20 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1303.0, whose tasks have all completed, from pool 
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1303 (parallelize at Transform.scala:16) finished in 0.045 s
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1305)
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:40,066  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1305 (MapPartitionsRDD[1527] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:40,067  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_653 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:40,072  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_653_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:40,073  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_653_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:40,073  INFO [org.apache.spark.SparkContext] - Created broadcast 653 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:40,073  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1305 (MapPartitionsRDD[1527] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:40,074  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1305.0 with 1 tasks
2019-06-11 09:39:40,074  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1305.0 (TID 871, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:40,074  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1305.0 (TID 871)
2019-06-11 09:39:40,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:40,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:40,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:40,077  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:40,078  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1305.0 (TID 871). 1052 bytes result sent to driver
2019-06-11 09:39:40,079  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1305.0 (TID 871) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:40,079  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1305.0, whose tasks have all completed, from pool 
2019-06-11 09:39:40,079  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1305 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:39:40,079  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 435 finished: print at Transform.scala:36, took 0.065408 s
2019-06-11 09:39:40,086  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:40,089  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 435 is 160 bytes
2019-06-11 09:39:40,090  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 434 is 83 bytes
2019-06-11 09:39:40,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 436 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:40,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1308 (print at Transform.scala:36)
2019-06-11 09:39:40,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1307, ShuffleMapStage 1306)
2019-06-11 09:39:40,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:40,090  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1308 (MapPartitionsRDD[1527] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:40,091  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_654 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:40,092  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_654_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:40,093  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_654_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:40,093  INFO [org.apache.spark.SparkContext] - Created broadcast 654 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:40,094  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1308 (MapPartitionsRDD[1527] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:40,094  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1308.0 with 1 tasks
2019-06-11 09:39:40,094  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1308.0 (TID 872, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:40,094  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1308.0 (TID 872)
2019-06-11 09:39:40,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:40,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:40,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:40,096  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:40,097  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1308.0 (TID 872). 1009 bytes result sent to driver
2019-06-11 09:39:40,097  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1308.0 (TID 872) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:40,097  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1308.0, whose tasks have all completed, from pool 
2019-06-11 09:39:40,097  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1308 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:40,098  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 436 finished: print at Transform.scala:36, took 0.011222 s
2019-06-11 09:39:40,098  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217180000 ms.0 from job set of time 1560217180000 ms
2019-06-11 09:39:40,098  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.098 s for time 1560217180000 ms (execution: 0.087 s)
2019-06-11 09:39:40,098  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1520 from persistence list
2019-06-11 09:39:40,098  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1520
2019-06-11 09:39:40,098  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1515 from persistence list
2019-06-11 09:39:40,098  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1515
2019-06-11 09:39:40,098  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1514 from persistence list
2019-06-11 09:39:40,098  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1514
2019-06-11 09:39:40,098  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1514] at socketTextStream at Transform.scala:18 of time 1560217180000 ms
2019-06-11 09:39:40,098  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217170000 ms
2019-06-11 09:39:40,099  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217170000 ms
2019-06-11 09:39:45,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217185000 ms
2019-06-11 09:39:45,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217185000 ms.0 from job set of time 1560217185000 ms
2019-06-11 09:39:45,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1529 (map at Transform.scala:20)
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 437 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1311 (print at Transform.scala:36)
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1309, ShuffleMapStage 1310)
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1309)
2019-06-11 09:39:45,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1309 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:45,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_655 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_655_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:39:45,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_655_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:45,011  INFO [org.apache.spark.SparkContext] - Created broadcast 655 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1309 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:45,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1309.0 with 2 tasks
2019-06-11 09:39:45,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1309.0 (TID 873, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:45,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1309.0 (TID 873)
2019-06-11 09:39:45,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1309.0 (TID 873). 810 bytes result sent to driver
2019-06-11 09:39:45,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1309.0 (TID 874, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:45,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1309.0 (TID 874)
2019-06-11 09:39:45,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1309.0 (TID 873) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:45,033  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1309.0 (TID 874). 853 bytes result sent to driver
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1309.0 (TID 874) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1309.0, whose tasks have all completed, from pool 
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1309 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1311)
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:45,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1311 (MapPartitionsRDD[1534] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:45,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_656 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:45,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_656_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:45,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_656_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:45,036  INFO [org.apache.spark.SparkContext] - Created broadcast 656 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:45,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1311 (MapPartitionsRDD[1534] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:45,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1311.0 with 1 tasks
2019-06-11 09:39:45,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1311.0 (TID 875, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:45,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1311.0 (TID 875)
2019-06-11 09:39:45,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:45,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:45,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:45,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:45,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1311.0 (TID 875). 966 bytes result sent to driver
2019-06-11 09:39:45,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1311.0 (TID 875) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:45,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1311.0, whose tasks have all completed, from pool 
2019-06-11 09:39:45,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1311 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:39:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 437 finished: print at Transform.scala:36, took 0.030884 s
2019-06-11 09:39:45,041  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:45,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 437 is 160 bytes
2019-06-11 09:39:45,041  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 436 is 83 bytes
2019-06-11 09:39:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 438 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1314 (print at Transform.scala:36)
2019-06-11 09:39:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1312, ShuffleMapStage 1313)
2019-06-11 09:39:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1314 (MapPartitionsRDD[1534] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:45,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_657 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:39:45,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_657_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:39:45,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_657_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:45,043  INFO [org.apache.spark.SparkContext] - Created broadcast 657 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1314 (MapPartitionsRDD[1534] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:45,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1314.0 with 1 tasks
2019-06-11 09:39:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1314.0 (TID 876, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:45,044  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1314.0 (TID 876)
2019-06-11 09:39:45,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:45,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:39:45,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:45,045  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:45,046  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1314.0 (TID 876). 966 bytes result sent to driver
2019-06-11 09:39:45,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1314.0 (TID 876) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:45,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1314.0, whose tasks have all completed, from pool 
2019-06-11 09:39:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1314 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:45,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 438 finished: print at Transform.scala:36, took 0.005666 s
2019-06-11 09:39:45,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217185000 ms.0 from job set of time 1560217185000 ms
2019-06-11 09:39:45,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560217185000 ms (execution: 0.043 s)
2019-06-11 09:39:45,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1527 from persistence list
2019-06-11 09:39:45,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1527
2019-06-11 09:39:45,047  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1522 from persistence list
2019-06-11 09:39:45,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1522
2019-06-11 09:39:45,047  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1521 from persistence list
2019-06-11 09:39:45,047  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1521] at socketTextStream at Transform.scala:18 of time 1560217185000 ms
2019-06-11 09:39:45,047  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1521
2019-06-11 09:39:45,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217175000 ms
2019-06-11 09:39:45,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217175000 ms
2019-06-11 09:39:50,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217190000 ms
2019-06-11 09:39:50,013  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217190000 ms.0 from job set of time 1560217190000 ms
2019-06-11 09:39:50,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_648_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,014  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_654_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,015  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 428
2019-06-11 09:39:50,015  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 431
2019-06-11 09:39:50,015  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 430
2019-06-11 09:39:50,016  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 427
2019-06-11 09:39:50,016  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_655_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:50,017  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:50,017  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_652_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1536 (map at Transform.scala:20)
2019-06-11 09:39:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 439 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1317 (print at Transform.scala:36)
2019-06-11 09:39:50,017  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1316, ShuffleMapStage 1315)
2019-06-11 09:39:50,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1316)
2019-06-11 09:39:50,018  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_657_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,018  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1316 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:50,018  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_658 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:50,019  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_651_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,020  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_658_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_646_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:50,020  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_658_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:50,020  INFO [org.apache.spark.SparkContext] - Created broadcast 658 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:50,021  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 429
2019-06-11 09:39:50,021  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1316 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:50,021  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1316.0 with 2 tasks
2019-06-11 09:39:50,021  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_650_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1316.0 (TID 877, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:50,021  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1316.0 (TID 877)
2019-06-11 09:39:50,022  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 434
2019-06-11 09:39:50,022  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_653_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,023  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 426
2019-06-11 09:39:50,023  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_656_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,024  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_645_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_647_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,025  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_649_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:50,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 435
2019-06-11 09:39:50,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 432
2019-06-11 09:39:50,026  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 433
2019-06-11 09:39:50,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1316.0 (TID 877). 853 bytes result sent to driver
2019-06-11 09:39:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1316.0 (TID 878, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:50,034  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1316.0 (TID 878)
2019-06-11 09:39:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1316.0 (TID 877) in 13 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:50,044  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1316.0 (TID 878). 810 bytes result sent to driver
2019-06-11 09:39:50,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1316.0 (TID 878) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:50,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1316.0, whose tasks have all completed, from pool 
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1316 (parallelize at Transform.scala:16) finished in 0.024 s
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1317)
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1317 (MapPartitionsRDD[1541] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:50,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_659 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:50,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_659_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:50,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_659_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,048  INFO [org.apache.spark.SparkContext] - Created broadcast 659 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1317 (MapPartitionsRDD[1541] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:50,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1317.0 with 1 tasks
2019-06-11 09:39:50,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1317.0 (TID 879, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:50,048  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1317.0 (TID 879)
2019-06-11 09:39:50,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:39:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:50,050  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:50,051  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1317.0 (TID 879). 966 bytes result sent to driver
2019-06-11 09:39:50,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1317.0 (TID 879) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:50,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1317.0, whose tasks have all completed, from pool 
2019-06-11 09:39:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1317 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:50,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 439 finished: print at Transform.scala:36, took 0.034718 s
2019-06-11 09:39:50,056  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:50,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 438 is 83 bytes
2019-06-11 09:39:50,056  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 439 is 160 bytes
2019-06-11 09:39:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 440 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1320 (print at Transform.scala:36)
2019-06-11 09:39:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1319, ShuffleMapStage 1318)
2019-06-11 09:39:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:50,057  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1320 (MapPartitionsRDD[1541] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:50,057  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_660 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:50,058  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_660_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:50,058  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_660_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:50,059  INFO [org.apache.spark.SparkContext] - Created broadcast 660 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:50,059  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1320 (MapPartitionsRDD[1541] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:50,059  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1320.0 with 1 tasks
2019-06-11 09:39:50,059  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1320.0 (TID 880, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:50,059  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1320.0 (TID 880)
2019-06-11 09:39:50,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:50,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:50,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:50,060  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:50,061  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1320.0 (TID 880). 966 bytes result sent to driver
2019-06-11 09:39:50,061  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1320.0 (TID 880) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:50,062  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1320.0, whose tasks have all completed, from pool 
2019-06-11 09:39:50,062  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1320 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:39:50,062  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 440 finished: print at Transform.scala:36, took 0.005972 s
2019-06-11 09:39:50,062  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217190000 ms.0 from job set of time 1560217190000 ms
2019-06-11 09:39:50,062  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.062 s for time 1560217190000 ms (execution: 0.055 s)
2019-06-11 09:39:50,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1534 from persistence list
2019-06-11 09:39:50,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1534
2019-06-11 09:39:50,062  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1529 from persistence list
2019-06-11 09:39:50,062  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1529
2019-06-11 09:39:50,062  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1528 from persistence list
2019-06-11 09:39:50,063  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1528
2019-06-11 09:39:50,063  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1528] at socketTextStream at Transform.scala:18 of time 1560217190000 ms
2019-06-11 09:39:50,063  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217180000 ms
2019-06-11 09:39:50,063  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217180000 ms
2019-06-11 09:39:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217195000 ms
2019-06-11 09:39:55,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217195000 ms.0 from job set of time 1560217195000 ms
2019-06-11 09:39:55,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1543 (map at Transform.scala:20)
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 441 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1323 (print at Transform.scala:36)
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1322, ShuffleMapStage 1321)
2019-06-11 09:39:55,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1321)
2019-06-11 09:39:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1321 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:39:55,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_661 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:55,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_661_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:39:55,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_661_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:39:55,011  INFO [org.apache.spark.SparkContext] - Created broadcast 661 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:55,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1321 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:39:55,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1321.0 with 2 tasks
2019-06-11 09:39:55,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1321.0 (TID 881, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:55,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1321.0 (TID 881)
2019-06-11 09:39:55,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1321.0 (TID 881). 810 bytes result sent to driver
2019-06-11 09:39:55,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1321.0 (TID 882, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:39:55,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1321.0 (TID 882)
2019-06-11 09:39:55,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1321.0 (TID 881) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:39:55,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1321.0 (TID 882). 810 bytes result sent to driver
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1321.0 (TID 882) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1321.0, whose tasks have all completed, from pool 
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1321 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1323)
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:39:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1323 (MapPartitionsRDD[1548] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:55,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_662 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:55,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_662_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:55,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_662_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:55,031  INFO [org.apache.spark.SparkContext] - Created broadcast 662 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:55,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1323 (MapPartitionsRDD[1548] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:39:55,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1323.0 with 1 tasks
2019-06-11 09:39:55,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1323.0 (TID 883, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:55,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1323.0 (TID 883)
2019-06-11 09:39:55,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:55,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:39:55,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:55,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:55,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1323.0 (TID 883). 966 bytes result sent to driver
2019-06-11 09:39:55,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1323.0 (TID 883) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:55,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1323.0, whose tasks have all completed, from pool 
2019-06-11 09:39:55,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1323 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:39:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 441 finished: print at Transform.scala:36, took 0.024826 s
2019-06-11 09:39:55,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:39:55,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 441 is 160 bytes
2019-06-11 09:39:55,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 440 is 83 bytes
2019-06-11 09:39:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 442 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:39:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1326 (print at Transform.scala:36)
2019-06-11 09:39:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1325, ShuffleMapStage 1324)
2019-06-11 09:39:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:39:55,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1326 (MapPartitionsRDD[1548] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:39:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_663 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:39:55,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_663_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:39:55,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_663_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:39:55,039  INFO [org.apache.spark.SparkContext] - Created broadcast 663 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:39:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1326 (MapPartitionsRDD[1548] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:39:55,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1326.0 with 1 tasks
2019-06-11 09:39:55,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1326.0 (TID 884, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:39:55,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1326.0 (TID 884)
2019-06-11 09:39:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:39:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:39:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:39:55,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1326.0 (TID 884). 966 bytes result sent to driver
2019-06-11 09:39:55,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1326.0 (TID 884) in 7 ms on localhost (executor driver) (1/1)
2019-06-11 09:39:55,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1326.0, whose tasks have all completed, from pool 
2019-06-11 09:39:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1326 (print at Transform.scala:36) finished in 0.007 s
2019-06-11 09:39:55,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 442 finished: print at Transform.scala:36, took 0.010001 s
2019-06-11 09:39:55,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217195000 ms.0 from job set of time 1560217195000 ms
2019-06-11 09:39:55,047  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.047 s for time 1560217195000 ms (execution: 0.040 s)
2019-06-11 09:39:55,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1541 from persistence list
2019-06-11 09:39:55,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1536 from persistence list
2019-06-11 09:39:55,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1541
2019-06-11 09:39:55,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1536
2019-06-11 09:39:55,048  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1535 from persistence list
2019-06-11 09:39:55,048  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1535
2019-06-11 09:39:55,048  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1535] at socketTextStream at Transform.scala:18 of time 1560217195000 ms
2019-06-11 09:39:55,048  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217185000 ms
2019-06-11 09:39:55,048  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217185000 ms
2019-06-11 09:40:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217200000 ms
2019-06-11 09:40:00,008  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217200000 ms.0 from job set of time 1560217200000 ms
2019-06-11 09:40:00,010  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1550 (map at Transform.scala:20)
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 443 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1329 (print at Transform.scala:36)
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1327, ShuffleMapStage 1328)
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1328)
2019-06-11 09:40:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1328 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_664 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:00,012  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_664_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:00,012  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_664_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:00,012  INFO [org.apache.spark.SparkContext] - Created broadcast 664 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1328 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:00,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1328.0 with 2 tasks
2019-06-11 09:40:00,013  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1328.0 (TID 885, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:00,013  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1328.0 (TID 885)
2019-06-11 09:40:00,023  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1328.0 (TID 885). 853 bytes result sent to driver
2019-06-11 09:40:00,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1328.0 (TID 886, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:00,023  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1328.0 (TID 885) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:00,023  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1328.0 (TID 886)
2019-06-11 09:40:00,030  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1328.0 (TID 886). 810 bytes result sent to driver
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1328.0 (TID 886) in 7 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1328.0, whose tasks have all completed, from pool 
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1328 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1329)
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:00,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1329 (MapPartitionsRDD[1555] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:00,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_665 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:00,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_665_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:00,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_665_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:00,033  INFO [org.apache.spark.SparkContext] - Created broadcast 665 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1329 (MapPartitionsRDD[1555] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1329.0 with 1 tasks
2019-06-11 09:40:00,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1329.0 (TID 887, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:00,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1329.0 (TID 887)
2019-06-11 09:40:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:00,034  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:00,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1329.0 (TID 887). 966 bytes result sent to driver
2019-06-11 09:40:00,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1329.0 (TID 887) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:00,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1329.0, whose tasks have all completed, from pool 
2019-06-11 09:40:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1329 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:00,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 443 finished: print at Transform.scala:36, took 0.025947 s
2019-06-11 09:40:00,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:00,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 442 is 83 bytes
2019-06-11 09:40:00,038  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 443 is 160 bytes
2019-06-11 09:40:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 444 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1332 (print at Transform.scala:36)
2019-06-11 09:40:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1330, ShuffleMapStage 1331)
2019-06-11 09:40:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1332 (MapPartitionsRDD[1555] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_666 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_666_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:00,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_666_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:00,040  INFO [org.apache.spark.SparkContext] - Created broadcast 666 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:00,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1332 (MapPartitionsRDD[1555] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1332.0 with 1 tasks
2019-06-11 09:40:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1332.0 (TID 888, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:00,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1332.0 (TID 888)
2019-06-11 09:40:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:00,041  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:00,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1332.0 (TID 888). 966 bytes result sent to driver
2019-06-11 09:40:00,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1332.0 (TID 888) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:00,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1332.0, whose tasks have all completed, from pool 
2019-06-11 09:40:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1332 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 444 finished: print at Transform.scala:36, took 0.004339 s
2019-06-11 09:40:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217200000 ms.0 from job set of time 1560217200000 ms
2019-06-11 09:40:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217200000 ms (execution: 0.034 s)
2019-06-11 09:40:00,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1548 from persistence list
2019-06-11 09:40:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1548
2019-06-11 09:40:00,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1543 from persistence list
2019-06-11 09:40:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1543
2019-06-11 09:40:00,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1542 from persistence list
2019-06-11 09:40:00,043  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1542
2019-06-11 09:40:00,043  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1542] at socketTextStream at Transform.scala:18 of time 1560217200000 ms
2019-06-11 09:40:00,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217190000 ms
2019-06-11 09:40:00,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217190000 ms
2019-06-11 09:40:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217205000 ms
2019-06-11 09:40:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217205000 ms.0 from job set of time 1560217205000 ms
2019-06-11 09:40:05,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1557 (map at Transform.scala:20)
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 445 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1335 (print at Transform.scala:36)
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1334, ShuffleMapStage 1333)
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1333)
2019-06-11 09:40:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1333 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_667 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_667_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:40:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_667_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 667 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1333 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:05,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1333.0 with 2 tasks
2019-06-11 09:40:05,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1333.0 (TID 889, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1333.0 (TID 889)
2019-06-11 09:40:05,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1333.0 (TID 889). 810 bytes result sent to driver
2019-06-11 09:40:05,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1333.0 (TID 890, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:05,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1333.0 (TID 890)
2019-06-11 09:40:05,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1333.0 (TID 889) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:05,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1333.0 (TID 890). 767 bytes result sent to driver
2019-06-11 09:40:05,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1333.0 (TID 890) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:05,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1333.0, whose tasks have all completed, from pool 
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1333 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1335)
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:05,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1335 (MapPartitionsRDD[1562] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_668 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:05,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_668_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:05,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_668_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:05,030  INFO [org.apache.spark.SparkContext] - Created broadcast 668 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:05,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1335 (MapPartitionsRDD[1562] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:05,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1335.0 with 1 tasks
2019-06-11 09:40:05,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1335.0 (TID 891, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:05,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1335.0 (TID 891)
2019-06-11 09:40:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:05,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1335.0 (TID 891). 966 bytes result sent to driver
2019-06-11 09:40:05,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1335.0 (TID 891) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:05,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1335.0, whose tasks have all completed, from pool 
2019-06-11 09:40:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1335 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 445 finished: print at Transform.scala:36, took 0.024998 s
2019-06-11 09:40:05,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 445 is 160 bytes
2019-06-11 09:40:05,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 444 is 83 bytes
2019-06-11 09:40:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 446 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1338 (print at Transform.scala:36)
2019-06-11 09:40:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1337, ShuffleMapStage 1336)
2019-06-11 09:40:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:05,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1338 (MapPartitionsRDD[1562] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_669 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:05,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_669_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_669_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:05,037  INFO [org.apache.spark.SparkContext] - Created broadcast 669 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:05,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1338 (MapPartitionsRDD[1562] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:05,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1338.0 with 1 tasks
2019-06-11 09:40:05,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1338.0 (TID 892, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:05,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1338.0 (TID 892)
2019-06-11 09:40:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:05,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1338.0 (TID 892). 966 bytes result sent to driver
2019-06-11 09:40:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1338.0 (TID 892) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1338.0, whose tasks have all completed, from pool 
2019-06-11 09:40:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1338 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 446 finished: print at Transform.scala:36, took 0.004960 s
2019-06-11 09:40:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217205000 ms.0 from job set of time 1560217205000 ms
2019-06-11 09:40:05,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217205000 ms (execution: 0.035 s)
2019-06-11 09:40:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1555 from persistence list
2019-06-11 09:40:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1555
2019-06-11 09:40:05,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1550 from persistence list
2019-06-11 09:40:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1550
2019-06-11 09:40:05,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1549 from persistence list
2019-06-11 09:40:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1549
2019-06-11 09:40:05,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1549] at socketTextStream at Transform.scala:18 of time 1560217205000 ms
2019-06-11 09:40:05,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217195000 ms
2019-06-11 09:40:05,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217195000 ms
2019-06-11 09:40:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217210000 ms
2019-06-11 09:40:10,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217210000 ms.0 from job set of time 1560217210000 ms
2019-06-11 09:40:10,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1564 (map at Transform.scala:20)
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 447 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1341 (print at Transform.scala:36)
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1340, ShuffleMapStage 1339)
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1340)
2019-06-11 09:40:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1340 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_670 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:10,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_670_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:40:10,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_670_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:10,011  INFO [org.apache.spark.SparkContext] - Created broadcast 670 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:10,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1340 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:10,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1340.0 with 2 tasks
2019-06-11 09:40:10,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1340.0 (TID 893, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:10,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1340.0 (TID 893)
2019-06-11 09:40:10,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1340.0 (TID 893). 853 bytes result sent to driver
2019-06-11 09:40:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1340.0 (TID 894, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:10,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1340.0 (TID 894)
2019-06-11 09:40:10,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1340.0 (TID 893) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:10,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1340.0 (TID 894). 767 bytes result sent to driver
2019-06-11 09:40:10,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1340.0 (TID 894) in 16 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:10,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1340.0, whose tasks have all completed, from pool 
2019-06-11 09:40:10,037  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 443
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1340 (parallelize at Transform.scala:16) finished in 0.027 s
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1341)
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:10,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1341 (MapPartitionsRDD[1569] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:10,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_664_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:10,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_671 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:10,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_668_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_671_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:10,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_671_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,040  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_665_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,040  INFO [org.apache.spark.SparkContext] - Created broadcast 671 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:10,041  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 442
2019-06-11 09:40:10,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1341 (MapPartitionsRDD[1569] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:10,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1341.0 with 1 tasks
2019-06-11 09:40:10,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1341.0 (TID 895, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:10,041  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1341.0 (TID 895)
2019-06-11 09:40:10,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_669_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 437
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_662_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_667_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 438
2019-06-11 09:40:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 441
2019-06-11 09:40:10,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 440
2019-06-11 09:40:10,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 439
2019-06-11 09:40:10,045  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1341.0 (TID 895). 1009 bytes result sent to driver
2019-06-11 09:40:10,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1341.0 (TID 895) in 5 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:10,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1341.0, whose tasks have all completed, from pool 
2019-06-11 09:40:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1341 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:40:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 447 finished: print at Transform.scala:36, took 0.036935 s
2019-06-11 09:40:10,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_661_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:10,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_659_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_666_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_663_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_660_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_658_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:10,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 436
2019-06-11 09:40:10,052  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:10,052  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 446 is 83 bytes
2019-06-11 09:40:10,053  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 447 is 160 bytes
2019-06-11 09:40:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 448 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1344 (print at Transform.scala:36)
2019-06-11 09:40:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1342, ShuffleMapStage 1343)
2019-06-11 09:40:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1344 (MapPartitionsRDD[1569] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:10,053  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_672 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:10,054  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_672_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:10,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_672_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:10,055  INFO [org.apache.spark.SparkContext] - Created broadcast 672 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:10,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1344 (MapPartitionsRDD[1569] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:10,055  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1344.0 with 1 tasks
2019-06-11 09:40:10,055  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1344.0 (TID 896, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:10,055  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1344.0 (TID 896)
2019-06-11 09:40:10,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:10,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:10,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:10,056  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:10,057  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1344.0 (TID 896). 966 bytes result sent to driver
2019-06-11 09:40:10,058  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1344.0 (TID 896) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:10,058  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1344.0, whose tasks have all completed, from pool 
2019-06-11 09:40:10,058  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1344 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:40:10,058  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 448 finished: print at Transform.scala:36, took 0.005735 s
2019-06-11 09:40:10,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217210000 ms.0 from job set of time 1560217210000 ms
2019-06-11 09:40:10,058  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.058 s for time 1560217210000 ms (execution: 0.051 s)
2019-06-11 09:40:10,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1562 from persistence list
2019-06-11 09:40:10,058  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1562
2019-06-11 09:40:10,058  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1557 from persistence list
2019-06-11 09:40:10,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1557
2019-06-11 09:40:10,059  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1556 from persistence list
2019-06-11 09:40:10,059  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1556
2019-06-11 09:40:10,059  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1556] at socketTextStream at Transform.scala:18 of time 1560217210000 ms
2019-06-11 09:40:10,059  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217200000 ms
2019-06-11 09:40:10,059  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217200000 ms
2019-06-11 09:40:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217215000 ms
2019-06-11 09:40:15,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217215000 ms.0 from job set of time 1560217215000 ms
2019-06-11 09:40:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1571 (map at Transform.scala:20)
2019-06-11 09:40:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 449 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1347 (print at Transform.scala:36)
2019-06-11 09:40:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1345, ShuffleMapStage 1346)
2019-06-11 09:40:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1346)
2019-06-11 09:40:15,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1346 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_673 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:15,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_673_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:15,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_673_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 673 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1346 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1346.0 with 2 tasks
2019-06-11 09:40:15,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1346.0 (TID 897, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:15,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1346.0 (TID 897)
2019-06-11 09:40:15,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1346.0 (TID 897). 810 bytes result sent to driver
2019-06-11 09:40:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1346.0 (TID 898, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:15,021  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1346.0 (TID 898)
2019-06-11 09:40:15,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1346.0 (TID 897) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:15,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1346.0 (TID 898). 767 bytes result sent to driver
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1346.0 (TID 898) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1346.0, whose tasks have all completed, from pool 
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1346 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1347)
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1347 (MapPartitionsRDD[1576] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:15,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_674 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:15,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_674_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:15,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_674_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:15,030  INFO [org.apache.spark.SparkContext] - Created broadcast 674 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:15,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1347 (MapPartitionsRDD[1576] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:15,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1347.0 with 1 tasks
2019-06-11 09:40:15,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1347.0 (TID 899, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:15,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1347.0 (TID 899)
2019-06-11 09:40:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:15,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:15,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1347.0 (TID 899). 1009 bytes result sent to driver
2019-06-11 09:40:15,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1347.0 (TID 899) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:15,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1347.0, whose tasks have all completed, from pool 
2019-06-11 09:40:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1347 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 449 finished: print at Transform.scala:36, took 0.024793 s
2019-06-11 09:40:15,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:15,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 448 is 83 bytes
2019-06-11 09:40:15,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 449 is 160 bytes
2019-06-11 09:40:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 450 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1350 (print at Transform.scala:36)
2019-06-11 09:40:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1348, ShuffleMapStage 1349)
2019-06-11 09:40:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:15,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1350 (MapPartitionsRDD[1576] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:15,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_675 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:15,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_675_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:15,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_675_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:15,038  INFO [org.apache.spark.SparkContext] - Created broadcast 675 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1350 (MapPartitionsRDD[1576] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:15,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1350.0 with 1 tasks
2019-06-11 09:40:15,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1350.0 (TID 900, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:15,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1350.0 (TID 900)
2019-06-11 09:40:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:15,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:15,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1350.0 (TID 900). 966 bytes result sent to driver
2019-06-11 09:40:15,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1350.0 (TID 900) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:15,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1350.0, whose tasks have all completed, from pool 
2019-06-11 09:40:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1350 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:15,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 450 finished: print at Transform.scala:36, took 0.004623 s
2019-06-11 09:40:15,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217215000 ms.0 from job set of time 1560217215000 ms
2019-06-11 09:40:15,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217215000 ms (execution: 0.034 s)
2019-06-11 09:40:15,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1569 from persistence list
2019-06-11 09:40:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1569
2019-06-11 09:40:15,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1564 from persistence list
2019-06-11 09:40:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1564
2019-06-11 09:40:15,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1563 from persistence list
2019-06-11 09:40:15,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1563
2019-06-11 09:40:15,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1563] at socketTextStream at Transform.scala:18 of time 1560217215000 ms
2019-06-11 09:40:15,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217205000 ms
2019-06-11 09:40:15,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217205000 ms
2019-06-11 09:40:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217220000 ms
2019-06-11 09:40:20,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217220000 ms.0 from job set of time 1560217220000 ms
2019-06-11 09:40:20,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:20,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1578 (map at Transform.scala:20)
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 451 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1353 (print at Transform.scala:36)
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1352, ShuffleMapStage 1351)
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1351)
2019-06-11 09:40:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1351 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:20,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_676 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_676_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:20,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_676_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:20,010  INFO [org.apache.spark.SparkContext] - Created broadcast 676 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1351 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1351.0 with 2 tasks
2019-06-11 09:40:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1351.0 (TID 901, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1351.0 (TID 901)
2019-06-11 09:40:20,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1351.0 (TID 901). 853 bytes result sent to driver
2019-06-11 09:40:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1351.0 (TID 902, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1351.0 (TID 902)
2019-06-11 09:40:20,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1351.0 (TID 901) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:20,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1351.0 (TID 902). 810 bytes result sent to driver
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1351.0 (TID 902) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1351.0, whose tasks have all completed, from pool 
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1351 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1353)
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1353 (MapPartitionsRDD[1583] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_677 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_677_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:20,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_677_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:20,030  INFO [org.apache.spark.SparkContext] - Created broadcast 677 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1353 (MapPartitionsRDD[1583] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1353.0 with 1 tasks
2019-06-11 09:40:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1353.0 (TID 903, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1353.0 (TID 903)
2019-06-11 09:40:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:20,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1353.0 (TID 903). 1009 bytes result sent to driver
2019-06-11 09:40:20,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1353.0 (TID 903) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1353.0, whose tasks have all completed, from pool 
2019-06-11 09:40:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1353 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 451 finished: print at Transform.scala:36, took 0.025217 s
2019-06-11 09:40:20,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:20,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 451 is 160 bytes
2019-06-11 09:40:20,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 450 is 83 bytes
2019-06-11 09:40:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 452 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1356 (print at Transform.scala:36)
2019-06-11 09:40:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1355, ShuffleMapStage 1354)
2019-06-11 09:40:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:20,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1356 (MapPartitionsRDD[1583] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:20,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_678 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:20,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_678_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:20,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_678_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:20,036  INFO [org.apache.spark.SparkContext] - Created broadcast 678 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:20,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1356 (MapPartitionsRDD[1583] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:20,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1356.0 with 1 tasks
2019-06-11 09:40:20,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1356.0 (TID 904, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:20,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1356.0 (TID 904)
2019-06-11 09:40:20,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:20,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:20,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:20,037  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:20,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1356.0 (TID 904). 966 bytes result sent to driver
2019-06-11 09:40:20,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1356.0 (TID 904) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1356.0, whose tasks have all completed, from pool 
2019-06-11 09:40:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1356 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:40:20,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 452 finished: print at Transform.scala:36, took 0.003959 s
2019-06-11 09:40:20,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217220000 ms.0 from job set of time 1560217220000 ms
2019-06-11 09:40:20,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217220000 ms (execution: 0.033 s)
2019-06-11 09:40:20,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1576 from persistence list
2019-06-11 09:40:20,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1576
2019-06-11 09:40:20,038  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1571 from persistence list
2019-06-11 09:40:20,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1571
2019-06-11 09:40:20,038  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1570 from persistence list
2019-06-11 09:40:20,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1570
2019-06-11 09:40:20,038  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1570] at socketTextStream at Transform.scala:18 of time 1560217220000 ms
2019-06-11 09:40:20,038  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217210000 ms
2019-06-11 09:40:20,038  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217210000 ms
2019-06-11 09:40:25,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217225000 ms
2019-06-11 09:40:25,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217225000 ms.0 from job set of time 1560217225000 ms
2019-06-11 09:40:25,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:25,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:25,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1585 (map at Transform.scala:20)
2019-06-11 09:40:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 453 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1359 (print at Transform.scala:36)
2019-06-11 09:40:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1358, ShuffleMapStage 1357)
2019-06-11 09:40:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1357)
2019-06-11 09:40:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1357 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:25,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_679 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_679_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:40:25,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_679_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:25,010  INFO [org.apache.spark.SparkContext] - Created broadcast 679 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:25,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1357 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:25,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1357.0 with 2 tasks
2019-06-11 09:40:25,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1357.0 (TID 905, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:25,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1357.0 (TID 905)
2019-06-11 09:40:25,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1357.0 (TID 905). 853 bytes result sent to driver
2019-06-11 09:40:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1357.0 (TID 906, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:25,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1357.0 (TID 906)
2019-06-11 09:40:25,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1357.0 (TID 905) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:25,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1357.0 (TID 906). 810 bytes result sent to driver
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1357.0 (TID 906) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1357.0, whose tasks have all completed, from pool 
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1357 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1359)
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:25,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1359 (MapPartitionsRDD[1590] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:25,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_680 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:25,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_680_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:25,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_680_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:25,029  INFO [org.apache.spark.SparkContext] - Created broadcast 680 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1359 (MapPartitionsRDD[1590] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:25,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1359.0 with 1 tasks
2019-06-11 09:40:25,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1359.0 (TID 907, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:25,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1359.0 (TID 907)
2019-06-11 09:40:25,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:25,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:25,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:25,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:25,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1359.0 (TID 907). 966 bytes result sent to driver
2019-06-11 09:40:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1359.0 (TID 907) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:25,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1359.0, whose tasks have all completed, from pool 
2019-06-11 09:40:25,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1359 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:25,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 453 finished: print at Transform.scala:36, took 0.023892 s
2019-06-11 09:40:25,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:25,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 453 is 160 bytes
2019-06-11 09:40:25,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 452 is 83 bytes
2019-06-11 09:40:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 454 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1362 (print at Transform.scala:36)
2019-06-11 09:40:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1360, ShuffleMapStage 1361)
2019-06-11 09:40:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:25,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1362 (MapPartitionsRDD[1590] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:25,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_681 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:25,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_681_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:25,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_681_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:25,036  INFO [org.apache.spark.SparkContext] - Created broadcast 681 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:25,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1362 (MapPartitionsRDD[1590] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:25,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1362.0 with 1 tasks
2019-06-11 09:40:25,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1362.0 (TID 908, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:25,037  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1362.0 (TID 908)
2019-06-11 09:40:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:25,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:25,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1362.0 (TID 908). 966 bytes result sent to driver
2019-06-11 09:40:25,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1362.0 (TID 908) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:25,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1362.0, whose tasks have all completed, from pool 
2019-06-11 09:40:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1362 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:40:25,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 454 finished: print at Transform.scala:36, took 0.006156 s
2019-06-11 09:40:25,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217225000 ms.0 from job set of time 1560217225000 ms
2019-06-11 09:40:25,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217225000 ms (execution: 0.035 s)
2019-06-11 09:40:25,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1583 from persistence list
2019-06-11 09:40:25,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1583
2019-06-11 09:40:25,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1578 from persistence list
2019-06-11 09:40:25,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1578
2019-06-11 09:40:25,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1577 from persistence list
2019-06-11 09:40:25,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1577
2019-06-11 09:40:25,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1577] at socketTextStream at Transform.scala:18 of time 1560217225000 ms
2019-06-11 09:40:25,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217215000 ms
2019-06-11 09:40:25,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217215000 ms
2019-06-11 09:40:30,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217230000 ms
2019-06-11 09:40:30,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217230000 ms.0 from job set of time 1560217230000 ms
2019-06-11 09:40:30,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1592 (map at Transform.scala:20)
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 455 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1365 (print at Transform.scala:36)
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1363, ShuffleMapStage 1364)
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1363)
2019-06-11 09:40:30,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1363 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:30,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_682 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_682_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:40:30,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_682_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,009  INFO [org.apache.spark.SparkContext] - Created broadcast 682 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:30,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1363 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:30,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1363.0 with 2 tasks
2019-06-11 09:40:30,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1363.0 (TID 909, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:30,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1363.0 (TID 909)
2019-06-11 09:40:30,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1363.0 (TID 909). 853 bytes result sent to driver
2019-06-11 09:40:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1363.0 (TID 910, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:30,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1363.0 (TID 910)
2019-06-11 09:40:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1363.0 (TID 909) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:30,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1363.0 (TID 910). 810 bytes result sent to driver
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1363.0 (TID 910) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1363.0, whose tasks have all completed, from pool 
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1363 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1365)
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:30,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1365 (MapPartitionsRDD[1597] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:30,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_683 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:30,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_683_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:30,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_683_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,032  INFO [org.apache.spark.SparkContext] - Created broadcast 683 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:30,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1365 (MapPartitionsRDD[1597] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:30,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1365.0 with 1 tasks
2019-06-11 09:40:30,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1365.0 (TID 911, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:30,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1365.0 (TID 911)
2019-06-11 09:40:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:30,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:30,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1365.0 (TID 911). 966 bytes result sent to driver
2019-06-11 09:40:30,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1365.0 (TID 911) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:30,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1365.0, whose tasks have all completed, from pool 
2019-06-11 09:40:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1365 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:30,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 455 finished: print at Transform.scala:36, took 0.027094 s
2019-06-11 09:40:30,040  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 445
2019-06-11 09:40:30,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_670_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_677_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_671_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:30,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_676_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,043  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 455 is 160 bytes
2019-06-11 09:40:30,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 454 is 83 bytes
2019-06-11 09:40:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 456 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1368 (print at Transform.scala:36)
2019-06-11 09:40:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1367, ShuffleMapStage 1366)
2019-06-11 09:40:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:30,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_675_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1368 (MapPartitionsRDD[1597] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:30,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_684 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:30,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_682_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,046  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_684_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:30,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 449
2019-06-11 09:40:30,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_684_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,047  INFO [org.apache.spark.SparkContext] - Created broadcast 684 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:30,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_683_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 447
2019-06-11 09:40:30,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1368 (MapPartitionsRDD[1597] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:30,047  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1368.0 with 1 tasks
2019-06-11 09:40:30,047  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1368.0 (TID 912, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:30,047  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1368.0 (TID 912)
2019-06-11 09:40:30,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_673_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_678_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 444
2019-06-11 09:40:30,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:30,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:30,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:30,049  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:30,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_679_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:30,050  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1368.0 (TID 912). 1009 bytes result sent to driver
2019-06-11 09:40:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_674_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1368.0 (TID 912) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:30,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1368.0, whose tasks have all completed, from pool 
2019-06-11 09:40:30,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 448
2019-06-11 09:40:30,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 451
2019-06-11 09:40:30,051  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1368 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:40:30,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 456 finished: print at Transform.scala:36, took 0.008566 s
2019-06-11 09:40:30,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217230000 ms.0 from job set of time 1560217230000 ms
2019-06-11 09:40:30,052  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.052 s for time 1560217230000 ms (execution: 0.047 s)
2019-06-11 09:40:30,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1590 from persistence list
2019-06-11 09:40:30,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_672_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1590
2019-06-11 09:40:30,052  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1585 from persistence list
2019-06-11 09:40:30,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 450
2019-06-11 09:40:30,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1585
2019-06-11 09:40:30,052  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1584 from persistence list
2019-06-11 09:40:30,052  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1584
2019-06-11 09:40:30,052  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1584] at socketTextStream at Transform.scala:18 of time 1560217230000 ms
2019-06-11 09:40:30,052  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217220000 ms
2019-06-11 09:40:30,052  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217220000 ms
2019-06-11 09:40:30,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_681_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:30,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 446
2019-06-11 09:40:30,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_680_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217235000 ms
2019-06-11 09:40:35,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217235000 ms.0 from job set of time 1560217235000 ms
2019-06-11 09:40:35,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1599 (map at Transform.scala:20)
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 457 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1371 (print at Transform.scala:36)
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1370, ShuffleMapStage 1369)
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1369)
2019-06-11 09:40:35,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1369 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:35,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_685 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:35,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_685_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:35,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_685_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:35,010  INFO [org.apache.spark.SparkContext] - Created broadcast 685 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1369 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:35,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1369.0 with 2 tasks
2019-06-11 09:40:35,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1369.0 (TID 913, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:35,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1369.0 (TID 913)
2019-06-11 09:40:35,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1369.0 (TID 913). 853 bytes result sent to driver
2019-06-11 09:40:35,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1369.0 (TID 914, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:35,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1369.0 (TID 914)
2019-06-11 09:40:35,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1369.0 (TID 913) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:35,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1369.0 (TID 914). 767 bytes result sent to driver
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1369.0 (TID 914) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1369.0, whose tasks have all completed, from pool 
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1369 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1371)
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:35,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1371 (MapPartitionsRDD[1604] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:35,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_686 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:35,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_686_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:35,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_686_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:35,030  INFO [org.apache.spark.SparkContext] - Created broadcast 686 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:35,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1371 (MapPartitionsRDD[1604] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:35,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1371.0 with 1 tasks
2019-06-11 09:40:35,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1371.0 (TID 915, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:35,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1371.0 (TID 915)
2019-06-11 09:40:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:35,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:35,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1371.0 (TID 915). 966 bytes result sent to driver
2019-06-11 09:40:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1371.0 (TID 915) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1371.0, whose tasks have all completed, from pool 
2019-06-11 09:40:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1371 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:35,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 457 finished: print at Transform.scala:36, took 0.025694 s
2019-06-11 09:40:35,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:35,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 457 is 160 bytes
2019-06-11 09:40:35,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 456 is 83 bytes
2019-06-11 09:40:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 458 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1374 (print at Transform.scala:36)
2019-06-11 09:40:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1373, ShuffleMapStage 1372)
2019-06-11 09:40:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1374 (MapPartitionsRDD[1604] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:35,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_687 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:35,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_687_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:35,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_687_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:35,037  INFO [org.apache.spark.SparkContext] - Created broadcast 687 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:35,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1374 (MapPartitionsRDD[1604] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:35,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1374.0 with 1 tasks
2019-06-11 09:40:35,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1374.0 (TID 916, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:35,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1374.0 (TID 916)
2019-06-11 09:40:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:35,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:35,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1374.0 (TID 916). 1009 bytes result sent to driver
2019-06-11 09:40:35,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1374.0 (TID 916) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:35,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1374.0, whose tasks have all completed, from pool 
2019-06-11 09:40:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1374 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:35,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 458 finished: print at Transform.scala:36, took 0.005450 s
2019-06-11 09:40:35,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217235000 ms.0 from job set of time 1560217235000 ms
2019-06-11 09:40:35,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217235000 ms (execution: 0.036 s)
2019-06-11 09:40:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1597 from persistence list
2019-06-11 09:40:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1597
2019-06-11 09:40:35,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1592 from persistence list
2019-06-11 09:40:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1592
2019-06-11 09:40:35,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1591 from persistence list
2019-06-11 09:40:35,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1591
2019-06-11 09:40:35,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1591] at socketTextStream at Transform.scala:18 of time 1560217235000 ms
2019-06-11 09:40:35,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217225000 ms
2019-06-11 09:40:35,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217225000 ms
2019-06-11 09:40:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217240000 ms
2019-06-11 09:40:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217240000 ms.0 from job set of time 1560217240000 ms
2019-06-11 09:40:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1606 (map at Transform.scala:20)
2019-06-11 09:40:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 459 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1377 (print at Transform.scala:36)
2019-06-11 09:40:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1376, ShuffleMapStage 1375)
2019-06-11 09:40:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1376)
2019-06-11 09:40:40,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1376 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_688 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_688_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_688_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 688 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:40,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1376 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:40,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1376.0 with 2 tasks
2019-06-11 09:40:40,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1376.0 (TID 917, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1376.0 (TID 917)
2019-06-11 09:40:40,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1376.0 (TID 917). 810 bytes result sent to driver
2019-06-11 09:40:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1376.0 (TID 918, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1376.0 (TID 918)
2019-06-11 09:40:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1376.0 (TID 917) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:40,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1376.0 (TID 918). 810 bytes result sent to driver
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1376.0 (TID 918) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1376.0, whose tasks have all completed, from pool 
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1376 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1377)
2019-06-11 09:40:40,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1377 (MapPartitionsRDD[1611] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_689 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:40,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_689_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:40,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_689_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:40,030  INFO [org.apache.spark.SparkContext] - Created broadcast 689 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1377 (MapPartitionsRDD[1611] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1377.0 with 1 tasks
2019-06-11 09:40:40,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1377.0 (TID 919, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:40,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1377.0 (TID 919)
2019-06-11 09:40:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:40,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1377.0 (TID 919). 966 bytes result sent to driver
2019-06-11 09:40:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1377.0 (TID 919) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1377.0, whose tasks have all completed, from pool 
2019-06-11 09:40:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1377 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:40,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 459 finished: print at Transform.scala:36, took 0.024096 s
2019-06-11 09:40:40,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 458 is 83 bytes
2019-06-11 09:40:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 459 is 160 bytes
2019-06-11 09:40:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 460 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1380 (print at Transform.scala:36)
2019-06-11 09:40:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1378, ShuffleMapStage 1379)
2019-06-11 09:40:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1380 (MapPartitionsRDD[1611] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_690 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_690_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:40,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_690_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:40,037  INFO [org.apache.spark.SparkContext] - Created broadcast 690 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1380 (MapPartitionsRDD[1611] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1380.0 with 1 tasks
2019-06-11 09:40:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1380.0 (TID 920, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1380.0 (TID 920)
2019-06-11 09:40:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:40,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1380.0 (TID 920). 1009 bytes result sent to driver
2019-06-11 09:40:40,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1380.0 (TID 920) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1380.0, whose tasks have all completed, from pool 
2019-06-11 09:40:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1380 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 460 finished: print at Transform.scala:36, took 0.005659 s
2019-06-11 09:40:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217240000 ms.0 from job set of time 1560217240000 ms
2019-06-11 09:40:40,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217240000 ms (execution: 0.034 s)
2019-06-11 09:40:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1604 from persistence list
2019-06-11 09:40:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1604
2019-06-11 09:40:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1599 from persistence list
2019-06-11 09:40:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1599
2019-06-11 09:40:40,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1598 from persistence list
2019-06-11 09:40:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1598
2019-06-11 09:40:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1598] at socketTextStream at Transform.scala:18 of time 1560217240000 ms
2019-06-11 09:40:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217230000 ms
2019-06-11 09:40:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217230000 ms
2019-06-11 09:40:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217245000 ms
2019-06-11 09:40:45,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217245000 ms.0 from job set of time 1560217245000 ms
2019-06-11 09:40:45,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1613 (map at Transform.scala:20)
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 461 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1383 (print at Transform.scala:36)
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1381, ShuffleMapStage 1382)
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1381)
2019-06-11 09:40:45,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1381 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:45,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_691 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:45,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_691_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:45,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_691_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:45,009  INFO [org.apache.spark.SparkContext] - Created broadcast 691 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1381 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:45,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1381.0 with 2 tasks
2019-06-11 09:40:45,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1381.0 (TID 921, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:45,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1381.0 (TID 921)
2019-06-11 09:40:45,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1381.0 (TID 921). 810 bytes result sent to driver
2019-06-11 09:40:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1381.0 (TID 922, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:45,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1381.0 (TID 922)
2019-06-11 09:40:45,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1381.0 (TID 921) in 11 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:45,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1381.0 (TID 922). 810 bytes result sent to driver
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1381.0 (TID 922) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1381.0, whose tasks have all completed, from pool 
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1381 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1383)
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:45,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1383 (MapPartitionsRDD[1618] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:45,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_692 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:45,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_692_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:45,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_692_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:45,031  INFO [org.apache.spark.SparkContext] - Created broadcast 692 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:45,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1383 (MapPartitionsRDD[1618] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:45,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1383.0 with 1 tasks
2019-06-11 09:40:45,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1383.0 (TID 923, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:45,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1383.0 (TID 923)
2019-06-11 09:40:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:45,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:45,034  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1383.0 (TID 923). 1009 bytes result sent to driver
2019-06-11 09:40:45,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1383.0 (TID 923) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:45,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1383.0, whose tasks have all completed, from pool 
2019-06-11 09:40:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1383 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:40:45,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 461 finished: print at Transform.scala:36, took 0.027305 s
2019-06-11 09:40:45,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:45,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 461 is 160 bytes
2019-06-11 09:40:45,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 460 is 83 bytes
2019-06-11 09:40:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 462 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1386 (print at Transform.scala:36)
2019-06-11 09:40:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1385, ShuffleMapStage 1384)
2019-06-11 09:40:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:45,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1386 (MapPartitionsRDD[1618] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:45,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_693 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:45,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_693_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:45,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_693_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:45,039  INFO [org.apache.spark.SparkContext] - Created broadcast 693 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:45,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1386 (MapPartitionsRDD[1618] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:45,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1386.0 with 1 tasks
2019-06-11 09:40:45,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1386.0 (TID 924, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:45,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1386.0 (TID 924)
2019-06-11 09:40:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:45,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:45,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1386.0 (TID 924). 1009 bytes result sent to driver
2019-06-11 09:40:45,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1386.0 (TID 924) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:45,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1386.0, whose tasks have all completed, from pool 
2019-06-11 09:40:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1386 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:45,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 462 finished: print at Transform.scala:36, took 0.004834 s
2019-06-11 09:40:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217245000 ms.0 from job set of time 1560217245000 ms
2019-06-11 09:40:45,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217245000 ms (execution: 0.037 s)
2019-06-11 09:40:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1611 from persistence list
2019-06-11 09:40:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1611
2019-06-11 09:40:45,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1606 from persistence list
2019-06-11 09:40:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1606
2019-06-11 09:40:45,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1605 from persistence list
2019-06-11 09:40:45,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1605
2019-06-11 09:40:45,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1605] at socketTextStream at Transform.scala:18 of time 1560217245000 ms
2019-06-11 09:40:45,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217235000 ms
2019-06-11 09:40:45,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217235000 ms
2019-06-11 09:40:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217250000 ms
2019-06-11 09:40:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217250000 ms.0 from job set of time 1560217250000 ms
2019-06-11 09:40:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1620 (map at Transform.scala:20)
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 463 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1389 (print at Transform.scala:36)
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1388, ShuffleMapStage 1387)
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1388)
2019-06-11 09:40:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1388 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_694 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_694_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:40:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_694_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:50,010  INFO [org.apache.spark.SparkContext] - Created broadcast 694 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1388 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:50,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1388.0 with 2 tasks
2019-06-11 09:40:50,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1388.0 (TID 925, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:50,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1388.0 (TID 925)
2019-06-11 09:40:50,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1388.0 (TID 925). 853 bytes result sent to driver
2019-06-11 09:40:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1388.0 (TID 926, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:50,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1388.0 (TID 926)
2019-06-11 09:40:50,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1388.0 (TID 925) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:50,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1388.0 (TID 926). 767 bytes result sent to driver
2019-06-11 09:40:50,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1388.0 (TID 926) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1388.0, whose tasks have all completed, from pool 
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1388 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1389)
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:50,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1389 (MapPartitionsRDD[1625] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:50,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_695 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:50,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_695_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:50,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_695_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,031  INFO [org.apache.spark.SparkContext] - Created broadcast 695 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:50,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1389 (MapPartitionsRDD[1625] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:50,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1389.0 with 1 tasks
2019-06-11 09:40:50,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1389.0 (TID 927, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:50,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1389.0 (TID 927)
2019-06-11 09:40:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:50,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:50,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1389.0 (TID 927). 1009 bytes result sent to driver
2019-06-11 09:40:50,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1389.0 (TID 927) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:50,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1389.0, whose tasks have all completed, from pool 
2019-06-11 09:40:50,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1389 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:50,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 463 finished: print at Transform.scala:36, took 0.025117 s
2019-06-11 09:40:50,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 462 is 83 bytes
2019-06-11 09:40:50,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 463 is 160 bytes
2019-06-11 09:40:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 464 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1392 (print at Transform.scala:36)
2019-06-11 09:40:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1391, ShuffleMapStage 1390)
2019-06-11 09:40:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1392 (MapPartitionsRDD[1625] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:50,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_696 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:40:50,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_696_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:40:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_688_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_696_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,044  INFO [org.apache.spark.SparkContext] - Created broadcast 696 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:50,045  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1392 (MapPartitionsRDD[1625] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:50,045  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1392.0 with 1 tasks
2019-06-11 09:40:50,045  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1392.0 (TID 928, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:50,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_695_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1392.0 (TID 928)
2019-06-11 09:40:50,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_687_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:50,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:40:50,047  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 459
2019-06-11 09:40:50,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:50,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:50,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_684_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,048  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 456
2019-06-11 09:40:50,048  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1392.0 (TID 928). 1052 bytes result sent to driver
2019-06-11 09:40:50,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1392.0 (TID 928) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:50,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1392.0, whose tasks have all completed, from pool 
2019-06-11 09:40:50,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_691_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:50,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1392 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:40:50,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 455
2019-06-11 09:40:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 464 finished: print at Transform.scala:36, took 0.013121 s
2019-06-11 09:40:50,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217250000 ms.0 from job set of time 1560217250000 ms
2019-06-11 09:40:50,049  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.049 s for time 1560217250000 ms (execution: 0.044 s)
2019-06-11 09:40:50,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1618 from persistence list
2019-06-11 09:40:50,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_685_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:50,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1618
2019-06-11 09:40:50,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1613 from persistence list
2019-06-11 09:40:50,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1613
2019-06-11 09:40:50,050  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1612 from persistence list
2019-06-11 09:40:50,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1612] at socketTextStream at Transform.scala:18 of time 1560217250000 ms
2019-06-11 09:40:50,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 457
2019-06-11 09:40:50,050  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1612
2019-06-11 09:40:50,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217240000 ms
2019-06-11 09:40:50,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 458
2019-06-11 09:40:50,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217240000 ms
2019-06-11 09:40:50,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_689_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_693_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 452
2019-06-11 09:40:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_686_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 454
2019-06-11 09:40:50,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_690_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:50,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_694_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:50,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 453
2019-06-11 09:40:50,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_692_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217255000 ms
2019-06-11 09:40:55,011  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217255000 ms.0 from job set of time 1560217255000 ms
2019-06-11 09:40:55,013  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1627 (map at Transform.scala:20)
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 465 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1395 (print at Transform.scala:36)
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1393, ShuffleMapStage 1394)
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1394)
2019-06-11 09:40:55,013  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1394 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:40:55,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_697 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:55,014  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_697_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:40:55,015  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_697_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:40:55,015  INFO [org.apache.spark.SparkContext] - Created broadcast 697 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:55,015  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1394 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:40:55,015  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1394.0 with 2 tasks
2019-06-11 09:40:55,015  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1394.0 (TID 929, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:55,015  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1394.0 (TID 929)
2019-06-11 09:40:55,027  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1394.0 (TID 929). 810 bytes result sent to driver
2019-06-11 09:40:55,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1394.0 (TID 930, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:40:55,027  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1394.0 (TID 930)
2019-06-11 09:40:55,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1394.0 (TID 929) in 12 ms on localhost (executor driver) (1/2)
2019-06-11 09:40:55,035  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1394.0 (TID 930). 810 bytes result sent to driver
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1394.0 (TID 930) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1394.0, whose tasks have all completed, from pool 
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1394 (parallelize at Transform.scala:16) finished in 0.021 s
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1395)
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:40:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1395 (MapPartitionsRDD[1632] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:55,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_698 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_698_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:55,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_698_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:55,038  INFO [org.apache.spark.SparkContext] - Created broadcast 698 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:55,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1395 (MapPartitionsRDD[1632] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:40:55,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1395.0 with 1 tasks
2019-06-11 09:40:55,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1395.0 (TID 931, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:55,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1395.0 (TID 931)
2019-06-11 09:40:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:55,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1395.0 (TID 931). 966 bytes result sent to driver
2019-06-11 09:40:55,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1395.0 (TID 931) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:55,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1395.0, whose tasks have all completed, from pool 
2019-06-11 09:40:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1395 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 465 finished: print at Transform.scala:36, took 0.028381 s
2019-06-11 09:40:55,043  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:40:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 464 is 83 bytes
2019-06-11 09:40:55,044  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 465 is 160 bytes
2019-06-11 09:40:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 466 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:40:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1398 (print at Transform.scala:36)
2019-06-11 09:40:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1396, ShuffleMapStage 1397)
2019-06-11 09:40:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:40:55,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1398 (MapPartitionsRDD[1632] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:40:55,044  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_699 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:40:55,045  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_699_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:40:55,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_699_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:40:55,046  INFO [org.apache.spark.SparkContext] - Created broadcast 699 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:40:55,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1398 (MapPartitionsRDD[1632] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:40:55,046  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1398.0 with 1 tasks
2019-06-11 09:40:55,046  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1398.0 (TID 932, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:40:55,046  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1398.0 (TID 932)
2019-06-11 09:40:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:40:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:40:55,047  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:40:55,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1398.0 (TID 932). 966 bytes result sent to driver
2019-06-11 09:40:55,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1398.0 (TID 932) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:40:55,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1398.0, whose tasks have all completed, from pool 
2019-06-11 09:40:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1398 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:40:55,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 466 finished: print at Transform.scala:36, took 0.004766 s
2019-06-11 09:40:55,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217255000 ms.0 from job set of time 1560217255000 ms
2019-06-11 09:40:55,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560217255000 ms (execution: 0.037 s)
2019-06-11 09:40:55,048  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1625 from persistence list
2019-06-11 09:40:55,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1625
2019-06-11 09:40:55,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1620 from persistence list
2019-06-11 09:40:55,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1620
2019-06-11 09:40:55,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1619 from persistence list
2019-06-11 09:40:55,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1619
2019-06-11 09:40:55,049  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1619] at socketTextStream at Transform.scala:18 of time 1560217255000 ms
2019-06-11 09:40:55,049  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217245000 ms
2019-06-11 09:40:55,049  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217245000 ms
2019-06-11 09:41:00,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217260000 ms
2019-06-11 09:41:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217260000 ms.0 from job set of time 1560217260000 ms
2019-06-11 09:41:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1634 (map at Transform.scala:20)
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 467 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1401 (print at Transform.scala:36)
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1399, ShuffleMapStage 1400)
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1399)
2019-06-11 09:41:00,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1399 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:00,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_700 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_700_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:00,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_700_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:00,011  INFO [org.apache.spark.SparkContext] - Created broadcast 700 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:00,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1399 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:00,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1399.0 with 2 tasks
2019-06-11 09:41:00,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1399.0 (TID 933, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:00,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1399.0 (TID 933)
2019-06-11 09:41:00,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1399.0 (TID 933). 853 bytes result sent to driver
2019-06-11 09:41:00,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1399.0 (TID 934, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:00,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1399.0 (TID 934)
2019-06-11 09:41:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1399.0 (TID 933) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:00,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1399.0 (TID 934). 767 bytes result sent to driver
2019-06-11 09:41:00,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1399.0 (TID 934) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1399.0, whose tasks have all completed, from pool 
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1399 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1401)
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1401 (MapPartitionsRDD[1639] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:00,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_701 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_701_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:00,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_701_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:00,031  INFO [org.apache.spark.SparkContext] - Created broadcast 701 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:00,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1401 (MapPartitionsRDD[1639] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:00,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1401.0 with 1 tasks
2019-06-11 09:41:00,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1401.0 (TID 935, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:00,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1401.0 (TID 935)
2019-06-11 09:41:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:00,033  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1401.0 (TID 935). 966 bytes result sent to driver
2019-06-11 09:41:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1401.0 (TID 935) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1401.0, whose tasks have all completed, from pool 
2019-06-11 09:41:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1401 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:41:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 467 finished: print at Transform.scala:36, took 0.024127 s
2019-06-11 09:41:00,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:00,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 467 is 160 bytes
2019-06-11 09:41:00,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 466 is 83 bytes
2019-06-11 09:41:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 468 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1404 (print at Transform.scala:36)
2019-06-11 09:41:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1403, ShuffleMapStage 1402)
2019-06-11 09:41:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:00,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1404 (MapPartitionsRDD[1639] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:00,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_702 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:00,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_702_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:00,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_702_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:00,038  INFO [org.apache.spark.SparkContext] - Created broadcast 702 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:00,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1404 (MapPartitionsRDD[1639] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:00,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1404.0 with 1 tasks
2019-06-11 09:41:00,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1404.0 (TID 936, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:00,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1404.0 (TID 936)
2019-06-11 09:41:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:00,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:00,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1404.0 (TID 936). 1009 bytes result sent to driver
2019-06-11 09:41:00,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1404.0 (TID 936) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:00,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1404.0, whose tasks have all completed, from pool 
2019-06-11 09:41:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1404 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 468 finished: print at Transform.scala:36, took 0.005141 s
2019-06-11 09:41:00,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217260000 ms.0 from job set of time 1560217260000 ms
2019-06-11 09:41:00,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217260000 ms (execution: 0.035 s)
2019-06-11 09:41:00,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1632 from persistence list
2019-06-11 09:41:00,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1632
2019-06-11 09:41:00,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1627 from persistence list
2019-06-11 09:41:00,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1627
2019-06-11 09:41:00,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1626 from persistence list
2019-06-11 09:41:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1626
2019-06-11 09:41:00,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1626] at socketTextStream at Transform.scala:18 of time 1560217260000 ms
2019-06-11 09:41:00,042  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217250000 ms
2019-06-11 09:41:00,042  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217250000 ms
2019-06-11 09:41:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217265000 ms
2019-06-11 09:41:05,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217265000 ms.0 from job set of time 1560217265000 ms
2019-06-11 09:41:05,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1641 (map at Transform.scala:20)
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 469 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1407 (print at Transform.scala:36)
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1406, ShuffleMapStage 1405)
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1405)
2019-06-11 09:41:05,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1405 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_703 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:05,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_703_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:05,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_703_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:05,010  INFO [org.apache.spark.SparkContext] - Created broadcast 703 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:05,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1405 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:05,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1405.0 with 2 tasks
2019-06-11 09:41:05,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1405.0 (TID 937, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:05,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1405.0 (TID 937)
2019-06-11 09:41:05,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1405.0 (TID 937). 853 bytes result sent to driver
2019-06-11 09:41:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1405.0 (TID 938, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:05,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1405.0 (TID 938)
2019-06-11 09:41:05,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1405.0 (TID 937) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:05,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1405.0 (TID 938). 810 bytes result sent to driver
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1405.0 (TID 938) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1405.0, whose tasks have all completed, from pool 
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1405 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1407)
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1407 (MapPartitionsRDD[1646] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_704 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:05,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_704_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:05,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_704_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:05,030  INFO [org.apache.spark.SparkContext] - Created broadcast 704 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:05,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1407 (MapPartitionsRDD[1646] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:05,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1407.0 with 1 tasks
2019-06-11 09:41:05,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1407.0 (TID 939, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:05,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1407.0 (TID 939)
2019-06-11 09:41:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:05,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:05,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1407.0 (TID 939). 1009 bytes result sent to driver
2019-06-11 09:41:05,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1407.0 (TID 939) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:05,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1407.0, whose tasks have all completed, from pool 
2019-06-11 09:41:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1407 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:05,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 469 finished: print at Transform.scala:36, took 0.023874 s
2019-06-11 09:41:05,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:05,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 469 is 160 bytes
2019-06-11 09:41:05,034  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 468 is 83 bytes
2019-06-11 09:41:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 470 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1410 (print at Transform.scala:36)
2019-06-11 09:41:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1409, ShuffleMapStage 1408)
2019-06-11 09:41:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1410 (MapPartitionsRDD[1646] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_705 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:05,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_705_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:05,036  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_705_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:05,036  INFO [org.apache.spark.SparkContext] - Created broadcast 705 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1410 (MapPartitionsRDD[1646] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1410.0 with 1 tasks
2019-06-11 09:41:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1410.0 (TID 940, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:05,036  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1410.0 (TID 940)
2019-06-11 09:41:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:05,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:05,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1410.0 (TID 940). 966 bytes result sent to driver
2019-06-11 09:41:05,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1410.0 (TID 940) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:05,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1410.0, whose tasks have all completed, from pool 
2019-06-11 09:41:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1410 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:05,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 470 finished: print at Transform.scala:36, took 0.005582 s
2019-06-11 09:41:05,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217265000 ms.0 from job set of time 1560217265000 ms
2019-06-11 09:41:05,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.039 s for time 1560217265000 ms (execution: 0.033 s)
2019-06-11 09:41:05,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1639 from persistence list
2019-06-11 09:41:05,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1639
2019-06-11 09:41:05,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1634 from persistence list
2019-06-11 09:41:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1634
2019-06-11 09:41:05,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1633 from persistence list
2019-06-11 09:41:05,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1633
2019-06-11 09:41:05,040  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1633] at socketTextStream at Transform.scala:18 of time 1560217265000 ms
2019-06-11 09:41:05,040  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217255000 ms
2019-06-11 09:41:05,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217255000 ms
2019-06-11 09:41:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217270000 ms
2019-06-11 09:41:10,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217270000 ms.0 from job set of time 1560217270000 ms
2019-06-11 09:41:10,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:10,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1648 (map at Transform.scala:20)
2019-06-11 09:41:10,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:10,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 471 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:10,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1413 (print at Transform.scala:36)
2019-06-11 09:41:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1411, ShuffleMapStage 1412)
2019-06-11 09:41:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1412)
2019-06-11 09:41:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1412 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:10,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_706 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:10,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_706_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:41:10,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_706_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:10,009  INFO [org.apache.spark.SparkContext] - Created broadcast 706 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:10,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1412 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:10,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1412.0 with 2 tasks
2019-06-11 09:41:10,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1412.0 (TID 941, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:10,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1412.0 (TID 941)
2019-06-11 09:41:10,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1412.0 (TID 941). 810 bytes result sent to driver
2019-06-11 09:41:10,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1412.0 (TID 942, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:10,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1412.0 (TID 942)
2019-06-11 09:41:10,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1412.0 (TID 941) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:10,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1412.0 (TID 942). 767 bytes result sent to driver
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1412.0 (TID 942) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1412.0, whose tasks have all completed, from pool 
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1412 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1413)
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:10,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1413 (MapPartitionsRDD[1653] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:10,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_707 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:10,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_707_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:10,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_707_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,030  INFO [org.apache.spark.SparkContext] - Created broadcast 707 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:10,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1413 (MapPartitionsRDD[1653] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:10,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1413.0 with 1 tasks
2019-06-11 09:41:10,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1413.0 (TID 943, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:10,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1413.0 (TID 943)
2019-06-11 09:41:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:10,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:10,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1413.0 (TID 943). 966 bytes result sent to driver
2019-06-11 09:41:10,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1413.0 (TID 943) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1413.0, whose tasks have all completed, from pool 
2019-06-11 09:41:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1413 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 471 finished: print at Transform.scala:36, took 0.026486 s
2019-06-11 09:41:10,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:10,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 470 is 83 bytes
2019-06-11 09:41:10,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 471 is 160 bytes
2019-06-11 09:41:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 472 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1416 (print at Transform.scala:36)
2019-06-11 09:41:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1414, ShuffleMapStage 1415)
2019-06-11 09:41:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:10,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1416 (MapPartitionsRDD[1653] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:10,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_708 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:10,043  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_708_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_708_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_698_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,044  INFO [org.apache.spark.SparkContext] - Created broadcast 708 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:10,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1416 (MapPartitionsRDD[1653] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:10,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1416.0 with 1 tasks
2019-06-11 09:41:10,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1416.0 (TID 944, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:10,045  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1416.0 (TID 944)
2019-06-11 09:41:10,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_700_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:10,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_706_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:10,046  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:10,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 467
2019-06-11 09:41:10,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 464
2019-06-11 09:41:10,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_696_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,047  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1416.0 (TID 944). 1052 bytes result sent to driver
2019-06-11 09:41:10,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1416.0 (TID 944) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:10,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1416.0, whose tasks have all completed, from pool 
2019-06-11 09:41:10,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1416 (print at Transform.scala:36) finished in 0.004 s
2019-06-11 09:41:10,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_703_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:10,048  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 472 finished: print at Transform.scala:36, took 0.012207 s
2019-06-11 09:41:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217270000 ms.0 from job set of time 1560217270000 ms
2019-06-11 09:41:10,048  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.048 s for time 1560217270000 ms (execution: 0.043 s)
2019-06-11 09:41:10,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1646 from persistence list
2019-06-11 09:41:10,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 460
2019-06-11 09:41:10,049  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1641 from persistence list
2019-06-11 09:41:10,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1646
2019-06-11 09:41:10,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1641
2019-06-11 09:41:10,049  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1640 from persistence list
2019-06-11 09:41:10,049  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1640
2019-06-11 09:41:10,050  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1640] at socketTextStream at Transform.scala:18 of time 1560217270000 ms
2019-06-11 09:41:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_707_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,050  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217260000 ms
2019-06-11 09:41:10,050  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217260000 ms
2019-06-11 09:41:10,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 466
2019-06-11 09:41:10,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_705_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_704_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_699_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 462
2019-06-11 09:41:10,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 461
2019-06-11 09:41:10,052  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 463
2019-06-11 09:41:10,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_701_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 465
2019-06-11 09:41:10,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_702_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:10,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_697_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217275000 ms
2019-06-11 09:41:15,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217275000 ms.0 from job set of time 1560217275000 ms
2019-06-11 09:41:15,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1655 (map at Transform.scala:20)
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 473 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1419 (print at Transform.scala:36)
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1417, ShuffleMapStage 1418)
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1418)
2019-06-11 09:41:15,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1418 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:15,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_709 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:15,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_709_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:15,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_709_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:15,010  INFO [org.apache.spark.SparkContext] - Created broadcast 709 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:15,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1418 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:15,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1418.0 with 2 tasks
2019-06-11 09:41:15,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1418.0 (TID 945, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:15,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1418.0 (TID 945)
2019-06-11 09:41:15,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1418.0 (TID 945). 810 bytes result sent to driver
2019-06-11 09:41:15,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1418.0 (TID 946, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:15,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1418.0 (TID 946)
2019-06-11 09:41:15,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1418.0 (TID 945) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:15,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1418.0 (TID 946). 810 bytes result sent to driver
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1418.0 (TID 946) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1418.0, whose tasks have all completed, from pool 
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1418 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1419)
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:15,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1419 (MapPartitionsRDD[1660] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:15,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_710 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:15,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_710_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:15,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_710_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:15,029  INFO [org.apache.spark.SparkContext] - Created broadcast 710 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:15,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1419 (MapPartitionsRDD[1660] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:15,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1419.0 with 1 tasks
2019-06-11 09:41:15,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1419.0 (TID 947, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:15,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1419.0 (TID 947)
2019-06-11 09:41:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:15,030  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:15,031  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1419.0 (TID 947). 1052 bytes result sent to driver
2019-06-11 09:41:15,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1419.0 (TID 947) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:15,031  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1419.0, whose tasks have all completed, from pool 
2019-06-11 09:41:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1419 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:15,031  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 473 finished: print at Transform.scala:36, took 0.023413 s
2019-06-11 09:41:15,033  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:15,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 472 is 83 bytes
2019-06-11 09:41:15,033  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 473 is 160 bytes
2019-06-11 09:41:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 474 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1422 (print at Transform.scala:36)
2019-06-11 09:41:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1421, ShuffleMapStage 1420)
2019-06-11 09:41:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:15,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1422 (MapPartitionsRDD[1660] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:15,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_711 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:15,035  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_711_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:15,035  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_711_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:15,035  INFO [org.apache.spark.SparkContext] - Created broadcast 711 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:15,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1422 (MapPartitionsRDD[1660] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:15,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1422.0 with 1 tasks
2019-06-11 09:41:15,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1422.0 (TID 948, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:15,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1422.0 (TID 948)
2019-06-11 09:41:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:15,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:15,038  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1422.0 (TID 948). 1009 bytes result sent to driver
2019-06-11 09:41:15,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1422.0 (TID 948) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:15,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1422.0, whose tasks have all completed, from pool 
2019-06-11 09:41:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1422 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:15,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 474 finished: print at Transform.scala:36, took 0.005258 s
2019-06-11 09:41:15,038  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217275000 ms.0 from job set of time 1560217275000 ms
2019-06-11 09:41:15,039  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.038 s for time 1560217275000 ms (execution: 0.033 s)
2019-06-11 09:41:15,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1653 from persistence list
2019-06-11 09:41:15,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1653
2019-06-11 09:41:15,039  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1648 from persistence list
2019-06-11 09:41:15,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1648
2019-06-11 09:41:15,039  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1647 from persistence list
2019-06-11 09:41:15,039  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1647
2019-06-11 09:41:15,039  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1647] at socketTextStream at Transform.scala:18 of time 1560217275000 ms
2019-06-11 09:41:15,039  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217265000 ms
2019-06-11 09:41:15,040  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217265000 ms
2019-06-11 09:41:20,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217280000 ms
2019-06-11 09:41:20,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217280000 ms.0 from job set of time 1560217280000 ms
2019-06-11 09:41:20,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1662 (map at Transform.scala:20)
2019-06-11 09:41:20,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 475 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1425 (print at Transform.scala:36)
2019-06-11 09:41:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1424, ShuffleMapStage 1423)
2019-06-11 09:41:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1424)
2019-06-11 09:41:20,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1424 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:20,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_712 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:20,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_712_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:20,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_712_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:20,010  INFO [org.apache.spark.SparkContext] - Created broadcast 712 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:20,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1424 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:20,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1424.0 with 2 tasks
2019-06-11 09:41:20,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1424.0 (TID 949, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:20,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1424.0 (TID 949)
2019-06-11 09:41:20,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1424.0 (TID 949). 810 bytes result sent to driver
2019-06-11 09:41:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1424.0 (TID 950, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:20,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1424.0 (TID 950)
2019-06-11 09:41:20,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1424.0 (TID 949) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:20,027  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1424.0 (TID 950). 810 bytes result sent to driver
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1424.0 (TID 950) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1424.0, whose tasks have all completed, from pool 
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1424 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1425)
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:20,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1425 (MapPartitionsRDD[1667] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:20,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_713 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:20,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_713_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:20,029  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_713_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:20,030  INFO [org.apache.spark.SparkContext] - Created broadcast 713 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:20,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1425 (MapPartitionsRDD[1667] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:20,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1425.0 with 1 tasks
2019-06-11 09:41:20,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1425.0 (TID 951, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:20,030  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1425.0 (TID 951)
2019-06-11 09:41:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:20,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:20,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1425.0 (TID 951). 1009 bytes result sent to driver
2019-06-11 09:41:20,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1425.0 (TID 951) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:20,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1425.0, whose tasks have all completed, from pool 
2019-06-11 09:41:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1425 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:20,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 475 finished: print at Transform.scala:36, took 0.025790 s
2019-06-11 09:41:20,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 474 is 83 bytes
2019-06-11 09:41:20,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 475 is 160 bytes
2019-06-11 09:41:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 476 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1428 (print at Transform.scala:36)
2019-06-11 09:41:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1427, ShuffleMapStage 1426)
2019-06-11 09:41:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:20,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1428 (MapPartitionsRDD[1667] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:20,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_714 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:20,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_714_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:20,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_714_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:20,037  INFO [org.apache.spark.SparkContext] - Created broadcast 714 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:20,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1428 (MapPartitionsRDD[1667] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:20,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1428.0 with 1 tasks
2019-06-11 09:41:20,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1428.0 (TID 952, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:20,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1428.0 (TID 952)
2019-06-11 09:41:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:20,038  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:20,039  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1428.0 (TID 952). 966 bytes result sent to driver
2019-06-11 09:41:20,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1428.0 (TID 952) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:20,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1428.0, whose tasks have all completed, from pool 
2019-06-11 09:41:20,039  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1428 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:41:20,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 476 finished: print at Transform.scala:36, took 0.004569 s
2019-06-11 09:41:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217280000 ms.0 from job set of time 1560217280000 ms
2019-06-11 09:41:20,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217280000 ms (execution: 0.036 s)
2019-06-11 09:41:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1660 from persistence list
2019-06-11 09:41:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1660
2019-06-11 09:41:20,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1655 from persistence list
2019-06-11 09:41:20,040  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1655
2019-06-11 09:41:20,040  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1654 from persistence list
2019-06-11 09:41:20,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1654
2019-06-11 09:41:20,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1654] at socketTextStream at Transform.scala:18 of time 1560217280000 ms
2019-06-11 09:41:20,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217270000 ms
2019-06-11 09:41:20,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217270000 ms
2019-06-11 09:41:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217285000 ms
2019-06-11 09:41:25,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217285000 ms.0 from job set of time 1560217285000 ms
2019-06-11 09:41:25,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1669 (map at Transform.scala:20)
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 477 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1431 (print at Transform.scala:36)
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1429, ShuffleMapStage 1430)
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1430)
2019-06-11 09:41:25,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1430 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:25,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_715 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:25,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_715_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:25,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_715_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:25,011  INFO [org.apache.spark.SparkContext] - Created broadcast 715 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:25,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1430 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:25,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1430.0 with 2 tasks
2019-06-11 09:41:25,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1430.0 (TID 953, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:25,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1430.0 (TID 953)
2019-06-11 09:41:25,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1430.0 (TID 953). 853 bytes result sent to driver
2019-06-11 09:41:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1430.0 (TID 954, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:25,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1430.0 (TID 954)
2019-06-11 09:41:25,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1430.0 (TID 953) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:25,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1430.0 (TID 954). 810 bytes result sent to driver
2019-06-11 09:41:25,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1430.0 (TID 954) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:25,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1430.0, whose tasks have all completed, from pool 
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1430 (parallelize at Transform.scala:16) finished in 0.018 s
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1431)
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:25,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1431 (MapPartitionsRDD[1674] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:25,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_716 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:25,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_716_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:25,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_716_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:25,030  INFO [org.apache.spark.SparkContext] - Created broadcast 716 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:25,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1431 (MapPartitionsRDD[1674] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:25,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1431.0 with 1 tasks
2019-06-11 09:41:25,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1431.0 (TID 955, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:25,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1431.0 (TID 955)
2019-06-11 09:41:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:25,031  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:25,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1431.0 (TID 955). 966 bytes result sent to driver
2019-06-11 09:41:25,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1431.0 (TID 955) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:25,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1431.0, whose tasks have all completed, from pool 
2019-06-11 09:41:25,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1431 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:41:25,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 477 finished: print at Transform.scala:36, took 0.025155 s
2019-06-11 09:41:25,034  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 476 is 83 bytes
2019-06-11 09:41:25,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 477 is 160 bytes
2019-06-11 09:41:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 478 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1434 (print at Transform.scala:36)
2019-06-11 09:41:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1432, ShuffleMapStage 1433)
2019-06-11 09:41:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:25,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1434 (MapPartitionsRDD[1674] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:25,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_717 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:25,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_717_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:25,037  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_717_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:25,037  INFO [org.apache.spark.SparkContext] - Created broadcast 717 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:25,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1434 (MapPartitionsRDD[1674] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:25,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1434.0 with 1 tasks
2019-06-11 09:41:25,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1434.0 (TID 956, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:25,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1434.0 (TID 956)
2019-06-11 09:41:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:25,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:25,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1434.0 (TID 956). 966 bytes result sent to driver
2019-06-11 09:41:25,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1434.0 (TID 956) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:25,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1434.0, whose tasks have all completed, from pool 
2019-06-11 09:41:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1434 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:25,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 478 finished: print at Transform.scala:36, took 0.005652 s
2019-06-11 09:41:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217285000 ms.0 from job set of time 1560217285000 ms
2019-06-11 09:41:25,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217285000 ms (execution: 0.034 s)
2019-06-11 09:41:25,040  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1667 from persistence list
2019-06-11 09:41:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1667
2019-06-11 09:41:25,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1662 from persistence list
2019-06-11 09:41:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1662
2019-06-11 09:41:25,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1661 from persistence list
2019-06-11 09:41:25,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1661
2019-06-11 09:41:25,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1661] at socketTextStream at Transform.scala:18 of time 1560217285000 ms
2019-06-11 09:41:25,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217275000 ms
2019-06-11 09:41:25,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217275000 ms
2019-06-11 09:41:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217290000 ms
2019-06-11 09:41:30,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217290000 ms.0 from job set of time 1560217290000 ms
2019-06-11 09:41:30,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1676 (map at Transform.scala:20)
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 479 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1437 (print at Transform.scala:36)
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1435, ShuffleMapStage 1436)
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1435)
2019-06-11 09:41:30,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1435 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:30,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_718 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:30,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_718_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:41:30,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_718_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:30,011  INFO [org.apache.spark.SparkContext] - Created broadcast 718 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:30,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1435 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:30,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1435.0 with 2 tasks
2019-06-11 09:41:30,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1435.0 (TID 957, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:30,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1435.0 (TID 957)
2019-06-11 09:41:30,020  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1435.0 (TID 957). 810 bytes result sent to driver
2019-06-11 09:41:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1435.0 (TID 958, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:30,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1435.0 (TID 958)
2019-06-11 09:41:30,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1435.0 (TID 957) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:30,048  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1435.0 (TID 958). 853 bytes result sent to driver
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1435.0 (TID 958) in 28 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1435.0, whose tasks have all completed, from pool 
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1435 (parallelize at Transform.scala:16) finished in 0.037 s
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1437)
2019-06-11 09:41:30,048  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:30,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1437 (MapPartitionsRDD[1681] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:30,049  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_719 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:30,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_719_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:30,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_719_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,050  INFO [org.apache.spark.SparkContext] - Created broadcast 719 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:30,050  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1437 (MapPartitionsRDD[1681] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:30,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1437.0 with 1 tasks
2019-06-11 09:41:30,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1437.0 (TID 959, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:30,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1437.0 (TID 959)
2019-06-11 09:41:30,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:30,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:30,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:30,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:30,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1437.0 (TID 959). 966 bytes result sent to driver
2019-06-11 09:41:30,052  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1437.0 (TID 959) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:30,052  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1437.0, whose tasks have all completed, from pool 
2019-06-11 09:41:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1437 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:30,052  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 479 finished: print at Transform.scala:36, took 0.043846 s
2019-06-11 09:41:30,054  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:30,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 479 is 160 bytes
2019-06-11 09:41:30,054  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 478 is 83 bytes
2019-06-11 09:41:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 480 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1440 (print at Transform.scala:36)
2019-06-11 09:41:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1439, ShuffleMapStage 1438)
2019-06-11 09:41:30,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:30,055  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1440 (MapPartitionsRDD[1681] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:30,055  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_720 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:30,061  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 475
2019-06-11 09:41:30,062  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_720_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:30,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 472
2019-06-11 09:41:30,062  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 471
2019-06-11 09:41:30,062  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_720_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,063  INFO [org.apache.spark.SparkContext] - Created broadcast 720 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:30,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_713_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,064  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1440 (MapPartitionsRDD[1681] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:30,064  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1440.0 with 1 tasks
2019-06-11 09:41:30,064  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1440.0 (TID 960, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:30,064  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1440.0 (TID 960)
2019-06-11 09:41:30,064  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_708_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,065  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 470
2019-06-11 09:41:30,065  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:30,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:41:30,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_710_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:30,066  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:30,066  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_718_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:30,067  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1440.0 (TID 960). 1009 bytes result sent to driver
2019-06-11 09:41:30,067  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_709_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:30,067  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1440.0 (TID 960) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:30,067  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1440.0, whose tasks have all completed, from pool 
2019-06-11 09:41:30,068  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1440 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:30,068  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 480 finished: print at Transform.scala:36, took 0.013377 s
2019-06-11 09:41:30,068  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217290000 ms.0 from job set of time 1560217290000 ms
2019-06-11 09:41:30,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1674 from persistence list
2019-06-11 09:41:30,068  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.068 s for time 1560217290000 ms (execution: 0.061 s)
2019-06-11 09:41:30,068  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_719_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1674
2019-06-11 09:41:30,068  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1669 from persistence list
2019-06-11 09:41:30,068  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1669
2019-06-11 09:41:30,068  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1668 from persistence list
2019-06-11 09:41:30,069  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 474
2019-06-11 09:41:30,069  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1668
2019-06-11 09:41:30,069  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1668] at socketTextStream at Transform.scala:18 of time 1560217290000 ms
2019-06-11 09:41:30,069  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 473
2019-06-11 09:41:30,069  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217280000 ms
2019-06-11 09:41:30,069  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 468
2019-06-11 09:41:30,069  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217280000 ms
2019-06-11 09:41:30,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_716_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,070  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_715_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:30,071  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_714_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,072  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 469
2019-06-11 09:41:30,072  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_712_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:30,073  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_717_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:30,074  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_711_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:35,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217295000 ms
2019-06-11 09:41:35,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217295000 ms.0 from job set of time 1560217295000 ms
2019-06-11 09:41:35,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1683 (map at Transform.scala:20)
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 481 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1443 (print at Transform.scala:36)
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1442, ShuffleMapStage 1441)
2019-06-11 09:41:35,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1441)
2019-06-11 09:41:35,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1441 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:35,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_721 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:35,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_721_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:35,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_721_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:35,011  INFO [org.apache.spark.SparkContext] - Created broadcast 721 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:35,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1441 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:35,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1441.0 with 2 tasks
2019-06-11 09:41:35,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1441.0 (TID 961, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:35,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1441.0 (TID 961)
2019-06-11 09:41:35,022  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1441.0 (TID 961). 810 bytes result sent to driver
2019-06-11 09:41:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1441.0 (TID 962, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:35,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1441.0 (TID 962)
2019-06-11 09:41:35,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1441.0 (TID 961) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:35,031  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1441.0 (TID 962). 853 bytes result sent to driver
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1441.0 (TID 962) in 10 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1441.0, whose tasks have all completed, from pool 
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1441 (parallelize at Transform.scala:16) finished in 0.020 s
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1443)
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:35,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1443 (MapPartitionsRDD[1688] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:35,032  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_722 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:35,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_722_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:35,033  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_722_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:35,034  INFO [org.apache.spark.SparkContext] - Created broadcast 722 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:35,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1443 (MapPartitionsRDD[1688] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:35,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1443.0 with 1 tasks
2019-06-11 09:41:35,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1443.0 (TID 963, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:35,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1443.0 (TID 963)
2019-06-11 09:41:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:35,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:35,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1443.0 (TID 963). 1009 bytes result sent to driver
2019-06-11 09:41:35,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1443.0 (TID 963) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:35,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1443.0, whose tasks have all completed, from pool 
2019-06-11 09:41:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1443 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:35,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 481 finished: print at Transform.scala:36, took 0.027285 s
2019-06-11 09:41:35,039  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 481 is 160 bytes
2019-06-11 09:41:35,040  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 480 is 83 bytes
2019-06-11 09:41:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 482 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1446 (print at Transform.scala:36)
2019-06-11 09:41:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1445, ShuffleMapStage 1444)
2019-06-11 09:41:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:35,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1446 (MapPartitionsRDD[1688] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:35,040  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_723 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:35,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_723_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:35,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_723_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:35,042  INFO [org.apache.spark.SparkContext] - Created broadcast 723 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:35,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1446 (MapPartitionsRDD[1688] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:35,042  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1446.0 with 1 tasks
2019-06-11 09:41:35,042  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1446.0 (TID 964, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:35,042  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1446.0 (TID 964)
2019-06-11 09:41:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:35,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:35,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1446.0 (TID 964). 966 bytes result sent to driver
2019-06-11 09:41:35,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1446.0 (TID 964) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:35,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1446.0, whose tasks have all completed, from pool 
2019-06-11 09:41:35,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1446 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:35,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 482 finished: print at Transform.scala:36, took 0.004651 s
2019-06-11 09:41:35,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217295000 ms.0 from job set of time 1560217295000 ms
2019-06-11 09:41:35,044  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.044 s for time 1560217295000 ms (execution: 0.037 s)
2019-06-11 09:41:35,044  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1681 from persistence list
2019-06-11 09:41:35,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1681
2019-06-11 09:41:35,045  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1676 from persistence list
2019-06-11 09:41:35,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1676
2019-06-11 09:41:35,045  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1675 from persistence list
2019-06-11 09:41:35,045  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1675
2019-06-11 09:41:35,045  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1675] at socketTextStream at Transform.scala:18 of time 1560217295000 ms
2019-06-11 09:41:35,045  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217285000 ms
2019-06-11 09:41:35,045  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217285000 ms
2019-06-11 09:41:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217300000 ms
2019-06-11 09:41:40,006  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217300000 ms.0 from job set of time 1560217300000 ms
2019-06-11 09:41:40,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1690 (map at Transform.scala:20)
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 483 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1449 (print at Transform.scala:36)
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1447, ShuffleMapStage 1448)
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1448)
2019-06-11 09:41:40,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1448 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:40,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_724 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:40,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_724_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:40,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_724_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:40,010  INFO [org.apache.spark.SparkContext] - Created broadcast 724 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:40,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1448 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:40,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1448.0 with 2 tasks
2019-06-11 09:41:40,011  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1448.0 (TID 965, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:40,011  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1448.0 (TID 965)
2019-06-11 09:41:40,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1448.0 (TID 965). 810 bytes result sent to driver
2019-06-11 09:41:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1448.0 (TID 966, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:40,020  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1448.0 (TID 966)
2019-06-11 09:41:40,020  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1448.0 (TID 965) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:40,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1448.0 (TID 966). 767 bytes result sent to driver
2019-06-11 09:41:40,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1448.0 (TID 966) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:40,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1448.0, whose tasks have all completed, from pool 
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1448 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1449)
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:40,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1449 (MapPartitionsRDD[1695] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:40,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_725 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:40,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_725_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:40,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_725_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:40,030  INFO [org.apache.spark.SparkContext] - Created broadcast 725 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:40,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1449 (MapPartitionsRDD[1695] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:40,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1449.0 with 1 tasks
2019-06-11 09:41:40,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1449.0 (TID 967, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:40,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1449.0 (TID 967)
2019-06-11 09:41:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:40,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:40,032  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1449.0 (TID 967). 966 bytes result sent to driver
2019-06-11 09:41:40,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1449.0 (TID 967) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:40,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1449.0, whose tasks have all completed, from pool 
2019-06-11 09:41:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1449 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:40,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 483 finished: print at Transform.scala:36, took 0.024836 s
2019-06-11 09:41:40,035  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 482 is 83 bytes
2019-06-11 09:41:40,035  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 483 is 160 bytes
2019-06-11 09:41:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 484 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1452 (print at Transform.scala:36)
2019-06-11 09:41:40,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1450, ShuffleMapStage 1451)
2019-06-11 09:41:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:40,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1452 (MapPartitionsRDD[1695] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:40,036  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_726 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:40,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_726_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:40,038  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_726_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:40,038  INFO [org.apache.spark.SparkContext] - Created broadcast 726 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:40,038  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1452 (MapPartitionsRDD[1695] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:40,038  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1452.0 with 1 tasks
2019-06-11 09:41:40,038  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1452.0 (TID 968, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:40,038  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1452.0 (TID 968)
2019-06-11 09:41:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:40,039  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:40,040  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1452.0 (TID 968). 1009 bytes result sent to driver
2019-06-11 09:41:40,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1452.0 (TID 968) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:40,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1452.0, whose tasks have all completed, from pool 
2019-06-11 09:41:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1452 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:40,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 484 finished: print at Transform.scala:36, took 0.005516 s
2019-06-11 09:41:40,040  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217300000 ms.0 from job set of time 1560217300000 ms
2019-06-11 09:41:40,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.040 s for time 1560217300000 ms (execution: 0.034 s)
2019-06-11 09:41:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1688 from persistence list
2019-06-11 09:41:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1688
2019-06-11 09:41:40,041  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1683 from persistence list
2019-06-11 09:41:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1683
2019-06-11 09:41:40,041  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1682 from persistence list
2019-06-11 09:41:40,041  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1682
2019-06-11 09:41:40,041  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1682] at socketTextStream at Transform.scala:18 of time 1560217300000 ms
2019-06-11 09:41:40,041  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217290000 ms
2019-06-11 09:41:40,041  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217290000 ms
2019-06-11 09:41:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217305000 ms
2019-06-11 09:41:45,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217305000 ms.0 from job set of time 1560217305000 ms
2019-06-11 09:41:45,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1697 (map at Transform.scala:20)
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 485 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1455 (print at Transform.scala:36)
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1453, ShuffleMapStage 1454)
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1454)
2019-06-11 09:41:45,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1454 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:45,010  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_727 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:45,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_727_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:45,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_727_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:45,012  INFO [org.apache.spark.SparkContext] - Created broadcast 727 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:45,012  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1454 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:45,012  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1454.0 with 2 tasks
2019-06-11 09:41:45,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1454.0 (TID 969, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:45,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1454.0 (TID 969)
2019-06-11 09:41:45,028  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1454.0 (TID 969). 853 bytes result sent to driver
2019-06-11 09:41:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1454.0 (TID 970, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:45,029  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1454.0 (TID 970)
2019-06-11 09:41:45,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1454.0 (TID 969) in 17 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:45,040  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1454.0 (TID 970). 853 bytes result sent to driver
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1454.0 (TID 970) in 11 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1454.0, whose tasks have all completed, from pool 
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1454 (parallelize at Transform.scala:16) finished in 0.028 s
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1455)
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:45,040  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1455 (MapPartitionsRDD[1702] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:45,041  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_728 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:45,042  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_728_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:45,042  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_728_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:45,042  INFO [org.apache.spark.SparkContext] - Created broadcast 728 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:45,043  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1455 (MapPartitionsRDD[1702] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:45,043  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1455.0 with 1 tasks
2019-06-11 09:41:45,043  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1455.0 (TID 971, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:45,043  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1455.0 (TID 971)
2019-06-11 09:41:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:45,043  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:45,044  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1455.0 (TID 971). 966 bytes result sent to driver
2019-06-11 09:41:45,044  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1455.0 (TID 971) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:45,044  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1455.0, whose tasks have all completed, from pool 
2019-06-11 09:41:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1455 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:41:45,044  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 485 finished: print at Transform.scala:36, took 0.035635 s
2019-06-11 09:41:45,048  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:45,048  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 484 is 83 bytes
2019-06-11 09:41:45,049  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 485 is 160 bytes
2019-06-11 09:41:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 486 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1458 (print at Transform.scala:36)
2019-06-11 09:41:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1457, ShuffleMapStage 1456)
2019-06-11 09:41:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:45,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1458 (MapPartitionsRDD[1702] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:45,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_729 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:45,050  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_729_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:45,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_729_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:45,051  INFO [org.apache.spark.SparkContext] - Created broadcast 729 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:45,051  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1458 (MapPartitionsRDD[1702] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:45,051  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1458.0 with 1 tasks
2019-06-11 09:41:45,051  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1458.0 (TID 972, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:45,051  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1458.0 (TID 972)
2019-06-11 09:41:45,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:45,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:45,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:45,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:45,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1458.0 (TID 972). 1009 bytes result sent to driver
2019-06-11 09:41:45,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1458.0 (TID 972) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:45,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1458.0, whose tasks have all completed, from pool 
2019-06-11 09:41:45,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1458 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:45,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 486 finished: print at Transform.scala:36, took 0.005484 s
2019-06-11 09:41:45,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217305000 ms.0 from job set of time 1560217305000 ms
2019-06-11 09:41:45,054  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.054 s for time 1560217305000 ms (execution: 0.047 s)
2019-06-11 09:41:45,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1695 from persistence list
2019-06-11 09:41:45,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1695
2019-06-11 09:41:45,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1690 from persistence list
2019-06-11 09:41:45,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1690
2019-06-11 09:41:45,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1689 from persistence list
2019-06-11 09:41:45,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1689
2019-06-11 09:41:45,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1689] at socketTextStream at Transform.scala:18 of time 1560217305000 ms
2019-06-11 09:41:45,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217295000 ms
2019-06-11 09:41:45,055  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217295000 ms
2019-06-11 09:41:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217310000 ms
2019-06-11 09:41:50,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217310000 ms.0 from job set of time 1560217310000 ms
2019-06-11 09:41:50,008  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1704 (map at Transform.scala:20)
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 487 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1461 (print at Transform.scala:36)
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1460, ShuffleMapStage 1459)
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1460)
2019-06-11 09:41:50,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1460 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:50,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_730 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:50,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_730_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:41:50,010  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_730_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:50,010  INFO [org.apache.spark.SparkContext] - Created broadcast 730 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:50,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1460 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:50,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1460.0 with 2 tasks
2019-06-11 09:41:50,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1460.0 (TID 973, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:50,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1460.0 (TID 973)
2019-06-11 09:41:50,024  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1460.0 (TID 973). 810 bytes result sent to driver
2019-06-11 09:41:50,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1460.0 (TID 974, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:50,024  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1460.0 (TID 974)
2019-06-11 09:41:50,024  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1460.0 (TID 973) in 14 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:50,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1460.0 (TID 974). 853 bytes result sent to driver
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1460.0 (TID 974) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1460.0, whose tasks have all completed, from pool 
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1460 (parallelize at Transform.scala:16) finished in 0.022 s
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1461)
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:50,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1461 (MapPartitionsRDD[1709] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:50,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_731 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:41:50,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_731_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:41:50,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_731_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,034  INFO [org.apache.spark.SparkContext] - Created broadcast 731 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:50,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1461 (MapPartitionsRDD[1709] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:50,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1461.0 with 1 tasks
2019-06-11 09:41:50,034  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1461.0 (TID 975, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:50,034  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1461.0 (TID 975)
2019-06-11 09:41:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:50,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:50,035  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1461.0 (TID 975). 966 bytes result sent to driver
2019-06-11 09:41:50,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1461.0 (TID 975) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:50,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1461.0, whose tasks have all completed, from pool 
2019-06-11 09:41:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1461 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:50,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 487 finished: print at Transform.scala:36, took 0.028167 s
2019-06-11 09:41:50,041  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_724_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:50,042  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 479
2019-06-11 09:41:50,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_727_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:50,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 481
2019-06-11 09:41:50,044  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_731_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:50,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_726_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,046  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 476
2019-06-11 09:41:50,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 486 is 83 bytes
2019-06-11 09:41:50,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 487 is 160 bytes
2019-06-11 09:41:50,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_721_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 488 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1464 (print at Transform.scala:36)
2019-06-11 09:41:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1462, ShuffleMapStage 1463)
2019-06-11 09:41:50,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:50,047  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1464 (MapPartitionsRDD[1709] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:50,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_732 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:50,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_728_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_723_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_732_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:50,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_732_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,049  INFO [org.apache.spark.SparkContext] - Created broadcast 732 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:50,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_725_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1464 (MapPartitionsRDD[1709] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:50,049  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1464.0 with 1 tasks
2019-06-11 09:41:50,049  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1464.0 (TID 976, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:50,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 483
2019-06-11 09:41:50,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1464.0 (TID 976)
2019-06-11 09:41:50,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 482
2019-06-11 09:41:50,051  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_729_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:50,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 477
2019-06-11 09:41:50,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 1 ms
2019-06-11 09:41:50,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:50,052  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:50,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_730_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:50,053  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1464.0 (TID 976). 1009 bytes result sent to driver
2019-06-11 09:41:50,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1464.0 (TID 976) in 4 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:50,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_720_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1464.0, whose tasks have all completed, from pool 
2019-06-11 09:41:50,054  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1464 (print at Transform.scala:36) finished in 0.005 s
2019-06-11 09:41:50,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 478
2019-06-11 09:41:50,054  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 488 finished: print at Transform.scala:36, took 0.008751 s
2019-06-11 09:41:50,054  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 480
2019-06-11 09:41:50,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217310000 ms.0 from job set of time 1560217310000 ms
2019-06-11 09:41:50,055  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.055 s for time 1560217310000 ms (execution: 0.050 s)
2019-06-11 09:41:50,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1702 from persistence list
2019-06-11 09:41:50,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1702
2019-06-11 09:41:50,055  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1697 from persistence list
2019-06-11 09:41:50,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1697
2019-06-11 09:41:50,055  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1696 from persistence list
2019-06-11 09:41:50,055  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_722_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:50,055  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1696
2019-06-11 09:41:50,055  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1696] at socketTextStream at Transform.scala:18 of time 1560217310000 ms
2019-06-11 09:41:50,056  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217300000 ms
2019-06-11 09:41:50,056  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217300000 ms
2019-06-11 09:41:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217315000 ms
2019-06-11 09:41:55,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217315000 ms.0 from job set of time 1560217315000 ms
2019-06-11 09:41:55,007  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1711 (map at Transform.scala:20)
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 489 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1467 (print at Transform.scala:36)
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1465, ShuffleMapStage 1466)
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1465)
2019-06-11 09:41:55,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1465 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:41:55,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_733 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:55,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_733_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:41:55,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_733_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:41:55,009  INFO [org.apache.spark.SparkContext] - Created broadcast 733 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:55,010  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1465 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:41:55,010  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1465.0 with 2 tasks
2019-06-11 09:41:55,010  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1465.0 (TID 977, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:55,010  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1465.0 (TID 977)
2019-06-11 09:41:55,019  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1465.0 (TID 977). 810 bytes result sent to driver
2019-06-11 09:41:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1465.0 (TID 978, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:41:55,019  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1465.0 (TID 978)
2019-06-11 09:41:55,019  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1465.0 (TID 977) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:41:55,028  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1465.0 (TID 978). 810 bytes result sent to driver
2019-06-11 09:41:55,028  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1465.0 (TID 978) in 9 ms on localhost (executor driver) (2/2)
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1465.0, whose tasks have all completed, from pool 
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1465 (parallelize at Transform.scala:16) finished in 0.019 s
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1467)
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:41:55,029  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1467 (MapPartitionsRDD[1716] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:55,029  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_734 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:55,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_734_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:55,030  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_734_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:55,030  INFO [org.apache.spark.SparkContext] - Created broadcast 734 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:55,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1467 (MapPartitionsRDD[1716] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:41:55,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1467.0 with 1 tasks
2019-06-11 09:41:55,031  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1467.0 (TID 979, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:55,031  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1467.0 (TID 979)
2019-06-11 09:41:55,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:55,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:55,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:55,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:55,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1467.0 (TID 979). 1009 bytes result sent to driver
2019-06-11 09:41:55,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1467.0 (TID 979) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:55,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1467.0, whose tasks have all completed, from pool 
2019-06-11 09:41:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1467 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:41:55,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 489 finished: print at Transform.scala:36, took 0.026390 s
2019-06-11 09:41:55,036  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:41:55,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 489 is 160 bytes
2019-06-11 09:41:55,036  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 488 is 83 bytes
2019-06-11 09:41:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 490 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:41:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1470 (print at Transform.scala:36)
2019-06-11 09:41:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1468, ShuffleMapStage 1469)
2019-06-11 09:41:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:41:55,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1470 (MapPartitionsRDD[1716] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:41:55,037  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_735 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:41:55,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_735_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:41:55,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_735_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:41:55,039  INFO [org.apache.spark.SparkContext] - Created broadcast 735 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:41:55,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1470 (MapPartitionsRDD[1716] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:41:55,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1470.0 with 1 tasks
2019-06-11 09:41:55,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1470.0 (TID 980, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:41:55,039  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1470.0 (TID 980)
2019-06-11 09:41:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:41:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:41:55,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:41:55,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1470.0 (TID 980). 1009 bytes result sent to driver
2019-06-11 09:41:55,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1470.0 (TID 980) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:41:55,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1470.0, whose tasks have all completed, from pool 
2019-06-11 09:41:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1470 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:41:55,041  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 490 finished: print at Transform.scala:36, took 0.005477 s
2019-06-11 09:41:55,041  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217315000 ms.0 from job set of time 1560217315000 ms
2019-06-11 09:41:55,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.041 s for time 1560217315000 ms (execution: 0.036 s)
2019-06-11 09:41:55,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1709 from persistence list
2019-06-11 09:41:55,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1709
2019-06-11 09:41:55,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1704 from persistence list
2019-06-11 09:41:55,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1704
2019-06-11 09:41:55,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1703 from persistence list
2019-06-11 09:41:55,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1703
2019-06-11 09:41:55,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1703] at socketTextStream at Transform.scala:18 of time 1560217315000 ms
2019-06-11 09:41:55,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217305000 ms
2019-06-11 09:41:55,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217305000 ms
2019-06-11 09:42:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217320000 ms
2019-06-11 09:42:00,007  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217320000 ms.0 from job set of time 1560217320000 ms
2019-06-11 09:42:00,009  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1718 (map at Transform.scala:20)
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 491 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1473 (print at Transform.scala:36)
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1471, ShuffleMapStage 1472)
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1472)
2019-06-11 09:42:00,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1472 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:00,009  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_736 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:00,011  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_736_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:00,011  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_736_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:00,011  INFO [org.apache.spark.SparkContext] - Created broadcast 736 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:00,011  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1472 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:00,011  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1472.0 with 2 tasks
2019-06-11 09:42:00,012  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1472.0 (TID 981, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:00,012  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1472.0 (TID 981)
2019-06-11 09:42:00,021  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1472.0 (TID 981). 853 bytes result sent to driver
2019-06-11 09:42:00,021  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1472.0 (TID 982, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:00,022  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1472.0 (TID 982)
2019-06-11 09:42:00,022  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1472.0 (TID 981) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:00,029  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1472.0 (TID 982). 767 bytes result sent to driver
2019-06-11 09:42:00,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1472.0 (TID 982) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:00,029  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1472.0, whose tasks have all completed, from pool 
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1472 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1473)
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:00,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1473 (MapPartitionsRDD[1723] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:00,030  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_737 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:00,031  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_737_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:00,031  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_737_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:00,031  INFO [org.apache.spark.SparkContext] - Created broadcast 737 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:00,032  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1473 (MapPartitionsRDD[1723] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:00,032  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1473.0 with 1 tasks
2019-06-11 09:42:00,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1473.0 (TID 983, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:00,032  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1473.0 (TID 983)
2019-06-11 09:42:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:00,032  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:00,033  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1473.0 (TID 983). 966 bytes result sent to driver
2019-06-11 09:42:00,033  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1473.0 (TID 983) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:00,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1473.0, whose tasks have all completed, from pool 
2019-06-11 09:42:00,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1473 (print at Transform.scala:36) finished in 0.001 s
2019-06-11 09:42:00,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 491 finished: print at Transform.scala:36, took 0.024685 s
2019-06-11 09:42:00,037  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 490 is 83 bytes
2019-06-11 09:42:00,037  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 491 is 160 bytes
2019-06-11 09:42:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 492 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1476 (print at Transform.scala:36)
2019-06-11 09:42:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1475, ShuffleMapStage 1474)
2019-06-11 09:42:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:00,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1476 (MapPartitionsRDD[1723] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:00,038  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_738 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:00,039  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_738_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:00,039  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_738_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:00,039  INFO [org.apache.spark.SparkContext] - Created broadcast 738 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:00,039  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1476 (MapPartitionsRDD[1723] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:00,039  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1476.0 with 1 tasks
2019-06-11 09:42:00,039  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1476.0 (TID 984, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:00,040  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1476.0 (TID 984)
2019-06-11 09:42:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:00,040  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:00,041  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1476.0 (TID 984). 966 bytes result sent to driver
2019-06-11 09:42:00,041  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1476.0 (TID 984) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:00,041  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1476.0, whose tasks have all completed, from pool 
2019-06-11 09:42:00,041  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1476 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:00,042  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 492 finished: print at Transform.scala:36, took 0.004601 s
2019-06-11 09:42:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217320000 ms.0 from job set of time 1560217320000 ms
2019-06-11 09:42:00,042  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.042 s for time 1560217320000 ms (execution: 0.035 s)
2019-06-11 09:42:00,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1716 from persistence list
2019-06-11 09:42:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1716
2019-06-11 09:42:00,042  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1711 from persistence list
2019-06-11 09:42:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1711
2019-06-11 09:42:00,042  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1710 from persistence list
2019-06-11 09:42:00,042  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1710
2019-06-11 09:42:00,042  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1710] at socketTextStream at Transform.scala:18 of time 1560217320000 ms
2019-06-11 09:42:00,043  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217310000 ms
2019-06-11 09:42:00,043  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217310000 ms
2019-06-11 09:42:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217325000 ms
2019-06-11 09:42:05,005  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217325000 ms.0 from job set of time 1560217325000 ms
2019-06-11 09:42:05,006  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1725 (map at Transform.scala:20)
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 493 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1479 (print at Transform.scala:36)
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1478, ShuffleMapStage 1477)
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1477)
2019-06-11 09:42:05,007  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1477 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_739 stored as values in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:05,008  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_739_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.4 MB)
2019-06-11 09:42:05,009  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_739_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:05,009  INFO [org.apache.spark.SparkContext] - Created broadcast 739 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:05,009  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1477 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:05,009  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1477.0 with 2 tasks
2019-06-11 09:42:05,009  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1477.0 (TID 985, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:05,009  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1477.0 (TID 985)
2019-06-11 09:42:05,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1477.0 (TID 985). 853 bytes result sent to driver
2019-06-11 09:42:05,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1477.0 (TID 986, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:05,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1477.0 (TID 986)
2019-06-11 09:42:05,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1477.0 (TID 985) in 9 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:05,026  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1477.0 (TID 986). 810 bytes result sent to driver
2019-06-11 09:42:05,026  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1477.0 (TID 986) in 8 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:05,026  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1477.0, whose tasks have all completed, from pool 
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1477 (parallelize at Transform.scala:16) finished in 0.017 s
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1479)
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:05,027  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1479 (MapPartitionsRDD[1730] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:05,027  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_740 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:05,028  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_740_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:05,028  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_740_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:05,028  INFO [org.apache.spark.SparkContext] - Created broadcast 740 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:05,028  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1479 (MapPartitionsRDD[1730] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:05,028  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1479.0 with 1 tasks
2019-06-11 09:42:05,029  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1479.0 (TID 987, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:05,029  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1479.0 (TID 987)
2019-06-11 09:42:05,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:05,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:05,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:05,029  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:05,030  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1479.0 (TID 987). 966 bytes result sent to driver
2019-06-11 09:42:05,030  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1479.0 (TID 987) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:05,030  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1479.0, whose tasks have all completed, from pool 
2019-06-11 09:42:05,030  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1479 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:05,030  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 493 finished: print at Transform.scala:36, took 0.023504 s
2019-06-11 09:42:05,032  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:05,032  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 493 is 160 bytes
2019-06-11 09:42:05,032  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 492 is 83 bytes
2019-06-11 09:42:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 494 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1482 (print at Transform.scala:36)
2019-06-11 09:42:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1480, ShuffleMapStage 1481)
2019-06-11 09:42:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:05,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1482 (MapPartitionsRDD[1730] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:05,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_741 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:05,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_741_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:05,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_741_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:05,034  INFO [org.apache.spark.SparkContext] - Created broadcast 741 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:05,034  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1482 (MapPartitionsRDD[1730] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:05,034  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1482.0 with 1 tasks
2019-06-11 09:42:05,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1482.0 (TID 988, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:05,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1482.0 (TID 988)
2019-06-11 09:42:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:05,035  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:05,036  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1482.0 (TID 988). 966 bytes result sent to driver
2019-06-11 09:42:05,036  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1482.0 (TID 988) in 1 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:05,036  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1482.0, whose tasks have all completed, from pool 
2019-06-11 09:42:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1482 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:05,036  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 494 finished: print at Transform.scala:36, took 0.004282 s
2019-06-11 09:42:05,037  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217325000 ms.0 from job set of time 1560217325000 ms
2019-06-11 09:42:05,037  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.037 s for time 1560217325000 ms (execution: 0.032 s)
2019-06-11 09:42:05,037  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1723 from persistence list
2019-06-11 09:42:05,037  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1723
2019-06-11 09:42:05,037  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1718 from persistence list
2019-06-11 09:42:05,037  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1718
2019-06-11 09:42:05,037  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1717 from persistence list
2019-06-11 09:42:05,038  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1717
2019-06-11 09:42:05,038  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1717] at socketTextStream at Transform.scala:18 of time 1560217325000 ms
2019-06-11 09:42:05,038  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217315000 ms
2019-06-11 09:42:05,038  INFO [org.apache.spark.streaming.scheduler.InputInfoTracker] - remove old batch metadata: 1560217315000 ms
2019-06-11 09:42:10,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Added jobs for time 1560217330000 ms
2019-06-11 09:42:10,004  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Starting job streaming job 1560217330000 ms.0 from job set of time 1560217330000 ms
2019-06-11 09:42:10,005  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 0 (parallelize at Transform.scala:16)
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Registering RDD 1732 (map at Transform.scala:20)
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 495 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1485 (print at Transform.scala:36)
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1483, ShuffleMapStage 1484)
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List(ShuffleMapStage 1483)
2019-06-11 09:42:10,006  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ShuffleMapStage 1483 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16), which has no missing parents
2019-06-11 09:42:10,006  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_742 stored as values in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:10,007  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_742_piece0 stored as bytes in memory (estimated size 1311.0 B, free 1989.3 MB)
2019-06-11 09:42:10,007  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_742_piece0 in memory on 192.168.91.1:63518 (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:10,007  INFO [org.apache.spark.SparkContext] - Created broadcast 742 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:10,008  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 2 missing tasks from ShuffleMapStage 1483 (ParallelCollectionRDD[0] at parallelize at Transform.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-06-11 09:42:10,008  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1483.0 with 2 tasks
2019-06-11 09:42:10,008  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1483.0 (TID 989, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:10,008  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1483.0 (TID 989)
2019-06-11 09:42:10,018  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1483.0 (TID 989). 853 bytes result sent to driver
2019-06-11 09:42:10,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 1.0 in stage 1483.0 (TID 990, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2019-06-11 09:42:10,018  INFO [org.apache.spark.executor.Executor] - Running task 1.0 in stage 1483.0 (TID 990)
2019-06-11 09:42:10,018  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1483.0 (TID 989) in 10 ms on localhost (executor driver) (1/2)
2019-06-11 09:42:10,032  INFO [org.apache.spark.executor.Executor] - Finished task 1.0 in stage 1483.0 (TID 990). 810 bytes result sent to driver
2019-06-11 09:42:10,032  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 1.0 in stage 1483.0 (TID 990) in 14 ms on localhost (executor driver) (2/2)
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1483.0, whose tasks have all completed, from pool 
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - ShuffleMapStage 1483 (parallelize at Transform.scala:16) finished in 0.025 s
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - looking for newly runnable stages
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - running: Set(ResultStage 0)
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - waiting: Set(ResultStage 1485)
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - failed: Set()
2019-06-11 09:42:10,033  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1485 (MapPartitionsRDD[1737] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:10,033  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_743 stored as values in memory (estimated size 3.7 KB, free 1989.3 MB)
2019-06-11 09:42:10,034  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_743_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.3 MB)
2019-06-11 09:42:10,034  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_743_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,035  INFO [org.apache.spark.SparkContext] - Created broadcast 743 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:10,035  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1485 (MapPartitionsRDD[1737] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(0))
2019-06-11 09:42:10,035  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1485.0 with 1 tasks
2019-06-11 09:42:10,035  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1485.0 (TID 991, localhost, executor driver, partition 0, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:10,035  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1485.0 (TID 991)
2019-06-11 09:42:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:10,036  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:10,037  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1485.0 (TID 991). 1009 bytes result sent to driver
2019-06-11 09:42:10,037  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1485.0 (TID 991) in 2 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:10,037  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1485.0, whose tasks have all completed, from pool 
2019-06-11 09:42:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1485 (print at Transform.scala:36) finished in 0.002 s
2019-06-11 09:42:10,037  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 495 finished: print at Transform.scala:36, took 0.031643 s
2019-06-11 09:42:10,043  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_734_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 491
2019-06-11 09:42:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 484
2019-06-11 09:42:10,044  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 487
2019-06-11 09:42:10,045  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_736_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:10,045  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 486
2019-06-11 09:42:10,045  INFO [org.apache.spark.SparkContext] - Starting job: print at Transform.scala:36
2019-06-11 09:42:10,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_732_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 495 is 160 bytes
2019-06-11 09:42:10,046  INFO [org.apache.spark.MapOutputTrackerMaster] - Size of output statuses for shuffle 494 is 83 bytes
2019-06-11 09:42:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Got job 496 (print at Transform.scala:36) with 1 output partitions
2019-06-11 09:42:10,046  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_742_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Final stage: ResultStage 1488 (print at Transform.scala:36)
2019-06-11 09:42:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Parents of final stage: List(ShuffleMapStage 1486, ShuffleMapStage 1487)
2019-06-11 09:42:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Missing parents: List()
2019-06-11 09:42:10,046  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting ResultStage 1488 (MapPartitionsRDD[1737] at map at Transform.scala:32), which has no missing parents
2019-06-11 09:42:10,047  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_737_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,047  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_744 stored as values in memory (estimated size 3.7 KB, free 1989.4 MB)
2019-06-11 09:42:10,048  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_733_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:10,048  INFO [org.apache.spark.storage.memory.MemoryStore] - Block broadcast_744_piece0 stored as bytes in memory (estimated size 2.0 KB, free 1989.4 MB)
2019-06-11 09:42:10,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Added broadcast_744_piece0 in memory on 192.168.91.1:63518 (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,049  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_740_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,049  INFO [org.apache.spark.SparkContext] - Created broadcast 744 from broadcast at DAGScheduler.scala:1006
2019-06-11 09:42:10,049  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 488
2019-06-11 09:42:10,049  INFO [org.apache.spark.scheduler.DAGScheduler] - Submitting 1 missing tasks from ResultStage 1488 (MapPartitionsRDD[1737] at map at Transform.scala:32) (first 15 tasks are for partitions Vector(1))
2019-06-11 09:42:10,050  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Adding task set 1488.0 with 1 tasks
2019-06-11 09:42:10,050  INFO [org.apache.spark.scheduler.TaskSetManager] - Starting task 0.0 in stage 1488.0 (TID 992, localhost, executor driver, partition 1, PROCESS_LOCAL, 4684 bytes)
2019-06-11 09:42:10,050  INFO [org.apache.spark.executor.Executor] - Running task 0.0 in stage 1488.0 (TID 992)
2019-06-11 09:42:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_735_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,050  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 485
2019-06-11 09:42:10,050  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_739_piece0 on 192.168.91.1:63518 in memory (size: 1311.0 B, free: 1989.5 MB)
2019-06-11 09:42:10,051  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 489
2019-06-11 09:42:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 0 non-empty blocks out of 0 blocks
2019-06-11 09:42:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Getting 1 non-empty blocks out of 2 blocks
2019-06-11 09:42:10,051  INFO [org.apache.spark.storage.ShuffleBlockFetcherIterator] - Started 0 remote fetches in 0 ms
2019-06-11 09:42:10,052  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_741_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,052  INFO [org.apache.spark.executor.Executor] - Finished task 0.0 in stage 1488.0 (TID 992). 1009 bytes result sent to driver
2019-06-11 09:42:10,053  INFO [org.apache.spark.scheduler.TaskSetManager] - Finished task 0.0 in stage 1488.0 (TID 992) in 3 ms on localhost (executor driver) (1/1)
2019-06-11 09:42:10,053  INFO [org.apache.spark.scheduler.TaskSchedulerImpl] - Removed TaskSet 1488.0, whose tasks have all completed, from pool 
2019-06-11 09:42:10,053  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_738_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - ResultStage 1488 (print at Transform.scala:36) finished in 0.003 s
2019-06-11 09:42:10,053  INFO [org.apache.spark.scheduler.DAGScheduler] - Job 496 finished: print at Transform.scala:36, took 0.007306 s
2019-06-11 09:42:10,053  INFO [org.apache.spark.ContextCleaner] - Cleaned shuffle 490
2019-06-11 09:42:10,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Finished job streaming job 1560217330000 ms.0 from job set of time 1560217330000 ms
2019-06-11 09:42:10,053  INFO [org.apache.spark.streaming.scheduler.JobScheduler] - Total delay: 0.053 s for time 1560217330000 ms (execution: 0.049 s)
2019-06-11 09:42:10,053  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1730 from persistence list
2019-06-11 09:42:10,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1730
2019-06-11 09:42:10,054  INFO [org.apache.spark.rdd.MapPartitionsRDD] - Removing RDD 1725 from persistence list
2019-06-11 09:42:10,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1725
2019-06-11 09:42:10,054  INFO [org.apache.spark.rdd.BlockRDD] - Removing RDD 1724 from persistence list
2019-06-11 09:42:10,054  INFO [org.apache.spark.storage.BlockManager] - Removing RDD 1724
2019-06-11 09:42:10,054  INFO [org.apache.spark.streaming.dstream.SocketInputDStream] - Removing blocks of RDD BlockRDD[1724] at socketTextStream at Transform.scala:18 of time 1560217330000 ms
2019-06-11 09:42:10,054  INFO [org.apache.spark.storage.BlockManagerInfo] - Removed broadcast_743_piece0 on 192.168.91.1:63518 in memory (size: 2.0 KB, free: 1989.5 MB)
2019-06-11 09:42:10,054  INFO [org.apache.spark.streaming.scheduler.ReceivedBlockTracker] - Deleting batches: 1560217320000 ms
